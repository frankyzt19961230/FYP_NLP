LINEAR
SYSTEMS
P a n o s   J .   A n t s a k l i s
A n t h o n y   N .   M i c h e l
Birkhäuser
Panos J. Antsaklis 
Anthony N. Michel 
Linear Systems 
Birkhauser 
Boston • Basel • Berlin 
Panos J. Antsaklis 
Dept. of Electrical  Engineering 
University  of Notre Dame 
275 Fitzpatrick  Hall 
Notre Dame, IN 46556 
USA 
Anthony  N. Michel 
Dept. of Electrical  Engineering 
University  of Notre  Dame 
275 Fitzpatrick  Hall 
Notre Dame, IN  46556 
USA 
Cover design by Mary Burgess. 
AMS  Subject  Classification:  34A30,  34H05,  47N70,  65F05,  93-XX,  93-01,  93Axx,  93A30,  93Bxx, 93B03, 
93B05, 93B07, 93B10, 93B11, 93B12, 93B15, 93B17, 93B18, 93B20, 93B25, 93B50, 93B52, 93B55, 93B60, 
93Cxx, 93C05, 93C10, 93C15, 93C35, 93C55, 93C57, 93C62, 93Dxx, 93D05, 93D10, 93D15, 93D20, 93D25, 
93D30 
Library of Congress Cataloging-in-Publication Data 
Antsaklis, Panos J. 
Linear systems / Panos J. Antsaklis, Anthony N. Michel. 
p. cm. 
Originally published : New York : McGraw-Hill, ©1997. 
Includes bibliographical references and index. 
ISBN 0-8176-4334-2 (alk. paper) -  ISBN 0-8176-4435-0 (e-ISBN) 1. Linear control 
systems. 2. Control theory. 3. Signal processing. I. Michel, Anthony N. II. Title. 
TJ220.A58 2005 
629.8^32-dc22 
2005053096 
ISBN-10 0-8176-4434-2 
ISBN-13 978-0-8176-4434-5 
elSBN 0-8176-4435-0 
Printed on acid-free paper. 
©2006 Birkhauser Boston, 2nd Corrected Printing 
Originally published by McGraw-Hill, Englewood Cliffs, NJ,1997. 
BirkhdUSer 
All rights reserved. This work may not be translated or copied in whole or in part without the written permission 
of the publisher (Birkhauser Boston, c/o Springer Sciences-Business  Media Inc., 233 Spring Street, New York, 
NY 10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in connection 
with  any form  of  information  storage  and retrieval, electronic  adaptation,  computer  software,  or by  similar or 
dissimilar methodology now known or hereafter developed is forbidden. 
The use in this publication  of  trade names, trademarks,  service  marks  and  similar  terms, even  if  they  are not 
identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary 
rights. 
Printed in the United States of America. 
(KeS/IBT) 
9 8 7 6 5 4 3 21 
www. birkhauser.com 
To Our  Families 
To 
Melinda and our daughter Lily 
and to my parents 
Dr  loannis and Marina Antsaklis 
—Panos J. Antsaklis 
To 
Leone and our children 
Mary, Kathy, John, 
Tony,  and Pat 
—Anthony N. Michel 
Mechanics  is the paradise  of  the  mathematical 
sciences  because  by  means  of  it  one  comes  to 
the fruits  of mathematics. 
LEONARDO  DA  VINCI 
1452-1519 
C O N T E N TS 
Preface 
Mathematical Descriptions of Systems 
1.1 
Introduction 
A.  Physical  Processes,  Models,  and  Mathematical 
Descriptions,  2/B.  Classification  of Systems,  3 / 
C. Finite-Dimensional  Systems,  4/D.  Chapter  Description,  6/ 
E.  Guidelines for  the Reader,  7 
1.2 
1.3 
Preliminaries 
A.  Notation,  8/B.  Continuous  Functions,  9 
Initial-Value  Problems 
A. Systems  of First-Order  Ordinary  Differential 
Equations,  10/B.  Classification  of Systems  of  First-Order 
Ordinary  Differential  Equations,  11 /  C.  nth-Order  Ordinary 
Differential  Equations,  12 
1.4 
Examples  of  Initial-Value  Problems 
*1.5  More  Mathematical  Preliminaries 
A. Sequences,  17 /B.  Sequences  of Functions,  18/C  The 
Weierstrass M-Test,  21 
*1.6 
Existence  of  Solutions  of  Initial-Value  Problems 
A. The Ascoli-Arzela  Lemma,  22 /B.  e-Approximate 
Solutions,  23 /  C.  The  Cauchy-Peano  Existence  Theorem,  25 
*1.7  Continuation  of  Solutions 
A. Zom's  Lemma,  26/B.  Continuable  Solutions,  27/ 
C  Continuation  of Solutions  to the Boundary  ofD,  28 
*1.8  Uniqueness  of  Solutions 
A. The Gronwall  Inequality,  29 /B.  Unique  Solutions,  30 
*1.9  Continuous  Dependence  of  Solutions  on  Initial 
Conditions  and  Parameters 
1.10 
Systems  of  First-Order  Ordinary  Differential  Equations 
A. More  Mathematical  Preliminaries:  Vector Spaces,  37/ 
B.  Further  Mathematical  Preliminaries:  Normed  Linear 
Spaces,  41 /  C. Additional  Mathematical  Preliminaries: 
Convergence,  44 /D.  Solutions  of Systems  of  First-Order 
Ordinary  Differential  Equations:  Existence,  Continuation, 
Uniqueness,  and  Continuous  Dependence  on  Initial 
Conditions,  45 
XV 
1 
2 
8 
10 
13 
17 
21 
26 
29 
33 
37 
^ 
Contents 
47 
54 
55 
58 
60 
65 
79 
80 
80 
81 
94 
94 
96 
1.11 
Systems  of Linear  First-Order  Ordinary  Differential 
Equations 
A. Linearization,  48 /B.  Examples,  52 
1.12  Linear  Systems:  Existence,  Uniqueness, 
Continuation,  and Continuity  witli Respect to  Parameters 
of  Solutions 
1.13 
1.14 
1.15 
1.16 
Solutions  of Linear  State  Equations 
State-Space  Description  of  Continuous-Time 
Systems 
State-Space  Description  of Discrete-Time  Systems 
Input-Output  Description  of Systems 
A. External  Description  of Systems:  General 
Considerations,  65 /B.  Linear  Discrete-Time  Systems,  68/ 
C. The Dirac  Delta  Distribution,  72 /D.  Linear 
Continuous-Time  Systems,  76 
1.17 
Summary 
1.18  Notes 
1.19  References 
1.20  Exercises 
2  Response of Linear  Systems 
2.1 
1,1 
Introduction 
A. Chapter  Description,  94/B.  Guidelines for  the Reader, 96 
Background  Material 
A. Linear  Sub spaces,  97 /B.  Linear  Independence,  97 / 
C. Bases,  99/D.  Linear  Transformations,  100/ 
E. Representation  of Linear  Transformations  by 
Matrices,"  104/  ""^F.  Some  Properties  of Matrices",  107/ 
*G. Determinants  of Matrices,  111 /H.  Solving  Linear 
Algebraic  Equations,  115/1.  Equivalence  and 
Similarity,  116/J.  Eigenvalues  and Eigenvectors,  121 / 
K. Direct  Sums  of Linear  Subspaces,  126/L.  Some 
Canonical  Forms of Matrices,  127/M.  Minimal 
Polynomials,  132 /N.  Nilpotent  Operators,  134/0.  The 
Jordan  Canonical  Form, 135 
2.3  Linear  Homogeneous  and Nonhomogeneous  Equations 
A. The Fundamental  Matrix,  139 /B.  The State  Transition 
Matrix,  143 /C.  Nonhomogeneous  Equations,  145/D.  How 
to Determine  ^(t^to),  146 
lA 
Linear  Systems  with  Constant  Coefficients 
A. Some  Properties  ofe^^,  148/B.  How to  Determine 
e^^, 150/C  Modes  and Asymptotic  Behavior  of 
Time-Invariant  Systems,  156 
*2.5  Linear  Periodic  Systems 
138 
148 
161 
2.6 
2.7 
State  Equation  and  Input-Output  Description  of 
Continuous-Time  Systems 
A.  Response  of Linear  Continuous-Time  Systems,  165 / 
B.  Transfer  Functions,  168/C.  Equivalence  of  Internal 
Representations,  170 
State  Equation  and  Input-Output  Description  of 
Discrete-Time  Systems 
A.  Response  of Linear  Discrete-Time  Systems,  174/B.  The 
Transfer  Function  and  the z-Transform,  177/C.  Equivalence 
Sampled-Data 
of Internal  Representations,  180/D. 
Systems,  182 /E.  Modes  and Asymptotic  Behavior  of 
Time-Invariant  Systems,  186 
Summary 
2.8  An  Important  Comment  on  Notation 
2.9 
2.10  Notes 
2.11 
2.12 
References 
Exercises 
Controllability, Observability, and Special Forms 
3.1 
Introduction 
A. Brief  Introduction  to Reachability  and  Observability,  215  / 
B.  Chapter  Description,  223 /  C.  Guidelines for  the 
Reader,  225 
PART  1  Controllability  and  Observability 
3.2  Reachability  and  Controllability 
A.  Continuous-Time  Time-Varying  Systems,  227/ 
B.  Continuous-Time  Time-Invariant  Systems,  235  / 
C  Discrete-Time  Systems,  241 
3.3  Observability  and  Constructibility 
A.  Continuous-Time  Time-Varying  Systems,  248  / 
B.  Continuous-Time  Time-Invariant  Systems,  252  / 
C  Discrete-Time  Systems,  257 
PART  2  Special  Forms  for  Time-Invariant  Systems 
3.4 
*3.5 
3.6 
Special  Forms 
A.  Standard  Forms for  Uncontrollable  and  Unobservable 
Systems,  263/B.  Eigenvalue/Eigenvector  Tests for 
Controllability  and  Observability,  272 /  C  Relating 
State-Space  and Input-Output  Descriptions,  275  / 
D.  Controller  and  Observer  Forms,  278 
Poles  and  Zeros 
Summary 
165  Contents 
174 
190 
191 
191 
192 
193 
214 
215 
226 
226 
247 
263 
263 
298 
308 
xii 
Contents 
3.7  Notes 
3.8  References 
3.9 
Exercises 
4  State Feedback and State Observers 
4.1 
4.2 
4.3 
4.4 
4.5 
4.6 
4.7 
4.8 
Introduction 
A.  A Brief  Introduction  to State-Feedback  Controllers  and 
State  Observers,  322 /B.  Chapter  Description,  325  / 
C. Guidelines for  the Reader,  326 
Linear  State  Feedback 
A.  Continuous-Time  Systems,  326/B.  Eigenvalue 
Assignment,  328 /  C.  The Linear  Quadratic  Regulator  (LQR): 
Continuous-Time  Case, 342 /D. 
Relations,  345 /E.  Discrete-Time  Systems,  348/E  The 
Linear  Quadratic  Regulator  (LQR):  Discrete-Time  Case,  348 
Input-Output 
Linear  State  Observers 
A.  Eull-Order  Observers:  Continuous-Time  Systems,  350/ 
B.  Reduced-Order  Observers:  Continuous-Time 
Systems,  355 /  C.  Optimal  State  Estimation: 
Continuous-Time  Systems,  357 /D.  Eull-Order  Observers: 
Discrete-Time  Systems,  358/E.  Reduced-Order  Observers: 
Discrete-Time  Systems,  362 /  E  Optimal  State  Estimation: 
Discrete-Time  Systems,  362 
Observer-Based  Dynamic  Controllers 
A.  State-Space  Analysis,  364/B.  Transfer  Function 
Analysis,  367 
Summary 
Notes 
References 
Exercises 
5  Realization  Theory and Algorithms 
5.1 
5.2 
5.3 
Introduction 
A. Chapter  Description,  384/B.  Guidelines for  the 
Reader,  384 
State-Space  Realizations  of  External  Descriptions 
A.  Continuous-Time  Systems,  385 /B.  Discrete-Time 
Systems,  388 
Existence  and  Minimality  of  Realizations 
A.  Existence  of Realizations,  390 /B.  Minimality  of 
Realizations,  394 /  C.  The  Order of  Minimal 
Realizations,  397/D.  Minimality  of  Realizations: 
Discrete-Time  Systems,  401 
310 
311 
311 
321 
322 
326 
350 
363 
370 
370 
371 
372 
383 
384 
385 
389 
5.4 
5.5 
5.6 
5.7 
5.8 
Realization  Algoritlims 
A. Realizations  Using Duality,  402 /B.  Realizations  in 
Controller/Observer  Form, 404 /  C.  Realizations  with  Matrix 
A Diagonal,  417/D.  Realizations  with Matrix  A  in Block 
Companion  Form, 418/E.  Realizations  Using Singular  Value 
Decomposition,  423 
Summary 
Notes 
References 
Exercises 
Stability 
6.1 
Introduction 
A. Chapter  Description,  433 /B.  Guidelines for  the 
Reader,  434 
6.2  Matliematical  Background  Material 
A. Bilinear  Functionals  and  Congruence,  435 /B.  Euclidean 
Vector Spaces,  437/C  Linear  Transformations  on  Euclidean 
Vector Spaces,  441 
PART  1  Lyapunov  Stability 
6.3 
The  Concept  of  an  Equilibrium 
6.4  Qualitative  Characterizations  of  an  Equilibrium 
6.5 
6.6 
6.7 
6.8 
Lyapunov  Stability  of  Linear  Systems 
Some  Geometric  and  Algebraic  Stability  Criteria 
A. Some  Graphical  Criteria,  462 /B.  Some  Algebraic 
Criteria,  465 
The  Matrix  Lyapunov  Equation 
Linearization 
PART  2  Input-Output  Stability  of  Continuous-Time 
Systems 
6.9 
Input-Output  Stability 
PART  3  Stability  of Discrete-Time  Systems 
6.10  Discrete-Time  Systems 
A. Preliminaries,  489/B.  Lyapunov  Stability  of  an 
Equilibrium,  492 /  C.  Linear  Systems,  495 /D.  The 
Schur-Cohn  Criterion,  498/E.  The Matrix  Lyapunov 
Equation,  499/F  Linearization,  503 /G. 
Stability,  505 
Input-Output 
6.11 
Summary 
6.12  Notes 
402 
Contents 
424 
424 
425 
425 
432 
432 
434 
445 
445 
447 
452 
461 
468 
477 
481 
481 
489 
489 
508 
509 
xiv 
Contents 
6.13  References 
6.14 
Exercises 
7  Polynomial Matrix Descriptions and Matrix 
Fractional Descriptions of Systems 
7.1 
Introduction 
A. A Brief  Introduction  to Polynomial  and  Fractional 
Descriptions,  518/B.  Chapter  Description,  522/ 
C. Guidelines for  the Reader,  523 
PART  1  Analysis  of  Systems 
7.2 
7.3 
Background  Material  on  Polynomial  Matrices 
A. Rank  and Linear  Independence,  524 /B.  Unimodular  and 
Column  (Row) Reduced  Matrices,  526/C.  Hermite  and 
Smith  Forms, 531 /D.  Coprimeness  and  Common 
Divisors,  535/E.  The Diophantine  Equation,  540 
Systems Represented by Polynomial  Matrix Descriptions 
A. Equivalence  of Representations,  554/B.  Controllability, 
Observability,  Stability,  and Realizations,  560/ 
C. Interconnected  Systems,  568 
PART  2  Synthesis  of  Control  Systems 
7.4 
7.5 
7.6 
7.7 
7.8 
Feedback  Control  Systems 
A. Stabilizing  Feedback  Controllers,  589 /B.  State  Feedback 
Control  and State Estimation,  605 /  C.  Stabilizing  Feedback 
Controllers  Using Proper  and Stable  MFDs,  611 /D.  Two 
Degrees  of Freedom  Feedback  Controllers,  622 
Summary 
Notes 
References 
Exercises 
Appendix  Numerical  Considerations 
A.l 
A.2 
A.3 
A.4 
Introduction 
Solving  Linear  Algebraic  Equations 
Singular  Values  and  Singular  Value  Decomposition 
Solving  Polynomial  and  Rational  Matrix  Equations 
Using  Interpolation  Methods 
A.5 
References 
Index 
510 
511 
517 
518 
524 
524 
553 
589 
589 
634 
635 
636 
638 
645 
645 
646 
648 
653 
659 
661 
PREFACE 
This text is intended primarily for  first-year  graduate students and advanced  under 
graduates  in  engineering  who  are  interested  in  control  systems,  signal  processing, 
and communication  systems. It is also appropriate for students in applied  mathemat 
ics, economics, and certain  areas in the physical  and biological  sciences.  Designed 
for a challenging, one-semester  systems course, the book presents an introduction to 
systems theory, with an emphasis on control theory. It can also be used as supplemen 
tary  material  for  advanced  systems  and  control  courses  and  as  a general  reference 
on the  subject. 
The prerequisites  for using this book are topics covered in a typical  undergrad 
uate  curriculum  in  engineering  and  the  sciences:  undergraduate-level  differential 
equations, linear  algebra,  Laplace  transforms,  and the modeling  of electric  circuits 
and simple mechanical  systems. 
The  study  of  linear  systems  is  a  foundation  for  several  disciplines,  including 
control and signal processing. It is therefore very important that the coverage of linear 
systems be comprehensive and give readers sufficient  breadth and depth in analysis 
and  synthesis  techniques  of  such  systems. We believe  that  the best preparation  for 
this is a firm understanding of the fundamentals  that govern the behavior of complex 
systems. Indeed,  only  a thorough  understanding  of  system behavior  enables  one to 
take full  advantage  of the various  options  available  in the  design  of the best  kinds 
of control  systems  and  signal processors. Therefore,  the primary  aim of this text  is 
to  provide  an  understanding  of  these  fundamentals  by  emphasizing  mathematical 
descriptions of systems and their properties. 
In writing this book, our goal was to clearly present the fundamental  concepts of 
systems theory in a self-contained  text. In addition to covering the fundamental  prin 
ciples, we provide  sufficient  background  in analysis  and  algebra,  to enable  readers 
to move on to advanced topics in the systems area. The book is designed to highlight 
the main results  and  distinguish  them from  supporting  results  and  extensions. Fur 
thermore,  we present  the  material  in  a  sufficiently  broad  context  to give  readers  a 
clear picture of the dynamical behavior of linear systems and the limitations of such 
systems. 
The  theory  of  linear  systems  is  a  mature  topic,  and  there  are  literally  thou 
sands  of  scholarly  papers  reporting  research  on  this  subject.  This  book  empha 
sizes  fundamental  results  that  are  widely  accepted  as  essential  to  the  subject.  For 
those  readers  interested  in  further  detail,  the  end-of-chapter  material  includes 
additional  results  in  the  exercise  sections  as  well  as  pertinent  references  and 
notes. 
The  book  covers  both  continuous-time  and  discrete-time  systems,  which  may 
be time-varying  or time-invariant.  The material  is organized  in  such  a manner  that 
it  is  possible  to  concentrate  only  on  the  time-invariant  case,  if  desired.  The  time-
invariant case is treated in separate sections, and the results are presented so that they 
can be developed independently  of the time-varying case. This type of  organization 
provides considerable  flexibility  in covering the material. 
xvi 
Preface 
Although the text is designed to serve primarily the needs of graduate students, it 
should also prove valuable to researchers, and practitioners, we tried to make it easy 
to  use,  and  the  book  should  prove  valuable  for  self-study.  Many  simple  examples 
are included  to clarify  the material  and to encourage readers  to actively  participate 
in the learning process. The exercises at the end of each chapter introduce  additional 
supporting  concepts  and results and encourage readers to gain additional insight by 
using what was learned. The exercises also encourage readers to comment, interpret, 
and  visualize  results  (e.g., responses),  making  use  of  computer  programs  to  aid  in 
calculations  and the generation of graphical results, when  appropriate. 
Over  the  past  several  years,  the  material  has  been  class-tested  in  a  first-year 
graduate-level  course  on  linear  systems,  and  its  development  has  been  influenced 
greatly by  student feedback.  Although  there are many  ways of using this book in a 
course, we suggest in the following  several useful guidelines. Because any course on 
linear systems will most likely serve students with different  educational  experiences 
from  a variety  of  disciplines  and  institutions.  Chapters  1 and  2 provide  necessary 
background  material  and  develop  certain  systems  fundamentals.  Armed  with  this 
foundation, we develop essential results on controllability and observability  (Chapter 
3), on state observers  and  state feedback  (Chapter 4), and on realization  of  systems 
(Chapter 5). Chapters  6 and 7 address basic issues concerning  stabihty  (Chapter  6) 
and  the  representation  of  systems  using  polynomial  matrices  and  matrix  fractions 
(Chapter 7). The appendix presents  supplementary  material  (concerning  numerical 
aspects). 
How to use this book 
At the beginning  of each chapter is a detailed  description  of the chapter's  con 
tents, along with guidelines for readers. This material should be consulted when de 
signing a course based on this book. In the following  we give a general overview of 
the book's  contents, with  suggested  topics for  an introductory,  one-semester  course 
in linear systems. 
From Chapter  1, covering a first course in linear systems should include the fol 
lowing: all the material on systems  (Section  1.1); the material on initial-value prob 
lems  (Sections  1.3  and  1.4);  the  material  on  systems  of  linear  first-order  ordinary 
differential  equations  (Sections  1.11,  1.12,  and  1.13); the material on state equation 
descriptions  of  continuous-time  systems  (Section  1.14)  and  discrete-time  systems 
(Section  1.15);  and  the  material  on  input-output  descriptions  of  systems  (Section 
1.16). The mathematical  background  material  in  Sections  1.2,  1.5  and  Subsections 
I.IOA  to  1.IOC  is included  for review  and to establish  some needed  notation.  This 
material  should  not  require  formal  class  time.  In  Subsection  1.1 OD  [dealing  with 
existence,  continuation,  uniqueness,  and  continuous  dependence  (on  initial  condi 
tions  and  parameters)  of  solutions  of  initial-value  problems],  the  coverage  should 
emphasize the results and their implications rather than the proofs  of those results. 
From  Chapter  2,  a first course  in  linear  systems  should  include  essentially  all 
the material  from  the following  sections:  Section  2.3  (dealing  with  systems  of  lin 
ear homogeneous  and nonhomogeneous  first-order  ordinary  differential  equations); 
Section  2.4  (dealing  with  systems  of  linear  first-order  ordinary  differential  equa 
tions  with constant  coefficients);  and  Sections  2.6  and  2.7  (which  address  the  state 
equation  description,  the  input-output  description,  and  important  properties,  such 
xvii 
Preface 
as asymptotic  stability of continuous-time  and discrete-time linear systems, respec- 
tively). Section  2.5  (concerned  with linear periodic  systems)  may be omitted  with- 
out  any  loss  of  continuity.  As in Chapter  1, the mathematical  background  material 
in Section 2.2 (dealing with linear algebra and matrices) is included for review  and 
to establish some important notation and should not require much formal  class time. 
For Chapter 3, it is best to consider the material in two parts. From Part 1 include 
Section 3.1 (where the concepts of controllability  and observability  are introduced); 
and Subsections  3.2B  and  3.3B  (where these concepts  are developed  in greater de 
tail  for  continuous-time  time-invariant  systems).  From  Part  2 include  Subsections 
3.4A  and  3.4D  (where  special  forms  of  system  descriptions  are  considered);  and 
Subsection  3.4B  (where  an  additional  controllability  and  observability  test  is  pre 
sented). Similarly, the course should include the following  material from  Chapter 4: 
Section 4.1  (where  state feedback  and  state observers  are introduced);  Subsections 
4.2A  and 4.2B  (linear  state feedback  and eigenvalue  assignment by  state  feedback 
are treated  in  detail);  and  Subsection  4.3A  (where  the  emphasis  is  on  identity  ob 
servers);  and  Section  4.4  (where  observer-based  controllers  are  developed).  Also, 
the  course  should  include  material  from  Chapter  5:  Section  5.2  (where  realization 
theory is introduced); Section 5.3 (where the existence, minimality, and the order of 
minimal  realizations  are  developed);  and  Subsections  5.4A,  5.4B,  5.4C,  and  5.4E 
(where realization  algorithms are presented). 
The  material  outlined  above  constitutes  the  major  portion  of  a  first  course  in 
linear systems. The course is rounded out, if time permits with selected topics  from 
Chapter 6 (stability) and Chapter 7 (polynomial matrix system descriptions and frac 
tional representations of transfer function  matrices of linear time-invariant systems). 
The choice of these topics, and where they are presented throughout the course, de 
pends on the interests of the instructor  and the students. 
We have been using this textbook in a one-semester first-year graduate course in 
electrical engineering. Typically, we spend the first half  of the course on Chapter  1, 
Chapter 2, and Part  1  of Chapter 3. The second half of the course is devoted to Part 2 
of Chapter 3 and Chapters 4 and 5. Selected topics from  stability theory and matrix 
fractional  descriptions  of  systems  from  Chapters  6  and  7  are  included,  as  needed. 
Detailed  coverage of Chapters  1 and 2, with only  selective coverage of Chapters 3, 
4,  and  5, would  be  appropriate  in  a course  that  emphasizes  mathematical  systems 
theory. 
Chapter 6 can also be used as an introduction to a second-level graduate  course 
on  nonlinear  systems  and  stability.  Similarly,  Chapter  7  stands  alone  and  can  be 
used  in  an  advanced  linear  systems  course  or  as  an  introduction  to  a  multi-input/ 
multi-output linear control course. There is enough material in Chapters 3 through 7 
for courses taught at several levels in a graduate  program. 
Acknowledgments 
We are indebted to our students for their feedback  and constructive  suggestions 
during the evolution of this book. In particular, we would like to thank B. Hu, I. Kon-
stantopoulos, and X. Koutsoukos and also Dr. K. Wang for their help and suggestions 
during the final editing of the manuscript.  Special thanks go to Clarice Staunton  for 
her  patience  in  typing  the  many  versions  of  our  manuscript.  We  are  also  very  ap 
preciative of our excellent working relation with the staff of McGraw-Hill, especially 
xviii 
Preface 
with  Lynn  Cox,  the  Electrical  Engineering  Editor.  Finally,  we  are  both  indebted 
to  many  individuals  who  have  shaped  our  views  of  systems  theory,  in  particular. 
Bill  Wolovich,  Brown  University;  Boyd  Pearson,  Rice  University;  David  Mayne, 
Imperial  College  of  the  University  of  London  (England);  Sherman  Wu,  Marquette 
University; and Wolfgang  Hahn, the Technical University  of Graz (Austria). 
The present  printing  of Linear  Systems,  by  Birkhauser,  is in  response  to  many 
requests by colleagues from  the US and around the world, who wanted to start using 
or  continue  using  the  book,  which  was  out  of  print.  Colleagues  who  had  used  the 
book in the classroom or as a reference, as well as our own students, identified  several 
items that needed to be changed. These corrections, which mostly constituted  minor 
typos, have been incorporated in the current printing of the book. This publication of 
Linear  Systems  was  made  possible  primarily  because  of  Tom  Grasso,  Birkhauser's 
Computational  Sciences  and Engineering  Editor,  whom  we would  like to thank  for 
his professionalism,  encouragement  and  support. 
A new  companion  book  entitled A  Linear  Systems  Primer  is forthcoming.  The 
Primer-bdiscd  on the more complete treatment  of the present Linear  Systems  book-
contains  a treatment  of  linear  systems  that  focuses  primarily  on  the  time-invariant 
case,  using  streamlined  presentation  of  the  material  with  less  formal  and  more 
intuitive proofs without sacrificing  rigor. 
Panos J. Antsaklis  and Anthony  N.  Michel 
Notre Dame, Indiana 
August 2005 
CHAPTER  1 
Mathematical Descriptions of Systems 
The dynamical behavior of systems can be understood by studying their mathemati 
cal descriptions. The flight path of an airplane subject to certain engine thrust, rudder 
and elevator angles, and particular wind conditions, or the behavior of an automobile 
on cruise control when climbing a certain hill, can be predicted using  mathematical 
descriptions of the pertinent behavior. Mathematical equations, typically  differential 
or difference  equations, are used to describe the behavior of processes and to predict 
their response to certain inputs. Although computer simulation is an excellent tool for 
verifying  predicted behavior, and thus for enhancing our understanding of processes, 
it is certainly not an adequate substitute for generating the information  captured in a 
mathematical  model, when  such a model is available. But computer  simulations  do 
complement mathematical descriptions. To be able to study the behavior of processes 
using mathematical  descriptions,  such  as differential  and difference  equations,  one 
needs  a  good  working  understanding  of  certain  important  mathematical  concepts 
and procedures. Only in this way can one seriously  attempt to study the behavior of 
complex  systems  and eventually  design processes  that exhibit the desired  complex 
behavior. 
This chapter  develops  mathematical  descriptions  for  the types of  systems  with 
which  we  are  concerned,  namely,  linear  continuous-time  and  linear  discrete-time 
finite-dimensional  systems.  Since  such  systems  are  frequently  the  result  of  a  lin 
earization  process  of  nonlinear  systems,  or  the  result  of  the  modeling  process  of 
physical  systems in which the nonlinear effects  have been suppressed  or neglected, 
the  origins  of  these  linear  systems  are  frequently  nonlinear  systems.  For  this  rea 
son, here  and  in Chapter  6, when  we  deal  with  certain  qualitative  aspects  (such  as 
existence, uniqueness, continuation, and continuity with respect to parameters of so 
lutions  of  system  equations,  stability  of  an equilibrium,  and  so forth),  we  consider 
linear as well as nonlinear system models, although the remainder of the book deals 
exclusively  with linear  systems. 
2 
Lhi^^Systems 
1.1 
INTRODUCTION 
A  systematic  study  of  (physical) phenomena  usually  begins  with  a modeling  pro 
cess.  Examples  of models include electric circuits consisting of interconnections of 
resistors, inductors,  capacitors, transistors,  diodes, voltage  or current  sources, etc.; 
mechanical circuits consisting of interconnections  of point masses, springs, viscous 
dampers  (dashpots),  applied  forces,  etc.; and  verbal  characterizations  of  economic 
and societal systems, among others. Next, appropriate laws ox principles  are invoked 
to generate equations  that describe the models (e.g., Kirchhoff's  current and voltage 
laws,  Newton's  laws,  conservation  laws,  and  so forth).  When  using  an  expression 
"such as ""we consider a system  described by ordinary differential  equations",""" we will "
have in mind a phenomenon  described by an appropriate set of ordinary  differential 
equations  (not the description of the physical phenomenon  itself). 
A.  Physical  Processes, Models, and Mathematical  Descriptions 
A  physical  process  (physical  system)  will  typically  give  rise  to  several  different 
models,  depending  on  what  questions  are  being  asked.  For  instance,  in  the  study 
of the voltage-current  characteristics  of a transistor  (the physical process), one may 
utilize  a  circuit  (the  model)  that  is  valid  at  low  frequencies  or  a  circuit  (a  second 
model)  that  is  valid  at high  frequencies;  alternatively,  if  semiconductor  impurities 
are of interest, a third model, quite different  from  the preceding two, is appropriate. 
Over the centuries, a great deal of progress has been made in developing  math 
ematical  descriptions  of  physical  phenomena  (using  models  of  such  phenomena). 
In  doing  so,  we  have  invoked  laws  (or principles)  of  physics,  chemistry,  biology, 
economics,  etc., to  derive  mathematical  expressions  (usually  equations)  that  char 
acterize the evolution  (in time) of the variables  of interest. The availability  of  such 
mathematical  descriptions  enables  us to make use  of the vast resources  offered  by 
the  many  areas  of  applied  and  pure  mathematics  to conduct  qualitative  and  quan 
titative  studies  of  the behavior  of  processes.  A  given  model  of  a physical  process 
may  give  rise  to  several  different  mathematical  descriptions.  For  example,  when 
applying Kirchhoff's  voltage and current laws to the low-frequency  transistor model 
mentioned  earlier,  one can  derive  a set of differential  and  algebraic  equations, or a 
set consisting of only differential  equations, or a set of integro-differential  equations, 
and so forth.  This process  of mathematical  modeling,  ''from a physical  phenomenon 
to a model  to a mathematical  description,"""  is essential  in science  and  engineering. "
To capture phenomena of interest accurately and in tractable mathematical form is a 
demanding  task,  as can be imagined,  and requires  a thorough understanding  of the 
physical process involved. For this reason, the mathematical description of complex 
electrical  systems,  such  as power  systems,  is  typically  accomplished  by  electrical 
engineers,  the  equations  of  flight  dynamics  of  an  aircraft  are  derived  by  aeronau 
tical engineers, the equations  of chemical processes  are arrived  at by chemists  and 
chemical  engineers,  and  the  equations  that  characterize  the  behavior  of  economic 
systems are provided by economists. In most nontrivial cases, this type of modeling 
process  is  close  to  an  art form  since  a good  mathematical  description  must  be  de 
tailed enough to accurately describe the phenomena of interest and at the same time 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
simple enough to be amenable to analysis. Depending  on the applications  on hand, 
a  given  mathematical  description  of  a process  may  be  further  simplified  before  it 
is used  in  analysis  and  especially  in  design  procedures. For  example,  using  the fi 
nite  element  method,  one  can  derive  a  set  of  first-order  differential  equations  that 
describe  the motion  of  a space  antenna.  Typically,  such  mathematical  descriptions 
contain hundreds  of differential  equations. Whereas  all of these equations  are quite 
useful  in simulating the motion of the antenna, a lower order model is more  suitable 
for the control design that, for example, may aim to counteract the effects  of certain 
disturbances.  Simpler mathematical  models  are required  mainly  because  of our in 
ability to deal effectively  with hundreds  of variables  and their interactions. In  such 
simplified  mathematical  descriptions,  only  those  variables  (and  their  interactions) 
that have significant  effects  on the phenomena of interest are included. 
A point that cannot be overemphasized is that the mathematical descriptions we 
will encounter characterize processes only approximately. Most often, this is the case 
because the complexity  of physical systems defies  exact mathematical  formulation. 
In many  other cases, however,  it is our own choice that a mathematical  description 
of a given process  approximate the actual phenomena by only a certain  desired  de 
gree  of  accuracy.  As  discussed  earlier,  this  is done  in the  interest  of  mathematical 
simplicity. For example, in the description of RLC circuits, one could use nonlinear 
differential  equations that take into consideration parasitic effects  in the capacitors; 
however, most often it suffices  to use linear ordinary differential  equations with con 
stant coefficients  to describe the voltage-current relations of such circuits, since typ 
ically  such  a description  provides  an  adequate  approximation  and  since it is  much 
easier to work with linear rather than nonlinear differential  equations. 
In this book it will generally be assumed that the mathematical  description  of a 
system in question is given. In other words, we assume that the modeling of the pro 
cess in question has taken place and that equations describing the process are given. 
Our  main  objective  will be to present  a qualitative  theory  of  an important  class of 
systems—finite-dimensional  linear  systems—by  studying  the  equations  represent 
ing such  systems. 
B.  Classification  of  Systems 
For our purposes, a comprehensive  classification  of systems is not particularly  illu 
minating. However, an enumeration of the more common classes of systems encoun 
tered in engineering  and  science may be quite useful,  if for  no other reason than to 
show  that the classes  of  systems  considered  in this book,  although  very  important, 
are quite  specialized. 
As  pointed  out  earlier,  the  particular  set  of  equations  describing  a  given  sys 
tem  will  in  general  depend  on  the  effects  one  wishes  to  capture.  Thus,  one  can 
speak of lumped parameter  ox finite-dimensional systems  and distributed  parameter 
or  infinite-dimensional  systems', continuous-time  and  discrete-time  systems',  linear 
and nonlinear  systems', time-varying  and  time-invariant  systems', deterministic  and 
stochastic  systems',  appropriate  combinations  of  the  above,  called  hybrid  systems', 
and perhaps others. 
The appropriate mathematical settings for  finite-dimensional  systems are finite-
dimensional vector spaces, and for infinite-dimensional  systems they are most  often 
4 
Linear Systems 
infinite-dimensional  linear  spaces. Continuous-time  finite-dimensional  systems  are 
usually described by ordinary differential  equations or certain kinds of integral equa 
tions, while discrete-time  finite-dimensional  systems are usually characterized by or 
dinary difference  equations or discrete-time counterparts to those integral equations. 
Equations  used  to describe infinite  dimensional  systems include partial  differential 
equations,  Volterra  integro-differential  equations,  functional  differential  equations, 
and so forth. Hybrid system descriptions involve two or more different  types of equa 
tions.  Nondeterministic  systems  are  described  by  stochastic  counterparts  to  those 
equations  (e.g., Ito differential  equations). 
In a broader context, not addressed  in this book, most of the systems  described 
by the equations enumerated  generate dynamical  systems.  It has become  customary 
"in the engineering literature to use the term ""dynamical system"" rather loosely", and it 
has even been applied to cases where the original definition  does not exactly fit. (For 
a  discussion  of  general  dynamical  systems,  refer,  e.g.,  to Michel  and  Wang  [13].) 
We will address in this book dynamical  systems determined by ordinary  differential 
equations or ordinary  difference  equations, considered  next. 
C.  Finite-Dimensional  Systems 
The  dynamical  systems  we  will  be  concerned  with  are  continuous-time  and 
discrete-time  finite-dimensional  systems—primarily  linear  systems.  However,  since 
such systems are frequently  a consequence of a linearization process, it is important 
when  dealing  with  fundamental  qualitative  issues  that  we  have  an  understanding 
of the origins  of  such linear  systems. In particular,  when  dealing  with  questions  of 
existence and uniqueness of solutions of the equations describing a class of systems, 
and with stability properties of such systems, we may consider nonlinear models as 
well. 
Continuous-time  finite-dimensional  dynamical  systems  that we will consider are 
described by equations of the  form 
^i  —  fii^y  ^l, 
yi  =  gi{t,xi,...,Xn,ui,...,Um), 
'  '  -y  ^m  U\, 
.  .  .,  Um), 
I,  .  .  .,  n, 
i  = 
i  =  1, • • •, A 
(Lla) 
(1.1b) 
where  Ui, i  =  1,...,  m,  denote  inputs  or  stimuli;  yi,  i  =  1,..., /?, denote  outputs 
or responses', xf,  i  =  1,...,  n, denote state  variables;  t denotes time; xi  denotes  the 
time  derivative  of  xt;  ft,  i  =  1,...,  n,  are real-valued  functions  of  1 +  ^  +  m real 
variables; and gi, i  =  \,...,  p,  are real-valued functions  of 1 -h ^ + m real variables. 
A complete description of such systems will usually also require a set of initial  con 
ditions  Xi(to)  =  Xio, i  =  \,.. 
.,n,  where  fo denotes  initial  time.  We will  elaborate 
later on restrictions  that need to be imposed  on the  ft,  gt,  and  ui and on the  origins 
"of the term ""state variables."" "
Equations  (1.1a) and (1.1b) can be represented in vector form  as 
X =  f{t,x,  u) 
y  =  g{t,x,u), 
(1.2a) 
(1.2b) 
where x is the state vector with components xt, u is the input vector with components 
Ui, y is the output vector with components  j /,  and/  and g are vector-valued  functions 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
with components  ft  and gi, respectively.  We call  (1.2a) a state  equation  and  (1.2b) 
an output  equation. 
Important  special  cases  of  (1.2a)  and  (1.2b)  are  the  linear  time-varying  state 
equation  and output  equation  given by 
X =  A{t)x  +  B{t)u 
y  -  C{t)x  +  D{t)u, 
(1.3a) 
(1.3b) 
where A, B, C, and D are real nXn,nXm,pXn, 
and pXm  matrices, respectively, 
whose  elements  are  time-varying.  Restrictions  oi^ these  matrices  will  be  provided 
later. 
Linear  time-invariant  state  and output  equations  given by 
X =  Ax  +  Bu 
y  =  Cx  +  Du 
(1.4a) 
(1.4b) 
constitute important  special cases of (1.3a) and (1.3b), respectively. 
Equations (1.3a), (1.3b) and (1.4a), (1.4b) may arise in the modeling process or 
they may be a consequence of linearization  of (1.1a) and (1.1b). 
Discrete-time  finite-dimensional  dynamical  systems  are described by  equations 
of the  form 
Xi(k  -\-  I)  =  fi(h  xi{k),...,  Xn{k), ui(k\ 
...,  Xn{k), ui(k\ 
yi(k)  =  gi(k,  xi{k\ 
...,  Um{k)\ 
. . .,  Um(k)\ 
/  =  1,.. 
/  =  1,.. 
., n, 
.,p, 
(1.5a) 
(1.5b) 
or in vector  form, 
x(k  +  1)  =  f(k,  x(kl  u(k)) 
y(k)  =  g(k,  x(kl  u(k)), 
(1.6a) 
(1.6b) 
where k is an integer that denotes discrete  time  and all other symbols are defined  as 
before.  A  complete  description  of  such  systems  involves  a set of  initial  conditions 
x(fco)  =  Xy^Q,  where feo denotes  initial  time.  The  corresponding  linear  time-varying 
and time-invariant  state and output equations are given by 
and 
x(k  +  1)  =  A(k)x(k)  +  Bik)u(k) 
y(k)  =  C(k)x(k)  +  D(k)u(k) 
x(k  +  1)  -  Ax(k)  +  Bu(k) 
y(k)  =  Cx(k)  +  Du(k), 
(1.7a) 
(1.7b) 
(1.8a) 
(1.8b) 
respectively,  where all symbols in (1.7a), (1.7b) and in (1.8a), (1.8b) are defined  as 
in (1.3a), (1.3b) and (1.4a), (1.4b), respectively. 
This  type  of  system  characterization  is  called  state-space  description  or 
state-variable  description  or  internal  description  of  finite-dimensional  systems. 
Another  way  of  describing  continuous-time  and  discrete-time  finite-dimensional 
dynamical  systems involves operators that establish  a relationship between the sys 
tem  inputs  and  outputs.  Such  characterization,  called  input-output  description,  or 
external  description  of a system, will be addressed later in this  chapter. 
Linear Systems 
D.  Chapter  Description 
In this book we will make liberal use of certain aspects of analysis and algebra. To help 
the reader  recall  some of these facts,  we will provide throughout  such  background 
material as needed. This is done, e.g., in the second section, where we provide some of 
the notation used and where we recall certain facts concerning continuous  functions. 
In the third section  we present the initial-value problem for  nth-order  ordinary 
differential  equations  and for  systems  of  first-order  ordinary  differential  equations, 
and  we  give  a  classification  of  ordinary  differential  equations.  We  also  show  that 
the study of nth-order ordinary  differential  equations can be reduced to the study of 
systems of first-order ordinary differential  equations. 
In the fourth  section  we give several specific examples of initial-value problems 
determined by ordinary differential  equations. 
In the fifth section  we provide mathematical  background  material  dealing  with 
sequences, sequences of functions,  and the Weierstrass  M-test. 
In the sixth  section  we establish  conditions under which initial-value  problems 
for  ordinary  differential  equations  possess  solutions.  This  is  accomplished  in  two 
stages. First, we establish  an existence result for e-approximate  solutions, of  which 
the  Euler  method  is  a  special  case. Next,  we  state  and  prove  a preUminary  result, 
called  the  Ascoli-Arzela  Lemma,  that  we  use,  together  with  the  existence  result 
for  6-approximate  solutions,  to  establish  a  result  for  the  existence  of  solutions  of 
initial-value problems. These solutions need not be unique. (This result is called the 
Peano-Cauchy  Theorem.) 
In  the  seventh  section  we  make  use  of  Zom's  Lemma  to  establish  a  result 
that  enables  us  to  determine  the  extent  (in  time)  of  the  existence  of  solutions  of 
initial-value problems. This is called continuation of solutions. 
In the eighth  section  we prove a result that ensures  the uniqueness  of  solutions 
of  initial-value  problems.  In  doing  so,  we  utilize  a  useful  result,  called  the  Gron-
wall Inequality,  that  we also prove. One of the results  of this  section, called  Picard 
iteration, provides a method of constructing  solutions  iteratively. 
In the ninth  section  we  show  that under  reasonable  conditions  the  solutions of 
initial-value problems depend continuously  on initial conditions and system param 
eters. 
To simplify  our presentation,  we  consider  in  Sections  6 to 9 the  case  of  scalar 
first-order  ordinary  differential  equations. In the tenth  section  we extend  all results 
to  the  case  of  systems  of  first-order  ordinary  differential  equations.  In  the  process 
of  accomplishing  this,  we  introduce  additional  mathematical  background  material 
concerning vector spaces, normed linear spaces, and convergence  on normed  linear 
spaces. 
The results  in  Sections  6 to  10 pertain  to differential  equations  that in  general 
are nonlinear. In the eleventh  section  we address linearization of such equations and 
provide several specific  examples. 
We utilize the results of Section  10 to establish in the twelfth  section  conditions 
for the existence, uniqueness, continuation, and continuity with respect to initial con 
ditions  and  parameters  of  solutions  of  initial-value  problems  determined  by  linear 
ordinary differential  equations. 
In  the  thirteenth  section  we  determine  the  solutions  of  linear  ordinary  differ 
ential  equations.  To  arrive  at  some  of  our  results  (the  Peano-Baker  series  and  the 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
matrix  exponential),  we  make  use  of  the  Picard  iteration  considered  in  Sections  8 
and  10. In this  section  we introduce  for  the first time  the notions  of  state  and  state 
transition  matrix.  We  also  present  the  variations  of  constants  formula  for  solving 
linear nonhomogeneous  ordinary differential  equations  and introduce the notions of 
homogeneous  and particular  solutions. 
Summarizing,  the  purpose  of  Sections  3  to  13  is  to  provide  material  dealing 
with  ordinary  differential  equations  and  initial-value  problems  that  is  essential  in 
the study of continuous-time  finite-dimensional  systems. This material enables us to 
give  the  state-space  equation  representation  of  continuous-time  finite-dimensional 
systems. This  is  accomplished  in  tho fourteenth  section.  We consider  nonlinear  as 
well as linear systems that may be time-varying  or time-invariant. 
In  the  fifteenth  section  we  present  the  state-space  equation  representation  of 
finite-dimensional  discrete-time  systems.  In  doing  so,  we  introduce  systems  of 
first-order  ordinary  difference  equations,  nth-order  ordinary  difference  equations, 
initial-value problems involving such equations, solutions of equations, the transition 
matrix, and so forth. 
Finally,  in  the  sixteenth  section  we  consider  an  alternative  description  of  the 
systems considered herein, called the input-output representation  of systems. In the 
process of accomplishing  this, we introduce  several important general properties of 
systems  (such  as  causality,  systems  with  memory,  linearity,  time  invariance,  and 
so  forth).  We  emphasize  linear  discrete-time  and  linear  continuous-time  systems. 
For  the  former  we  introduce  the  notion  of  pulse  response,  while  for  the  latter  we 
introduce the concepts of impulse response and the integral representation  of linear 
continuous-time systems. For both continuous-time and discrete-time linear systems 
we make  a connection  between  the  state-space representation  and the  input-output 
description of systems, and we introduce the concept of system transfer  function.  In 
the first subsection of this section we encounter Dirac delta distributions. 
This chapter has been organized in such a way that proofs of results may be omit 
ted  without  much  loss  of  continuity,  should  time  constraints  be  a factor.  However, 
the concepts  (including the statements of most theorems) introduced in this  chapter 
are of fundamental  importance and will be utilized throughout the remainder of this 
book. 
E.  Guidelines  for the  Reader 
In  a first reading,  certain  material  may  be  omitted  without  loss of continuity.  Such 
material  is  identified  throughout  the  book  by  starring  the  section  or  subsection 
title. 
A typical graduate course in linear  systems will include the following  material 
from  this  chapter: 
Mathematical  description  and classification  of systems  (Section  1.1). 
Initial-value problems with examples  (Sections  1.3  and  1.4). 
Material on vector spaces and the results concerning existence and  uniqueness 
of solutions of systems of first-order ordinary differential  equations  (Sections 
1.10  and  1.12). 
Linearization  of nonlinear  systems with examples  (Section  1.11). 
Linear Systems 
Solutions of the linear state equations  x  =  A(t)x  and x  =  A(t)x  + g(t)  (Section 
1.13). 
State-variable descriptions  of continuous-time  and discrete-time  systems 
(Sections  1.14  and  1.15). 
Input-output  description of systems  (Section  1.16). 
1.2 
PRELIMINARIES 
We will employ a consistent notation and use certain facts  from  the calculus, analy 
sis, and linear algebra. We will summarize this type of material, as needed, in various 
sections throughout the book. This is the first such  section. 
A.  Notation 
Let  V and  W be sets.  Then  VUW,VnW,V-W,mdVxW 
denote the  union, 
intersection,  difference,  and  Cartesian  product  of  V  and  W, respectively.  If  V is  a 
subset  of W, we write V  C  W', if x is an element  of V, we write x  G  V; and \fx  is not 
an element of V, we write x  ^V.  We let V\dV,  V, and int V denote the  complement, 
boundary,  closure,  and interior  of  V, respectively. 
Let 0  denote the  empty  set,  let R  denote the  real numbers,  let  R^  =  {x  ^  R \ 
x>  0} (i.e., R^  denotes the set of nonnegative real numbers), let Z denote the  inte 
gers,  and let Z^  =  {x G Z  : x  >  0}. 
We will let /  C  i? denote open, closed, or half-open intervals. Thus, for 
a,bGR, 
a  ^  b, J  may  be  of the  form  J  =  (a, b)  =  {x  G  R  : a  <  x  <  b}, or J  =  [a,b]  = 
{x  G R  :  a  ^  X ^  b}, or J  =  [a, b)  =  {x  G R  :  a  ^  x  <  b}, or J  =  (a, b]  =  {x  E 
R  :  a  <  X ^  b}. 
Let R^ denote the real n-space.  If x  E  R^,  then 
''xi 
and  x^  =  (xi,...,  Xn) denotes the transpose  of the vector x.  Also, let R^^^  denote 
the set ofmXn 
"real matrices. If A G i^^X""",  then 
[Clij] 
an 
an 
ail 
^ ml 
CLynl 
Clin 
and A^  =  [aji]  G R^^^  denotes the transpose  of the matrix A. 
Similarly,"  let  C""  denote the  set of n-vectors  with  complex  components  and  let "
(^mxn  denote the set of mX  n matrices with complex  elements. 
Let  f  : V  -^  W  denote  a mapping  or function  from  a  set  V  into  a  set  W,  and 
denote by D(f)  and R(f)  the domain  and the range of/,  respectively. Also, let f~^  : 
R(f)  -^  D(f), 
if it exists, denote the inverse  off. 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
B.  Continuous  Functions 
First, iQiJCR 
denote an open interval  and consider  a function  f  : J  ^  R.  Recall 
that/ is said to be continuous  at the point  to G J if lim^_>/Q f(t)  =  f(to)  exists, i.e., if 
for every e  >  0 there exists a 5  >  0 such that \f(t)  -  f(to)\  <  e whenever \t-to\  <  8 
and t  ^  J.  The function/  is said to be continuous  on J, or simply continuous,  if it is 
continuous at each point in  /. 
In the above definition,  8 depends on the choice of to and e, i.e., 8  =  8(6, to). If 
at each to ^  J  it is true that there is a 5  >  0, independent of fo [i-e., 8  =  8(e)],  such 
that 1/(0  -  /(^o)|  <  ^ whenever  \t -to\<8 
and f E  /,  then/ is said to be  uniformly 
continuous  (on  J). 
Let 
C(J, R)  =  {f  : J  ^  R\  f  is continuous on  / }. 
Now  suppose  that /  contains  one or both  endpoints.  Then  continuity  is  interpreted 
as being one-sided at these points. For example, if 7  =  [a, b], then /  E  C(J, R) will 
mean that  /  G  C((a, b), R)  and that Um^^^+ f(t)  =  f(a)  and lim^^^-  f(t)  = 
f(b) 
exist. 
With k any positive integer, and with J an open interval, we will use the notation 
C^J,  R)  =  {f  :J^ 
R\ 
the derivative  f^J^ exists on /  and 
fj^  G  C(J, R)  for  j  =  0,h...,k,  where/^^^  =  /} 
and will call/ in this case a C^-function.  Also, we will call/ apiecewise  C^-function 
if /  G C^~^(J, R) and /^^~^^ has continuous derivatives for all r G 7 with the possi 
"ble exception of a finite set of points where  /""^^^ may have jump discontinuities. As "
before,  when /  contains one or both endpoints, then the existence  and continuity of 
derivatives is one-sided  at these points. 
For  any  subset  D  of  the  n-space  R^  with  nonempty  interior,  we  can  define 
C(D, R)  and  C^(D,  R)  in  a  similar  manner  as  before.  Thus,  /  G  C(D, R)  indi 
cates  that  at  every  point  xo  =  (:v:io,...,  Xno)^  ^  D,  lim;c->xo fM 
^  f(^o)  exists, 
or equivalently,  at every  XQ G D  it is true  that  for  every  e  >  0 there  exists  a S  = 
8(e,  Xo) >  0 such that \f(x)  -  f(xo)\  <  e whenever  \xi  -  xio| H 
^-1-^/2 -  x^o] <  8 
and X G D. Also, we define  C^(D,  R)  as 
C\D, 
R)  =  {f 
:D 
R 
dJf 
dx'l' 
C(D,  R), 
"i\  +  '""  + in  =  j", 
j  =  l,...,k, 
mdfGC(D,R)} 
(i.e.,  ii,.. 
.,in  take on all possible positive  integer  values  such that their  sum  is7). 
When D contains its boundary  (or part of its boundary), then the continuity of/  and 
the  existence  and  continuity  of partial  derivatives  of/,  d^fldx^^ • • •o'xjf,  /i  +  • • •  -h 
in  =  j,  j  =  1,...,  ^, will have to be interpreted in the appropriate way at the bound 
ary points. 
Recall that if K  C  R^, K  7^  0,  and K is compact  (i.e., K is closed and bounded), 
and if /  G  C(K,  R), then/ is uniformly  continuous (on K) and/  attains its maximum 
and minimum on  K. 
Finally, let D be a subset of R'^ with nonempty interior and Ictf-.D-^R^. 
Then 
: D ->  7^, /  =  1,...,  m. We say that  /  G  C(D," R""^)  if "
/  =  (fh  ...,  /m)^, where  / 
10 
Linear Systems 
/;.  E  C(A  / ? ) , / - ! , . . .,  m, and that for  some positive integer K  f  E. C^(D,"  R""^) if "
ft  ^  C^{D, R),i  =  I,... 
,m. 
1.3 
INITIAL-VALUE  PROBLEMS 
In  this  section  we  make  precise  the  meaning  of  several  concepts  that  arise  in  the 
study of continuous-time  finite-dimensional  dynamical  systems. 
A.  Systems  of First-Order  Ordinary  Differential  Equations 
Let  D  C  R^^^  denote  a domain,  i.e.,  an  open,  nonempty,  and  connected  subset  of 
/^«+i  We call  R^^^  the  {t, x)-space\  we denote  elements  of R^^^  by  {t, x)  and  ele 
ments  of  R^  hy  X  =  {x\,...,  Xnf.  Next,  we  consider  the  functions  ft  E  C{D,  R), 
i  =  I,..  .,n,  and if xt is a function  of t," let jc-""^  =  d^xtldt^  denote the nth derivative "
of Xi with respect to t (provided that it exists). In particular, when n  == 1, we usually 
write 
(1) 
. 
dxi 
We call the system of equations given by 
Xi  =  fiit,  x i , . . .,  Xn), 
i  =  1,...,  n, 
(Ei) 
a system  of n first-order ordinary  differential  equations.  By a solution  of the system 
of equations  (Ei) we  shall mean  n continuously  differentiable  functions  (/>!,...,(/)„ 
defined on an interval /  =  (a, b) [i.e.," 4>  ^  C^U^ ^"")] such that (f", (f)\{t),...,  (j)n{t))  E 
D for  all f E  /  and such that 
(/>/(0  =  fiit,  Mt),..., 
(/>^(0), 
i  = 
l,.,,,n, 
for  all t  E  /. 
Next,  we  let  (to, x\o,..., 
x„o)  E  D.  Then  the  initial-value  problem  associated 
with  (Ei) is given by 
Xi  =  fi(t,  xi,...,  Xn\ 
i  = 
l,...,n, 
Xi(to)  =  Xi^, 
i  = 
l,...,n. 
A  set  of  functions  {(pi,...,  c/)^} is  a  solution  of  the  initial-value  problem  (//)  if 
{(1)1,...,"  (pn}  is  a  solution  of  (£""/)  on  some  interval  /  containing  ^o  and  if "
((t)l(to), 
(pnOo))  =  (-^lO,  '•-,  Xno)' 
..., 
In  Fig.  1.1  the  solution  of  a  hypothetical  initial-value  problem  is  depicted 
graphically  when  n  =  1. Note  that  (/>(T)  =  / ( r,  x)  =  tanm,  where  m  is  the  slope 
of  the  line  L  that  is  tangent  to  the  plot  of  the  curve  (/)(0  vs.  t,  at  the  point 
(T,  X). 
In  dealing  with  systems  of  equations,  we  will  find  it  convenient  to  utilize 
the  vector  notation  x  =  (x\,...,  XnY,  XQ =  (xio,...,  ^^Q)^'  ^  ^  (^i^  • • •' 4^n)^, 
f(t,  X)  = 
X  = 
(xi,..., 
xn)\  and \l^ f(s,  ci>(s)) ds  =  [\l  fi(s,  (/>(^)) ds,..., 
\l  fn(s,  cl>(s)) dsf. 
x),  . . .,  fn(t,  x)Y, 
Xn))^  =  (f\(t, 
(fi(t,  Xi,..., 
fn(t,  Xi,..., 
Xn),  ..., 
Solution (p 
11 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
FIGURE 1.1 
Solution of an initial-value problem when n  = I 
With  the  above notation  we  can  express  the  system  of  first-order  ordinary  dif 
"ferential  equations  (£""/) by "
X =  fit,  x) 
iE) 
and the initial-value problem (//)  by 
(/) 
We leave it to the reader to prove that the initial-value  problem  (/)  can be  equiva-
lently expressed by the integral  equation 
X =  fit,  x), 
xito)  =  XQ. 
m  =  X0+  C fis,cl,is))ds, 
JtQ 
iV) 
w^here cj) denotes a solution of  (/). 
B.  Classification  of Systems  of First-Order  Ordinary 
Differential  Equations 
Systems  of  first-order  ordinary  differential  equations  have been  classified  in  many 
ways. We enumerate here some of the more important cases. 
If in iE\  fit,  X) ^  fix)  for all it, x)  G D, then 
X = 
fix). 
(A) 
We call (A) an autonomous  system  of first-order ordinary differential  equations. 
If it-{-T,x)ED  whenever it, x)  G D and if fit,  x)  =  fit  + T, x) for all it,  x) 
D,  then iE)  assumes the  form 
X =  fit,  x)  =  fit  +  T, X). 
iP) 
We call such an equation a. periodic  system  of first-order differential  equations  with 
period  T. The smallest  T  >  0 for which  (P) is true is called the least period  of this 
system of equations. 
"When in (£"")", fit,  x)  =  Ait)x,  where Ait)  =  [atjit)]  is a real nX  n matrix with 
elements aij that are defined  and at least piecewise continuous on a ^interval /,  then 
12 
Linear Systems 
we have 
x  =  A{t)x 
(LH) 
and refer to (LH)  as a linear homogeneous  system  of first-order ordinary  differential 
equations. 
If for (LH),  A(t)  is defined  for all real t, and if there is a T  >  0 such that A(t)  = 
A(t  +  T)  for  all t, then we have 
X =  A(t)x  =  A(t  +  T)x. 
(LP) 
This  system  is  called  a  linear  periodic  system  of  first-order  ordinary  differential 
equations. 
Next,  if  in  (E),  f(t,  x)  =  A(t)x  +  g(t),  where  A(t)  is  as  defined  in  (LH),  and 
g(t)  =  [g\(Oy • • • > gn(t)V  is a real /z-vector with elements  gi that are defined  and at 
least piecewise continuous on a ^interval /,  then we have 
X =  A(t)x  +  g(t). 
(LN) 
In this case we speak of a linear nonhomogeneous  system  of first-order ordinary 
differential  equations. 
Finally, if in (E),  f(t,  x)  =  Ax,  where A  =  [atj] G R^^^^ then we have 
This  type  of  system  is  called  a  linear, autonomous,  homogeneous  system  of  first-
order ordinary differential  equations. 
X =  Ax. 
(L) 
C.  nth-Order  Ordinary  Differential  Equations 
Thus  far  we  have  been  concerned  with  systems  of  first-order  ordinary  differen 
tial equations. It is also possible to characterize  initial-value problems by means of 
nth-order ordinary differential  equations. To this end we let /z be a real function that is 
defined and continuous on a domain/) of the real (r, y,..., 
}^^)-space [i.e.,/)  C  R^^^, 
D is a domain, and h  G  C(D, R)]. Then 
/ -)  =  h(t,y,/'\...,/--'^) 
(En) 
is an nth-order  ordinary  dijferential  equation. 
"A  solution  of  (En) is  a function  (f)  G  C""(/",  R)  that  satisfies  (t, (f)(t),  4>^^\t),..., 
"(/)^""-i>(0)  G D for  alH  G /  and "
cly^^\t) = 
h(t,cfy(tlcj>^'\t),...,cf>^--'\t)) 
for  all r G /,  where /  =  (a, b) is a r-interval. 
Now for  a given  (to, xio,..., x„o)  G /), the initial-value  problem  for  (£„) is 
A  function  (/> is  a  solution  of  (/„)  if  0  is  a  solution  of  Eq.  (En)  on  some  interval 
containing  to and if (/)(^)  =  xio, •..,  <p^^~^\to)  =  Xno-
As  in  the  case  of  systems  of  first-order  ordinary  differential  equations,  we 
can point to several important  special  cases. Specifically,  we consider  equations of 
13 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
the  form 
/«) + a,_i(oy in-1) 
^  ai(t)/^^  + ao(t)y  -  g(t), 
(3.1) 
where a/  G  C(J, R), i  =  0,1,.. 
nonhomogeneous  ordinary  differential  equation  of order  n. 
.,n-l, 
and^  E  C(/, R). Wereferto  (3.1) as  a/mear 
If in (3.1) we let ^(0  ^  0, then 
/^^  +  a,"-i(0/""-^^  +  • • • +  ^i(0/^^  +  ao(Oy  =  0. "
(3.2) 
We call (3.2) a linear  homogeneous  ordinary  differential  equation  of order  n. 
If in (3.2) we have ai{t)  =  at,  i  =  0,1,., 
.,n  -  I,  then 
/-^  +  an-i/^-'^ 
+ 
+  aiy^^^ +  aoj 
0, 
(3.3) 
and we call (3.3) a linear, autonomous,  homogeneous  ordinary  differential  equation 
of order  n. 
As in the case of  systems  of  first-order  ordinary  differential  equations,  we  can 
dt^ne  periodic  and linear periodic  ordinary  differential  equations  of order n in the 
obvious way. 
It  turns  out  that  the  theory  of  nth-order  ordinary  differential  equations  can  be 
reduced to the theory  of a system of n  first-order  ordinary  differential  equations. To 
demonstrate  this,  we  let  y  =  xi, 
j^^^  =  X2,..., y^^~^^  =  Xn in  Eq.  (/„).  We  now 
obtain the system of first-order ordinary differential  equations 
X\  =  X2 
X2  =  X3 
Xn  =  h(t,Xi, 
...,Xn) 
(3.4) 
that is defined  for  all (t, xi,...,  Xn) E  D. Assume that 4>  =  ( 0 1 , . . .,  0^)^  is a solu 
tion of (3.4) on an interval J.  Since 02  =  (pi," 03  =  0 2 . . . ..  0«  =  0 i "" ^\  and  since "
h(t, 0 i ( O , . . ., 0.(0)  -  hit, 0i(0,0^/^(0,...,  0 r ' \ O) 
it  follows  that  the  first  component  0i  of  the  vector  0  is  a  solution  of  Eq.  (En) 
on  the  interval  /.  Conversely,  if  0i  is  a  solution  of  (En)  on  /,  then  the  vector 
(0, 0^^\  . . .,"  0^""""^^)^  is  clearly  a  solution  of  (3.4). Moreover",  if  0i(ro)  =  ^lo. • • •. 
0i'^~^\^o)  =  ^no^ then the vector 0  satisfies  0(^o)  ^  ^o  =  (-^lo. • • •.  ^no)^-
1.4 
EXAMPLES OF INITIAL-VALUE PROBLEMS 
We now give several specific  examples of initial-value problems. 
EXAMPLE 4.1.  The mechanical  system of Fig.  1.2  consists of two point masses Mi 
and M2 that are acted upon by viscous damping forces (determined by viscous damping 
constants B, Bi,  and B2), spring forces  (specified  by the spring constants K, K\,  and 
K2), and external forces  f\  and /i. The initial displacements of Mi  and M2 at ^  =  0 
are given by yi(0) and y2(0), respectively, and their initial velocities are given by y\(0) 
14 
Linear  Systems 
v77'y//////yyy////yy//7?\^ 
FIGURE 1.2 
An example of a mechanical  circuit 
and  J2(0).  The  arrows  in Fig.  1.2 indicate  positive  directions  of displacement  for M\ 
and  M2. 
Newton's  second  law  yields  the  following  coupled  second-order  ordinary  differ 
ential  equations  that  describe  the motions  of the  masses  in Fig.  1.2 (letting  y^^^ = 
d^yldf  =  y\ 
Miyi  +{B + Bi)yi  + (K + Ki)y, -  Bh  -  ^ J2  =  / i (0 
M2y2  +  (5 +  B2)y2  + (^  +  ^2)^2  -  ^i ji  -  Kyi  =  -  f2(t) 
(4.1) 
with initial data ji(0), 3^2(0), yi(0), and J2(0). 
Letting x\  = y\, X2 = y\, X'i = 3^2, and x^  = ^2, we can express Eq.  (4.1)  equiv-
alently by the system of first-order ordinary  differential  equations 
x{ 
X2 
x?> 
M. 
0 
Ki+K 
Ml 
0 
K 
.  M2 
1 
Bi+B 
Ml 
0 
B 
Ah 
0 
K 
Ml 
0 
0 
B 
Wi 
1 
K  + K2 
5  + ^2 
M2 
M2 
J 
j 
pi 
0 
U2 
Us 
L-^4 
(4.2) 
/2(0 
M2 
with initial data given by  x(0)  =  (xi(0), X2(0), ^3(0), ^4(6))^. 
EXAMPLE4.2.  Using the node voltages vi, V2, and V3 and applying Kirchhoff's  current 
law, we can describe the behavior  of the electric circuit given in Fig.  1.3  by the  system 
of  first-order  ordinary  differential  equations 
1 
/I 
/I 
1 
Ci 
1 
1 
1 
R2C2 
1 
RiCi 
(Ri 
V L 
1 
^ 2 Ci 
1 
RiC: 2 ^2 
1 
0 
Rl 
L 
0 
[vi' 
V9 
LV3. 
+ 
V 
/^iCi 
V 
RiC, 
0 
(4.3) 
To  complete  the  description  of this  circuit,  we specify  the  initial  data  at ^o = 0, 
• 
given by vi (0), V2(0), and V3(0). 
EXAMPLE  4.3.  Figure  1.4 represents  a  simplified  model  of an armature  voltage-
controlled  dc servomotor  consisting  of a stationary  field  and  a rotating  armature  and 
load.  We  assume  that  all effects  of the  field  are  negligible  in the description  of this 
• A A /V 
6 
v^  ^VW 
C^^ 
15 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
FIGURE  1.3 
An  example  of  an  electric 
circuit 
Armature 
FIGURE  1.4 
An example of an electromechanical  system 
system.  The  various  parameters  and  variables  in  Fig.  1.4  are:  Ca  =  externally  apphed 
armature  voltage,  ia =  armature  current,  Ra =  resistance  of  the  armature  winding.  La  = 
armature  winding  inductance,  Cm  =  back-emf  voltage  induced  by  the  rotating  armature 
winding,  B  =  viscous  damping  due  to  bearing  friction,  /  =  moment  of  inertia  of  the 
armature and load, and  0  =  shaft  position. 
The back-emf  voltage  (with the polarity  as shown) is given by 
em  =  KeO, 
where  KQ  >0  is 2i constant  and the torque  T  generated by the motor is given by 
T=KTia-
Application of Newton's  second law and Kirchhoff's  voltage law yields 
and 
at 
je+Be  =  T{t) 
(4.4) 
(4.5) 
(4.6) 
(4.7) 
Combining  (4.4)  to  (4.7)  and  letting  xi  =  e,X2  =  9,  and  X3 =  4  yields  the  system  of 
first-order  ordinary differential  equations 
16 
Linear  Systems 
1 
0 
B 
KT 
J  T 
-
0 
0 
0 
0 
0 
_ 
pi 
"IU2I + I """" |. "
\x2 
Us J 
[Ta\ 
+ 
(4.8) 
A  suitable  set  of  initial  data  for  (4.8)  is  given  by  ^o  =  0  and  (xi(0), X2(0), X3(0))^  = 
• 
(^(0), ^(OX/,(0))^ 
EXAMPLE  4.4.  A much  Studied ordinary  differential  equation is given by 
X  +  f(x)x  +  g(x)  =  0, 
(4.9) 
where /  G  C\R,  R)  and g  G  C\R,  R), 
When  f(x)  >  0  for  all  x  G  /?  and  xg(x)  >  0  for  all  x  7^ 0,  then  (4.9)  is  called 
the Lienard  Equation.  This  equation  can  be  used  to represent,  e.g.,  RLC  circuits  with 
nonlinear circuit  elements. 
Another important  special case of (4.9) is the van der Pol Equation  given by 
x-e{\ 
-  x^)x  + x  =  0, 
(4.10) 
where e  >  0 is a parameter. This equation has been used to represent certain  electronic 
oscillators. 
If in (4.9), f(x)  ^  0, we obtain 
X  +  g(x)  =  0. 
(4.11) 
When xg(x)  >  0 for all x  9^  0," then  (4.11) represents various models of so-called  ""mass "
"on a nonlinear spring."" In particular", if g(x)  =  ^(1 + a^x^)x,  where ^  >  0 and a^  >  0 are 
parameters, then g represents the restoring force of a hard spring. If g(x)  = 
k(l-a^x^)x, 
where  ^  >  0 and  a^  >  0 are parameters,, then g represents  the restoring  force  of  a  soft 
spring.  Finally, if g(x)  =  x, then g represents the restoring force of a linear spring.  (See 
Figs.  1.5  and  1.6.) 
For another special case of (4.9), let f(x)  =  0 and g(x)  =  k sin jc, where  /: >  0 is a 
parameter. Then  (4.9) assumes the  form 
X +  ^ sin X =  0. 
(4.12) 
This equation  describes  the motion  of a point mass moving  in a circular path  about  the 
axis of rotation normal to a constant gravitational field,  as shown in Fig.  1.7. The param 
eter k  depends  on the radius  / of the circular path,  the gravitational  acceleration  g,  and 
the mass. The symbol x denotes the angle of deflection  measured from  the vertical. The 
present model is called  a simple  pendulum. 
//////// 
FIGURE  1.5 
Mass on a nonlinear  spring 
9(x)i 
/ 
V-X 
/ 
17 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(a) Soft spring 
(b) Hard spring 
(c) Linear spring 
FIGURE  1.6 
Letting  x\  =  x  and  X2 =  x,  the  second-order  ordinary  differential  equation  (4.9) 
can be represented by the system of  first-order  ordinary differential  equations given by 
Xi  =  X2 
Xl  =  -f(Xi)X2 
- 
g(Xi). 
(4.13) 
The required initial data for  (4.13) are given by  xi(0)  and X2(0). 
FIGURE  1.7 
Model of a simple  pendulum 
*1.5 
M O RE  M A T H E M A T I C AL  P R E L I M I N A R I ES 
At  this  point,  v^e  need  to  review  additional  material  from  the  calculus  and  anal 
ysis. 
A.  Sequences 
Let /  denote  an  index  set  (usually  the  set of positive  integers). A  sequence 
a  real  sequence) 
such  a  sequence  by  {x„}, rather  than  {/(n)}. 
in 7^ (i.e., 
is  a  mapping  of /  into  R,  say,  f{n)  =  x„.  It is  customary  to  denote 
*Throughout the book, starred sections, subsections, or items may be omitted to conserve time without 
loss of continuity. 
18 
Linear Systems 
Let  {xn}  be  a  sequence  in  R,  n  =  1, 2, 3 , . . .,  and  let  ni,  n2,...,  n^,...  be  a 
j.  Then 
strictly increasing sequence of positive integers, i.e., ni  >  Uj whenever  /  > 
the sequence {x„J  is called a subsequence  of {x„}. 
Recall  that  a real  sequence  {xn} is  said  to  converge  to  an  element  in  R  if  for 
every 6  >  0 there is an integer N  such that for all n  >  N,\x-  Xn\ <  e. In general, A^ 
depends  on e, i.e., N  =  N(€).  We call x the limit  of {x„}, and we usually  write this 
as lim„_>oo Xn =  x  or Xn -^  x  as n ^  ^.  If there is no x  E  /^ to which the  sequence 
converges, then we say that {xn}  diverges. 
A real sequence {xn} is said to be a Cauchy sequence  or a fundamental  sequence 
if for  every  e  >  0 there is an integer A^ =  N(e)  such that  |x^  -  x^|  <  e  whenever 
m,n^N. 
It  is  easy  to  show  that  every  convergent  sequence  is  also  a Cauchy  sequence. 
One  of  the  fundamental  results  in  analysis  shows  that  for  R,  the  converse  to  this 
statement is also true: every real Cauchy  sequence is a convergent  sequence  (i.e., it 
converges  to an element in R).  To express  this property,  we say that R is  complete. 
Other important fundamental  properties that follow  from  the completeness  of R  in 
clude the Bolzano-Weierstrass  (B-W) property  and the Heine-Borel  (H-B)  property. 
The  B-W  property  states  that  every  bounded  sequence  of  real  numbers  contains  a 
convergent  subsequence. 
To present the H-B property,  we require the following  additional concept: by a 
finite (or countable, or uncountable)  open  covering  of a set £  C  /^ we mean a finite 
(or countable, or uncountable) collection {Ga} of open sets such that E  C  UaGa.  The 
H-B property  states that every open covering of a compact set K contains 3. finite open 
subcovering of K.  (Recall that aset  K  C  Ris  compact  if it is closed and bounded.) 
B.  Sequences  of  Functions 
Next, we consider sequences  of functions.  For our purposes," we let £"" be a nonempty "
subset of ^,  and we let {/„}, n  =  1, 2, 3 , . .. denote a collection of real-valued  func 
tions defined  on E  (i.e., for  each  n  G I,  where /  denotes the positive integers, there 
is a mapping  fn  :  E  -^  R). 
We say that the sequence of functions  {fn} is pointwise  convergent  to a  function 
/  on E,  if  lim^^oo fn(t)  =  f{t)  for  all  t  G E,  i.e.,  if  for  every  e  >  0  and  for  every 
t  E  E  there exists an integer N  that may depend on e  and t [i.e., N  =  N(e,  t)] such 
that  1/^(0  -  f(t)\  <  e whenever  n>  N. 
The sequence {/„} is said to converge  uniformly  to a function/  on E if for  every 
6  >  0 there is an integer N that depends only on e  [i.e., N  =  N(e)]  such that 1/^(0  ~ 
f(t)\  <  e  whenever  n>  Nfor  all t  G  E. 
For example, the sequence {/„} specified  by 
fM 
^ t\ 
0  <  r <  1, 
(5.1) 
is pointwise  convergent  to the  function 
but  it  is  not  uniformly  convergent  to /.  Note  also  that  whereas  for  each  n  = 
fn  in  (5.1)  is  continuous  on  E  =  [0, 1], the  limiting  function/  in  (5.2) 
1,2,..., 
is not continuous on  E. 
As another example, we note that the sequence {/„} specified  by (^  =  1, 2,  3 , . . .) 
19 
fn(t) 
^ 
t+ 
1 
-, 
n 
- 00  <  r  <  00 
is pointwise  convergent  and  uniformly  convergent 
to the  function 
f{t)  =  t, 
-co  <  t  <co. 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(5.3) 
(5.4) 
Note  also  that  in the  above  example,  the  / „,  n  =  1, 2, 3 , . .. given  in  (5.3)  as  well  as 
/  given  in  (5.4)  are  continuous  on  R. 
THEOREM  5.1.  Let  /„  G  C(E,  R),  n  =  1, 2 , . . .,  and  assume  that  the  sequence  {/„} 
converges uniformly  t o/  on E. Then  /  G  C{E,  R). 
Proof,  Let  to G E.  We must  show  that  lim^^^^ f(t)  =  f(to),  or equivalently,  we  must 
show  that for  every  e  >  0, there  exists  a 8  =  8(6, to) >  0 such  that  \f(t)  -  f(to)\  <  e 
whenever  |^ -  ^o| <  ^• 
Since  /„  converges  t o/  uniformly  on E,  given  e  >  0, there exists N  =  N(e)  such 
that  \fN(t)  -  f(t)\  <  e/3  for  all  t  G  E.  Also,  since  fN  G  C(E,  R),  there  exists  8  = 
8(e,  to) >  0  such  that  |/iv(0  -  /iv(^)|  <  ^/3  whenever  \t -  to\ <  8.  Therefore,  when 
ever  1^  -  ^1 <  8, we have 
1/(0  -  /(^0)|  =  1/(0  -  fN(t)  +  fN(t)  -  fN(t0)  +  fN(to)  - 
f(to)\ 
^  1 / (0  - 
€ 
€ 
/ v ( 0|  +  | / v (0  - 
€ 
<  3 +  3 +  3  = e. 
fN(to)\  +  \fN(to)  ~ 
f(to)\ 
THEOREM  5.2.  Let  /„  G  C(E,  R), n  =  1, 2 , . . .,"  and £"" be a bounded  subset of R.  As "
sume that the sequence {/«} converges uniformly  t o/  on E.  Then 
lim 
fn(t)dt 
\imfn{t)dt  = 
f(t)dt. 
"E  ""-^°° "
JE 
(5.5) 
Proof  We  have 
fn(t)dt- 
f(t)dt= 
Unit)- 
fit)]  dt. 
E 
JE 
JE 
Also,  let  /  =  (a, b)  denote  a  bounded  interval  with  the  property  that  J  D  E  and  let 
L(J)  =  (b-  a). 
Since f  converges t o/ in t, uniformly on a bounded set E, we can choose for a given 
e  >  0  an  A^ =  N(€)  such  that  \fn(t)  -  f(t)\  <  elL{J)  for  dXX  t  G E  whenever  n>  N. 
Therefore, 
fn(t)dt- 
f(t)dt 
\fn(t)-f(t)\dt 
UJ)  = € 
L(J) 
whenever  n>  N. 
As  an  example,  consider 
fn{t)  = 
0^ 
t  ^  n, 
n  <  t, 
n  =  1, 2, 3, 
The  sequence  {fn}  converges  uniformly  to the function  f(t)  =  0  for 
20 
Linear Systems 
all t. It is easily  shown that 
while 
fn(t)dt  =  1 
r  OC 
lim 
7 1 -^  CO  0 
r  00 
lim/„(0^^  =  0. 
Jo  n^oo 
Theorem 5.2 does not apply in this case, since the interval E is not  bounded. 
As another example, consider 
fn(t)  =  n^te~''\ 
0  <  ^ <  1, 
n  =  1, 2, 3, 
in this case that 
The sequence {/„} converges pointwise on [0, 1]. It is easily  shown 
while 
lim 
fn(t)dt  =  1 
lim  fn(t)dt  =  0. 
Jo  «-^°° 
Theorem  5.2  does not apply  in this case, since {/„} is not uniformly  convergent  on 
[0, 1]. 
The point of the above two examples is this: in the case of sequences of functions, 
care must be taken when interchanging  limits and  integration. 
The  next  result  is  called  the  Cauchy  criterion for  the  uniform  convergence  of 
functions. 
THEOREM 5.3.  Let fn'.E-^  R, n  =  1, 2, 3, 
The sequence of functions  {/„} con 
verges uniformly  on E if and only if for every e > 0 there exists an integer A^ =  N(e) 
such that \fn(t) -  fm(t)\ < € for Sillt G E whenever n>  N and m>  N. 
Proof. Assume that {/„} converges uniformly  on E to the limit function /.  Then there 
exists an integer A^ =  N{e) such that when n>  N,we  have 
l / « ( 0 - / ( O l <| 
foralUG^. 
This implies that 
"\fn(t) -  fm(t)\ =  \fn(t) ""  f(t)  + f(t)  "" "
fM\ 
^\fn(t)-f(t)\ 
+ 
\f(t)-f^(t)\<e 
for all r E £• whenever n>  N and m>  N. 
Conversely, assume that the Cauchy condition holds, i.e., for all t E. E, 
\fn{t) -  f^{t)\  < e 
when n^  N,m^  N. 
(5.6) 
This implies that the sequence {/n(0} converges, for every ^ E £•, to a limit that we 
call f(f).  (This follows  since in R, every Cauchy sequence converges to an element in 
R.) We must show that this convergence is uniform.  To this end, we let e >  0 be given 
and pick A^ >  0 so that (5.6) holds. Fix n and let m ^  ^  in (5.6). Since fmit) -^  f(t),  as 
m ^  00, this yields for all t G. E, 
\fn(t)-f(t)\^e 
foralln^A^. 
• 
C.  The Weierstrass  M-test 
For an  infinite  series  of real-valued  functions  written  X j =i  fj(0^  with each  fj  de 
"fined  on  a  set £"" C  R",  convergence  is  defined  in  terms  of  the  sequences  of  partial 
sums, 
21 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
n 
Sn{t) = 
^fj(t). 
7 = 1 
The  series  2 J =i  fn(t)  is  said  to  converge  pointwise  to  the  function/  if  for  every 
t  GE, 
Km 
=  0. 
7 = 1 
Also, the  series Xj  = i fj(t)  is  said to converge  uniformly  tofonE 
of partial sums {sn} converges uniformly  t o/  on E. 
The next result is called the  Weierstrass  M-test. 
THEOREM 5.4.  Let fn'. E ^  R,n  =  \,2,3, 
stants Mn  such that \fn{t)\  <  Mn for dXXt GE  and 
Suppose there exist nonnegative con 
if the  sequence 
XM„  <  00. 
Then the sum X^=i /n(0 converges uniformly on E. 
Proof, If  X^=i Mn converges, then for  arbitrary  6 >  0, there are m >  /2 sufficiently 
large so that 
Y\fM 
j = n 
m 
The uniform convergence of X^= i fn{t) follows now from Theorem 5.3. 
*1.6 
EXISTENCE OF SOLUTIONS OF INITIAL-VALUE PROBLEMS 
In  this  section  we  address  the  following  question:  under  what  conditions  has  the 
initial-value problem  (/)  at least  one solution  for  a given  set of initial data  (to,  XQ)! 
The significance  of this question is illustrated by the following  two examples. 
1.  For the initial-value  problem, 
X =  g(x), 
x(0)  =  0, 
t^O, 
(6.1) 
where 
I, 
g(x)  =  0, 
X  =  0, 
X ^  0, 
no differentiable  function  cf) exists that satisfies  (6.1). Hence, no solution  (as de 
fined in Section  1.3)  exists for this initial-value  problem. 
22 
Linear Systems 
2.  The initial-value  problem, 
x  =  x^'^, 
xit^)  =  0 
(6.2) 
has the  solution  (j){t) =  [2it  -  ^)/3]^^^  (determined  by  separation  of  variables). 
This solution is not unique since i//(0  =  0 is clearly also a solution. 
To  simplify  our  presentation,  we  will  consider  in  this  section  and  in  Sections 
1.7  to  1.9  one-dimensional  initial-value problems  [i.e., we will assume that for  (/), 
n  =  I]. Later, we will  show how these results  are modified  for  higher  dimensional 
systems.  Thus,  we  have  a domain  D  C  R^,  f  E  C{D, R),  we  are  given  the  scalar 
differential  equation 
X =  fit,  x), 
(E') 
we are given the initial data (to, XQ) G D, and we seek a solution  (or solutions) to the 
one-dimensional  initial-value  problem 
In doing so, it suffices  to find a solution of the integral  equation 
X =  f(t,  X\ 
x(to)  =  XQ. 
m  =  xo^ 
f  f(s,cl>(s))ds. 
J to 
(/') 
(V) 
We will solve the above problem in stages. First, we establish an existence result 
for  a  sequence  of  approximate  solutions  of  (/').  Next,  we  show  that  this  sequence 
converges to the actual  solution of (/'),  using  a preliminary  convergence result. We 
will establish this preliminary  result first. 
A.  The Ascoli-Arzela  Lemma 
We will require the following  concepts. 
DEFINITION 6.1.  Let ^  be a family of real-valued functions  defined on a set £  C R. 
(i)  9^ is called uniformly bounded if there is a nonnegative constant M such that \f{f)\  < 
M for 2i\\t^E  and for all /  G  9^. 
(ii)  ^  is called equicontinuous on E if for every € >  0 there isaS  = 6 ( e ) >0  (inde 
pendent of t\, t2, and/)  such that |/(^i)  -  /(^2)| <  ^ whenever |ri  -  ^2! <  ^ for all 
tut2  G£  and for a l l/  G 9^. 
• 
The next result is known as the Ascoli-Arzela  Lemma. 
THEOREM 6.1.  Let £ be a closed and bounded subset of R and let {/^} be a sequence 
of functions in C(E, R). If {/m} is equicontinuous and uniformly bounded on E, then there 
is a subsequence {m^} of {m} and a function  /  G C(E, R) such that {/m^} converges to/ 
uniformly on E. 
"Proof. Let {r^} be a dense subset of £"" (i.e.", {r^} =  E). (For example, let {r^} be the enu 
meration of the rational numbers contained in an interval [a, b] C R.) The sequence of 
real numbers {/m(^i)} is bounded since {/^} is uniformly bounded on E. By the Bolzano-
Weierstrass Theorem (see Section 1.5), {fm(ri)} contains a convergent subsequence that 
we label {/im(^i)}- We denote the point to which this subsequence converges by  /(ri) 
and the sequence of functions obtained in this way by {fim}- Consider next the sequence 
of real numbers {/im(^2)}, which is also bounded and contains a convergent subsequence 
that we label {/2m(^2)}- We denote the point to which {/2m(^2)} converges by /(r2) and 
23 
CHAPTER 1: 
Mathematical 
Descriptions of 
Systems 
we  label  the  sequence  of  functions  obtained  in  this  way  by  {fim}-  Continuing,  we  ob 
tain the subsequence {/^^}  of the sequence {fk-i,m}  and the real number  /(r^)  such that 
fkmiXk) -^  fi^k)  as  m ^  00 for  ^  =  1, 2, 3, 
Since  the  sequence  {fkm} is  a  subse 
quence of all the preceding  sequences {fjm} for  1 <  7 <  /: -  1, it will converge at each 
point Kj  with  1 <  j  <  /:. 
Next," we generate a subsequence by  ''diagonalizing""  the preceding infinite  collec "
tion of sequences. In doing so, we set gm  =  fmm for  all m. If the terms  fkm are  arranged 
as the elements of a semi-infinite  matrix, as shown in Fig.  1.8, then the elements gm are 
the diagonal elements of this matrix. 
Since [gm] is eventually  a subsequence of every sequence {fum}, we have gmirk)  -^ 
f(rk)  as m ^  00 for  /:  =  1, 2, 3,  We now  show that {gm} converges uniformly  on  E. 
Fix e  >  0. For any rational number  rj  G E  there exists Mj  =  Mj{e)  such that  {gmiXj)  ~ 
Sn{rj)\ <  e for all m,n>  Mj(e).  By the equicontinuity of {/„}, there is a 5  >  0 such that 
\gn(ti) -  gn(t2)\ <  € foY all u whcu ti, t2 E:  E  and 1^1  -12\  <  8. Therefore, for  \t -  rj\  < 8 
and m,n^  Mj{e),  we have 
\gm(t)  -  gn{t)\  < 
"\gm{t)  ""  gm{rj)\  +  \gm{rj)  ""  gn{rj)\ "
+  \gn{rj)  -  gn{t)\  <  3e. 
8} covers 
By construction, the collection of neighborhoods B{rj,  8)  =  {t E  R'.\t-rj\< 
E  (i.e.,  Uy B(rj, 8)  D E).  Since  Eh  a  closed  and  bounded  subset  of R  (i.e.,  since  E  is 
compact), by the Heine-Borel Theorem there is ?i finite subcollection of the above neigh 
borhoods, say, {B{rji, 8),...,  B(rjL, 8)} that covers E, i.e., B(rji,  5) U • • •  U B(rjL, 8)  D  D 
(see  Section  1.5).  Let  M(e)  =  max{M;i(e),..  .,MJL(€)}. 
If  m  and  n  are  larger  than 
M(e),  and  if  t is  any  point  in  E,  then  t  E  B(rji, 8)  for  some  /  G  { 1 , . . .,  L}.  Therefore, 
IgmiO  ~  gn(t)\  <  36  for  all  ^ E  £• whenever  m,n>  M(e).  This  shows  that  {gm} con 
"verges  uniformly  on £"" to a function/",  by  Theorem  5.3. Furthermore,  /  E  C(E,  R)  by 
Theorem 5.1. 
• 
/ll  /12  /l3  /l4 
/2I 
/23  /24 
/3I  /32  /33  /34 
fll 
FIGURE  1.8. 
Diagonalization  of a collection of  sequences 
B.  6-Approximate  Solutions 
We will require the following concept. 
DEFINITION6.2.  A real-valued function  (p defined and continuous on a ^-interval J  = 
(a, b) containing  ^  is called an e-approximate  solution of (/')  if <^(^)  =  XQ  and 
(i)  {t, (/)(0)  E  D for  all t  E  /; 
(ii)  (j)  has  a continuous  derivative  on /  except  possibly  on  a  finite  set /  of points  in J 
where there are jump discontinuities  allowed; 
(iii)  |(/)(0 -  f{t,  c/>(0)| <  e  for alU  E  /  -  /. 
• 
Recall  that if /  in the  above  definition  is not empty,  (j) is  said  to have 
apiecewise 
continuous  derivative  on  J. 
24 
Linear  Systems 
Now  let 
S  =  {{t,x)  eD: 
\t-to\  < a, 
|JC-JCO|  <b} 
(6.3) 
be  a  fixed  rectangle  in D  containing  (^0,-^0), as  shown  in Fig.  1.9.  Since /  G  C{D^R), 
it is bounded  on  S  and  there  is  an M  >  0  such  that  \f{t,x)\  <M  for  all  {t,x)  e  S.  We 
define  (see  Fig.  1.9) 
mm 
b 
""" 'M "
(6.4) 
We  now  prove  the  following  existence  result. 
xo  + b 
rs LZ y^.xo) 
\\ 
xo + b 
to + a 
{to^Xo)^^^>^ 
to + a 
(a) 
(b) 
FIGURE  1.9 
(a) Case c = b/M,  (b) case c = a 
THEOREM 6.2.  If f  eC{D,R)  and if c is as defined  in (6.4), then for  any  e >  0 there 
is an e-approximate  solution of  (/')  on the interval  |^ — ^o|  <  c. 
Since  / 
is  continuous  on  S,  a  closed  and  bounded  set,  then  / 
Proof,  Given e >  0, we shall show that there is an e-approximate  solution on  [^o, ^0 +  c]. 
The proof  for  the interval  [^0 — c, to]  is  similar.  The  approximate  solution  will be  made 
up of a finite number of straight line segments joined at their ends to achieve continuity. 
is  uniformly 
continuous  on  S.  Hence,  there  is  a  5  >  0  such  that  \f(t,x)  — f(s,y)\  <  e  whenever 
(t,x)  and  (s,y)  are  in  S  with  \t — s\  <  d  and  \x — y\  <  d.  Now  subdivide  the  interval 
[^0, ^0 +  c] into m equal subintervals by a partition  ^0 <  ^1 <h  <  • • •  <tm  = to-\-c,  where 
tj^i  — tj  < min{5, d/M}  and where M  is the bound  for /  given above. On the  interval 
let  ^(t)  be  the  line  segment  issuing  from  (^o,-^o) with  slope  /(^o,-^o)-  On 
to <t  <ti, 
h  <  t  <  t2,  ^Qt (j)(t) be  the  line  segment  starting  at  (^1,^(^1))  with  slope 
f{t\,(^{t\)). 
Continuing  in  this  manner,  we  define  0  over  to < t  <  tm-  A  typical  solution  is  shown 
in  Fig.  1.10.  The  resulting  <p  is  piecewise  linear  and  hence  piecewise  continuously 
differentiable  and (l){to)  =xo.  Indeed,  on tj  <t  < tj^i  we have 
(^it)  =  ^{tj)+f{tj,^{tj)){t-tj). 
(6.5) 
Since the slopes of the linear segments in (6.5) are bounded between  ±M, then  (^  0(0) 
cannot leave S before  time tm = to-\-c  (see Fig.  1.10). 
To see that  0  is an 6-approximate  solution,  we use (6.5) to obtain 
\<i>it)-f{t,<l>{t))\ = 
\fitj,cj>itj))-fit,cj>it))\<e. 
This inequality  is true by the choice of  5,  since  \tj -
•t\<\tj-
-tj^i\  <  5  and 
\(t>it)-Htj)\<M\t-
-tj\  <M 
d. 
This completes the proof. 
25 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(^0. ^o) 
FIGURE 1.10 
Typical e-approximate 
solution 
^0+^ 
The approximations  defined  in the proof  of Theorem  6.2  are called Euler  poly 
gons,  and (6.5) with t  =  tj+i  assumes the  form 
0(O+i)  =  ^(0)  +  f(^P  ^(0))(0+i  -  0)^ 
(6.6) 
which  is  called  Euler's  method.  This  technique  and  more  sophisticated  piecewise 
polynomial  approximations  are common  in determining  numerical  approximations 
to solutions of (/')  via computer  solutions. 
C.  The  Cauchy-Peano  Existence  Theorem 
We are now in a position to state and prove the main result of this  section. 
THEOREM 6.3.  If /  G C{D, R) and (^0, -^o) G D, then (/')  has a solution defined on 
\t -  to\  ^  c [where c is defined in (6.4)]. 
Proof. Let  {e^},  m  =  1, 2,...  be  a monotone  decreasing  sequence  of positive num 
bers  tending  to  zero,  e.g.,  6^  =  l/m.  Let  c  be  defined  in  (6.4)  and  let  c/)^ be  the 
"e^-approximate solution given in Theorem 6.2. Then |0m(O """" <Pm(s)\  ^  M\t -  s\ for all "
t, s in [to  -  c,to + c] and for all m >  1. Therefore, {(f)m} is an equicontinuous sequence. 
Now since 
\ct>m(t)\ 
n(to)\  +  \(l>m(t)  - 
(t>m(to)\  ^  k o|  +  Mc, 
the sequence is also uniformly  bounded. By the Ascoli-Arzela Lemma (Theorem 6.1) 
there is a subsequence {(/>mj that converges uniformly on /  =  [^o -  c, ^  + c] to a con 
tinuous function  0. 
Next, define 
emit)  =  (f)m{t)  - 
fit, 
(j)mit)) 
(6.7) 
at those points where 4>m exists. From the proof of Theorem 6.2, em is piecewise contin 
uous and \emit)\  ^  6^ on 7 where 4>m exists. Integrating (6.7) and rearranging terms, we 
obtain 
(t>mit)  =  ^0  + 
[ / ( ^,  (t>mis))  +  emis)] 
J to 
ds. 
(6.8) 
26 
Linear Systems 
Now since {4>mj} tends to cf) uniformly on /, and since/ is uniformly continuous on 
^^^ ^^^ '^ [defined in (6.3)], it follows that f(t,  (l>mj,(t)) tends to f(t,  (f){t)) uniformly on /. 
To see this, we note that for every 6'  >  0 there is an A/^ =  N{d') such that |(^^^ (0 - 0(01 < 
3'  for allr  E  /  whenever  k > N,  and also, for  every e  >  0 there is a 6  =  6(e)  such 
that for all t E  J, \f{t, p)  -  f(t,  q)\ < e for all (t, pi  (t, q) e  S whenever  \p -  q\ < 8. 
Pick A^ large enough so that  |6m^(0 ~  </>(0l < ^  for  alH  E  /  whenever  k>  N.  Then 
\fit,  (l)m^(t))  -  fit,  0(0)1 <  e for all f E /  whenever k>  N. 
Using Theorem 5.2, we now obtain 
lim  I  f(s,(l)^^(s))ds  =  \ 
s =  I  \imf(s,4>mk(s))ds 
\imf(s,(l)mk(s))ds 
(6.9) 
f(s,cl,(s))ds, 
to 
Also, observing that 
em^(s)ds<\ 
\em,^(s)\ds  =  \  e^^ds  <  €mj^c 
JtQ 
JtQ 
JtQ 
and recalling that lim^^^oo 6^^  = 0,  we obtain 
lim  I  em,^(s)ds  = 0. 
(6.10) 
Letting in (6.8) m  = rrik and using (6.9) and (6.10), we finally obtain 
lim 0^,(0  =  m  =  xo +  f  f(s,cl>(s))ds, 
(V) 
• 
which completes the proof. 
"Theorem  6.3  establishes  the  existence  of  a  solution  of  (/')  ""locally",''  i.e.,  only 
on some sufficiently  short time interval. In general, this theorem cannot be  changed 
to assert  the  existence  of  a  solution  for  all  t  >  to or for  all  r <  ^Q. As  an  example, 
consider the initial-value  problem 
X =  1 -\-  x^, 
x(0)  -  jco  =  0, 
which has a solution given by (pit)  =  tant.  This solution exists only when  -7r/2  < 
t  <  77/2. 
*1.7 
CONTINUATION  OF  SOLUTIONS 
Once the existence of a solution of an initial-value problem has been established over 
some time interval, it is reasonable to ask w^hether this solution can be extended to a 
larger time interval. We call this process continuation  of solutions.  In this section we 
address this problem for the scalar initial-value problem  (/'). We shall consider  the 
continuation  of  solutions  of  an initial-value  problem  (/)  characterized  by  a  system 
of equations later (in Section  LIO). 
A.  Zorn's  Lemma 
In the proof  of the main result of this  section,  we will require  a fundamental  result 
from analysis, called Zorn's Lemma, that we will present without proof. To state this 
lemma, we need to introduce the following  concepts. 
K partially  ordered set {A, 
:) consists of a set A and a relation <  on A such that 
for any a, b, and c in A, 
1.  a ^  a, 
2.  a ^  b and Z?  <  c implies that a 
3.  a  <  Z? and b ^  a implies that a  b. 
27 
CHAPTER 1: 
Mathematical 
Descriptions of 
Systems 
A chain is a subset AQ of A such that for all a and b in AQ, either a ^  b or b ^  a. 
An wp/^^r bound for a chain AQ is an element ^o E A such that b ^  ao for all Z?  E  AQ. 
A maximal  element  for A, if it exists, is an element ai  of A such that for all b in A, 
a\  ^  b implies (3i  =  b. 
THEOREM 7.1.  (ZORN'S LEMMA).  If each chain in a partially ordered set (A, <) 
has an upper bound, then A has a maxiinal element. 
• 
B.  Continuable  Solutions 
"Now let (/) be a solution of (£""') on an interval /. By a continuation  of cf) we mean an "
"extension (j)o of (/) to a larger interval  /Q in such a way that the extension solves (£""') "
on  JQ\ then (/) is said to be continued  or extended  to the larger interval  JQ. When no 
such continuation is possible, then cf) is called  noncontinuable. 
To illustrate  these  ideas,  consider  the differential  equation  x  =  x^  that  has a 
solution 
"0(0  -  (1 - 0 "" ^ o n/  =  (-1",1). 
This  solution is continuable to the left  to -oo and is noncontinuable to the right. As 
a second example, consider the differential  equation x  =  x^^^ that has a solution 
il/(t)^OonJ  =  (-1,0). 
This  solution  is continuable  to the right  in more  than  one way. For example,  both 
i/^i(0  =  0 and il/2(t) =  {ItH^f^  are solutions of i:  =  x^'^ for t >  0. The solution ip 
can also be continued to the left  using  ijj^it) =  0 for alW < - 1. 
THEOREM 7.2.  Let /  E C{D, R) with/ bounded on D. Suppose (/> is a solution of {E') 
on the interval J  = (a, b). Then 
(i)  the limits 
lim  (j){t) 
<t>{a^) 
and 
lim  (/)(0 
cj>{b-) 
exist, and 
(ii)  if {a, (f)(a'^))  [respectively, (Z?, (t>(b'))] is in £), then the solution 0 can be continued 
to the left past the point t  = a (respectively, to the right past the point t  = b). 
Proof, We give the proof for the endpoint b. The proof for the endpoint a is similar. Let 
M be a bound for \f{t, x)\ on D, fix ^o E /, and let (f){t{y)  = XQ. Then for to < t < u < b 
the solution 0 satisfies (V),  and thus. 
|c^(^^) -  ml  = 
f(s,ct>(s))ds 
\f(s,cl,(s))\ds 
(7.1) 
Mds  = M(u -  t). 
28 
Linear  Systems 
Given  any  sequence  {tm} C  (to,b)  tending  monotonically  to  Z?,  we  see  from  (7.1) 
^^^^  {4^(^m)}  is  a  Cauchy  sequence,  and  therefore,"  the  Hmit  (/>(/?"")  exists  (see  Sub "
section  1.5 A). 
Next,  if  (b, (i>{b~))  G  D,  then  by  Theorem  6.3  there  is  a  solution  (/)o of  (£')  that 
satisfies  (/>o(^)  =  4>(b~). The solution (/)o will be defined on some interval Z?  <  t  ^  b + c 
for  some  c  >  0. Define  (f)o(t) =  (j){t)  on a  <  t  <  b. Then  cf^o  is  continuous  on a  <  r  < 
b  + c and  satisfies 
(/>o(0  =  -^0 +  [  f(s,  (l)o(s))ds, 
a<t<b, 
(7.2) 
and 
"(/)o(0  -  (^(Z?"") 4- "
Jb 
f(s,  (l)o(s))ds, 
b  <  t  <  b  + c. 
The limit of (7.2) as t tends to b is seen to be 
"(/>(/?"")  =  xo + "
f{s,(l)o(s))ds. 
JtQ 
Therefore, 
(j)Q{t)  =  xo+\ 
Jto 
f(s,(l)o(s))ds  + 
Jb 
f(s,(l)o{s))ds 
=  ^0 + 
f(s,  (t)o(s)) ds, 
b  <  t  <  b +  c. 
Jto 
Hence, </>o  solves (V)  ona  <  t  <  b + c, and therefore,  (J)Q  solves (/')  ona  <  t  <  b +  c. 
C.  Continuation of Solutions to the Boundary of D 
We are now in a position to prove the following result. 
THEOREM  7.3.  If  /  G  C{D, R)  and  if  (/) is  a  solution  of  (E')  on  an  open  interval  7, 
then  (/) can be continued  to a maximal  open interval  /*  D 7 in such a way that  {t, (pit)) 
tends to dD  ast-^ 
extended  solution (^* on /*  is noncontinuable. 
(?/* when o'D is not empty  and  \t\  + \4>(t)\ -^  (^ifdD 
is empty. The 
Proof,"  Let 0  be a given solution of (£"") on J.  The graph  of (/> is the  set "
Gr(cl>)  =  {(t, m) 
-t^Jl 
Given  any  two  solutions  (j)\ and  (/>2 of  {E')  that  extend  </>, we  define  ^\  <  (/>2 if  and 
only  if  Gr((pi)  C  Gr{4>i)^  i.e.,  if  and  only  if  (f)2  is  an  extension  of  cpi. The  relation  < 
determines  a partial ordering  on continuations  of (f) over open intervals. If {4>a  : a  G A} 
is any chain of such extensions, then  U{Gr((/)Q,) : a  G A} is the graph of a continuation of 
(j) that we call (/)A. This (pA is an upper bound for the chain. By Zorn's Lemma  (Theorem 
7.1)  there  is  a maximal  element  (/>*. Clearly,  c^* is  a  noncontinuable  extension  of  the 
original  solution (/>. 
Now let 7* denote the domain of (/>*. By Theorem 7.2 the interval /*  must be open, 
for  otherwise  0*  could not be maximal.  Call /*  =  {a, b). If  b  =  ^,  then we know  that 
D is unbounded and \t\ + |0(O| -^  o^ as r ^  b~.So  let us assume that b  <^  and assume, 
for  purposes  of  contradiction,  that  (t, </>*(0)  does  not  approach  dD  on  any  sequence 
{tm} that  approaches  b~.  Then  (t, (p^it))  must remain  in  a compact  subset K  of D  when 
^ E  [c, Z?)  for  any  c  G  (<2, b).  Since/  must  be bounded  on K,  then  by  Theorem  7.2  we 
can continue (/)*past b. But this is impossible since (^*is noncontinuable. We have shown 
that {t, (/)*(0) must approach SD on some sequence {tm} that approaches b~. 
We now claim that {t, (^*(0) -^  dD as r ^  h~ .\i  this is not the case, there exists 
a sequence {T;„} that approaches h~, and a point (Z?, ^)  E^  D such that (t)^{Tm) —>  ^. Let 
e be one-third the distance from {b, ^) to dD. We can assume without loss of generality 
that Tm<tm<  Tm+x,  (T^, (/>*(T^))  ^  5((Z?, ^  e\  and (^^, (/>*(r^)) £  5((Z7, ^), 2e) for all 
m >  1. Let M be a bound for \f{t, x)\ over ^((Z?, ^), 2e). It now follows from the proper 
"ties of (£"") that "
29 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
"/fe(^*(5))J^  +  {tm -  Tm) <  (M  -h  \){tm  ""  T^)", 
i.e., ^^ -  T^ >  el{M + 1) for all m. But this is impossible since tm 
conclude that {t, (/>*(0) 
-^dD2iSt->b~. 
The proof for the endpoint t  = ais  similar. 
b  and b < ^. We 
*1.8 
UNIQUENESS  OF  SOLUTIONS 
We now  establish  conditions  for  the  uniqueness  of  solutions  of  initial-value  prob 
lems determined  by  scalar  first-order  ordinary  differential  equations. Later, in Sec 
tion  LIO,  we  will  address  the  uniqueness  of  solutions  of  initial-value  problems 
characterized by systems of first-order ordinary  differential  equations. 
A.  The  Gronwall  Inequality 
We will require the following  preliminary  result on several occasions. 
THEOREM  8.1.  (GRONWALL  INEQUALITY).  Let  r, k  G  C([a,  b], R)  and  suppose 
that r{t) >  0 and k(t) >  0 for all t G [a, b]. Let 6 be a given nonnegative constant. If 
foralU  E  [(3, Z?], then 
r ( 0^  d + 
k(s)r(s)ds 
Ja 
r(t)<  8e^ak(s)ds 
for all r G [a,b]. 
Proof. Let R(t)  =  8 + \^ k(s)r(s)ds.  Then  r(t) <  R(tX R(a)  =  8, R(t)  =  k(t)r(t) 
k{t)R(t), and 
^(0  -  k(t)R(t) <  0 
(8.1) 
for all t G [a, b]. Let K(t)  = e'^a ^(^)^^ Then 
K(t)  =  -k(t)e-^akis)ds ^ 
-K{t)k{t). 
Multiplying both sides of (8.1) by ^(0, we obtain 
K{t)R{t) -  K(t)k(t)R(t)  <  0 
^ 
Linear Systems 
or 
or 
^-(0^(0  + ^ ( 0 ^ (0  ^  0 
j 
-[K(t)R(t)]^0. 
(8.2) 
Integrating  (8.2) from a to t, we obtain 
or 
or 
or 
K(t)R(t)  -  K(a)R(a)  <  0 
K(t)R(t)  -  6 <  0 
e-^i^^'^'^'R(t)-8^ 
0 
r(t)^  R(t)^  8e^ik{s)ds^ 
which is the desired inequaUty. 
• 
B.  Unique  Solutions 
Before  addressing  the uniqueness  issue, we need to introduce  the notion of Lipschitz 
continuity. 
DEFINITION  8.1.  A function  /  E  C(A R), D C R\  is said to satisfy  a Lipschitz  con 
dition  on D (with respect to x) with Lipschitz  constant  L if 
\f(t,x)-f(t,y)\^L\x-y\ 
for all (t, x), {t, y) in D. The function/  is said to be Lipschitz  continuous  mxonD 
case. 
in this 
• 
For  example,  if /  E  C (A R)  and if dfldx 
exists  and is continuous  on D,  then 
/  is Lipschitz  continuous  on any compact  and convex  subset  Do  ofD.  To show  this, 
let  LQ  be a bound  for \(df/dx)(t, 
x)\ on DQ. Let {t, x)  and (t, y) be in DQ. Since  DQ  is 
convex, the straight  line that connects  (t, x) and (t, y) is a subset of DQ,  By the Mean 
Value  Theorem  there is a point z on this  line  such  that 
|/(r,  X) -  fit,  y)\  = 
(t,z)(x-y) 
dx 
Lo|x  -  y\. 
THEOREM  8.2.  If /  G C{D, R) and if/  satisfies  a Lipschitz  condition  (with  respect 
to x) on D with Lipschitz constant L, then the initial-value problem (/') has at most one 
solution on any interval \t -  to\ ^  d. 
Proof,  Suppose for some d > 0 there are two solutions (/>! and (/)2 on |r -  fo| —  d. Since 
both solutions  solve (V)  on ^o — t — to + d, we have 
1^1(0-02(01 
[f(s,Ms))-f(s,Ms))]ds 
to 
< 
JtQ 
\f(s,Ms))-f(s,Ms))\ds 
<  f  L\cl>i(s)-ct>2(s)\ds. 
JtQ 
Applying the Gronwall Inequality  (Theorem 8.1) with k  = L and 8  =  0, it follows  that 
|(/>i(0 -  02(01 ^  0 on the interval to^  t <  to + d. Thus, 0i(O  =  02(0 on this interval. 
• 
The proof for the interval  to -  d ^  t ^  to proceeds  similarly. 
COROLLARY 8.3.  If/  and dfldx  are both in C(A R), then for any (^,  XQ) G D and 
any J containing ^o, if a solution of (/')  exists on 7, it must be unique. 
Proof.  Let (j)\  and (/)2 be two solutions of (/')  on /  and define 
b  = sup{/ >  to  : 01(0  -  02(0}, 
a  = mf{t  <  ro : 0i(O  -^ </>2(0}. 
31 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
We claim that a and Z? are the endpoints of J {dJ  = {a, b}). For if b is not an endpoint 
of/,  then by continuity we would have 01 (Z?) =  (piib). Since (b, 4>\{b))  E Z) and D is a 
domain, we know that there exists 6 >  0 such that 
DQ = {(t, x):\t-b\^ 
e, 
Mb)\^€}ca 
Clearly,  DQ is a compact and convex subset of D. Now from  the comments  following 
Definition 8.1 and Theorem 8.2, we have that 0i(O  =  02(0 for ^ ^  [b,b + e'] for some 
0 <  e'  <  e. This contradicts the definition  of b. We conclude that b is an endpoint of 
7, and so is a. It follows that 0i(O  = 02(O> t ^  J, which implies the uniqueness of the 
solution of (/'). 
• 
Using Theorems 7.3  and 8.2, we can prove the following  continuation  result. 
THEOREM 8.4.  Let /  E  C(J  X  R, R) for some open interval J  C R and let/  satisfy 
a Lipschitz condition on J  X R (with respect to x). Then for any (to, XQ) E  /  X R, the 
initial value problem (/') has a unique solution that exists on the entire interval /. 
Proof, The local existence and uniqueness of solutions 0(/, to, xo) of (/')  are clear from 
Theorem 8.2. Now if 0(0^ 
(V),  and therefore, 
•- (j)(t, to, Xo) is a solution defined on ^  <  t < c, then 0  satisfies 
0(0  -  ^0  = 
[f{s, <f){s)) -  f(s,  Xo)] ds + 
JtQ 
Jto 
f{s,  xo)ds 
and  10(0 -  xo| ^ 
L\<p(s) -  xo\ds + 8, 
where 8  =  [max^Q<^<c \f(s,  xo)\](c -  to). By the Gronwall Inequality, we have 
10(0 -  xol <  6 exp[L(c -  to)l 
to  ^  t < c. 
Hence, |0(O| is bounded on [to, c) whenever 0(0 is a solution defined on [to, c), c E. J. 
Let /  =  (a, b) and assume that 0  is a noncontinuable solution of (/')  that is defined on 
/*  =  (a', b'). We must prove that b'  = b. If this is not the case, we have b' < b. We have 
shown that |0(O| is bounded, say, |0(O| ^  M, for t E  [to, b'). Let D  = J  X [-M  -  1, 
M + 1]. Applying Theorem 7.3, we have that (t, 0(0) -^  dD as ^ -^  b'. Since b' < b, we 
must have |0(O| -^  M + 1 as r ^  b'. But this contradicts our assumption that |0(O| ^  M 
for t E  [to, b'). Therefore, b'  =  b. 
A similar argument works for r <  ^. 
• 
Successive approximation of solution 
If a solution 0  of (/')  is unique, then the e-approximate  solutions constructed in 
the proof of Theorem 6.2 will tend to 0  as e -^  0^, and this is the basis for justifying 
Euler's  method,  a numerical  method  of  constructing  approximations  to  0.  Now^ if 
we  assume  that/  satisfies  a Lipschitz  condition,  an  alternative  classical  method  of 
approximation  is the  method  of  successive  approximations  (also  known  as  Picard 
iterations).  Specifically,  let  /  E  C{D, R), D  C  R^,  and  5' be  a rectangle  in D  cen 
tered  at  (^,  XQ) (see Fig.  1.9),  and  let  c and M  be  defined  by Eq.  (6.4).  Successive 
32 
Linear  Systems 
approximations 
for  (/'),  or  equivalently  for  ( V ),  are  defined  as 
^m+i(0  =  -^0 + 
ft 
ho 
f(s,  (f)m{s))ds, 
m  -  0,  1, 2 , . .. 
(8.3) 
for  |r  -  ^ol  — c. For  this  sequence  {4>m}^  we  have  the  following  result. 
THEOREM8.5.  I f /E  C(A  /?) and if/  is Lipschitz continuous on S (with respect to x) 
with  constant L, then  the  successive  approximations  (f)m, m  =  0, 1, 2 , . ..  given  in  (8.3) 
exist  on  I? -  ^01 — c,  are  continuous  there,  and  converge  uniformly,  as  m ^  oo, to  the 
unique  solution of  (/'). 
Proof.  We  give  the  proof  for  the  interval  ^  <  ^ <  to +  c.  The  proof  for  the  interval 
to -  c  ^  t  ^  to proceeds  similarly. 
Using induction on the integer m, we first prove the following  statements: 
(i)  (j)fn  exists on  [to, to +  c], 
(ii)  (l>meC\[to>to  + 
(iii)  10^(0  -  xo\^  M(t~ 
clRl 
to) on  [to, to + c] 
for  all m >  0. 
Each  statement  is  clearly  true  when  m  =  0.  Assume  that  each  statement  is  true 
for  a  fixed  integer  m  >  0.  By  (iii)  and  by  the  choice  of  c,  it  follows  that  (t, 4>m(t))  £ 
5  C  D  for  all t  G  [^0, to + c]. Therefore,  f(t,  (pmit)) exists  and is continuous  in t, while 
\f(t,  (t>m(t))\  ^  M  on the time interval. This in turn means  that 
4>m+l(t)  =  Xo+ 
\ 
J to 
f(s,(t)m(s))ds 
exists, that (1)^+1  G  C\[to,  to +  c], R),  and that 
\(l>m+l(t)  -  -^ol  = 
f{s,4>m{s))ds 
M{t  -  to). 
This completes the induction on m. 
Next, we define ^mit)  =  4>m+\(t)  -  (t>mit).  Then 
|^m(0| : 
| / ( ^,  (l)m{s))  - 
f{s, 
(t)m-\is))\ds\ 
< 
L\4)m{s)- 
(f)ni-\{s)\ds 
=  L\ 
<tm-\{s)ds. 
Jto 
JtQ 
Notice in particular  that 
l^o(Ol 
f(s,  xo) ds  <  M{t  -  to). 
The above two estimates  show  that 
1^1 (01 ^  L\  M(s-to)ds  = 
JtQ 
LMjt  -  tof 
2! 
and that 
|O2(0|  ^  L 
[LM{s  -  tofl2\]ds  • 
Jto 
L^Mjt  -  tof 
3! 
and, by induction, that 
Therefore, the mth term of the series 
\^m(t)\ 
(m+  1)!  * 
is bounded on the interval [to, to + c] by ^  ^——TTT • Now since 
"M  (Lc)""^^^ "
L  (m+  1)!' 
33 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(8.4) 
nLc 
=  >  ^: 
i-  <  00, 
Ley 
Id 
it follows from the Weierstrass M-test (see Theorem 5.4) that the series (8.4) converges 
uniformly  to a continuous function  (f).  This in turn means that the sequence of partial 
sums 
m 
</>0 +  ^,{4>k+\ 
-  4>k)  =  4>0  +  (<pl  -  M  +  '••  +  (0m+l  -  </>m)  =  4>m+\ 
k = 0 
tends uniformly to (^ as m —>  oo. Since the bound (iii) given above is true for all c/)^, it is 
also true in the limit, i.e., 
10(0 -  xo\ <  M(t  -  to). 
Therefore, f(t,  (p(t)) exists and is a continuous function oft. Using an identical argument 
as in the proof of Theorem 6.3, it now follows that 
(/)(0  =  lim 0^+1(0  = xo+  lim 
f(s,(l)m(s))ds 
=  xo-h  \  f{s,(j){s))ds, 
to <  t ^  to +  C. 
Therefore, (f) solves {V). 
• 
We  will  consider  the  application  of  Theorem  8.5  to  specific  cases  (linear  sys 
tems) in Section  1.13. 
*1.9 
CONTINUOUS DEPENDENCE OF SOLUTIONS ON INITIAL 
CONDITIONS AND PARAMETERS 
In practice  it frequently  happens  that  an  initial-value  problem  may  exhibit  depen 
dence on some parameter  A. An example of such a class of problems is given by 
X =  fit,  X, A) 
X{T)  =  ^, 
(n,.,p 
where /  G  C{J  X  RX  D, R), J  C  Ris  m  open interval, and D  C  R, 
If it is assumed that for each pair of compact  subsets  JQ C  J  and DQ C  D  there 
exists a constant L  =  LJ^,DO >  0 such that for all (t, X) G  JQ X  DQ,  x, y  G  R, 
\f(t,x,X)-f(t,y,X)\^L\x-yl 
(9.1) 
34 
Linear Systems 
then by previous results we know that for every r  ^  J,\E.  D, and ^  G /? the initial-
value  problem  (/{  r  P  ^^^  ^ unique  solution  (j){t) =  (f){ty r, ^, A) that  exists  for  all 
^ E  /.  It turns out that this solution depends continuously on the initial data (T, ^, A). 
We express this in the following  result. 
THEOREM9.1.  L c t /E  C{J XRXD,  R), where J  C Risan  open interval and D C R. 
Assume that for each pair of compact subsets JQ  C J and Do C D, there exists a constant 
L  =  LJQ,DQ  > 0 such that for all (t, X)  E.  JQXDQ,  x,y  G R, the Lipschitz condition (9.1) 
is true. Then the initial-value problem (I'xre^ ^^^ ^ unique solution (pit, r, ^, A), where 
cf)  G C(J  X J  X R X D,R).  Furthermore, if Z) is a set such that for every XQ  G D there 
exists 6 >  0 so that  [XQ  -  e, XQ  + e] H D C D, then </)(^, r, ^, A) ->  (j){t, TQ, ^O> AQ) uni 
formly for ? E 7o as (r, ^, A) -^  (TQ, &, AQ), where Jo is any compact subset of/. 
• 
It  is  because  of  uniform  convergence  that  we  require  the  restrictions  on D  in 
Theorem  9.1. However,  in practice, most  sets that are of interest to us  satisfy  these 
assumptions, including open and closed  sets in R, intervals  such as {a, b\  and  {a, b), 
sequences  such  as {(1/n)  : n  G N},  {0} U {{lln)  : n  G N),  {m  +  (1/n)  : m,n  E.  N}, 
{m : m G A/^} U {m +  (l/n)  \ m,n  EL  N},  and so forth. 
Applying Theorem 9.1 to the initial-value  problem 
X =  f(t,  X, A) 
(n,r) 
where  it  is  assumed  that  ^A  depends  continuously  on  A, we  obtain  the  following 
result. 
COROLLARY 9.2.  Let /  G C(J  X R X D, R), where J  C R is an open interval and 
D C R. Assume that for each pair of compact subsets Jo E J and Do E D there exists a 
constant L  =  LJ^,DQ  > 0 such that for all (t, X)  E  JQ X Do, x,yER, 
the Lipschitz con 
dition (9.1) is true. Then the initial-value problem (/j^^) has a unique solution (/>(?, r, A), 
where  (f)  E  C(J  X J  X D, R). Furthermore, if D is  a set  such  that  for  every  AQ G D 
there exists an 6 >  0 so that  [Ao -  6, Ao  + e] fl D C D, then (/)(^, r. A) -^  (j){t, TQ, AQ), 
uniformly for r G /o as (r, A) -^  (TO, AO), where Jo is any compact subset of J. 
• 
Proof of Theorem 9 J.  For the solution (/>(/, r, ^, A), we first show that 4> E  C(J  X J X 
RXD,  R). By (/{ ^^) we have that 
cl>(t, T, ^, A) =  ^ +  f  f(s,  cl>(s, T, ^, A), A) ds. 
(9.2) 
J to 
We want to show that for (to, TQ, ^O, AQ) G /  X /  X /? X D, 
(l>(tm>  Tm, ^m,  A^)  -^ 
(f)(to,  To, &,  Ao) 
as  {tm, Tm, U> Am) -^  (^0, To, &, Ao), where  (tm, Tm, U,Xm)  E  J  X J  X RXD 
m G A^. By (9.2) we have 
for  each 
(p{tm,  Tm, ^m,  A^)  - 
(j){to,  To, &,  Ao) 
=  ^m  -  &  + 
I 
f{s, 
^{S,  Tm, ^m,  ^m\  Xm)  ds 
f{s,  (f){s, To, &, Ao), Ao) ds 
I 
•^0 
=  ^m  -  &  + 
( / ( 5,  (I>{S,  Tm," ^m>  K\  ^m)  "" "
f(s, 
(^(5,  To, &,  Ao),  A^))  ds 
m. 
{f{s,  ct)(s, To, &, Ao), A^) -  /(5, (t)(s, To, ^0, Ao), Ao)) ds 
+ 
f(s,  (/)(5, To, &, Ao), Ao) ds 
J to 
fTm 
f(s,(l)(s,To,^o,\oXXo)ds. 
Denote 
35 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(9.3) 
{a,b) 
[b,a], 
\fa>b. 
Since fo, '^b £  «/, and 7 is an open interval, it follows that for m sufficiently  large, (T^, tm), 
{to, tm), and (TO, T^) are contained in /.  Also, given  (TO, ^Q, AQ) E. JxjxD, 
(f)(s, To, ^o, Ao) 
is a continuous function  on J. Note that since /  E  C (/  X RXD,  R), we can assume that 
for m sufficiently  large. 
niax  \f(s,  (i){s, To, &, Ao), Ao)| ^  M 
S^{tQ,trn) 
max  1/(5, (/>(5, To, &, Ao), Ao)| <  M 
S&{TQ,Tm) 
and 
for  some M  >  0. 
We now have 
\4>itm,  Tm,  ^m,  ^m) 
"""  </>(^",  ^o,  &,  A o )| 
<  1^^ -  &|  +  M(\tm  -  tQ\  +  \Tm  -  Tol) 
1/(5, 0(5, Tm, ^m, A^), A^) -  f(s,  (t){s, To, &, Ao), km)\ds 
1/(5,  (/)(5, To, &,  Ao),  A ^)  - 
/ ( 5,  (f){s,  To, fo,  Ao),  Ao)|(i5  . 
Without  loss of generality,  we  assume that  ^  >  To. Then  for  m  sufficiendy  large,  there 
exists e  >  0 such that  [TO -  e, ^  +  e]  C  /  and 
\4>itm, Tm, ^m,"  ^m)  ""  4>{k",  To, &,  Ao)| 
< 
\^m  -  &|  +  M{\tm 
"-  k\  +  \Tm  ""  To|) "
1/(5,  (/)(5,  Tm, U,  Xm),"  ^m)  "" "
f{s, 
(^(5,  To, &,  AQ),  A ; „ )|  ds 
1/(5, (^(5, To, &, Ao), Am)  -  f(s,  (j^is, To, ^0, Ao), Ao)| J5 
TQ-e 
+ 
To-e 
"\^rn -  &|  +  M ( | ^^  -  ^1  +  \Tm ""  To|) "
to+6 
1/(5, (/)(5, To, &, Ao), A;„) -  /(5, (f){s, To, &, Ao), Ao)| ds 
rto+e 
+  L 
10(5,  Tm, ^m,"  Am)  ""  0 ( ^",  To, &,  Ao)| <i5. 
By the Gronwall Inequality, we obtain that 
\(t>{tm,  Tm, ^m,  K) 
"""  0(^0",  TQ, &,  Ao)|  < 
"(|^m  ""  &|  +  M{\tm "
"'  ^o|  +  Vm  ""  To|) "
+ 
[ ' ' ^'  1/(5,  0 ( 5,  TO, &,  Ao),  km)  - 
J To-6 
f{s,  0 ( 5,  To, &,  Ao),  Ao)| J5)^^(^0-0+2.)_ 
(9  4) 
36 
Linear Systems 
Since f(s,  cl)(s,  TQ, &, AQ), A) G C([TO  -  eJo  + e]X  RX  {Xj,  R) (with 5, A as variables 
and {A^} C D since A^ ^  AQ G D) and since  [TQ -  6, ^  4- e] x {A;„} is a compact  subset 
of /  X D, we have by Theorem 5.2 and (9.4), as m ^  oo, that 
l im 
\(l)(tm>  Tm, ^m,"  A m) "" "
(/>(^0,  TQ,  &,  A o )|  =  0. 
Thus, 
(I)GC(JXJXRXD,R). 
Similarly,  under  the  assumption  on  D,  we  can  prove  that  </>(^, r, ^, A)  -^ 
<l>(t, To, ^o> Ao),  uniformly  for t  G JQ as (r, ^, A) -^  (TQ, ^O> AQ),  where  JQ is any com 
pact subset of J. In place of (9.3), we have 
(/>(?, To +  AT, & + A^, Ao + AA) -  0(r, ^, &, AQ) 
=  A^ +  [ 
(f(s,  (l)(s, To +  AT, & + A^, Ao + AA), Ao + AA) 
JTQ+AT 
-  f(s,  (j){s, To, &, Ao), Ao + AA)) J^ 
+ 
{f{s, (j){s, To, &, Ao), Ao + AA) -  f{s,  (Pis,  TQ, fo, Ao), Ao)) ds 
JTQ+AT 
Jro 
/(5,(/)(^,To,&,Ao),Ao)J^. 
(9.5) 
Let  ||A||  =  V(AT)2  + (A^)2 + (AA)2,  ^^^ax  ^  max{^ : r G /o}, and /min  =  min{f  : r E 
JQ}.  Then  there  exists  e  >  0  such  that  when  ||A|| <  6, <  TO +  AT, r >  C <  TO -  6, 
tmax  >  U  < 
tmin,  TQ  +  €  >  =  Trr,  C  J,  <  TQ, TQ  +  AT  >C  [TO -  6,  TQ  +  e]  C  J,  and 
[Ao -  6, Ao + 6] n  D  ^  DAO  C D. 
Note  that  both  7^^ and D^^  are compact  subsets  of J and D, respectively. For (t, A) E 
r,QXDAo,let 
M  =  max 
5G[To-e,To+e] 
1/(5, (/)(5, To, &, Ao), Ao)|. 
By the Lipschitz  condition, we obtain 
|(/)(r, To +  AT, ^0 + A^, Ao + AA) -  (/)(?, TO, ^O, AO)| 
<  |A^| +  M | A T| 
+  I 
1/(5, (/)(5, To, &, AO), AO + AA) -  f(s,  cf^is,  TQ, &, Ao), Ao)| ds 
+  L I 
|(/)(5, To +  AT, & + A^, Ao + AA) -  (/>(5, To, &, Ao)| J^. 
Again, using the Gronwall Inequality,  we have that 
|0(/, To +  AT, & + A|^, Ao + AA) -  (/>(r, TQ, &, Ao)| 
<  (|A^|  +  M | A T| 
+  i 
^ET-^0 
1/(5, (/>(5, TO, &, Ao), Ao + AA) -  f(s,  (/>(5, To, &, Ao), Ao)| ^5) 
By  the first part  of the  proof,  we already  know  that  f(s,  (/)(5, To, ^o. Ao), A) E  €(1^^  X 
R  X  DXQ, R), which  implies  t h a t/  is uniformly  continuous  on the compact  set Tj^  X 
DXQ.  Therefore,  by Theorem  5.2 and (9.6) we know  that  (/)(^, T, ^, A) -^  (pit, TQ, io, Ao), 
• 
uniformly  as (T, ^, A) -^  (TO, ^O, AO) for t ^  JQ. 
1.10 
SYSTEMS  OF FIRST-ORDER  ORDINARY 
DIFFERENTIAL  EQUATIONS 
In  Sections  1.6  to  1.9  we addressed  the existence  of solutions, the continuation  of 
solutions, the uniqueness  of solutions, and the continuous  dependence  of  solutions 
on initial  data and parameters  for the scalar  initial-value  problem  for  ordinary dif 
ferential  equations 
[characterized  by  {E')  and (/')  or by (V)  (resp., by  (/j^^.)]. In 
this  section  we  show  that  these  results  can be  extended  to  initial-value  problems 
characterized  by systems  of equations  [determined  by {E) and (/)  or by (V) (resp., 
by  (/A,T))] with no essential changes in proofs. Before we can accomplish this, how 
ever, we need to introduce additional background  material. 
37 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
A.  More Mathematical Preliminaries: Vector Spaces 
We will require the notion of vector space, or linear space over a field. 
DEFINITION  10.1.  Let F be a set containing more than one element and let there be 
"two operations ""+"" and ""•"" defined on F (i.e.","""+"" and ""•"" are mappings of F XF into F)", 
called addition and multiplication, respectively. Then for each a, p  G F there is a unique 
element a + (3  E. F, called the sum of a and jB, and a unique element a(3  = a - (3  E^ F, 
called the product of a and f3. We say that {F; +, •} is afield provided that the following 
axioms are satisfied: 
(i)  a  + (/3 + y)  =  (a + /3) + 7 and a  • (jS • y)  =  (a • j8) • 7 for all a, jS, y G F 
(i.e.," ""+"" and ""•"" are associative operations); "
(ii)  a  + (3 = (3  + a  and a  - (3 == /3 • a  for all a, /3 E F  (i.e.," ""+"" and ""•"" are "
(iii)  a  • (j8 + y)  =  a  • jS + a  •  y  for  all a, /3, y  G F  (i.e.,"  ""•"" is  distributive "
commutative operations); 
"over ""+""); "
(iv)  There exists an element Of G F such that Of + a  =  a  for all a  E F (i.e., Of 
"is the identity element of F with respect to ""+""); "
(v)  There exists an element IfEF^lfj^Of, 
such that If  - a  = a for all a  E F 
"(i.e.. If  is the identity element of F with respect to ""•""); "
(vi)  For every a  E F there exists an element  -a  G F such that a  + (-a)  =  Of 
(i.e., -a  is the additive inverse of F); 
"(vii)  For any a  T^ Of there exists an o;""^ G F such that a  - (a~^) =  If  (i.e.", a~^ 
is the multiplicative inverse of F). 
• 
In the sequel," we will usually  speak of a field F rather than ""a field {F; +","  •}."" "
Perhaps  the most  widely  known  fields  are the field of real numbers  R  and the 
field  of complex  numbers  C. Another field we will encounter  (see Chapter 2) is the 
field  of rational functions  (i.e., rational fractions  over polynomials). 
As a third example, we let F  =  {0, 1} and define  on F  (binary)  addition  as 0 + 
0 : ^ 0 =1  +  1, 1 + 0 = 1 = 0 +1  and (binary) multipHcation as 1 • 0  =  0 • 1  = 
0 • 0  =  0, 1 • 1 =  1. It is easily verified  that {F; +, •} is a field. 
As a fourth  example, let P denote the set of polynomials  with real  coefficients 
"and  define  addition  "" +""  and  multiplication  ""•""  on  P  in  the  usual  manner.  Then "
{F; +, •} is not a field since, e.g., axiom (vii) in Definition  10.1 is violated  (i.e., the 
multiplicative  inverse of a polynomial p  G P is not necessarily  a polynomial). 
38 
Linear Svstems 
DEFINITION  10.2.  Let V be a nonempty set, let F be  a field," l e t "" +"" denote a mapping "
of V X V into  V," and let ""•"" denote a mapping of F  X y  into V. Let the members x  ^  V "
be called vectors,  let the elements a  G F be called scalars,"  let the operation "" +""  defined "
on V be called vector addition,"  and let the mapping ""•"" be called scalar  multiplication  or "
multiplication  of vectors  by scalars.  Then for each  x,y  ELV there is a unique  element, 
X + y  EV,  called the sum ofx  and y,  and for each x  ELV and a  G F there is a unique 
element, ax  = a  • x  E  V, called the multiple  ofx  by a. We say that the nonempty set V 
and the field F, along with the two mappings of vector addition and scalar multiplication, 
constitute a vector  space  or a linear  space  if the following  axioms are satisfied: 
x,ySV. 
(i)  X + y  = y + xfoY  every 
(ii)  X + (y + z)  = (x + y) + zfoY  every  x,y,zE.  V. 
(Hi)  There is a unique vector in V, called  the zero  vector  or the null  vector  or the 
origin,  that  is denoted  by Oy and has the property  that  Oy +  x  == x for all 
xEV. 
(iv)  a:(x + y)  = ax  + ay  for all a  G F  and for all x,y  EV. 
(v)  (a  + P)x  =  ax + j8x for all a, ^  G F and for all x E V. 
(vi)  (a;/3)x  =  Q:(/3X) for  all a,  jS  G F  and for  all x  E  V. 
(vii)  OFX  = Oy for all x E V. 
(viii)  Ipx  =  X for all x  G V. 
• 
In  subsequent  applications,  when  the meaning  is  clear  from  context,  we  will 
write 0 in place of OF,  1 in place of Ip,  and 0 in place of Oy. To indicate the relation 
ship  between  the set of vectors  V and the underlying  field  F, we sometimes  refer  to 
a  vector  space  V  over  the  field  F, and we  signify  this  by  writing  (V, F).  However, 
usually,  when  the  field  in question  is clear  from  context,  we speak  of a vector  space 
V. If F is  the field of real numbers, R, we call the space a real  vector  space.  Similarly, 
if F  is the  field  of complex  numbers,  C, we speak  of a complex  vector 
space. 
Examples  of vector  spaces 
EXAMPLE  10.1.  Let V  = F^ denote the set of all ordered  /z-tuples of elements  from 
a  field F. Thus, if x E  F'', then  x  =  {x\,...,  Xnf,  where  xt  G F,  i  =  1,..., n. With 
x,"y  GF""^ and a  E F", let vector addition and scalar multiplication be defined as 
X  + y  =  {Xi, . . . , Xnf  + {y\, . . .,  ynf 
^  {x,^-y,,...,Xn 
+ ynf 
and 
ax  = a{xi,...,  Xnf  =  {axi,.. 
.,axnf. 
(10.1) 
(10.2) 
In this case the null vector is defined  as 0  =  (0,...,  0)^ and the vector  -x is defined as 
Xnf  =  ( - x i , . . .,  -Xnf.  Thcu wc utilizc the properties of the field F, 
-X  =  -(xi,..., 
all axioms of Definition  10.2 are readily verified,  and therefore, F^ is a vector space. We 
"call this space the space  F"" ofn-tuples  of elements  ofF.  If in particular we let F  =  R", 
"we  have  /?""", the n-dimensional  real  coordinate  space.  Similarly, if we let F  =  C, we 
"have C""", the n-dimensional  complex  coordinate  space. 
• 
We  note  that the set of points  in R^,  {x\,  X2), that  satisfy  the linear  equation 
Xi  +  X2 +  C  == 0, 
C 7^ 0, 
with  addition  and multiplication  defined  as in Eqs.  (10.1)  and (10.2), is not  a  vector 
space  (why?). 
EXAMPLE  10.2.  Let y  =  7?°° denote the set of all infinite  sequences of real numbers, 
X  =  {Xi, X2, .  . .,  Xk, .  . .}  = {Xi}, 
let  vector  addition  be  defined  similarly  as  in  (10.1),  and  let  scalar  multiplication  be 
defined  as in (10.2). It is again an easy matter to show that this space is a vector  space. 
On  some  occasions  we  will find it convenient  to modify  V  = R°° io  consist  of  the 
• 
set of all real infinite  sequences  {xi},  i eZ. 
EXAMPLE  10.3.  Let  1 <  /? <  oo and define  V  =  lphy 
39 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
"xeR""^ "
<^ oo 
1  < / ? << 
i=l 
{xeR^^ 
: sup{|x;|} <oo}. 
(10.3) 
Define  vector  addition  and  scalar  multiplication  on  Ip as in  (10.1)  and  (10.2),  respec 
tively. It can be verified  that this space, called the Ip-space,  is a vector space. 
• 
In  proving  that  Z^, 1 <  p  <  ^,  is  indeed  a  vector  space,  in  establishing  some  of 
the  properties  of  norms  defined  on  the  /^-spaces  (see  Examples  10.10  and  10.11),  in 
defining  linear  transformations  on  /^-spaces  (see,  e.g..  Example  10.8),  and  in  many 
other applications,  we make use of the Holder  and  Minkowski  Inequalities 
infinite 
sums,  given  below.  (These  inequalities  are  of  course  also  valid  fox  finite  sums.)  For 
proofs  of  these  results, refer,  e.g.,  to Michel  and  Herget  [12, pp.  268-270]. 
for 
Holder's 
Inequality 
states  that  if  p,q  e  R  are  such  that  1  <  p  <  oo and  1/p  + 
l/q  =  1,  and  if  {xi}  and  {yi}  are  sequences  in  either  R  or  C,"  and  if  YtLi  \^i\^  <  ""^ "
"and  YiLi  \yi\^  <  ""^^ then "
/ 
oo 
\ ^ IP 
f 
oo 
\ 
V^ 
Minkowski's 
Inequality 
states  that  if  p  e  R,  where  1 <  p  <  ^,  and  if  {xi}  and 
{yi}  are  sequences  in  either R  or C,"  and  if  YiLi  \^i\^  <  ""^ and  YiLi  \yi\^  <  ""^^ then "
/ 
oo 
\ ^ / P / oo 
\ ^ / P / oo 
\  VP 
[l\^i^yi\n  <[l\^i\n  +ll\yi\n 
• 
(M,) 
If in  particular  p  =  q  =  2,  then  (Hs)  reduces  to  the  Schwarz  Inequality  for  sums. 
EXAMPLE  10.4.  Let  V  =  C{[a,b],R).  We  note  that  x  =  y  if  and  only  if  x{t)  =  y{t) 
for  all  t  G [a,b],  and  that  the  null  vector  is  the  function  that  is  zero  for  all  t  G [a,b]. 
Let  F  denote  the  field  of  real  numbers,  let  a  G F,  and  let  vector  addition  and  scalar 
multiplication be defined  pointwise by 
{x + y){t)=x{t)+y{t) 
foralU  G [a,b] 
^j^(^ 
{ax){t)  =  ax{t) 
foY?illt  e[a,b]. 
(10.4) 
(10.5) 
Then  clearly x-\-y  eV  whenever x,y  eV,ax 
eV  whenever  a  G  F  and x G V,  and  all 
the  axioms  of  a vector  space  are  satisfied.  We call this  space  the  space  of  real-valued 
continuous functions  on  [a, b] and we frequently  denote it simply by  C[a,b]. 
• 
EXAMPLE  10.5.  Let  I  < p  < oo and let V  denote the set of all real-valued  functions  x 
on the interval  \a, b] such that 
\x{t)\Pdt<' 
/ 
Ja 
(10.6) 
40 
Linear Svstems 
Let F  = R and let vector addition and scalar multiplication be defined as in (10.4) and 
(10-5), respectively. It can be verified that this space is a vector space. 
In this book we will usually  assume that in (10.6), integration is in the Riemann 
sense. When integration in (10.6) is in the Lebesgue sense, then the vector space under 
discussion is called an L^-space (or the space Lp[a, b]). 
• 
In proving that the L^-spaces are indeed vector spaces, in establishing properties 
of norms  defined  on L^-spaces  (see, e.g.,  Example  10.12), in defining  linear trans 
formations  on Lp-spaces  (ee, e.g.. Example  10.12), and in many other  applications, 
we make use of the Holder  and Minkowski  Inequalities  for  integrals,  given  below. 
(These inequalities  are valid  when integration  is in the Riemann  and the  Lebesgue 
senses.)  For proofs  of these results, refer,  e.g.,  to Michel  and  Herget  [12, pp.  268-
270]. 
Holder's  Inequality  states  that  if  p,q  ^  R  are  such  that  1  <  j9  <  oo  and 
lip  -\-  1/q  =  1, if  [a, b] is  an  interval  on  the  real  line,  if  /,  ^  : [a, b] -^  R,  and 
if \a  1/(01^ dt<^ 
and  j/  \g(t)\^ dt  <  oo, then 
\l//7 
/ 
, 
\[/q 
( , 
"[  1/(01"" ^M  ij  \g(t)\''dt\  . "
(HI) 
Minkowski's  Inequality  states that if p  G  R, where 1 ^  p  <'^,ii  f,  g  :  [a,b\^' 
R,"  and if //  1/(01"" dt  <'x> and //  [^(Ol'' dt  <  oo", then 
\\lp 
\A/p 
I 
, 
I 
, 
\\lp 
( , 
\^\f(t)±g{t)Ydt\ 
"<  M  1/(01""^H  ^\\\g{t)Ydt\ "
. 
(M,) 
If  in  particular  p  =  q  =  j, then  (///)  reduces  to  the  Schwarz  Inequality  for 
integrals. 
EXAMPLE  10.6.  Let  V denote the set of all continuous real-valued functions  on the 
interval [a, b]  such that 
sup  \x(t)\ < ^. 
a<t<:b 
(10.7) 
Let F  = R and let vector addition and scalar multiplication be defined  as in (10.4) and 
(10.5), respectively. It can readily be verified that this space is a vector space. 
In some applications it is necessary to expand the above space to the set of measur 
able real-valued functions  on [a, b] and to replace (10.7) by 
ess  sup  \x(t)\ < 00, 
a<t<b 
(10.8) 
where ess  sup denotes the essential supremum, i.e., 
ess  sup  \x(t)\ =  inf {M : m{t:  \x(t)\ > M}  =  0}, 
a<t<b 
where m denotes the Lebesgue measure. In this case, the vector space under discussion 
is called the Loo-space. 
• 
Next, we consider linear  transformations. 
DEFINITION  10.3.  A mapping T of a linear space V into a linear space W, where V 
and  W are vector spaces over the same field F, is called  a linear transformation  or a 
linear operator provided that 
(L-i) 
(L-ii) 
T{x + y)  = T{x) + T(y) 
for all  x,yeV. 
T(ax)  = aT(x) 
for all x e  V and a  G F. 
• 
In  Section  1.16  we  will  discuss  in  detail  the  representation  of  linear  systems 
by means of linear operators. This discussion  will be continued in Chapter 2. In the 
following,  we consider three specific  examples of linear transformations. 
41 
CHAPTER 1: 
Mathematical 
EXAMPLE 10.7.  Let (V, R)  = (/?«, R) and (W," R)  = {R""^", R) be vector spaces defined 
as in Example 10.1, let A =  [a/y] G /?^>'^ and let T : V ^  VF be defined by the equation 
Descriptions of 
Systems 
y =  Ax, 
y^R'' 
R\ 
It is easily verified, using the properties of matrices, that 7 is a linear transformation.  • 
EXAMPLE  10.8.  Let  (V, R)  =  (Ip, R) be  the  vector  space  defined  in  Example  10.3 
(modified  to  consist  of  sequences  {x/}, /  G Z,  in  place  of  {x/}, /  =  1,2,...).  Let 
h  : Z  X Z  ^ 
/?bea  function  having  the property  that  for  each  x  E  V,  the  infinite 
sum 
^ 
h(n, k)x(k) 
exists and defines a function  of n on Z. Let T :V  ^  F be defined by 
00 
y{n)  =  ^_^  h{n, k)x(k). 
k= 
- co 
It is easily verified that T is a linear transformation. 
The  existence  of  the  above  sum  is  ensured  under  appropriate  assumptions. For 
example,  by  using  the  Holder  Inequality  it  is  readily  shown  that  if,  e.g.,  for fixed 
n, {h(n, k)} G I2  and {x(k)} G fc, then the above sum is well defined.  The above sum 
• 
exists also if, e.g., {x(k)} G L  and {h(n, k)} G /i for fixed n. 
EXAMPLE  10.9.  Let (V, R)  denote  the  vector  space  given  in  Example  10.5 and let 
k G C([a, b] X [a, b], R) have the property that for each x E  V, the Riemann integral 
k(s,t)x(t)dt 
exists and defines a continuous function of s on [a, b]. Let T  : V ^  V be defined by 
(Tx)(s)  = y(s)  = 
k{s,t)x{t)dt. 
rb 
Ja 
It is readily verified that T is a linear transformation of V into V. 
B.  Further Mathematical  Preliminaries:  Normed  Linear  Spaces 
In  the following,  we require  for  (V; F)  that F be  either  the  field  of real  numbers  R 
or the  field  of  complex  numbers  C. For  such  linear  spaces  we  say  that  a  function 
II • II : y  ->  7?^ is a norm  if 
(N-i)  ||x|| >  0 for  every  vector  x  E  V  and  \\x\\  =  0 if  and only if x is the  null 
vector (i.e., x  =  0); 
(N-ii)  For  every  scalar  a  E  F  and  for  every  vector  x  E  K ||Q:X||  =  Ic^Hkll, 
where  |Q:| denotes the absolute value of a  when F  =  R and the modulus 
when F  =  C; 
(N-iii)  For every x and y in V, \\x +  y\\ <  ||xi| + ||y||. (This inequality is called the 
triangle  inequality.) 
42 
Linear Systems 
We call a vector space on which a norm has been defined  a normed  vector  space 
^^ ^ normed  linear  space. 
"EXAMPLE 10.10.  On the linear space (/?""", R), we define for every x  = {xi,...,  XnY, 
and 
\\A\p  =  Zl^'-lM 
||x||oo =  max{|x/| : I <  i <  n}. 
' 
l^P<^, 
(10.9) 
(10.10) 
Using Minkowski's Inequality for finite sums, (M^), it is an easy matter to show that for 
every/?, 1 <  /> <  oo, || • ||^ is a norm on R^. In addition to || • ||oo, of particular interest to 
us will be the cases p  =  \  and p  = 2, i.e., 
IWIi  =i^M 
and 
\\x\\2  -^\T\xi?\ 
. 
(10.11) 
(10.12) 
The norm || • ||i is sometimes referred to as the taxicab norm or Manhattan norm,  while 
II • II2 is called the Euclidean norm. 
The foregoing norms are related by the inequalities 
\\x\\o.  <  IWIi <  ^IWJoo 
ll^lloo <  llxlb <  >||x||oo 
Iklb ^  IWIi <  v^lWb. 
(10.13) 
(10.14) 
(10.15) 
Also, for p  =  2, we obtain from the Holder Inequality for finite sums, (//^), the Schwarz 
Inequality 
\x^y\ 
•T^,\ 
^ 
^xtyt 
\l/2  /  „ 
xl/2 
^Ei^'H  E NI 
i=l 
(10.16) 
forallx," y E /?"". "
The assertions made in the above example turn out to be also true for the  space 
"(C""", C). We ask the reader to verify  these relations. 
EXAMPLE 10.11.  On the space Ip given in Example 10.3, let 
\\4p = (XM'] 
, 
i^p<^, 
and 
||x||oo =  sup|x/|. 
Using Minkowski's Inequahty for infinite sums, (Ms), it is an easy matter to show that 
II • lip is a norm for every p,  1 <  /? <  00. 
• 
EXAMPLE 10.12.  On the space given in Example 10.5, let 
x(t)\Pdt] 
, 
1 <  p  < 00. 
Using Minkowski's Inequality for integrals, (M/), it can readily be verified  that || •  \\p 
is a norm for every p,  1 <  p  <  00.  Also, on the space of continuous functions  given in 
43 
CHAPTER  1 : 
Mathematical 
Descriptions of 
Systems 
Example  10.6, assume that (10.7) holds. Then 
||x||oo  =  sup  \x(t)\ 
a<t<b 
is  easily  shown  to  define  a  norm.  Furthermore,  expression  (10.8)  can  also  be  used  to 
define  a norm. 
• 
EXAMPLE  10.13.  We can  also define  the norm  of  a matrix.  To this  end,  consider  the 
set  of  real  m  X  n  matrices,  R^^^  =  V  and  F  =  R.  It  is  easily  verified  that  (V, F)  = 
(R^^'^,  R) is a vector space, where vector addition is defined  as matrix addition and mul 
tiplication of vectors by scalars is defined  as multiplication  of matrices by scalars. 
For  a  given  norm 
I,,"  : R^""""^  -^  i?+  by "
It is easily verified  that 
"\\u on  i?""  and  a  given  norm  ||  • ||v  on  R""^",  we  define 
sup{||Ax||v  : X G /?^ with \\x\\u  =  1}. 
(10.17) 
(M-i) 
(M-ii) 
(M-iii) 
(M-iv) 
(M-v) 
||Ax||v  <  ||A||vJx||« for  any  x  G /?^ 
||A +  5 | U < | | A |U  +  ||5|U; 
||aA|U  =  |a|||A|U  for all a  G  R; 
||A||vM ^  0 and  ||A||VM  =  0 if and only if A is the zero matrix  (ie., A  =  0); 
||A|U  ^  XT=iT%i 
\aij\ for any p-vector norms defined  on i?^ and /?^. 
Properties (M-ii) to (M-iv) clearly show that ||  • ||VM defines  a norm on R^^^  and jus 
tifies the use of the term matrix norm.  Since the matrix norm ||  • ||VM depends on the choice 
of the vector norms, ||  • \\u, and ||  • ||v, defined  onU  =  R^ and V  =  R^,  respectively,  we 
say that the matrix  norm  || • 
is induced  by the vector norms  ||  • \\u  and  ||  • ||v. In  par-
ticular, if  ||  • ||«  =  ||  • ||^ and 
llv  =  II • II;?, then the notation  ||A||;, is frequently  used to 
denote the norm of A. 
As a specific  case, let A  =  [atj] G  R 
, Then it is easily verified  that 
/  m 
||A||i  =  m a x ^ l a , -^ 
||A||2  =  [maxA(A^A)]i/^ 
where max A(A-^ A) denotes the largest eigenvalue of A^A,  and 
||A||.  =  m a x ^ | f l , vl 
. 
When  it  is  clear  from  context  which  vector  spaces  and  vector  norms  are  being 
used, the indicated  subscripts on the matrix norms are usually not used. For example, if 
"A  G /?^^"" and B  G /?""><^ it can be shown that "
(M-vi) 
||A5||^ 
B\\. 
In  (M-vi)  we  have  omitted  subscripts  on  the  matrix  norms  to indicate  inducing  vector 
norms. 
• 
We  conclude  this  subsection  by  noting  that  it  is  possible  to  define  norms  on 
^j^mxn^ 7?) that need  not be  induced  by  vector  norms. Furthermore,  the  entire  discus 
sion  given  in  Example  10.13  holds  also  for  norms  defined  on  complex  spaces,  e.g., 
"(C^x""",  C). 
44 
Linear Systems 
C.  Additional  Mathematical  Preliminaries:  Convergence 
Although  most of what we will present in this  subsection  is true in a rather  general 
setting, we will confine  ourselves to the spaces {R^, R) or {C^,  C). 
Using  the concept  of norm, we can define  distance  between  vectors x  and y  in 
R^  [or in C^] by d{x,  y)  =  \\x -  y\\. The three basic properties of distance are given 
next and are a consequence of the axioms of a norm: 
(D-i) 
(D-ii) 
(D-iii) 
\\x -  y\\>  0 for all vectors  x, y and \\x -  y\\ =  0 if and only if  x  =  y; 
\\x -  y\\ =  \\y -  x\\ for  all vectors x, y; 
\\x -  z\\ ^  \\x -  y\\ +  \\y —  z\\ for all vectors x, y, z. 
"We can  now  define  spherical  neighborhood  in  R^  (in  C"")  with  center  XQ and "
radius  /^ >  0 as 
B{xo, h)  =  {xER'' 
: \\x -  xo\\ <  h}. 
If in particular the center of a spherical neighborhood with radius h is the origin, then 
we write B(0, h)  =  B{h),  i.e. 
B(h)  =  {xER'' 
: ||x|| <  h}. 
We shall use the notation 
B{xo," h)  =  {xG  R""""  :  \\x -  xo\\  <  h} "
and 
"B(h)  =  {x  G R""""  : \\x\\  <  h}. "
The introduction of vector and matrix norms enables us to generalize the notions 
of convergence of sequences, continuity of functions, and the like. We will not retrace 
here  the  entire  presentation  given  in  Sections  1.2  and  1.5.  Instead,  to  demonstrate 
what is involved in these generalizations, we consider a few  specific  cases. 
A sequence  of vectors  {xm)  =  {{x\m, • • •. ^nmf}  C  R^  is  said to converge  to a 
vector X E  R^  (i.e., x^  ^  x as m ^  oo) if 
lim  \\xm  —  x\\ =  0, 
or  equivalently,  if  for  every  e  >  0  there  exists  an  integer  A^  =  N(e)  such  that 
Ikm  ~  -^11  <  ^  whenever  m  >  N.  (In  this  definition  ||  • || denotes  a  norm  on  R^.) 
Using the properties of norms, it is easily shown that x^  -^  x if and only if for  each 
coordinate one has  x^rn -^  Xk^s  m-^  ^,  k  =  1,.. 
.,n. 
The above allows the generalization  of many  of the properties  of R to R^  (e.g., 
the Bolzano-Weierstrass  property and the Heine-Borel  property). 
As another example, consider/>6>m^/5'^ convergence  of a sequence of functions. 
We  say  that  a  sequence  of  functions  {f^}, fk  - D ^  R'^, D  C  R^,  k  =  1, 2 , . . .,  is 
pointwise convergent to a function  f  : D ^  R^ if for every e  >  0 and every  x  E:  D 
there is an integer N  =  N(e,  x)  such that ||/^(jc)  -  f(x)\\  <  e  whenever  k^  N.  (In 
the above definition,"  ||  • || denotes a norm on R""^",) Using the properties of norms, it is 
again easy to show that /^(x) ->  f(x)  for all x  G Z) if and only if for each coordinate 
one has fik(x)  -^  fi(x)  as fc ^  oo, /  =  1,...,  n, for  all x  E  D. 
As  a third  example,  consider  continuity  of a function  f  : D ^  R^,  where D  is 
an open subset of R^.  The function/  is said to be continuous  at point  XQ  G Dif  for 
every e  >  0 there is a §  =  8(e,  XQ) >  0 such that 
ll/(-^)  ~  /(-^o) IIF  <  ^ 
whenever  || x -  XQIU  <  ^-
In the  above  definition  | 
on/?^. 
\\Y is  a norm  defined  on  R^  and  ||  • ||x is  a norm  defined 
45 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
Next, let g(t)  =  [gi{t\  . . .,  gn(t)V  be a vector-valued function  defined  on some 
interval J  C  R. Assume that each component of ^ is differentiable  and integrable on 
/.  As pointed out earlier, differentiation  and integration of ^ are defined  component 
wise, e.g., 
di 
dt  (0 = 
(0, 
dg\ 
dt 
b 
dgn 
dt  (0 
and 
g{t)dt  = 
g\{t)dt,.. 
gn(t)dt 
It is easily verified  that for b>  a, 
g{t)dt\\ 
i)\\dt, 
Ja 
where again ||  • || denotes a norm on  R^. 
Finally, if D is an open connected  nonempty  set in the  {t, x)-space  RX  R^  and 
if /  : D ^  R^, then/ is said to satisfy  a Lipschitz  condition  with Lipschitz  constant 
L (with respect to x) if for  all {t, x)  and {t, y) in  D, 
\\f{t,x)-f{t,y)\\^L\\x-yl 
This is an obvious extension of the notion of a Lipschitz condition for  scalar-valued 
functions. 
D.  Solutions  of Systems  of First-Order  Ordinary  Differential  Equations: 
Existence,  Continuation,  Uniqueness,  and  Continuous  Dependence 
on Initial  Conditions 
It  turns  out  that  every  result  given  in  Sections  1.6  to  1.9  can  be  restated  in  vector 
form and proved, using the same methods as in the scalar case and invoking obvious 
modifications  (such  as the  replacement  of  absolute  values  of  scalars  by  the  norms 
of vectors or the norms of matrices, and  so forth). In the following  we restate  these 
results in vector form  and ask the reader to prove these results. 
We  have  a  domain  D  C  R^^^,  f  G  C(A  R^)  and  we  are  given  the  system  of 
first-order  ordinary differential  equations 
We are given  (to, XQ) G D  and  seek a solution  (or solutions) to the  initial-value 
X =  fit,  x). 
(E) 
problem 
In doing so, it suffices  to find a solution of the integral  equation 
X =  fit,  X), 
x(to)  =  XQ. 
(/>(0  =  xo+ 
\ 
Jto 
f(s,cl)(s))ds, 
(/) 
(V) 
As in the scalar case, this can be accomplished by the use of 6-approximate solutions. 
46 
Linear Systems 
DEFINITION  10.4.  A  function  0  defined  and  continuous  on  a  ^interval  /  =  {ci,b) 
containing  ^o is called an e-approximate  solution  of  (/)  if  0 (^o) = ^o and 
(i) 
(ii) 
(iii) 
(t,(l)(t))  e  D for 2i\\te  J; 
(p  has a continuous  derivative on /  except possibly  on a finite set /  of points in  / 
where there are jump discontinuities  allowed; 
II 0 (0  -  / (^ 0(0)  II <  e for alU  G /  - /,"  where  || • || denotes a norm on R""^. "
• 
Now  let 
S  =  {{t,x) 
: l^-^ol  <a,\xi-Xio\ 
and  let  (^o^-^o)  ^  S.  Since  /  G C{D^R^), 
Mi  >  0  such  that  \fi{t,x) 
\ <  Mi  for  all  (f,jc)  G 5, / =  1 , . . ., n.  Define 
<bi, 
i=l,...,n} 
(10.18) 
it  is  bounded  on  S,  and  hence,  there  are 
cD 
Ci  =  min  <  a,  —  >  , 
bi\ 
i=\,...,n, 
c  =  min/  {c/}. 
THEOREM  10.1.  li  f  eC{D,W) 
there is an e-approximate  solution of  (/)  on the interval  |^ — ^o| ^  <^- 
and if  c is as defined  in  (10.19), then  for  any  e >  0 
• 
In  the  proof  of  the  next  result,  we  require  a  slight  generalization  of  the  Ascoli-
Arzela  Lemma  given  in  Theorem  6.1.  To  this  end,  we  let  ^  denote  a  family  of 
real-valued  functions  defined  on  a  set  G  C  /^^  Then  ^ 
is  called  uniformly  bounded 
if  there  is  a nonnegative  constant  M  such  that  \f{x)  \ <  M  for  all x  in  G  and  for  all  / 
in  ^.  Furthermore,  ^ 
is called  equicontinuous  on  G if  for  any  e >  0 there  is  a  5  >  0 
(independent  of  x^y,  and  /)  such  that  \f{x)  — f{y)\  <  e  whenever  || x —j  ||<  5  for 
all X and  j  in  G  and  for  ail  f  e  ^ 
(||  • ||  denotes  a  norm  on  R^).  The  Ascoli-Arzela 
Lemma  now  reads  as  follows. 
THEOREM  10.2.  Let  G  be  a  closed  and  bounded  subset  of  R^  and  let  {fm}  be  a 
sequence  of  functions  in  C{G,R).  If  {fm}  is  equicontinuous  and  uniformly  bounded 
on  G,  then  there  is  a  subsequence  {rrik} and  a functuion  /  G C{G,R)  such  that  {fmk} 
converges uniformly  to /  on G. 
• 
THEOREM  10.3.  If /  G  C(D,R'')  and  (to,xo)  G Z), then  (/)  has  a solution  defined  on 
m 
\t-to\<c. 
THEOREM  10.4.  Let /  G C(D,R'^)  with /  bounded on D.  Suppose that 0  is a solution 
of  (E)  on the interval /  =  {a,b).  Then 
(i) 
the two  limits 
lim  0(r)  =  0(<2+) 
and 
lim  0(r)  = (l)(b~) 
(ii) 
exist; 
if  {a,(p{a'^))  [respectively,  {b,(p{b~)]  is in Z), the  solution  (p  can be continued  to 
• 
the left  past the point t = a (resp., to the right past the point t = b). 
THEOREM  10.5.  If /  G  C{D,R'^)  and if  0  is  a solution  of  (E)  on  an open  interval  /, 
then  (p  can be continued to a maximal open interval /*  D /  in such a way that  (t,(p(t)) 
tends  to  dD  as ^ ^  dJ*  when  dD  is not  empty  and  |^|+  || (p(t)  | |^  oo if  dD  is  empty. 
• 
The extended  solution  0* on /*  is noncontinuable. 
THEOREM  10.6.  If  /  G C{D,R'^)  and  if  /  satisfies  a Lipschitz  condition  on  D  with 
Lipschitz  constant L  (with respect  to x), then  the initial-value  problem  (/)  has  at  most 
one solution on any interval  |^ — ^o| ^  <^- 
• 
COROLLARY  10.7.  If /  E  C{D," /?«) and dfildxj  E  C(A /?"") (/", j  =  \,...,n), 
then 
for  any  (to,  XQ)  E  D  and  any  J  containing  ^o, a  solution  of  (/)  exists  on  /  and  is 
"^""^n^^- "
THEOREM 10.8.  Let /  E  C{J X /?«, R^) for some open interval 7 C /? and let/ satisfy 
a Lipschitz condition on /  X /?« (with respect to x). Then for any (^,"  XQ) E /  X  /?""", the 
initial-value problem (/) has a unique solution that exists on the entire interval J. 
• 
47 
CHAPTER 1 • 
•  Mathematical 
Descriptions of 
Systems 
Next,  let  /  E  C{D," R"")",  let  5  C  D  be  the  set  defined  in  (10.18),  centered  at 
(to, JCo), and let c be defined  in (10.19). Successive  approximations  for  (/), or equiv-
alently for  (V), are defined  as 
<i>oit)  =  xo 
f{s,(f)m{s))ds, 
m  =  0, 1, 2 , . .. 
(10.20) 
for  \t -  ^1 <  c. 
THEOREM 10.9.  If /  E  C{D, E^) and if/  is Lipschitz continuous on S with constant 
L (with respect to x), then the successive approximations (/>^, m  = 0, 1, 2,...,  given in 
(10.20) exist on \t -  to\  <  c, are continuous there, and converge uniformly,  as m ^  oo, 
to the unique solution of (/). 
• 
In the final result of this  subsection,  we address initial-value problems that ex 
hibit dependence on some parameter  X G G  C  R^  given by 
X —  f(t,  X, A) 
(/A,r) 
v^here /  E  C(J  X  R^  X  G, R^),  /  C  /^ is an open interval, and ^x depends  continu 
ously on A. 
"THEOREM 10.10.  Let /  E  C{J X  /?"" X G"," 7?"")", where J  C Rism  open interval and 
G G R^. Assume that for each pair of compact subsets Jo C J and Go C G there exists 
a constant L  =  LJQ,GQ  > 0 such that for  all (t, X) G JQ X Go, x,"y  E  jR""", the Lipschitz 
condition 
\\f{t,x,X)-f(t.y,X)\\^L\\x-y\\ 
is  true.  Then  the  initial-value  problem  (/A,T)  has  a unique  solution  (t)(t, r, A), where 
(j)  E  C(J  X J  X G," /?""). Furthermore", if D is a set such that for all Ao E D there exists 
e  >  0 such that  [Ao -  e, Ao  + e] Pi D C D, then 0(r, r, A) -^  (f){t, TQ, AQ) uniformly  for 
to E  JQ as (T, A) —>  (TO, AO), where JQ is any compact subset of 7. 
• 
Theorem  10.10  is  a  generalization  of  Corollary  9.2  from  the  one-dimensional 
case  (/{^)  to the  /z-dimensional  case  (/A,T)-  The  generalization  of  Theorem  9.1  for 
the one-dimensional  case  {i'xrp)  ^^ the n-dimensional  case  (/A,T,^)  is of course  also 
readily established. We leave the details to the reader. 
1.11. 
SYSTEMS  OF LINEAR  FIRST-ORDER  ORDINARY 
DIFFERENTIAL  EQUATIONS 
In this section we v^ill address linear ordinary differential  equations of the  form 
X =  A(t)x  +  g(t) 
(LN) 
48 
Linear Systems 
and 
and 
and 
X =  A(t)x 
X =  Ax  -\-  g(t) 
X =  Ax, 
(LH) 
(11.1) 
(L) 
where x  G /?^ A(t)  =  [aij(t)]  G  C(R,"  /^^><"")", g  G  C(R,"  R"""")"," and A  G 7^""^^ "
Linear equations of the type enumerated above may arise in a natural manner in 
the  modeUng  process  of  physical  systems  (see  Section  1.4  for  specific  examples) 
or  in  the  process  of  linearizing  equations  of  the  form  (E)  or  some  other  kind  of 
form. 
A.  Linearization 
We consider the system of first-order ordinary  differential  equations  given by 
X =  fit,  xl 
(E) 
"where f  :  RX  D->  R""""  md  D  C  R""""  is some domain. If  f  GC\RXD", 
"R"""") and if "
(/) is a given  solution of (E)  defined  for  all t  G R, then we can linearize  (E)  about cj) 
in the following  manner. Define  8x  =  x  -  4>{t)  so that 
dt 
= fit, 8x + m)  -  fit,  m) 
=  ^it,(l>it))Sx  +  Fit,Sx), 
dx 
(11.2) 
where idfldx)it,  x) denotes the Jacobian  matrix of fit,  x)  =  (/i it, x),..., 
with respect to A: =  ( x i , . . .,  x„)^, i.e.. 
/„(f,  x)Y 
it, x)  = 
dx 
'J^it,x) 
dX\ 
••• 
'J^it,x) 
dXn 
it,x) 
dxi 
it,x) 
dXn 
(11.3) 
and 
Fit,  8x)  ^  [fit,  Sx  +  ct>it))  -  fit,  (/.(O)]  -  ^-fit,  4>ii))8x. 
(11.4) 
dx 
It turns out that Fit,  8x)  is <9(||5x||) as ||5x|| -^  0 uniformly  in / on compact subsets of 
R,  i.e., for any compact  subset I  G R,vi/e  have 
sup 
lim 
HSx\ho\,ei 
\\Fit,  8x) 
\\8x\\ 
=  0. 
To prove this, we will use the fact that for each  /  =  ! , . . . , «, 
fit,  Sx  + <t>it))  -  fit,  <j>it))  =  iSxf 
Jo 
•1 
I  Vfit,  si8x)  + (f>it))ds 
=  y  5x,-  f  ^ i t,  si8x)  +  ^it))ds, 
(11.5) 
pi 
Jo  dXj 
where Sxt  =  {Sx)i  and Wfi  =  i ^ .. . .,  ^ 
I . To verify  (11.5), we let 
\dXi 
dXfi  ' 
g(s)  =  Mt,s(8x)  + cl>(t)) 
and use the fact  that 
^(1) - ^(0) = fi(t, sx + m) - fiit, m) 
49 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
•1 
g'{s)ds= 
rl 
f  dfi{t,s{8x)  +  m) 
Jo 
1  n 
dx 
-(t,s{8x)  + 4>(t))ds  Sxj 
=  (8xy 
Jo 
Vfi(t,si8x)  +  (l)(t))ds. 
Next, we note that the /th component of F(t,  Sx)  is given by 
Fi(t, Sx)  = 
^^^Sxj 
0  o'Xj 
dXj 
^(t,s(Sx) +  ci>(t))-^(t,m) 
ds. 
axj 
dXj 
Choose \\Sx\\ =  Q11=^i(Sxi)^)^^^  and let /  be a compact interval in R.  Then 
^. 
hm 
/ 
s up 
\Ft(t,Sx)\\ 
11^  II 
\^U^^j\o 
= 
lim  I  sup 
^(t^s(Sx) +  ci>(t))-^(t,m) 
ds\ 
dXj 
WSxW 
dXj 
(X;=,(Sxi)^)i'MS}=,(sup,^,J 
yi{t,s{8x) 
\_dxj 
+  <f>{t))-^{t,<t>{t)) 
dXj 
AI2 
dsf 
< 
lim 
lis^lho 
iZ%y(Sxj)2) 
1/2 
111 
lim 
\\8. 
^ 
(sup 
^(t^ss(x) + 
m)-^it^m) 
ds 
=  0, 
where we have made use of the Schwarz  Inequality. 
To establish  equality  (equal  to  zero)  in  the  last  line  of  the  above  equation  re 
quires  perhaps  a bit  of extra  work.  Since I  C  Ris  compact  and  cf) is continuous,  it 
follows  that  the  set  (/>(/) is  compact.  Since  (f)(1)  C  D  and Z) is  a domain,  we  have 
dist{(j){I), dD)  =  d>  0. Clearly, then, 
Xo  =  {(/)(0 +  I -^  ](Sh . --^Sn)^  : r G /,  -1  <  ^/  <  1,  /  =  1,...,  n} C  D 
\2jn 
^ 
Linear Systems 
and XQ is a compact subset of D, since (pit) +  [d/(2 ^)](si,..., 
vector-function  of (t, Si,...,  Sn). 
Sn)^ is a continuous 
Now for  ||§x|| <  d/2,  0  <  ^ <  1, ^ G /,  we have that s(Sx)  +  (/)(0  G  ZQ.  Since 
{dfldxj){t,  x)  is uniformly  continuous  on the compact  set /  X XQ, we conclude  the 
equality  (equal to zero). 
Finally,  since  the  above  argument  is  true  for  all  /  =  1,...,  n,  it  follows  that 
F{t, 8x)  is (9(||Sx||) as ||Sx|| -^  0 uniformly  in t on compact subsets of i^. 
Letting 
we obtain from  (11.2) the equation 
^-f{t,cl>{t))  = A{t\ 
dx 
^^ 
4  Si  =  A{t)hx  +  Fit,  Sx\ 
(11.6) 
at 
Associated  with (11.6) we have the linear differential  equation 
z  =  A(t)z, 
(LH) 
called the linearized  equation  of {E) about the solution  0. 
In  applications,  the linearization  {LH)  of  (£*), about  a given  solution  (/>, is  fre 
quently used as a means of approximating a nonlinear process by a linear one (in the 
vicinity of (/>). In Chapter 6, where we will study the stability properties of equilibria 
"of {E)  [which  are specific  kinds of solutions of  (£"")]", we will show under what con 
ditions  it makes  sense to deduce  qualitative properties  of  a nonlinear  process  from 
its  linearization. 
"Of special interest is the case when in (£"")",/ is independent of t, i.e., 
X =  fix) 
(A) 
and (/) is a constant solution of (A), say, (f)(t) =  XQ for  all t  ^  R. Under these condi 
tions we have 
^^ 
^  Sx  =  Adx  +  F(Sxl 
where 
lim  ^ ^ ^ j^  =  0 
(11.7) 
(11.8) 
and A  denotes  the Jacobian  {dfldx){x^).  Again,  associated  with  (11.7) we have  the 
linear differential  equation 
z  =  Az, 
called the linearized  equation  of (A) about the solution (j){t)  =  XQ. 
We can generalize the above to equations of the  form 
X =  fit,  X, u), 
(Eu) 
"where  f  : R  X  Di  X  D2 -^  R"""" md  Di  C  /?""","  D2  C  R""^ are  some  domains.  If "
f  E  C^(RX  Di  X D2, R^)  and if (j){t) is a given  solution of {Eu) that we assume to 
exist  for  all  ^ G /? and  that  is  determined  by  the initial  condition  XQ  and  the  given 
specific function 
ip E  C{R, R^),  i.e., 
m  =  fit,  m,  ifjit)), 
t  G  R, 
then we can linearize (Eu) in the following  manner. Define Sx  =  x-  cf)(t) and 8u  = 
u  -  ijj{t). Then 
d{8x) 
dt 
8x  =  X-  (f)(t) =  f(t,  X,  u)  -  fit,  (j){t), ijj{t)) 
=  fit,  8x + 0(0, 8u + ^(0) -  fit,  0(0, ^(0) 
51 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
=  ^Mt,  cj)it\ iPit))8x  +  ^Mt,  cl)it), iljit))8u 
ax 
du 
+  Fiit,8x,u)  +  F2it,8u\ 
(11.9) 
where Fife  8x,  u)  =  fit,  Sx + (/>(0, u)-fit, 
^ /. 
(j)it),  u)-^it, 
ax 
cfyit),  il/it))8x  is oi\\8x\\ 
as  \\8x\\ 
0,  uniformly  in  t  on  compact  subsets  of  R  for  fixed  u  i.e.,  for  fixed 
u  and  for  any  compact  subset  I  C  R,  lim||§;^;||_^o (sup^^/ 
where 
\\Fiit,  8x,u 
\\Sx\\ 
and 
F2{t, 8u)  =  fit,  m,  8u  + iff{t))  -  fit,  <^it), iPit)) -  -fit,  0(0,  «A(0)SM 
^f, 
au 
is  6>(||Sw||) as  ||Sw|| -^  0, uniformly  in  t on compact  subsets  of  R 
i.e.,  for  any  com-
pact  subset  I  C  R, lim||§;^||^o  sup^^^ 
^F2it, 8u 
115^11 
=  0 
, and where  idfldx)i 
• ) and 
idfldu)i 
of/  with respect to w, respectively. 
'  ) denote the Jacobian matrix of/  with respect to x and the Jacobian matrix 
Letting 
it, cl)it), if/it))  =  Ait) 
and 
dx 
it, cj>it),  iPit))  =  Bit), 
du 
we obtain from  (11.9), 
di8x) 
dt 
=  8x  =  Ait)8x  +  Bit)8u  +  Flit,  8x,  u) +  F2it, 8u). 
(11.10) 
Associated  with (11.10), we have 
z  =  Ait)z  +  Bit)v 
iLN) 
and  call  iLN)  the  linearized  equation  of  iEu)  about  the  solution  0  and  the  input 
function  ijj. 
"As  in  the  case  of  the  linearization  of  (£"")  by  (L//)",  the  linearization  iLN)  of 
system iEu) about a given solution 0  and a given input 0  is often used in attempting 
to capture the qualitative properties of a nonlinear process by a linear process (in the 
vicinity  of  0  and  0).  In  doing  so, great  care  must  be  exercised  to  avoid  erroneous 
conclusions. 
The motivation  of linearization is of course very obvious: much more is known 
about linear ordinary differential  equations than about nonlinear ones. For example, 
the  explicit  forms  of  the  solutions  of  (L)  and  (11.1)  are  known;  the  structures  of 
the  solutions  of  (L//),  iLN),  and  iLN)  are known;  the  qualitative  properties  of  the 
solutions of linear equations  are known; and so  forth. 
52 
Linear  Systems 
B.  Examples 
We now consider some specific cases. 
EXAMPLE  11.1.  We consider the simple  pendulum  discussed  in Example 4.4  and de 
scribed by the  equation 
where  ^  >  0 is a constant. Letting  xi  =  x  and X2 =  i:, ( I L l l)  can be expressed  as 
x  + A:sinx  =  0, 
( H . H) 
Xi  =  X2 
X2 =  —/:sinxi. 
(11.12) 
It  is  easily  verified  that  (/)i(0  =  0  and  </>2(0  =  0  is  a  solution  of  (11.12).  Letting 
fi(xi,  X2)  =  X2 and  f2(xi,  X2)  =  - ^ s i n x i,  the  Jacobian  of  f(xi,X2)  =  (fi(xi,  X2\ 
f2{x\,  X2)Y  evaluated  at {x\,  X2Y  =  (0, 0)-^ is given by 
/(O) 
0 
—/rcosxi 
1 
0_ 
0  1 
0 
-k 
JC2=0 
The linearized equation of (11.12) about the solution (j)i{t) =  0, <j^2(0 =  0 is given by 
EXAMPLEII.2.  The system of equations 
0  1 
-k 
0 
xi  =  ax\  —  bxiX2  —  cx\ 
X2 =  dx2  —  ex\X2  —  fx\ 
(11.13) 
describes the growth of two competing  species (e.g., two species of small fish) that prey 
on  each  other  (e.g.,  the  adult  members  of  one  species  prey  on  the  young  members  of 
the  other  species,  and  vice  versa).  In  (11.13)  a,  b,  c,  d,  e,  a n d/  are  positive  parame 
ters  and it is assumed  that  xi  >  0 and  X2 ^  0. For (11.13), 4>i{t)  =  (i)\(t, 0, 0)  =  0 and 
"02(0  ="" (}>2{t", 0, 0)  =  0, r >  0, is a solution of (11.13). A simple computation  yields 
A  =  ^ ( 0)  = 
dx 
a  0 
0  d 
and thus the system of  equations 
constitutes  the  linearized  equation  of  (11.13)  about  the  solution  01 (0 
r>  0. 
0, 02(0  = 0, 
EXAMPLE  11.3.  Consider  a unit  mass  subjected  to an inverse  square  law  force  field, 
as  depicted  in  Fig.  1.11. In  this  figure,  r denotes  radius  and  6  denotes  angle,  and  it  is 
assumed that the unit mass (representing, e.g., a satellite) can thrust in the radial and in 
the tangential  directions  with thrusts  u\  and  U2, respectively. The equations that  govern 
this system are given by 
r  =  rO^  -
H-  Ml 
-lOr 
r 
+ 
1 
-U2. 
r 
(11.14) 
y^ 
/ 
\ 
N 
53 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
FIGURE  1.11 
A unit mass subjected  to an inverse  square law 
force  field 
When  r(0)  =  ro, r(0)  =  0, ^(0)  =  ^o, ^(0)  =  COQ  and  uxif)  ^  0, U2(t)  ^  0 for  r >  0, it 
is easily verified  that the system of equations  (11.14) has as a solution the circular  orbit 
given by 
r(t)  =  TQ  =  constant 
6(t)  =  coo  =  constant 
(11.15) 
for all r >  0, which implies  that 
^ (0  =  (Oot + Oo, 
(11.16) 
where  COQ  = 
{klriy^. 
If  we  let  xi  =  r,  X2  =  r,  x^  =  0,  and  X4 =  6,  the  equations  of  motion  (11.14) 
assume the  form 
k 
x\ 
+1 
(11.17) 
Xi 
= 
X2 
X2 
= 
Xi 
T2 
-
X3 
= 
X4 
X4 
= 
-
2X2X4 
Xi 
u 
U2 
Xx 
The linearized equation of (11.17) about the solution (11.16)  [with u\{t)  =  0, U2{t)  =  0] 
is given by 
r.  n 
Zl 
Z2 
Z3 
ZA_ 
"""  0 "
3col 
0 
0 
— 
0 
1 
0 
0 
0 
0 
-2COQ_  0 
IVQCOQ  I 
0 
1 
0 
r- 
-
Ul 
U2 
Us 
[Z4_ 
0 
1 
0 
0 
+ 
r- 
0  1 
0 
0 
1 
-| 
Vi 
|_V2. 
^0-' 
EXAMPLE  11.4.  In  this  example  we  consider  systems  described  by  equations  of  the 
form 
X  +  Af(x)  +  Bg(x)  =  u, 
(11.18) 
"where  xGR'^.A  =  [atj] G 7?^><"""," B  =  [btj] G  7?""><"" with an  >  0", bu  >  0,  1 <  /  <  ^, 
f,ge 
"C^R""",  R%  u  G  C(/?+," /?"")", and f{x)  =  0, g(x)  =  0 if and only if x  =  0. 
Equation  (11.18)  can  be  used  to  model  a  great  variety  of  physical  systems.  In 
particular,  (11.18) has been used to model a large class of integrated  circuits  consisting 
54 
Linear  Systems 
of  (nonlinear)  transistors  and  diodes,  (linear)  capacitors  and  resistors,  and  current  and 
voltage sources. (Figure  1.12  gives a symbolic representation  of such circuits.) For such 
circuits, we assume that f(x)  =  [fi(xi),..., 
fn{Xn)Y -
tfH-
» 
^  ^ + FIGURE  1.12 
Integrated  circuit 
If  u{t)  =  0 for all t  >  0, then (/)/(0  =  0, r >  0,  1 <  /  <  n, is a solution of (11.18). 
The system of equations  (11.18) can be expressed  equivalently  as 
Xi 
7 = 1 
/ - = ! ,. 
(11.19) 
The linearized equation of (11.19) about the solution (/>/(0  =  0, and the input  Ui(t)  =  0, 
t  >  0, /  =  1,...,  w, is given by 
Zi =  -^[atjfjiO) 
+  bijg'jmzj 
+ V,-, 
(11.20) 
7 = 1 
where /;(0)  =  (dfj/dxj)(0)  and ^;.(0)  =  (dgj/dxj)(0\ 
i  = 
l...,n. 
1.12 
LINEAR SYSTEMS: EXISTENCE, UNIQUENESS,  CONTINUATION, 
AND CONTINUITY WITH RESPECT TO PARAMETERS 
OF SOLUTIONS 
In this  section  we  address  nonhomogeneous  systems  of  first-order  ordinary  differen 
tial  equations  given  by 
X  =  A(t)x  +  g(tX 
(LN) 
where  x  G  R^,  A(t)  =  [aij(t)]  is  a real  nX  n matrix,  and  g  is  a real  n-vector-valued 
function. 
THEOREM  12.1.  Suppose thatA  G  C{J," /?"">^"")andg  G  C(7", /?''), where 7 is some open 
"interval.  Then  for  any  to G  J  and  any  XQ G  /?""", equation  (LN)  has  a  unique  solution 
satisfying  x(to)  =  XQ. This  solution  exists  on the  entire  interval /  and  is continuous  in 
(t, to, xo). 
Proof.  The function  f(t,  x)  =  A(t)x  + g(t) is continuous in (t, jc), and moreover, for any 
compact  subinterval  Jo G J  there is an  LQ ^  0 such that 
\\f(t,  X) -  fit,  y)\\i  =  \\A(t)(x  -  y)\\i  <  ||A(0||i||x  -  y\\i 
- 
i 
,^^^  ko-(Ol  Ik -  y\\i ^  Lo\\x -  y\\i 
for all (t, x), (t, y)  G  JQXR^,  where LQ is defined in the obvious way. Therefore,/  satisfies 
a Lipschitz condition on Jo X  R^. 
If (^0. -^o) G JoXR^,  then the continuity of/  implies the existence of solutions (The 
orems  6.3  and  10.3), while  the Lipschitz  condition  implies  the uniqueness  of  solutions 
(Theorems 8.2 and 10,6). These solutions exist for the entire interval JQ  (Theorems 8.4 
and 10.8). Since this argument holds for any compact subinterval JQ  C /,  the solutions 
exist and are unique for alU G /. Furthermore, the solutions are continuous with respect 
to ^0 and XQ (Theorems 9.1 and 10.10 modified for the case where A and g do not depend 
on any parameters A). 
• 
55 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
For the case when  in  {LN)  the matrix A  and the vector g depend  continuously 
on parameters  A and  [x, respectively, it is possible to modify  Theorem  12.1, and its 
proof, in the obvious way to show that the unique solutions of the system of equations 
X =  Ait,  A)x +  g{t, fji) 
(LNx^) 
are  continuous  in  A  and  /x  as  well.  [Assume  that  A  G  C(J  X  R^, R^^^)  and 
g G  C (/  X R^, 
/?'^)andfollowaprocedurethatissimilartotheproofofTheoreml2.1.] 
1.13 
SOLUTIONS  OF LINEAR  STATE  EQUATIONS 
In this  section  we determine  the  specific  form  of the  solutions  of  systems  of  linear 
first-order ordinary differential  equations. We will revisit this topic in much  greater 
detail in Chapter 2. 
Homogeneous  equations 
We begin by considering linear homogeneous  systems 
X =  A(t)x, 
(LH) 
where  A  G  C(R,"  R""""^"""").  By  Theorem  12.1", for  every  XQ G  /?^, {LH)  has  a  unique 
solution that exists for all t  G R. We will now use Theorem  10.9 to derive an expres 
sion  for  the  solution  (/)(f, ^o, ^o)  for  (LH)  fovtE.R  with  0(^0, to, XQ)  =  ^Q.  In  this 
case the successive approximations  given in (10.20) assume the  form 
(poit, to, xo)  =  xo 
(f>i{t, to, Xo) =  xo+\ 
A{s)xods 
J to 
(t>2{t,  to,  Xo)  =  Xo+ 
\  A(s)(l)i(s, 
to,  Xo)ds 
Jto 
(t>m(t, to, Xo) =  ^0 + 
JtQ 
A(s)(l)fn-i(s,  to, Xo)ds 
or 
(i>m{t,to,xo)  =  ^0 + 
A{si)xodsi  + 
A{sx) 
A{s2)xods2dsi  + 
Si 
J to 
+ 
ft 
Jto 
fSl 
A(si)\ 
Jto 
J to 
C^m-l 
to 
Afe)---| 
ho 
"A(Stn)XodSm""'dSi "
|/  + 
ft 
Jto 
A(si)dsi  + 
ft 
Jto 
A(s2)ds2dsi  + 
fsi 
A(si) 
Jto 
Sm-l 
+  \  A(si)r 
A(s2y 
Jto 
Jto 
"A(Sm)dSni""'dSi "
Xo, 
(13.1) 
56 
Linear Systems 
where  /  denotes  the  n  X n  identity  matrix.  By  Theorem  10.9, the  sequence  {(l)m}, 
m  =  0,1,2,... 
determined by (13.1) converges uniformly,  as m —^ oo, to the unique 
solution (/)(f, to, XQ) of (LH)  on compact  subsets of R. We thus have 
where  <b{t, to)  = / + 
(/)(/,  to,  Xo)  =  ^(t, 
to)Xo, 
A{si)dsi  + 
I 
rt 
JtQ 
A{si) 
rs, 
J  to 
A(s2)ds2dsi 
Si 
+  I  A(s,) I  Afe) 
S2 
Jto 
JtQ 
+  f  Ais,)^ 
A{S2) 
Jto 
Jto 
A{Sy)dS2,dS2dS\ 
+ 
Sm-\ 
"A{Sm)  dSm  dSm-  l'""dsi "
+ 
-• 
Expression  (13.3) is called the Peano-Baker  series. 
From expression  (13.3) we immediately  note that 
(13.2) 
(13.3) 
(13.4) 
Furthermore, by differentiating  expression (13.3) with respect to time and  substitut 
ing into {LH),  we obtain that 
^(t,t)  =  L 
^{t,to)  =  A{t)^{t,to). 
(13.5) 
From  (13.2)  it  is  clear  that  once  the  initial  data  are  specified  and  once  the 
nXn  matrix ^{t,  to) is known, the entire behavior of system {LH)  evolving in time 
t  is  known.  This  has  motivated  the  state  terminology:  x{to)  =  xo  is  the  state  of 
the system  (LH)  at  time  to, (j>{t, to, xo)  is the  state  of  the  system  (LH)  at  time  t,  the 
solution (f) is called the state vector  of {LH),  the components of ^  are called the state 
variables  of {LH),  and the matrix ^{t,  to) that maps x{to) into cl){t, to, xo) is called the 
state  transition  matrix  for  {LH).  Also, the vector space containing the state vectors 
is called the state  space  for  {LH). 
We can specialize the preceding discussion to Hnear systems of equations 
X =  Ax. 
{L) 
In this case the mth term in (13.3) assumes the  form 
A{si) 
A(S2)\  Afe)-
to 
Jto 
A{Sm)  dSyj 
t  rsi  rs2 
ds\ 
Sm-\ 
to 
=  A^ 
Jto  Jto 
Jto 
Jto 
IdSn 
' ds\  = 
"A'""(t  -  to)"" "
ml 
and expression  (13.1) for  0^  assumes now the  form 
(j)ni{t,  to,  Xo)  =  ^+2: 
A'{t  -  to)^ 
Xo. 
k=i 
k\ 
We conclude once more from Theorem 10.9 that {c/)^} converges uniformly as m ^  oo 
to the unique solution </>(?, to, xo) of (L) on compact  subsets ofR.  We have 
(f){t, to, Xo) = 
A\t 
-  to)'' 
k\ 
Xo 
=  <|)(r, to)xo  =  0(?  -  to)xo, 
(13.6) 
57 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
where  ^(t  -  to) denotes  the  state  transition  matrix  for  (L).  [Note  that  by  writing 
^(t,  to)  =  ^(t  -  to), we have used a slight abuse of notation.] By making the analogy 
with the scalar e^  =  I  + ^1=i{a^lk\),  usage of the notation 
^ 
A^ 
- ' + 1 :^ 
i c -1  k\ 
(13.7) 
should be clear. We call e^  a matrix exponential.  In Chapter 2 we will explore several 
ways of determining  e^  for a given A. 
Nonhomogeneous  equations 
Next, we consider linear nonhomogeneous systems of ordinary differential  equa 
tions 
X =  A(t)x  +  g(t), 
(LN) 
where  A  G  C{R,W^'') 
and  g  G  C(R,"  R"""").  Again",  by  Theorem  12.1,  for  every 
"xo G /?""", (LN)  has a unique solution that exists for all t  E:  R. Instead of deriving  the 
complete  solution  of  (LN)  for  a given  set of  initial  data  x(to)  =  ;co, we  will  guess 
the  solution  and  verify  that it indeed  satisfies  (LN).  To this  end, let us assume  that 
the solution is of the  form 
(t)(t, to, xo)  =  ^(t,  to)xo + 
0(r,  s)g(s)ds 
(13.8) 
where 3>(r, to) denotes the state transition matrix for  (LH). 
To show that (13.8) is indeed the solution of (LN),  we first let t  =  to. In view of 
(13.4) and  (13.8), we have (f)(to, to, xo)  =  xo. Next, by differentiating  both  sides of 
(13.8) and by using (13.4), (13.5), and (13.8) we have 
(j)(t,  to,  Xo)  =  ^(t, 
to)xo  +  ^(t, 
t)g(t) 
+ 
4>(r, s)g(s)  ds 
=  A(t)^(t, 
to)xo +  g(t)  + 
A(t)^(t, 
s)g(s)ds 
=  A(t){^(t,  to)xo  + 
^(t,s)g(s)ds^  +  g(t) 
=  A(t)(f)(t, to, xo)  +  g(t), 
i.e.,  (j)(t, to, Xo) given  in  (13.8)  satisfies  (LN).  Therefore,  (j)(t, to, xo)  is  the  unique 
solution of (LN).  Equation (13.8) is called the variation  of constants formula,  which 
is discussed further in Subsection 2.3C of Chapter 2. In the exercise section of Chap 
ter 2 (refer  to Exercise  2.33), we ask the reader  (with hints) to derive  the  variation 
of constants formula  (13.8), using change  of  variables. 
We note that when  xo  =  0, (13.8) reduces to 
(/)(^, ^0,0)  =  ^p(t)  = 
^(t,s)g(s)ds, 
(13.9) 
and when  XQ 7^ 0 but g(t)  =  0 for all r G /?, (13.8) reduces to 
(l)(t, to, Xo) =  (/)/z(0  =  ^(t,  ^)^0-
(13.10) 
58 
Linear Systems 
Therefore, the total solution  of {LN) may be viewed as consisting of a component that 
is due to the initial conditions {t^,  XQ) and another component that is due to the  'Jorc-
ing term''  g(t).  This type of  separation  is in general possible only in linear  systems 
of differential  equations. We call (l)p  3. particular  solution  of the  nonhomogeneous 
system  (LN)  and call (f)h the homogeneous  solution. 
From  (13.8)  it  is  clear  that  for  given  initial  conditions  x(to)  =  XQ and  given 
forcing  term g(t),  the behavior  of system  (LN),  summarized  by  </>,  is known  for  all 
t. Thus, (/)(r, to, xo)  specifies  the state  vector  of  (LH)  at time  t. The components </>/ 
of (/), /  =  1,...,  n, represent the state  variables  for  (LH),  and the vector  space that 
contains the state vectors is the state  space  for  (LH). 
Before  closing this section, it should be pointed out that in applications the ma 
trix A(t)  and the vector  g(t)  in  (LN)  may be only piecewise  continuous  rather  than 
continuous, as assumed above [i.e., A(t)  and g(t) may have (at most) a finite number 
of  discontinuities  over  any  finite  time  interval]. In  such  cases,  the  derivative  of  x 
with respect  to t  [i.e., the right-hand  side in  (LN)],  will be discontinuous  at a finite 
number of instants over any finite time interval; however, the state itself, x, will still 
be  continuous  at  these  instants  [i.e., the  solutions  of  (LN)  will  still  be  continuous 
over R].  In  such  cases,  all the  results  presented  concerning  existence,  uniqueness, 
continuation of solutions, and so forth, as well as the explicit expressions of solutions 
of  (LN),  are either  still valid  or can be modified  in the obvious  way. For  example, 
should g(t)  experience a discontinuity  at, say, ti  >  to, then expression (13.8) will be 
modified  to read 
(/>(r, to, Xo) =  ^(t,  to)xo + 
^(t,  s)g(s)ds, 
to^ 
t<ti, 
(13.11) 
(t)(t,ti,xx)-^^(t,ti)xi 
+  \  ^(t,s)g(s)ds, 
t^tu 
(13.12) 
where xi  =  lim^^^- (l)(t, to, xo). 
1.14 
STATE-SPACE  DESCRIPTION  OF  CONTINUOUS-TIME  SYSTEMS 
Returning  now to Section  1, let us consider  once more  systems  described  by  equa 
tions of the  form 
X =  f(t,x,  u) 
y^g(t,x,ul 
(14.1a) 
(14.1b) 
"where  x  ^  R""""", y  ^  RP,"  u  ^  R""^","  f  : R  X  R"""" X  R""^ -^  R\  md  g  : R  X  R""""  X "
R^  ^  RP. Here  t  denotes  time  and  u  and  y  denote  system  input  and  system  out 
put,  respectively. Equation  (14.1a) is called the state  equation,  (14.1b) is called the 
output  equation,  and  (14.1a)  and  (14.1b)  constitute  the  state-space  description  of 
continuous-time  finite-dimensional  systems. 
The system input may be a function  of t only (i.e., u : R->  R^),  or as in the case 
of feedback  control systems,  it may be a function  of t and x (i.e., u : RX  R^ -^  R^). 
In either  case, for  a given  (i.e., specified)  u, we let  f(t,  x, u)  =  F(t,  x)  and  rewrite 
(14.1a)  as 
X =  F(t,  x). 
(14.2) 
59 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
Now  according  to Theorems  10.8  and  10.10," if  F  G  CiR  X /^"""," R"""")  and  if  for  any "
compact  subinterval  JQ C  R  there  is  a constant  Lj^  such  that  \\F(t, x)  -  F(t,  x)\\  < 
Lj^\\x -  x\\ for  all t  G  JQ and for all x, x  G R^,  then the following  are true: 
1.  For any (^,  XQ) ^  Rx  R^,  Eq. (14.2) has a unique solution (f)(t, to, XQ)  satisfying 
(/)(ro, to," xo)  =""  XQ that exists for all t  ^  R. "
2.  The solution 0  is continuous in t, to, and XQ. 
3.  If F depends continuously on parameters (say, \  G R^) and if XQ depends  contin 
uously on A, the solution (/> is continuous in A as well. 
Thus,  if  the  above  conditions  are  satisfied,  then  for  a  given  to, XQ,  and  u,  Eq. 
(14.1a) will have  a unique  solution that exists  for  t  E. R.  Therefore,  as already  dis 
cussed  in  Section  13,  (^(^, to, xo)  characterizes  the  state  of  the  system  at  time  t. 
Moreover, under these conditions, the system will have a unique response for t  E  R, 
determined by Eq. (14.1b). We usually assume that g  G  C(R  X i?^ X /^^, RP) or that 
gG 
C\RXR''XR'^,RP). 
An important  special case of (14.1a) and (14.1b) is systems described by linear 
time-varying  equations of the  form 
X =  A(t)x  +  B(t)u 
y  =  C(t)x  +  D(t)u, 
(14.3a) 
(14.3b) 
where  A  G  C(R,"  R'""'""'')",  B  G  C(R,"  R'""'""'^)",  C  G  C{R,"  RP"""""""")",  and  D  G  C(R,"  RP""""""^). "
Such equations may arise in the modeling process of a physical system, or they may 
be a consequence of a linearization process, as discussed in Section 11. 
By  applying  the  results  of  Section  12  we  see  that  for  every  initial  condition 
x{to)  =  Xo and for every given input w  : R^ 
solution  that exists  for  alltGR 
and that is continuous  in  (t, to, xo). Moreover,  if A 
and  B  depend  continuously  on parameters,  say,  A G  /?^ then  the  solutions  will  be 
continuous in the parameters as well. Indeed, in accordance with (13.8), this solution 
is given by 
"i?'""", system (14.3a) possesses a unique 
(/)(r, to, Xo) =  ^(t,  to)xo + 
^(t, 
s)B(s)u(s)ds, 
(14.4) 
Jto 
where ^(t,  to) denotes the state transition matrix of the system of equations 
X =  A{t)x. 
(14.5) 
By using (14.3b) and (14.4) we obtain the system  response  as 
y(t)  =  C(t)<^(t, to)xo +  C(t) 
^(t,  s)B(s)u(s)ds  +  D{t)u{t\ 
(14.6) 
JtQ 
When in (14.3a) and (14.3b), A{t)  ^  A, B{t)  ^  B,  C{t)  =  C, and D(t)  =  D, we 
have the important linear time-invariant  case given by 
X =  Ax-\-  Bu 
y  =  Cx  + Du. 
(14.7a) 
(14.7b) 
In  accordance  with  (13.6),  (13.7),  (13.8),  and  (14.4),  the  solution  of  (14.7a)  is 
given by 
(t){t,to,xo)  =  e^'^'-'^^xo  + 
e''^'~'^Bu(s)ds 
(14.8) 
ho 
60 
Linear Systems 
and the response of the system is given by 
y(t)  =  Ce^^^'-'^ho  +  C  [  e^^'-'^Bu{s)ds  +  Du{t\ 
(14.9) 
Linearity 
We  have  referred  to  systems  described  by  the  hnear  equations  (14.3a)  and 
(14.3b)  [resp.,  (14.7a)  and  (14.7b)]  as  linear  systems.  In  the  following,  we  estab 
lish precisely  the  sense in which  this  linearity  is to be understood.  To this  end,  for 
(14.3a)  and  (14.3b)  we first let  yi  and  y2 denote  system  outputs  that  correspond  to 
system inputs given by u\  and W2, respectively, under the condition  that  XQ  =  0. By 
invoking  (14.6), it is clear that the system output corresponding  to the system  input 
u  =  a\U\  •^-  ^2^2, where «i  and a2  are real scalars, is given by y  =  a i ji  +  aiyi^ 
i.e.. 
y{t)  =  C{t)'  <b{t, s)B{s)[a\Ui{s)  +  a2U2{s)\ds  +  D{t)[aiUi{t)  +  a2W2(0] 
=  aiC(r) 
(&(r, s)B(s)ui(s)ds  +  0:2^(0 
*(^,  s)B(s)u2(s)ds 
+  aiD(t)ui(t)  +  a2D(t)u2(t) 
=  aiyiit)  + a2y2{t\ 
(14.10) 
Next,  for  (14.3a)  and  (14.3b)  we let  yi  and  j2  denote  system  outputs  that  cor 
respond  to  initial  conditions  XQ  and  XQ  ,  respectively,  under  the  condition  that 
u(t)  =  Q for  all  t  ^  R,  Again,  by  invoking  (14.6),  it  is  clear  that  the  system  out 
put corresponding to the initial condition XQ =  aix^^^ + o^2^^o\ where a 1  and a 2 are 
real scalars, is given by  y  =  aiyi  -{-  0:2J2. i-^-? 
y(t)  =  C(00(r,fo)[«i4'^  +  «24'^] 
=  aiC(t)^(t, 
=  aiyi(t)  + a2y2{tl 
to)x^d^  +  a2C{t)^{t, to)x^o^ 
(14.11) 
Equations  (14.10)  and  (14.11)  show  that  for  systems  described  by  the  linear 
equations  (14.3a),  (14.3b)  [and  hence,  also  by  (14.7a),  (14.7b)],  a  superposition 
principle  holds in terms of the input u and the corresponding  output y of the  system 
under the assumption of zero initial conditions, and in terms of the initial conditions 
XQ and the corresponding output y under the assumption of zero input. It is important 
to note, however,  that  such  a superposition  principle  will in general  not hold  under 
conditions that combine nontrivial inputs and nontrivial initial conditions. For exam 
ple, with xo #  0 given, and with inputs ui  and U2 resulting in corresponding  outputs 
yi  and j2  in (14.3a) and  (14.3b), it does not follow  that the input aiwi  +  ^2^2  will 
result in an output a\yi  + a2}^2-
1.15 
STATE-SPACE  DESCRIPTION  OF DISCRETE-TIME  SYSTEMS 
State-space  representation 
The  state-space  description  of discrete-time  finite-dimensional  dynamical  sys 
tems is given by equations of the  form 
Xi(k  +  1)  =  fi(k,  xi(k),...,  Xn(k), u\{k),...,  Utn{k)) 
yi{k)  =  gi{k, xi(k),...,  Xn(kl  ui(k),...,  Um(k)) 
i  =  I,..  .,n, 
i  =  1,..., p, 
(15.1a) 
(15.1b) 
for fc =  k{),k{)+\,...,  where fco is an integer. (In the following we let Zdenote the set 
of integers  and we let Z+  denote the set of nonnegative  integers.) Letting  x{kY  = 
(Xiikl 
=  (/l(  • X  . . . , / .(  • )),  U(k)^  =  (Ui(kl  . . ., Um(k)X 
f{'f 
y(kf  =  (yi(k\...,yp(k)), 
)),  we  can  rewrite 
and  g(  - V  =  (gi(  'l...,gm(' 
(15.1a) and (15.1b) more compactly  as 
. . ., Xn(k)l 
61 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
x(k  +  1)  =  f(k  x{k),  u(k)) 
y{k)  =  g{K x{k),  u{k)). 
(15.2a) 
(15.2b) 
"Throughout  this  section  we  will  assume  that  f  : Z  X  R^  X  R""^ -^  R^  and  g  : Z X "
Since /  is  a  function,  for  given  ko, x{ko)  =  XQ,  and  for  given  u(k),  k  =  ko, 
ko + I,...,  Eq.  (15.2a) possesses  a unique  solution  x(k)  that exists  for  all  k  =  ko, 
^0 +  1. 
Furthermore,  under  these  conditions,  y(k)  is uniquely  defined  for  k  = 
ko,ko  + 
I.... 
As in the case of continuous-time  finite-dimensional  systems  [see Eqs.  (14.1a) 
and  (14.1b)], ko denotes  initial  time,  k denotes  time,  u{k)  denotes the  system  input 
(evaluated at time k), y(k)  denotes the system output  or system response  (evaluated 
at  time  k),  x(k)  characterizes  the  state  (evaluated  at  time  k),  Xi(k),  i  =  I,.. 
.,n, 
denote the state  variables,  (15.2a) is called the state  equation,  and (15.2b) is called 
the output  equation. 
A  moment's  reflection  should  make  it  clear  that  in  the  case  of  discrete-time 
finite-dimensional  dynamical  systems described by (15.2a), (15.2b), questions con 
cerning existence, uniqueness, and continuation of solutions are not an issue, as was 
the case in continuous-time  systems. Furthermore, continuity  with respect to initial 
data  x(ko)  =  XQ, or with  respect  to  system  parameters,  is  not  an  issue  either,  pro 
vided that /(  • ) and g(  • ) have appropriate continuity properties. 
In the case of continuous-time  systems described by ordinary differential  equa 
tions [see Eqs. (14.1a) and (14.1b)]," we allow time t to evolve ""forward""  and  ""back "
"ward."" Note", however, that in the case of discrete-time systems described by (15.2a) 
and  (15.2b),  we  restrict  the  evolution  of  time,  k,  in  the  forward  direction  to  en 
sure  uniqueness  of  solutions.  (We  will  revisit  this  issue  in  further  detail  in  Chap 
ter 2.) 
Special  important  cases  of  (15.2a),  (15.2b)  are  linear  time-varying  systems 
given by 
x(k  +1)  =  A(k)x(k)  +  B(k)u(k) 
y(k)  =  C(k)x(k)  +  D(k)u(k), 
(15.3a) 
(15.3b) 
"i?""^""",  B  : Z-^ 
"RP"""""""""," and  D  : Z  ^  RP""""""^.  When "
where  A  : Z-^ 
A(k)  =  A, B(k)  =  B,  C(k)  =  C, and D(k)  =  £), we have linear  time-invariant  sys 
tems given by 
"i^""><^",  C  :Z^ 
x(k  +  1)  =  Ax(k)  +  Bu(k) 
y(k)  =  Cx(k)  4-  Du(kl 
(15.4a) 
(15.4b) 
62 
Linear Systems 
As in the case of continuous-time  finite-dimensional  dynamical  systems, many 
^f the qualitative properties of discrete-time  finite-dimensional  systems can be stud 
ied in terms of initial-value  problems  given by 
x(k  +  1)  =  f(k  x(k)\ 
x(ko)  =  xo, 
(ID) 
"where  x  E. R"""""," f  : Z  X  R""""  -^  R""""",  ko  G  Z,  and  ^  =  ^o, 'to  +  1 , . . ..  We  call  the 
equation 
x(k  +  1)  =  f(k,  x(k)\ 
(ED) 
a system  offirst-order  ordinary difference  equations.  Special important cases of  (ED) 
include autonomous  systems  described  by 
periodic  systems  given by 
x(k  +  1)  - 
f(x(k)), 
x(k  +  1)  =  f(k,  x(k))  =  f(k  +  K, x(k)) 
"for fixed K  G Z""^ and for all  k  G Z",  linear  homogeneous  systems  given by 
linear periodic  systems  characterized  by 
x(k  +  1)  =  A(k)x(k), 
x(k  +1)  =  A(k)x(k)  =  A(k  +  K)x(k) 
(AD) 
(PD) 
(LHD) 
(LPD) 
for fixed K  E. Z^  and for all  kE  Z,  linear  nonhomogeneous  systems  given by 
and linear, autonomous,  homogeneous  systems  characterized  by 
x(k  +  1)  =  A(k)x(k)  +  g(k), 
x(k  +  1)  =  Ax(k). 
(LND) 
(LD) 
In these equations  all symbols used  are defined  in the obvious way by making  ref 
erence  to  the  corresponding  systems  of  ordinary  differential  equations  (see  Sub 
section  1.3B). 
Difference  equations of order n 
Thus  far  we  have  addressed  systems  of  first-order  difference  equations.  As  in 
the continuous-time case, it is also possible to characterize initial-value problems by 
nth-order ordinary  difference  equations, say, 
y(k  +n)  =  h(k,  y(k),  y(k  +  I),..  .,y(k  + n -  \)), 
(E^D) 
where  h  : Z  X  R^ ^  R,  n  G Z^,  k  =  ko, ko -\-  1, —  By  specifying  an initial  time 
ko G  Z  and  by  specifying  y(kQ), y(ko  +  1),...,  y(ko  +  n  -  1),  we  again  have  an 
initial-value problem given by 
y(k  + n)  =  h(k,  y(k),  y(k  -h 1),..  .,y(k  + n  -  I)) 
y(ko)  =  xio,..., y(ko  -\-  n -  I)  =  x^o-
UnD) 
We  call  (EfiD) an  nth-order  ordinary  difference  equation  and  we  note  once  more 
that in the case of initial-value  problems  described  by  such equations, there are no 
difficult  issues involving the existence, uniqueness  and continuation of solutions. 
We can  reduce  the  study  of  (IUD)  to the  study  of  initial-value  problems  deter 
mined  by  systems  of  first-order  ordinary  difference  equations. To accomplish  this. 
we let in (Ino) y(k)  =  xi(k),  y(k  +  1)  =  X2(k),...,  y(k  +  n -  1) 
obtain the system of first-order  ordinary  difference  equations 
xi(k  +  1)  =  X2(k) 
Xn-l(k  +  1)  == Xn(k) 
Xn(k +  1)  =  h(k,  xi(k),...,  Xn(k)). 
Xn(k). We now 
63 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(15.5) 
Equations  (15.5), together  with  the initial  data  XQ  =  (xio,..., Xno), are  equivalent 
to the initial-value problem (Ino) in the sense that these two problems will  generate 
identical  solutions  [and in the  sense that the transformation  of (Ino)  into (15.5)  can 
be reversed unambiguously  and uniquely]. 
As  in  the  case  of  systems  of  first-order  ordinary  difference  equations,  we  can 
point to several important  special  cases  of nth-order  ordinary  difference  equations, 
including equations of the  form 
y(k  + n)  + an-i(k)y(k 
-\-  n -  1)+  • • 
+  ai{k)y(k  +  1) +  ao(k)y{k)  =  g{k\ 
(15.6) 
y(k  + n)  -\-  an-i(k)y(k  + n-  1)+  • • 
+  ai(k)y(k  +  1) +  ao(k)y(k)  =  0, 
-\-  n -  1)+  • • 
and  y{k  +  n)  +  a^-iyik 
+  aiy(k  +  1) +  aoy(k)  =  0. 
(15.7) 
(15.8) 
We  call  (15.6)  a  linear  nonhomogeneous  ordinary  difference  equation  of  order 
n;  we  call  (15.7)  a  linear  homogeneous  ordinary  difference  equation  of  order  n; 
and we call (15.8) a linear, autonomous,  homogeneous  ordinary  difference  equation 
of order n. As in the case of systems of first-order ordinary difference  equations, we 
can dtfmQ periodic  and linear periodic  ordinary  difference  equations  of order n in 
the obvious way. 
Solutions of state  equations 
Returning now to linear homogeneous  systems 
we observe that 
x{k  +\)  =  A(k)x(k), 
(LHD) 
x(k  +  2)  =  A(k  +  l)x(k  +  1)  -  A(k  + 
l)A(k)x(k) 
x(n)  =  A(n  -  l)A(n  -  2) • • • A()t + 
l)A{k)x(k) 
n-\ 
=  YlA(j)x(k), 
i.e., the state of the system at time n is related to the state at time k by means of the 
nX  n matrix  YI^JZ\A(J) 
(as can easily be proved by induction). This  suggests  that 
the state  transition  matrix  for  (LHD) is given by 
n-l 
^(n, k) = Yl Mjl 
n> k, 
and that 
^(k,  k)  =  I. 
(15.9) 
(15.10) 
64 
Linear Systems 
As in the continuous-time  case, the solution to the initial-value  problem 
^(^ +  1)  ^  A(k)x(k) 
x(ko)  =  Xk^, 
ko G Z, 
is now given by 
n-l 
x(n)  =  ^(n,  ko)xk,  =  n 
^U)^h, 
n  >  ko. 
(15.12) 
Continuing,  let  us  next  consider  initial-value  problems  determined  by  linear 
nonhomogeneous  systems 
(LND), 
x(k+l)  =  A(k)x(k)  + 8(k) 
^^^^3^ 
x(ko)  = Xk^. 
Then 
x(ko  +  1)  -  A{ko)x(ko)  +  g(ko) 
x(ko  +  2)  =  A(ko  +  l)x(ko  +  1) +  g(ko  +  1) 
-  A(ko  +  l)A(ko)x(ko)  +  A(ko  +  l)g(ko)  +  g(ko  +  1) 
x(ko  +  3)  =  A(ko  +  2)4^0  +  2) -h ^(^o  +  2) 
-  A(fco  +  2)A(ko  +  l)A(/:o)4/:o)  +  A(ko  +  2)A(/:o  +  l)g(^o) 
+  A(ko  +  2)^(fco  +  1) +  g(ko  +  2) 
=  0(/:o  +  3, ^o)^;to  +  ^(^0  +  3, /:o +  l)g(^o) 
+  cD(/:o +  3, /:o +  2)g(ko  +  1) +  *(/:o  +  3, /CQ +  3)g(^o  +  2), 
and  so  forth.  For fc >  A:o +  1, we  easily  obtain  the  expression  for  the  solution  of 
(15.13)  as 
x(k)  =  ^(k,  ko)Xk, +  X  ^ ( ^' ^' +  1)^0'). 
(15.14) 
k-i 
We note that when  x^^  =  0, (15.14) reduces to 
xp{k)= 
k-i 
^^{kJ+DgUl 
; = ^o 
(15.15) 
and when  x^^ T^  0 but ^(/:)  =  0, (15.14) reduces to 
(15.16) 
Therefore, the total solution  of (15.13) consists of the sum of its particular  solution, 
Xp(k),  and its homogeneous  solution,  Xh(k). 
Xh{k)  =  ^{kko)xk,. 
System  response 
Finally, we observe that in view of (15.3b)  and (15.14), the system  response  of 
the system (15.3a), (15.3b) is of the  form 
k-\ 
y(k)  =  C(kmk,  ko)Xk,  +  C(k) X  ^(k,  J +  ^)BUMj)  + D(kMk\ 
k > ko, 
and 
yiko)  =  C(ko)Xk,  + D{ko)u(ko). 
(15.17) 
(15.18) 
Discrete time systems, as discussed  above, arise in several ways, including  the 
numerical  solution  of  ordinary  differential  equations  (see,  e.g.,  our  discussion  of 
Euler's  method  in  Subsection  1.6B); the representation  of sampled-data  systems  at  Mathematical 
Descriptions of 
discrete  points  in  time  (which  will  be  discussed  in  further  detail  in  Chapter  2); in 
the modeling process of systems that are defined  only at discrete points in time (e.g., 
Systems 
digital computer  systems); and so forth. 
65 
CHAPTER 1: 
As  a  specific  example  of  a  discrete-time  system  we  consider  a  second-order 
section  digital  filter  in direct  form, 
X\{k  +  1)  =  X2{k) 
X2(k +  1)  =  axi{k)  +  bx2(k)  +  u(k) 
y(k)  =  xi(k\ 
(15.19a) 
(15.19b) 
k  G Z^,  where  xi(k)  and  X2(k) denote  the  state  variables,  u(k)  denotes  the  input, 
and y(k)  denotes the output of the digital filter. We depict system (15.19a), (15.19b) 
in block diagram form in Fig.  1.13. 
ujk)  + 
X2(/f +  1^ 
+ 
/v 
1 
x,(k  + 1) 
Unit 
delay 
x,(k) 
=  y(k) 
Unit 
delay 
b 
FIGURE 1.13 
Second-order section digital filter in direct form 
a 
1.16 
INPUT-OUTPUT  DESCRIPTION  OF  SYSTEMS 
This  section  consists  of  four  subsections.  First  we  consider  rather  general  aspects 
of the input-output  description  of  systems. Because  of their  simplicity,  we  address 
the characterization  of linear discrete-time  systems next. In the third  subsection  we 
provide  a  foundation  for  the  impulse  response  of  linear  continuous-time  systems. 
Finally, we address the external description  of linear continuous-time  systems. 
A.  External  Description  of Systems: General  Considerations 
The  state-space  representation  of  systems  presupposes  knowledge  of  the  internal 
structure  of the system. When  this  structure  is unknown,  it may  still be possible to 
arrive at a system description—an  external  description—that  relates  system  inputs 
to  system  outputs.  In  linear  system  theory,  a great  deal  of  attention  is  given  to re 
lating  the  internal  description  of  systems  (the  state  representation)  to  the  external 
description  (the input-output  description). 
66 
Linear Systems 
In the present context, we view system  inputs  and system  outputs  as elements of 
two real vector spaces  U and  7, respectively,  and we view a system as being repre 
sented by an operator  T that relates elements of  U to elements of  F. For  u  E. U and 
J  G  7  we will assume that  u:  R^  R^  and y  \ R-^  RP m  the case of  continuous-
time  systems,  and  that  u  : Z  —>  R^  and  y  : Z  ^  RP in  the  case  of  discrete-time 
systems.  For  continuous-time  systems  we define  vector  addition  (on  U) and  multi 
plication of vectors by scalars (on  L^) as 
and 
"(ui  +  U2)(t)  ="" ui(t)  +  U2(t) "
{au){t)  =  au(t) 
(16.1) 
(16.2) 
for all ui,  U2  E  U,a  G R,  and t  E  R. We similarly  define  vector addition  and mul 
tiplication  of  vectors  by  scalars  on  Y.  Furthermore,  for  discrete-time  systems  we 
define  these operations  on  U and  Y analogously. In this case the elements  of  U and 
Y  are real  sequences  that  we  denote,  e.g.,  by  w =  {uk} or u  =  {u(k)}.  (It  is  easily 
verified  that under these rather general conditions,  U and  Y satisfy  all the axioms of 
a vector space, both for the continuous-time case and the discrete-time case.) In the 
continuous-time  case as well  as in the discrete-time  case the  system  is  represented 
hy  T  : U ->  Y, and we write 
y  =  T(u). 
(16.3) 
In the subsequent development, we will impose restrictions on the vector spaces 
U,  F,  and  on  the  operator  T,  as  needed.  For  example,  if  T is  a linear  operator,  the 
system is called a linear  system.  In this case we have 
3;  =  T(aiui  +  ^2^2) 
=  aiT(ui)  +  a2T(u2) 
=  aiyi  +  0:2^2 
(16.4) 
for all a i, 0^2 E  /?and ui,  U2  G U, where j/  =  T{ui)  E  7, /  =  1,2,  and j  E  Y. Equa 
tion (16.4) represents the well-known  principle  of superposition  of linear  systems. 
(SISO) 
system.  Systems  for  which  m  >  1,  p  >  1,  are  called  multi-input/multi-output 
(MIMO)  systems. 
If  in  the  above,  m  =  p  =  1, we  speak  of  a single-input/single-output 
We  say that  a system  is memoryless,  or without  memory,  if  its output  for  each 
value of the independent  variable  {t or k)  is dependent  only  on the input  evaluated 
at the same value of the independent  variable  [e.g., yit\)  depends only on u{t\)  and 
y{k\)  depends  only  on  u{k\)l.  An  example  of  such  a  system  is the  resistor  circuit 
shown  in Fig.  1.14,  where the current  i{t)  =  u(t)  denotes  the  system  input  at  time 
t and the voltage across the resistor, v(t)  =  Ri(t)  =  y(t),  denotes the system  output 
at time  t. 
v{t) 
FIGURE 1.14 
Resistor circuit 
A system that is not memoryless is said to have memory. An example of a con- 
tinuous time system with  memory  is the capacitor circuit shown in Fig.  1.15,  where 
the current  i(t)  =  u(t)  represents  the  system  input  at time  t and  the voltage  across  Mathematical 
the capacitor, 
67 
CHAPTER 1: 
Descriptions of 
Systems 
y{t)  =  v(t)  -  -  I 
/(T)  dr, 
1  r t 
denotes  the  system  output  at time  t. Another  example  of  a continuous-time  system 
with memory is described by the scalar  equation 
y(t)  =  u(t  -  1), 
K 
and an example of a discrete-time system with memory is characterized by the scalar 
equation 
y(n)  =  ^ 
x(k), 
n, k  G  Z. 
A system is said to be causal if its output at any time, say, ti  (or ki)  depends only 
on values  of  the  input  evaluated  for  t  ^  ti  (for  /: <  k\).  Thus,  y(ti)  depends  only 
on u{t), t  ^  ti  [or y(ki)  depends only on u(k), fc <  ki].  Such a system is referred  to 
as being nonanticipative  since the system output does not anticipate future  values of 
the input. 
To make the above concept a bit more precise, we define  the function  Uj :  R^ 
"R""^ fovu^U "
by 
Uj{t) 
_  J  u{t\ 
0, 
/<  T, 
t  >  T, 
and we similarly define the function  yj  \ R -^  RP fox y  ^  Y. K  system that is repre 
sented by the mapping  y  ^^ T(u)  is said to be causal  if and only if 
(T(u))r 
- 
(T(Ur))r 
for  all  TG  R,  for  all  uGU. 
Equivalently,  this system is causal if and only if for  u,v^U 
that 
and  u^  =  Vr it is true 
(T(u))r  =  (T(v))r 
for all r  ^  R. 
For example, the discrete-time  system described by the scalar  equation 
y(n)  =  u(n)  -  u(n  +1), 
n  G  Z 
is  not  causal.  Neither  is  the  continuous-time  system  characterized  by  the  scalar 
equation 
y(t)  =  x(t  +1), 
t  E  R. 
v{t) 
FIGURE 1.15 
Capacitor circuit 
68 
Linear Systems 
It  should be pointed  out that  systems  that  are not causal  are by  no means  use-
1^^^- ^^^  example, causality  is not  of fundamental  importance in  image-processing 
applications  where the independent  variable  is not time. Even  when time is the in 
dependent variable, noncausal systems may play an important role. For example, in 
the processing of data that have been recorded (such as speech, meteorological  data, 
demographic data, stock market fluctuations, etc.), one is not constrained to process 
ing the data causally. An example of this would be the smoothing of data over a time 
interval, say, by means of the  system 
">'^""^ = 2MTT  S  ""(« - ^)-"
k=-M 
A  system is said to be time-invariant  if a time shift  in the input  signal causes a 
corresponding time shift in the output signal. To make this concept more precise, for 
fixed a  E  i?, we introduce the shift  operator  Qa  - U -^  L^ as 
Qaii(t)  =  u{t -  a\ 
uG  Uj  ^  R. 
A  system that is represented  by the mapping  y  =  T(u)  is said to be  time-invariant 
if and only if 
TQaiu)  =  Qa(T(u))  =  Qaiy) 
for  any  a  E  R  and  any  w E  t/.  If  a  system  is  not  time-invariant,  it  is  said  to  be 
time-varying. 
For example, a system described by the relation 
is time-invariant. To see this, consider the inputs  ui(t)  and U2(t) == ui(t  -  to). Then 
y(t)  =  cos  u(t) 
yi(t)  =  COSWi(r), 
yiit)  ==  C0SU2(t)  = 
COSUi(t-to) 
and 
As a second example, consider a system described by the relation 
yi(t  -  ^o)  =  cosui(t  -  to)  =  y2(t). 
y(n)  =  nu(n) 
and consider two inputs  ui{n)  and  U2(n) =  u\{n~  no). Then 
y\{n)  — nui(n) 
and 
yiM  =  nu2(n)  =  nu\{n  —  no). 
However, if we shift  the output yi{n)  by no, we obtain 
yi{n  -  no)  =  (n  -  no)ui(n  -  ^o)  ^  yiin). 
Therefore,  this system is not  time-invariant. 
B.  Linear Discrete-Time  Systems 
In this subsection  we investigate the representation  of linear discrete-time  systems. 
We begin our discussion by considering  SISO  systems. 
In  the  following,  we  employ  the  discrete-time  impulse  (or  unit pulse  or  unit 
sample),  which is defined  as 
8{n)  =  \ 
[ 0, 
I I, 
^7^0, n  E Z, 
n  =  0. 
(16.5) 
Note that if  {p{n)}  denotes the unit step sequence,  i.e., 
then 
and 
J l, 
^ ^ ^ ^ ~ | o, 
5{n)  = p{n)  — p{n—  1) 
/ I > 0 , / I G Z, 
n < 0 , n G Z, 
p{n) 
^lk=oS{n-k), 
^0, 
n>0, 
n<0. 
Furthermore, note that an arbitrary  sequence  {x{n)}  can be expressed as 
x{n)= 
^ 
x{k)5{n-k). 
69 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
(16.6) 
(16.7) 
(16.8) 
In Example  10.8 we showed that a transformation  T  :U  ^Y  determined by the 
equation 
y{n)= 
^ 
k=-oo 
h{n,k)u{k), 
(16.9) 
where y =  {y{k)}  G F, w =  {w(^)} G 6^, and /z: Z x Z ^  /^, is a linear  transformation. 
We also noted in Example  10.8 that for (16.9) to make any sense, we need to impose 
restrictions  on {h{n,k)}  and  {u{k)}.  For example, if for every fixed n, {h{n,k)}  G h 
and  {u{k)}  ^  h  =  U,  then  it  follows  from  the  Holder  Inequality  (resp.,  Schwarz 
Inequality),  that  (16.9)  is  well  defined.  There  are  of  course  other  conditions  that 
one  might  want  to  impose  on  (16.9)  (refer  to  Example  10.8).  For  example,  if  for 
every  fixed  n,Yk^_^\h{n,k)\  <  oo (i.e.,  for  every  fixed  n,{h{n,k)}  G h)  and  if 
"sup^^2 W(^)\ <  ""^ (i-^-' {i^{k)}  ^  loo)", then (16.9) is also well  defined. 
We  shall  now  elaborate  on the  suitability  of  (16.9)  to represent  linear  discrete-
time  systems.  To  this  end,  we  will  agree  once  and  for  all  that,  in  the  ensuing 
discussion,  all  assumptions  on  {h{n,k)}  and  {u{k)}  dire  satisfied  that  ensure  that 
(16.9) is well  defined. 
We will view y eY  and ueU  SLS system outputs and system inputs, respectively, 
and we let r  : L^ ^  F denote a linear transformation  that relates u to y. We first con 
sider the case when u{k) =Ofork<ko, 
k,  ko ^  Z. Also, we assume that for ^ >  n  > 
^0, the inputs u{k) do not contribute to the system output at time n (i.e., the system is 
causal).  Under these assumptions, and in view of the linearity of T, and by invoking 
the representation of signals by (16.8), we obtain for j  =  {y{n)},n  G Z, the expression 
y{n)  = r ( i r_  uik)d{n  -k))  = Ti^Uo  <k)5{n-k))= 
^l=k  h{n,k)u{k),n  > ko, dindy{n)  =  0,/i  <  ^o, where  T{5{n  — k))  =  {T5){n  — k)  = 
h{n,k)  represents  the response  of  T  to  a unit  pulse  (resp.,  discrete-time  impulse  or 
unit sample) occurring atn  =  k. 
Y.U,  u{k)T{5{n-k)) 
= 
When  the  assumptions  in  the  preceding  discussion  are  no  longer  valid,  then 
a  different  argument  than  the  one  given  above  needs  to  be  used  to  arrive  at  the 
system  representation.  Indeed,  for  infinite  sums,  the  interchanging  of  the  order  of 
the  summation  operation  X  with  the  linear  transformation  T  is  no  longer  valid. 
"We  refer  the  reader  to  a  paper  by  I.  W.  Sandberg  (""A  Representation  Theorem "
"for  Linear  Discrete-Space  Systems""", IEEE  Transactions  on  Circuits and  Systems-I, 
Vol.  45,  No.  5,  pp.  578-580,  May  1998.)  for  a  derivation  of  the  representation 
of  general  linear  discrete-time  systems.  In  that  paper  it  is  shown  that  an  extra 
term  needs  to  be  added  to  the  right-hand  side  of  equation  (16.9),  even  in  the  rep 
resentation  of  general,  linear,  time-invariant,  causal,  discrete-time  systems.  (In 
the  proof,  the  Hahn-Banach  Theorem  (which  is  concerned  with  the  extension  of 
70 
Linear Systems 
bounded  linear  functionals)  is  employed  and  the  extra  required  term  is  given  by 
lim/^oo T{Yk^^~^  u{k)5{n  — ^) + Er=Q+l u{k)5{n  — k))  with  c/  ^  ©o  as  / ^  ©o. For 
a  statement  and  proof  of  the  Hahn-Banach  theorem,  refer,  e.g.,  to  reference  [12, 
pp.  367-370]  given  at the  end  of  this  chapter.)  In  that  paper  it is  also  pointed  out, 
however, that cases with such extra non-zero terms are not necessarily of importance 
in applications. In particular, if inputs and outputs are defined  (to be non-zero) on just 
the non-negative  integers,  then  for  causal  systems  no  additional  term  is needed  (or 
more specifically, the extra term is zero), as seen in our earlier argument. In any event, 
throughout  the present  book we will concern  ourselves  with  linear discrete-time  sys 
tems which  can be  represented  by equation  (16.9) for  the  single-input/single-output 
case (and appropriate generalizations  for multi-input/multi-output  cases). 
Next,  suppose  that  T  represents  a  time-invariant  system.  This  means  that  if 
{/z(/i,0)} is the response to  {5(/i)}, then by time invariance, the response to {d{n — 
^)}is simply {h{n — k,0)}.  By a slight abuse of notation, welet/z(/i —^,0) =h{n  — k). 
Then (16.9) assumes the  form 
y{n)= 
^ 
u{k)h{n-k). 
(16.10) 
Expression  (16.10) is called a convolution sum and is written more compactly  as 
Now by a substitution  of variables, we obtain for  (16.10) the alternative  expression 
y{n)  =  u{n)  ^h{n). 
and therefore, we have 
3^(^) =  ^  h{k)u{n  — k)^ 
y{n)  =  u{n) *h{n)  =  h{n) * w(/i), 
i.e., the convolution operation  * commutes. 
As  a  specific  example,  consider  a  linear,  time-invariant,  discrete-time  system 
with unit impulse response given by 
"^^""""^  =  {  0",' 
n <  0/  =  ''''^^''^' 
0 <  ^ <  1. 
where p{n)  is the unit step sequence given in (16.6). It is an easy matter to show that 
the response of this system to an input given by 
is 
y{n)  = 0, 
/i<  0, 
u{n) =  p{n)  — p{n — N) 
y{n)  =  Y,"a""-'  = a'^- "
-  =  - 
, 
0 < n < A ^, 
yS) 
l—a~^ 
I—a 
and 
y{n)  =  Y  a^-^  =  a ^ ^ —%  = 
ic^o 
l—a~^ 
^, 
I—a 
N<n. 
Proceeding,  with reference  to (16.9), we note that h{n,k)  represents the  system 
output at time n due to a 5-function  input applied  at time k. Now if  system (16.9) is 
causal,  then  its  output  will be identically  zero before  an input  is  applied.  Hence,  a 
linear system (16.9) is causal if and only if 
Therefore,  when the system (16.9) is causal, we have in  fact 
h{n, k)  =0 
for all k  and all n <  k. 
y{n)= 
^  h{n,k)u(k). 
(16.11a) 
We can rewrite (16.1 la) as 
y{^)  ^  ^  h{n^k)u{k)-\-  ^  h{n^k)u{k) 
k=-oo 
k=ko 
^y{ko-l)^f^h{n,k)u{k). 
k=ko 
(16.11b) 
71 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
We say that the discrete-time  system described by (16.9) is at rest 3tk = ko  ^Z 
ko. Accordingly, if system  (16.9) 
ko, implies that y{k)  =Ofork> 
if u{k) =Ofork> 
is known to be at rest at ^ = ^o» we have 
y{^)  =  ^  h{n^k)u{k). 
k=kQ 
Furthermore, if system  (16.9) is known to be causal and at rest at ^ =  ^o» its input-
output description  assumes the form  [in view of (16.1 lb)] 
y{^)  =  ^  h{n^k)u{k). 
k=kQ 
(16.12) 
Next,  turning to linear,  discrete-time, MIMO  systems,  we can generalize  (16.9) 
to 
y{n)=  X  H{n,k)u{k) 
(16.13) 
where y \Z  ^RP 
,u\Z 
^W^.dind 
'hii{n,k) 
h2i{n,k) 
hi2{n,k) 
h22{n,k) 
himin.k)-
h2m{n,k) 
H{n,k) 
(16.14) 
hpi{n,k) 
hp2{n,k) 
where  hij{n^k)  represents  the system  response  at time  n of the  i\h component  of y 
due to a discrete-time  impulse  5 applied at time k at the jth component of u, while 
the inputs  at all other components  of u are being  held  zero.  The matrix H is called 
the discrete-time  unit impulse  response matrix of the system. 
Similarly, it follows  that the system (16.13) is causal if and only if 
H{n^ k) =0 
for all k and all n < k, 
and that the input-output description of linear, discrete-time, causal  systems is given 
by 
n 
y{n)=  ^  H{n,k)u(k). 
(16.15) 
A discrete-time  system described by (16.15) is said to be at rest at k = ko ^Z  if 
u{k) = 0 for ^ > ^0 implies that y{k)  = 0 for ^ > ^o- Accordingly, if system  (16.13) 
is known to be at rest at ^ = ^o, we have 
y{n)= 
J^H{n,k)u{k). 
k=ko 
(16.16) 
72 
Linear Systems 
Moreover, if a linear discrete-time  system that is at rest at ko is known to be causal, 
then its input-output  description reduces to 
n 
y(n)  =  ^  H(n,  k)u(k). 
k=ko 
(16.17) 
Finally, as in (16.10), it is easily shown that the unit impulse response H(n,  k) of 
a linear, time-invariant,  discrete-time MIMO system depends only on the  difference 
of n and k, i.e., by a slight abuse of notation we can write 
H{n,  k)  =  H(n  -  k,0)  =  H(n  -  k) 
(16.18) 
for all n and k. Accordingly, linear, time-invariant, causal, discrete-time MIMO sys 
tems that are at rest at k  =  ko are described by equations of the  form 
n 
y(n)  =  ^H(n- 
k)u(k), 
(16.19) 
We  conclude  by  supposing  that  the  system  on  hand  is  described  by  the  state 
and output equations  (15.3a) and  (15.3b) under the assumption that x(ko)  =  0, i.e., 
the  system  is  at  rest  at  ^  =  ^o- Then,  according  to  Eqs.  (15.17)  and  (15.18),  we 
obtain 
Hin,  k)  =  < 
C(«)0(n, k +  \)B{k), 
Din), 
0, 
n>  k, 
n  =  k, 
n <  k. 
Furthermore, for the time-invariant case we obtain 
H{n -k)  = 
CA^'-^^^^^B, 
\D, 
0, 
n 
n 
n 
>  k, 
=  k, 
< k. 
(16.20) 
(16.21) 
C.  The Dirac Delta  Distribution 
For any linear time-invariant operator P from  C(R,  R) to itself, we say that P  admits 
an  integral  representation  if there exists  an integrable  function  (in the Riemann  or 
Lebesgue  sense), gp  : R^  R,  such that for  any /  G  C(R,  R), 
{Pf){x)  =  (/  * gp){x)  ^ 
r  00 
J  - co 
f(T)gpix 
-  T)  dr. 
We call gp a kernel  of the integral  representation  of  P. 
For the identity operator /  [defined by If  =  f  for any /  E  C(R,  R)] an integral 
representation  for which gp is a function  in the usual sense does not exist (see, e.g., 
Z.  Szmydt,  Fourier  Transformation  and  Linear  Differential  Equations,  D.  Reidel 
Publishing Company, Boston,  1977). However, there exists a sequence of  functions 
{(/)„} such that for  any /  G  C(R,  R), 
(If)(x)  =  fix)  =  l i m (/  * c/>,)(x). 
(16.22) 
To prove  (16.22)  we  will  make  use  of  functions  {(pn) given  by 
«(1  -
-  n\x\). 
0«W  =  < 
0, 
if  IJCI  < 
-
n 
if  \x\ >  -, 
n 
73 
CHAPTER 1: 
Mathematical 
Descriptions of 
Systems 
n  =  1, 2, 3, 
A  plot  of  (/)„ is  depicted  in  Fig.  1.16. 
We  first  establish  the  following  useful  property  of {(/)„}. 
FIGURE  1.16 
LEMMA  16.1.  L e t/  be  a continuous  real-valued  function  defined  on R  and  let  (/>„ be 
defined  as above (Fig.  1.16). Then for any a  E  R, 
lim 
f{T)(f>n{a  -T)dT  = 
f(a). 
(16.23) 
Proof,  It is easy to verify  that for  n  =  1, 2,..., 
Then 
(/>„(T) dr  = 
4>n{T) dr  =  1. 
J-l/n 
(pnici^  ~  T)  dr 
a-l/n 
\ln 
(f)n{a —  T)  dr 
(j)n{T)dT  =  1. 
(16.24) 
We  first  assume  t h a t/  is  a  nonnegative  function.  By  the  continuity  of/  we  may 
suppose that/  assumes  a maximum value  f(bn)  and a minimum value  /(c„), where bn 
and Cn  E  \a  ~  -,a  +  -\.  Then 
I 
n 
n\ 
r  a+l/n 
(l>n(a  -  T)f{T)  dr  = 
3 
Ja-l/n 
(f)n{a  -  T)f(T)  dr 
r a+l/n 
f(bn) 
Ma 
-T)dT  =  f{bn), 
(16.25) 
Ja-\ln 
where we have used  (16.24). In a similar manner we can show  that 
ct>n{a-T)f{T)dT^ 
f{Cn). 
(16.26) 
Since  bn and  Cn 
1 
a  -  -,a  +  -
n 
1 
n 
, it  follows  that  lim„_^oo bn  =  lim„^oo Cn =  a.  Thus, 
(16.25) and (16.26) together with the continuity  of/  imply  (16.23). 
74 
Linear Systems 
To remove the assumption that /  is a nonnegative function,  we recall that every 
continuous  function  /  can  be  written  as  the  sum  of  two  nonnegative  functions, 
/  = /+—/_, where 
.,  J/W, 
"^ ^ ^ "" [ 0", 
if/(x)>0, 
if/(x)<0, 
[-/(x), 
if/(x)<0. 
Then 
lim  / 
f{T)(l)n{a-T)dT 
=  lim  / 
/+(T)0„(a —T)(iT—lim  / 
/_(T)0„(a —T)(iT 
= U{a)-U{a)=f{a). 
• 
The above result, when applied to (16.22), now allows us to J^^n^  a generalized 
function  5  (also called  a distribution)  as the kernel  of  di formal  or symbolic  integral 
representation  of the identity operator/,  i.e., 
f{x)  =  lim  r 
f{T)Ux-T)dT 
= 
/ 
/ ( T ) 5 ( J C - T ) JT 
(16.27) 
(16.28) 
(16.29) 
/f  is emphasized  that expression  (16.28)  is not an integral at all (in the Riemann  or 
Lebesgue  sense), but only  a symbolic  representation.  The generalized function  d  is 
called the unit impulse or the Dirac delta  distribution. 
=  /*5(jc). 
In applications we frequently  encounter functions  /  G C{R^,R).  If we extend  / 
to be defined  on all ofRby 
letting f{x)  =  0 for x <  0, then (16.23) becomes 
lim  / 
f{T)^n{ci-T)dT  = f{a) 
(16.30) 
for any a  >  0, where we have used the fact that in the proof  of Lemma  16.1 we need 
/  to be continuous only in a neighborhood of a. Therefore, for /  G C{R^,R),  (16.27) 
to (16.30) yield 
lim  rf{T)Ut-^)dT^ 
n^^Jo 
rf{T)5{t-T)dT 
Jo 
= f{t) 
(16.31) 
for  any t  > 0. Since the 0^ are even functions,  we have 0^(f  — T) =  0^(T — f),  which 
allows for the representation  d{t — T) =  d{T— t).  We obtain from  (16.31) that 
lim  rf{T)U^-t)dT^ 
n^^Jo 
rf{T)5{T-t)dT 
Jo 
=  f{t) 
for any t > 0. Changing the variable  T^ =  T — f,  we obtain 
lim  r 
f{T'+t)U^')dT'^ 
r 
f{T'  + 
t)5{T')dT'=f{t) 
for any t > 0. Taking the limit f ^  0+, we obtain 
lim  r 
n^^Jo- 
f{T'+  t)UT')dT' 
^  r 
Jo-
f{T')5{T')dT'  = f{Q), 
(16.32) 
where, as in (16.24), J^- f{T')5{T')dT' 
tion 
0f\imn^ooSQf{T'+t)(^n{^')dT'. 
is not an integral, but a symbolic  representa 
75 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
Now  let  s  denote  a  complex  variable.  If  in  (16.31)  to  (16.32)  we  let  / ( T)  = 
e~^^ ^ T >  0, then we obtain the Laplace  transform 
lim  /  e-'^(l)n{T)dT= 
n^^  Jo- 
I  e-'^5{T)dT=l. 
Jo-
Symbolically  we denote (16.33) by 
^ ( 5)  =  1, 
(16.33) 
(16.34) 
and we say that the Laplace transform  of the unit impulse function  or the Dirac delta 
distribution is equal to one. 
Next, we point out another important property  of  5. Consider  a  (time-invariant) 
operator P and assume that P admits an integral representation  with kernel gp.  If in 
(16.31) we let /  =  gp, we have 
\im{P^n){t)=gp{t), 
(16.35) 
and we write this (symbolically)  as 
PS  =  gp. 
(16.36) 
This  shows  that  the  impulse  response  of  a  linear,  time-invariant,  continuous-time 
system  with  integral representation  is equal  to the kernel  of the integral  representa 
tion of the system.  Symbolically this is depicted in Fig.  1.17. 
Next,  for  any  linear  time-varying  operator  P  from  C{R^R)  to  itself,  we  say 
that P admits an integral representation  if there exists  an integrable function  (in the 
Riemann or Lebesgue sense), gp : RxR^ 
R,  such that for any /  G  C{R,R), 
{Pf){ri) = 
iyit)gp{ri,t)dt. 
(16.37) 
Again,  we  call  gp  a kernel  of  the  integral  representation  of  P.  It  turns  out  that  the 
impulse  response  of  a  linear,  time-varying,  continuous-time  system  with  integral 
9)1 
' n 
• 
• 
• 
• 
5 
FIGURE 1.17 
p 
• 
• 
• 
• 
p 
9n 
• 
• 
• 
• 
9p 
oo 
76 
Linear Systems 
representation  is again  equal  to the kernel  of the integral  representation  of the sys-
^^^- To see this, we first observe that if /z G  C{R  X R, R),  and if in Lemma  16.1 we 
replace /  G  C{R, R) by h, then all the ensuing relationships  still hold, with  obvious 
modifications.  In particular,  as in (16.27), we have for  all t  ^  R, 
lim 
h{t, T)(l>n(V  -T)dT  =  I  h{t, 7)8(7] -  T) dj  =  h(t, 7]).  (16.38) 
Also, as in (16.31), we have 
lim 
«^°°Jo 
h(t, T)(j)n{r]  -T)dT  = 
Jo 
h(t, T)8(r] -T)dT  =  hit,  r/) 
(16.39) 
for  7]>0. 
Now let hit,  T)  =  grit,  r). Then (16.38)  yields 
r  00 
^ 00 
lim 
gpit,  r)cl)niv -r)dr 
= 
gp(t,  7)8(7] -7)d7  =  grit,  T]), 
(16.40) 
which establishes our assertion. The common interpretation of (16.40) is that gp(t, 17) 
represents  the response of the system at time t due to an impulse applied  at time  r/. 
In  establishing  the  results  of  the  present  subsection,  we  have  made  use  of  a 
specific  sequence of functions  {(/>„} given by 
n(\  -
- n\x\), 
^n(x) =  { 
0, 
if Ixl <  -
n 
, 
if \x\  >  -
n 
n= 
\,2,,... 
We  wish  to emphasize  that  there  are  many  other  functions  that  could  have  served 
this purpose.  An  example  of  a commonly  used  sequence  of functions  employed  in 
the development  of the Dirac delta distribution is given by {ipn}, where 
^n(t)  =  \  In' 
I 0, 
"'^'  ""  """"' "
\t\  >  n, 
n  =  \,2, 
this is given by {r/^}, where 
Another  example  of  a  sequence  of  functions  that  can  be  utilized  for 
"f  n^te'""""^", 
Vn(t)  =  \ 
0, 
0 <  ^ <  00, 
elsewhere. 
n= 
1,2,..,. 
D.  Linear  Continuous-Time  Systems 
We let P denote a linear time-varying operator from  C(R,  R^)  =  Uto  C(R, RP)  =  Y 
and we assume that P admits an integral  representation  given by 
y(t)  =  (Pu)(t)  =  i  Hp(t,7)u(7)d7, 
(16.41) 
where  Hp  : R  X  R^ 
j^pxm^ u  ^  U, and  j  G  F,  and  where  Hp  is  assumed  to  be 
integrable. This means that each element of Hp, hp..  : RX  R-^  Ris  integrable  (in 
the Riemann  or Lebesgue  sense). 
Now  let  yi  and  j2  denote the response  of  system  (16.41)  corresponding  to the 
input  ui  and  U2,  respectively,  let  ai  and  0^2 be  real  scalars,  and  let  y  denote  the 
response of system (16.41) corresponding to the input aiui  +  0:2^2  =  u. Then 
y  =  P(u)  — P(aiU\  +  ^2^2)  — 
Hp(t,  T)[aiUi(T)  +  «2W2(T)]  dr 
77 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
—  ai 
\  Hp{t,  T)U\(T)  dr 
J—00 
-\- a2 
\  Hp(t,  T)U2(T)  dr 
J—cc 
=  aiP(u\) 
(16.42) 
which  shows  that  system  (16.41)  is indeed  a linear  system  in the  sense  defined  in 
(16.4). 
-\- a2P{u2)  =  cxiyi  + a2y2y 
Next,  we let all components  of  U(T)  in  (16.41) be zero, except for  the jth  com 
ponent. Then the /th component of y(t)  in (16.41) assumes the  form 
yi(t)  = 
hp.j(t,T)Uj(T)dT. 
J —00 
(16.43) 
According  to the results  of the previous  subsection  [see Eq.  (16.40)], hp.j(t, r)  de 
notes the response of the /th component of the output of system (16.41), measured at 
time t, due to an impulse applied to thejth  component of the input of system (16.41), 
applied  at time r,  while  all the remaining  components  of the input  are zero. There 
fore,  we call Hp(t,  r)  =  [hp.j(t, r)] the impulse  response  matrix  of system (16.41). 
Now suppose that it is known that system (16.41) is causal.  Then its output will 
be identically zero before an input is applied. It follows that system (16.41) is causal 
if and only if 
Hp(t,  T)  =  0 
for all r  and for  all t  <  r. 
Therefore,  when  system (16.41) is causal, we have in fact  that 
y(t)  = 
Hp{t,  T)U{T)  dr. 
(16.44) 
We can rewrite (16.44) as 
y(t)  = 
Hp{t,  T)U(T)  dr  + 
Hp(t,  T)U(T)  dr 
=  y(to)  + 
Hp(t,  T)U{T)  dr. 
(16.45) 
We  say  that  the  continuous-time  system  (16.41)  is  at  rest  at  t  =  to if  u(t)  = 
0  for  r ^  to implies  that  y(t)  =  0  for  ^ >  ^o- Note  that  our  problem  formulation 
mandates  that the system be at rest at to  =  -^.  Also, note that if a system  (16.41) 
is known to be causal and to be at rest at  ^  =  ^o^ then according to (16.45) we have 
y(t) 
Hp(t,  T)U(T)  dr. 
J to 
(16.46) 
Next,  suppose  that  it  is known  that  the  system  (16.41)  is  time-invariant.  This 
means that if in (16.43) hp..(t, r) is the response yt at time t due to an impulse applied 
at time  r  at thejth  component  of the input  [i.e.,  UJ(T)  =  8(t)],  with  all other  input 
components  set to zero, then a  -r  time shift  in the input  [i.e., Uj(t -  r)  =  8{t  -  r)] 
will result in a corresponding  -  r time shift in the response, resulting in hp. 
.(t-T,0). 
78 
Linear Systems 
Since this argument holds for all t,TGR 
and for all /  =  1,..., p,  and j  =  1,...,  m, 
we  have  Hp(t,  r)  =  Hp(t  -  r, 0).  If  we  define  (using  a  sHght  abuse  of  notation) 
Hp{t  -  T,G)  =  Hp{t  -  T), then (16.41) assumes the  form 
y(t)  = 
J  —cc 
Hp(t  -  T)U(T)  dr. 
(16.47) 
Note that (16.47) is consistent with the definition  of the integral representation  of a 
linear time-invariant  operator introduced in the previous  subsection. 
The right-hand  side of (16.47) is the familiar  convolution  integral  of Hp  and u 
and is written more compactly  as 
y(t)  =  (Hp  * u)(t). 
(16.48) 
We note that since Hp(t  -  r) represents responses at time t due to impulse inputs 
applied  at time r,  then Hp(t)  represents responses  at time t due to impulse  function 
inputs  applied  at r  =  0. Therefore,  a linear time-invariant  system  (16.47) is causal 
if and only if Hp(t)  =  0 for all t  <  0. 
If it is known that the linear time-invariant system (16.47) is causal and is at rest 
at ^0, then we have 
rt 
y(t)  =  Hp(t-T)u(T)dT. 
to 
(16.49) 
In  this  case  it  is  customary  to  choose,  without  loss  of  generality,  to  =  0.  We  thus 
have 
y(t)  =  f  Hp(t  -  T)U(T)  dr, 
Jo 
t  >  0. 
(16.50) 
If we take the Laplace transform  of both sides of (16.50), provided it exists, we 
obtain 
y{s)  =  Hp(s)uis\ 
(16.51) 
where  y(s)  =  [yi{s\  ..  .,ypJis)f,Hp(s)  =  [hp.j(s)l  md  u(s)  =  [ui(s\  ...,  Um(s)]\ 
where the yi(s),  Uj(s), and  hp..(s)  denote the Laplace transforms  of  yi{t),  Uj(t),  and 
hpij(t),  respectively. Consistent with Eq. (16.34), we note that Hp(s)  represents  the 
Laplace  transform  of  the impulse  response  matrix  Hp(t).  We call Hp(s)  a  transfer 
function  matrix. 
Now suppose that the input-output relation of a system is specified  by the  state 
and output equations  (14.3a), (14.3b), repeated here as 
X =  A(t)x  +  B(t)u 
y  =  C(t)x  +  D(t)u. 
(16.52a) 
(16.52b) 
If we assume that x(to)  =  0 so that the system is at rest at to  =  0, we obtain  for 
the response of this  system, 
y(t)  =  [  C{t)^{t,T)B{T)u{T)dT  + D{t)u{t) 
(16.53) 
=  [  {C{t)^{t,  T)B(T)  +  D(t)8(t  -  T)]U(T)  dr, 
(16.54) 
JtQ 
where in (16.54) we have made use of the interpretation of 8 given in Subsection  C. 
Comparing  (16.54)  with (16.46), we conclude that the impulse response matrix  for 
system (16.52a), (16.52b) is given by 
M  (tr^-l 
^^^)*(^^ ^)^(^)  +  ^WS(r  -  T), 
t^  T, 
(16.55) 
79 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
Finally, for  time-invariant  systems  described by the state and output  equations 
(14.7a), (14.7b), repeated here as 
X =  Ax  +  Bu 
y  =  Cx  -\-  Du, 
we obtain for the impulse response matrix the  expression 
r)  =  f  Ce'^^'-^^B +  D8(t  -  r), 
Hp(t 
0, 
or, as is more commonly  written. 
r >  T, 
t  < T, 
Hp(t)  = 
Ce^'B  +  D8(t\ 
0, 
t^  0, 
t<0. 
We will pursue the topics of this section further  in Chapter 2. 
1.17 
SUMMARY 
(16.56a) 
(16.56b) 
(16.57) 
(16.58) 
In  this  chapter  we  addressed  mathematical  descriptions  of  systems.  First,  initial-
value problems determined by systems of first-order nonlinear ordinary  differential 
equations were introduced. Conditions for existence and uniqueness of solutions, and 
approaches to determine such solutions, were established. The main reason for con 
sidering nonlinear mathematical descriptions of systems in a book on linear  systems 
is that the origins  of most linear  systems  are nonlinear  systems. Specifically,  linear 
systems  are frequently  obtained from  nonlinear  systems by  a linearization  process, 
or are the result of modeling where the nonlinear effects  of a physical process  have 
been  suppressed  or neglected.  Accordingly,  the validity  of linear mathematical  de 
scriptions  must  always  be  interpreted  in  the context  of the nonlinear  systems  they 
approximate. 
The linearization of nonlinear systems along a given solution (and a given input) 
was discussed in Section  1.11. The solutions of linear (time-varying) state equations 
were obtained  in Section  1.13  using the method  of successive  approximations.  The 
response  of  a  linear  continuous  time  system  to  an  input,  given  initial  states,  was 
derived in Section  1.14. 
The  development  of  the  theory  of  discrete-time  systems  parallels  that  of 
continuous-time  systems and was addressed in Section  1.15. 
State-space representations  provide detailed  descriptions  of the internal  behav 
ior of  a system,  while  input-output  descriptions  of  systems  emphasize  external be 
havior  and  how  a system  interacts  with  its  environment.  Input-output  descriptions 
of  linear  systems,  addressed  in  Section  1.16,  involve  the  convolution  integral  for 
continuous-time  systems  and the convolution  sum for discrete-time  systems. 
80 
Linear Systems 
In the next chapter, both  state-space  descriptions  and input-output  descriptions 
^f systems are revisited, and their dynamic behavior is studied in detail. 
1.18 
NOTES 
Standard  references  on  linear  algebra  include  Birkhoff  and  MacLane  [2], Halmos 
[9], and Gantmacher  [8]. For more recent texts on this  subject,  refer,  e.g., to  Strang 
122] and Michel and Herget [12]. 
Excellent sources on analysis at the elementary level include Apostol [1], Rudin 
[17], and Taylor  [24]. For treatments  at an intermediate level, consult, e.g.,  Royden 
[16], Taylor  [23], Naylor and Sell  [15], and Michel and Herget [12]. 
For  a classic  reference  on ordinary  differential  equations,  see Coddington  and 
Levinson  [6]. Other excellent  sources include Brauer and Nohel  [3], Hartman  [10], 
and  Simmons  [21]. Our treatment  of ordinary  differential  equations  in this  chapter 
was greatly influenced by Coddington and Levinson  [6] and Miller and Michel [14]. 
An original  standard reference  on linear  systems is Zadeh  and Desoer  [25]. Of 
the  many  excellent  texts  on  this  subject,  the  reader  may  want  to refer  to  Brockett 
[4],  Kailath  [11], and  Chen  [5]. For  more  recent  texts  on  linear  systems,  consult, 
e.g., Rugh  [18] and DeCarlo [7]. 
In  Section  16  we  showed  that  continuous-time  finite-dimensional  linear  sys 
tems described by state equations have an input-output description given by integral 
equations. For a general and comprehensive treatment of the integral  representation 
of linear systems, refer  to Sandberg  [19], [20]. 
1.19 
REFERENCES 
1.  T. M. Apostol, Mathematical Analysis, Addison-Wesley, Reading, MA, 1974. 
2.  G. Birkhoff and S. MacLane, A Survey of Modern Algebra, Macmillan, New York, 1965. 
3.  F. Brauer and J. A. Nohel, Qualitative Theory of Ordinary Differential Equations, Ben 
jamin, New York, 1969. 
4.  R. W. Brockett, Finite Dimensional Linear Systems, Wiley, New York, 1970. 
5.  C. T. Chen, Linear System Theory and Design, Holt, Rinehart and Winston, New York, 
1984. 
6.  E. A. Coddington and N. Levinson, Theory of Ordinary Differential Equations, McGraw-
Hill, New York, 1955. 
7.  R. A. DeCarlo, Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1989. 
8.  F. R. Gantmacher, Theory of Matrices, Vols. I, II, Chelsea, New York, 1959. 
9.  R R. Halmos, Finite Dimensional Vector Spaces, D. Van Nostrand, Princeton, NJ, 1958. 
10.  P. Hartman, Ordinary Differential Equations, Wiley, New York, 1964. 
11.  T. Kailath, Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1980. 
12.  A. N. Michel and C. J. Herget, Applied Algebra and Functional Analysis, Dover, New 
York, 1993. 
13.  A. N. Michel and K. Wang, Qualitative Theory of Dynamical Systems, Marcel Dekker, 
New York, 1995. 
14.  R. K. Miller  and A. N. Michel,  Ordinary  Differential  Equations,  Academic Press, New 
81 
York,  1982. 
15.  A. W. Nay lor and G. R. Sell, Linear  Operator  Theory  in Engineering  and Science,  Holt, 
Rinehart  and Winston, New York, 1971. 
16.  H. L. Royden, Real Analysis,  Macmillan,  New  York,  1965. 
17.  W. Rudin, Principles  of Mathematical  Analysis,  McGraw-Hill, New York,  1976. 
18.  W. J. Rugh, Linear  System  Theory,  Second Edition, Prentice-Hall, Englewood Cliffs, NJ, 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
1996, 
19.  I. W. Sandberg,"  ""Linear  maps  and  impulse  responses",""" IEEE  Transactions  on  Circuits "
and Systems,  Vol. 35, No. 2, pp. 201-206,  1988. 
20.  I. W. Sandberg," ""Integral representations for linear maps",""" IEEE  Transactions  on  Circuits "
and Systems,  Vol. 35, No. 5, pp. 536-544,  1988. 
21.  G. F. Simmons, Differential  Equations,  McGraw-Hill, New York,  1972. 
22.  G. Strang, Linear  Algebra  and Its Applications,  Academic Press, New York,  1980. 
23.  A. E. Taylor, Introduction  to Functional  Analysis,  Wiley, New York,  1958. 
24.  A. E. Taylor, Advanced  Calculus,  Blaisdell, New York,  1965. 
25.  L.  A.  Zadeh  and  C.  A.  Desoer,  Linear  System  Theory—The  State  Space  Approach, 
McGraw-Hill, New York, 1963. 
1.20 
EXERCISES 
1.1.  (Hamiltonian  dynamical  systems)  Conservative  dynamical  systems,  also  called 
Hamiltonian  dynamical  systems,  are  those  systems  that  contain  no  energy-dissipating 
elements. Such  systems  with n degrees  of freedom  can be characterized  by means  of a 
Hamiltonian  function  H{p,  q), where  q^  =  {q\,...,  qn) denotes n generalized  position 
coordinates  and  p^  =  {p\,...,  Pn) denotes  n  generalized  momentum  coordinates.  We 
assume that H{p,  ^) is of the  form 
H{p,q)  =  T(q,q)  + W(qX 
(20.1) 
where  T denotes  the kinetic  energy  and  W denotes  the potential  energy  of the  system. 
These energy terms are obtained from  the path-independent  line  integrals 
T(q,q)=\ 
p(q,^fd^=\ 
JO 
Jo  / ^i 
^pt(q,Od^i 
(20.2) 
(20.3) 
where  fj  =  1,...,  n, denote generalized potential  forces. 
For the integral  (20.2) to be path-independent,  it is necessary  and sufficient  that 
dpi{q,q)  _ 
dpj{q,q) 
dqj 
dqt 
i,j=l,..., 
n. 
(20.4) 
A similar statement  can be made about Eq. (20.3). 
Conservative dynamical systems are described by the system of 2n ordinary  differ 
ential  equations 
qi  =  -z—{p,q), 
I  = 
l,...,n, 
"""^P^ "
Pi  =  -—-(p,q), 
oqt 
I  = 
h...,n. 
(20.5) 
82 
Linear Systems 
Note that if we compute the derivative of H(p, q) with respect to t for (20.5) [i.e., along 
the solutions qi{t), Pi{t\ i  =  I,..  .,n],  then we obtain, by the chain rule. 
-^(p(t\q(t)) 
i=l 
^  dH ^ 
JH^ 
, 
^  OH ^ 
JH  ^ 
, 
^ 
^ - S ^^^' '^-^'' '^ ^ S ^^^' 'W'  '^ ^ '• 
In other words, in a conservative system (20.5) the Hamiltonian, i.e., the total energy, 
will be constant along the solutions (20.5). This constant is determined by the initial data 
(p(0),^(0)). 
(a)  In Fig.  1.18, Mi  and M2 denote point masses,  ^1, K2, K  denote spring constants, 
and xi, X2 denote the displacements of the masses M\ and M2. Use the Hamiltonian 
formulation of dynamical systems described above to derive a system of  first-order 
ordinary differential  equations that characterize this system. Verify your answer by 
using Newton's second law of motion to derive the same system of equations. As 
sume that x\{0\  x\{0), ^2(0), i:2(0) are given. 
K 
A 
A 
/77777777777V7777777777777777777777777A 
FIGURE 1.18 
Example of a conservative dynamical system 
M, 1 h^A/W-
^2  —VW  i 
Ko 
(b)  In Fig. 1.19, a point mass m is moving in a circular path about the axis of rotation 
normal to a constant gravitational field (this is called the simple pendulum problem). 
Here / is the radius of the circular path, g is the gravitational  acceleration,  and x 
denotes the angle of deflection  measured  from  the vertical. Use the Hamiltonian 
formulation of dynamical systems described above to derive a system of  first-order 
ordinary differential  equations that characterize this system. Verify your answer by 
FIGURE 1.19 
Simple pendulum 
using Newton's  second  law  of motion  to derive the  same  system of equations. As 
sume that x(0)  and i:(0) are given, 
(c)  Determine  a system of  first-order  ordinary  differential  equations  that  characterizes 
the  two-link  pendulum  depicted  in  Fig.  1.20.  Assume  that  ^i(O), ^2(0), ^i(O),  and 
^2(0) are given. 
83 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
y////////y 
FIGURE  1.20 
Two-link  pendulum 
1.2.  (Lagrange's  equation) If a dynamical  system contains elements that dissipate  energy, 
such as viscous friction elements in mechanical systems and resistors in electric circuits, 
then we can use Lagrange's  equation  to describe such systems. (In the following, we use 
some of the same notation used in Exercise  1.1.)  For a system with n degrees of  freedom, 
this equation is given by 
d  idL 
\ 
dL 
..^dD 
/  =  1,...,  n, 
(20.6) 
where q^  =  {q\, ••-,qn)  denotes the generalized position vector. The function  L{q, q) is 
called the Lagrangian  and is defined  as 
L{q, q)  =  T(q,  q) -  W{ql 
i.e., the difference  between the kinetic energy  T and the potential energy  W. 
The function  D{q) denotes Rayleigh's  dissipation  function,  which we shall  assume 
to be of the  form 
^(^)- 
la^iMp 
^  i=\  7=1 
where [jS/y] is a positive semidefinite matrix (i.e., [/3/y] is symmetric and all its eigenval 
ues  are nonnegative).  The  dissipation  function  D  represents  one-half  the rate  at  which 
energy  is  dissipated  as  heat.  It  is  produced  by  friction  in  mechanical  systems  and  by 
resistance in electric circuits. 
Finally,  ft  in  Eq.  (20.6)  denotes  an  applied  force  and  includes  all  external  forces 
associated  with the qt coordinate. The force  ft  is defined  as being positive when it acts 
to increase the value of the coordinate  qt. 
(a)  In  Fig.  1.21,  M\  and  M2  denote  point  masses;  Ki,  K2, K  denote  spring  constants; 
yh  yi  denote the  displacements  of masses  M\  and M2, respectively;  and  B\,  B2, B 
denote  viscous  damping  coefficients.  Use  the  Lagrange  formulation  of  dynamical 
84 
Linear  Systems 
y77'Y/////yyyyy////y//7?^ 
81 
Bp 
FIGURE  1.21 
An example of a mechanical  system with energy  dissipation 
systems described  above to derive two second-order  ordinary differential  equations 
that characterize this system. Transform  these equations into a system of first order 
ordinary differential  equations. Verify your answer by using Newton's second law of 
motion  to derive  the  same  system  equations. Assume  that  ji(0), ji(0), j2(0), J2(0) 
are given. 
(b)  Consider the capacitor microphone depicted in Fig.  1.22.  Here we have a capacitor 
constructed from  a fixed plate and a moving plate with mass M. The moving plate is 
suspended from the fixed frame by a spring that has a spring constant k and also some 
damping expressed by the damping constant B. Sound waves exert an external  force 
fit)  on the moving  plate. The  output  voltage  v^, which  appears  across  the  resistor 
R,  will reproduce electrically  the sound-wave patterns that strike the moving plate. 
When  fit)  =  0  there  is  a  charge  q^  on  the  capacitor.  This  produces  a  force 
of  attraction  between  the plates  that  stretches  the  spring  by  an  amount  x\,  and  the 
space between the plates is XQ. When sound waves exert a force on the moving plate, 
there will be a resulting motion displacement x that is measured from the equilibrium 
position. The distance between the plates will then be  XQ -  x,  and the charge on the 
plates will be ^0 +  ^• 
Moving plate 
with mass M 
-Xi  -\- X-
K 
->AAN— 
^B 
fit) 
V 
Fixed plate 
- x o - x-
tl'tr^ 
•^Tjcir—' 
FIGURE  1.22 
Capacitor  microphone 
When  displacements  are small, the expression  for the capacitance is given ap 
85 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
proximately  by 
XQ  —  X 
with  Co  =  eA/xo, where e  >  0 is the dielectric constant for air and A is the area of 
the plate. 
Use the Lagrange formulation of dynamical systems to derive two second-order 
ordinary differential  equations that characterize this system. Transform  these equa 
tions into a system of first-order ordinary differential  equations. Verify  your  answer 
by  using  Newton's  laws  of  motion  and  Kirchhoff's  voltage/current  laws.  Assume 
that x(0), i(0), ^(0), and q{0) are given. 
Use the Lagrange formulation  to derive a system of first-order differential  equations 
for the system given in Example 4.3. 
(c) 
1.3.  Find examples  of initial-value problems  for  which  (a) no solutions exist;  (b) more than 
one solution exists; (c) one or more solutions exist, but cannot be continued for all r G  R\ 
and (d) unique solutions exist for all r G /?. 
1.4.  (Numerical  solution  of  ordinary  differential  equations—Euler's  method)  In  Sub 
section  1.6B  it is shown that an approximation  to the solution of the scalar  initial-value 
problem 
y  =  jyt,y), 
fit,  y), 
j(ro)  =  JO 
y{to)  =  Jo 
is given by Euler's  method  [see Eq.  (6.6)], 
yk+i  =  yk  + hf{tk,yk\ 
k  =  Q,h2,. 
(20.7) 
(20.8) 
where h  =  tk+\—  tk is the (constant) integration  step. The interpretation  of this method 
is that the area below the solution curve  [see Eq. (V) in Section  1.6]  is approximated  by 
a sequence of sums of rectangular  areas. This method is also called \hQ forward  rectan 
gular  rule (of integration), 
(a)  Use Euler's  method to determine the solution of the initial-value  problem 
j  =  3 j, 
y{tQ) 
tQ =  0, 
tQ^  t ^  10. 
(b)  Use Euler's method to determine the solution of the initial-value  problem 
y  =  t{yf 
- 
/ 
yit^)  =  1, 
y(to)  =  0, 
to  =  0, 
to ^  t  ^  10. 
Hint:  In  both  cases,  use  h  =  0.2.  For  part  (b),  let  y  =  xi, xi  =  X2, X2 =  tx^  -  x\, 
and  apply  (20.8),  appropriately  adjusted  to  the  vector  case.  In  both  cases,  plot  yk  vs. 
^^ y^ =  0,1, 2 , . . .. 
Remark:  Euler's  method yields  arbitrarily  close approximations  to the solutions of 
(20.7),  by  making  h  sufficiently  small,  assuming  infinite  {computer)  word  length.  In 
practice,  however,  where  truncation  errors  (quantization)  and  round-off  errors  (finite 
precision  operations)  are  a reality,  extremely  small  values  of  h may  lead  to  numerical 
instabilities. Therefore,  Euler's method is of limited value as a means of solving initial-
value problems  numerically. 
1.5.  (Numerical  solution  of  ordinary  differential  equations—Runge-Kutta  methods) 
The Runge-Kutta  family  of integration  methods  are among the most widely used  tech 
niques to solve initial-value problems  (20.7). A simple version is given by 
where 
k  =  Uki  -h 2y^2 +  2^3  +  ^4), 
yi+i  =  yi  +  K 
86 
Linear Systems 
with 
fe 
k\  =  hf(ti,  yt) 
=  hfiu  +  ^hyi  +  ^ki) 
h  =  hf(ti  +  i/i,};/  +  ife) 
k4  =  hfiti  +  h, ji  +  h), 
andf/+i  =  ti +  Kyito)  =  y^. 
The idea of this method is to probe ahead (in time) by one-half or by a whole step h 
to determine the values of the derivative  at several points, and then to form  a weighted 
average. 
Runge-Kutta methods can also be applied to higher order ordinary differential  equa 
tions. For example, after  a change of variables, suppose that a second-order  differential 
equation has been changed to a system of two  first-order  differential  equations, say, 
x\  =  fi(t,xi,X2), 
Xl  =  flit,  Xi, X2X 
xiito)  =  xio 
X2(to) = X20. 
^20 9) 
In solving (20.9), a simple version of the Runge-Kutta  method is given by 
yt+i  =  Ji  +  k, 
yi  =  {xu,  xiiY 
and 
k  =  (k,  lY 
k  =  ^('^i  +  ^h  +  2fe  +  h), 
I  =  l(l\+  2/2  +  2/3 +  U) 
where 
with 
and 
h  =  hfi{tuXii,X2i) 
h  =  hfiiU,  Xu, X2i) 
h  =  hfiiti  +  i/z, Xu  +  ^ki,  X2i  +  5/1) 
h  =  hf2(ti  +  ^h,  xu  +  ^h,  X2i  +  5/1) 
h  =  hfiiU  +  ^h,  Xu  +  ^k2, X2i  +  5/2) 
h  =  hf2(ti  +  \K  Xu  +  {h,  X2i  +  ^2) 
h  =  hfi(ti  +  h, Xu  +  ks, X2i  +  h) 
k  =  hf2(ti  +  h, Xu  + h,  X2i  +  h\ 
Use the Runge-Kutta  method described  above to obtain numerical  solutions to the 
initial value problems given in parts (a) and (b) of Exercise  1.4. As there, plot your data. 
Remark:  Since  Runge-Kutta  methods  do  not  use  past  information,  they  consti 
tute  attractive  starting  methods  for  more efficient  numerical  integration  schemes  (e.g., 
predictor-corrector methods). We note that since there are no built-in accuracy  measures 
in the Runge-Kutta  methods, significant  computational  efforts  are frequently  expended 
to achieve a desired  accuracy. 
1.6.  (Numerical  solution  of  ordinary  differential  equations—Predictor-Corrector 
methods)  A  common  predictor-corrector  technique  for  solving  initial-value  problems 
determined  by  ordinary  differential  equations,  such  as  (20.7),  is  the  Milne  method, 
which we now  summarize. In this method,  yt-i  denotes the value of the first derivative 
at time ^/_i, where  ti is the time for  the  /th iteration  step, j/-2 is  similarly  defined,  and 
yt+i represents the value of j  to be determined. The details of the Milne method are: 
1-  yi+i,p  =  yi-3  +  —(2J/-2  -  yt-i  +  2j/) 
(predictor) 
Ah, 
T 
2.  yi+i,p  = 
fiti+uyt+ip) 
3.  yt+ic  =  yt-i  +  3 (i^z-i  +  4j/  + yt+ip) 
h 
(corrector) 
4.  yi+i,c = 
f(ti+uyi+i,c) 
5.  yt+u  =  yi-i  +  3 (>'/-i  +  4j/  +  yt+ic) 
h 
(iterating  corrector) 
The  first  step  is to  obtain  a predicted  value  of  yt+i  and  then  substitute  yi+\,p into 
the  given  differential  equation  to  obtain  a predicted  value  of  yi+i,  as  indicated  in  the 
second equation above. This predicted value, yi+i,p is then used in the second equation, 
the corrector  equation,  to obtain  a corrected  value  of  yi+\.  The corrected  value,  yt+ic 
is next  substituted  into  the  differential  equation  to  obtain  an  improved  value  of  y/+i, 
and  so  on.  If  necessary,  an  iteration  process  involving  the  fourth  and  fifth  equations 
continues until successive values of yi+i differ  by less than the value of some desirable 
tolerance. With yt+i determined to the desired accuracy, the method steps forward  one 
h  increment. 
A  more  complicated  predictor-corrector  method  that  is  more  reliable  than  the 
Milne  method  is  the  Adams-Bashforth-Moulton  method,  the  essential  equations  of 
which  are 
87 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
yi+i,p  =  yt  + 
^ 5 5 ^,  -  59y,-i  +  31yi-2  -  9^,-3) 
24' 
Ji+U 
J/  + 
- ( 9 j , +i  +  19j,-
5 j / -i  +  yi-2), 
where in the corrector equation, yi+\ denotes the predicted value. 
The  application  of predictor-corrector  methods  to  systems  of  first-order  ordinary 
differential  equations  is  straightforward.  For  example,  the  application  of  the  Milne 
method to the second-order  system in (20.9) yields from  the predictor  step 
^k,i  + \,p  =  Xk,i-3  +  ^(2Xk,i-2 
4/z. 
-  Xk,i^i  +  2Xk,il 
k  =  1,  2. 
T h en 
^k,i+i,p  —  fk{U+\, 
^i,i+\,py  X2,i+\,p)> 
k=  1,2, 
and the corrector  step assumes the  form 
^k,i+\,c  —  ^k,i-l 
+ 
l^{^k,i-\ 
+  ^^k,i  +  ^k,i  + \), 
k  —  1,2, 
and 
Xk,i+\,c  =  fk(ti+h  xij+ic,  X2,i+i,c\ 
k  =  1,2. 
Use  the  Milne  method  and  the  Adams-Bashforth-Moulton  method  described 
above to obtain numerical  solutions to the initial-value problems given in parts (a) and 
(b) of Exercise  1.4.  To initiate the algorithm, refer  to the Remark in Exercise  1.5. 
Remark.  Derivations and convergence properties of numerical integration schemes, 
such as those discussed here and in Exercises  1.4  and  1.5, can be found in many of the 
standard texts on numerical  analysis (see, e.g., D. Kincaid  and W. Cheney,  Numerical 
Analysis,  Brooks-Cole, Belmont, CA,  1991). 
1.7.  (a)  Prove Theorem 6.2 for the interval  [to  -  c, to]. 
(b)  Prove Theorem 7.2 for the endpoint  a. 
(c)  Prove Theorem  8.2 for the interval  [to  -  d, to]. 
(d)  Prove Theorem  8.4 for  t  <  to. 
(e)  Prove Theorem  8.5 for the interval  [to  -  c,to]. 
(f)  Prove Theorem  10.1 through  and including Theorem  10.10. 
1.8.  (a)  Prove that the function  f(x)  =  x^^^ is continuous but not Lipschitz  continuous. 
(b)  Show that the initial-value problem i;  =  x^^^, 
ent solutions. (Remember to consider t  <  0.) 
x(0)  =  0 has infinitely  many  differ-
1.9.  Use Theorem  8.5  to solve the initial-value problem  x  =  ax  + t, x(0)  =  xo for  ^ >  0. 
Here a  E  R. 
1.10.  Consider the initial-value  problem 
X =  Ax, 
x(0)  -  Xo, 
(20.10) 
88 
Linear Systems 
where  x  ^  R^  and  A  E  R^^^.  Let  Ai, A2 denote  the  eigenvalues  of A, i.e.,  Ai  and A2 
^^^ ^^^ ^^^^^ ^^ ^^^ equation  det (A  -  XI)  =  0, where  det  denotes  determinant,  A is a 
scalar, and /  denotes the 2 X 2 identity matrix. Make specific  choices of A to obtain the 
following  cases: 
rollowing cases: 
L  Ai  >  0, A2 >  0, and Ai 7^  A2; 
2.  Ai  <  0, A2 <  0, and Ai 7^  A2; 
^ 
\.  ^  0-
3.  Ai  =  A2 >  0; 
4.  Ai  =  A2 <  0; 
5.  Ai  >  0, A2 <  0; 
6.  Ai  =  a  +  /j8, A2 =  a  -  /jS, /  =  v ^,  a  >  0; 
7.  Ai  =  a  +  //3,  A2  =  a  -  //3, a  <  0; 
8.  Ai  =  /jS,A2  =  - / / 3. 
\.  = 
Using  r as  a parameter,  plot  (l)2(t, 0, xo)  vs.  (t)i(t, 0, XQ) for  0  <  ^ <  r/  for  every 
case enumerated  above. Here  [(/>i(t, to, XQ), (f)2{t, to, xo)V  =  <P(t, to, xo) denotes the so 
lution  of  (20.10). On your plots, indicate  increasing  time  t by means  of  arrows.  Plots 
of this type  are called  trajectories  for  (20.10), and  sufficiently  many  plots  (using  dif 
ferent initial conditions and sufficiently  large tf)  make up a phase  portrait  for (20.10). 
Generate a phase portrait for each case given  above. 
1.11.  Write two first-order ordinary differential  equations for the van der Pol equation  (4.10) 
by choosing xi  =  x and X2 =  i i. Determine by simulation/?/z<35^p6>rrra/r5 (see Exer 
cise  LIO) for this example for the cases e  =  0.05  and e  =  10 (refer  also to Exercises 
L5  and  L6  for  numerical  methods  for  solving  differential  equations).  The  periodic 
function  to which the trajectories  of (4.10) tend is an example of a limit  cycle. 
1.12.  For (4.11) consider the hard, linear, and soft spring  models  given by 
g(x)  =  k(l  +  a^x^)x, 
g{x)  =  kx, 
g(x)  =  k(l  -  a^x^)x, 
respectively,  where  ^  >  0 and a  7^ 0. Write two  first-order  ordinary  differential  equa 
tions  for  (4.11)  by  choosing  x\  =  x  and  X2 =  x.  Pick  specific  values  for  k  and  a^. 
Determine by  simulation/7/i(2>y^ portraits  (see Exercise  1.10)  for  this example  for  the 
above three cases. 
1.13.  Verify  that the spaces in Examples  10.1 to  10.6 satisfy  the axioms of vector  space. 
1.14.  Let F  =  {0, 1, 2," 3}. Determine operations  "" +""  and ""•"" so that [F", -H, •} is a field. 
1.15.  (a)  Verify  that the transformation  given in Example  10.8 is linear, 
(b)  Verify  that the transformation  given in Example  10.9 is linear. 
1.16.  (a)  Prove (10.13), (10.14), (10.15), and  (10.16). 
(b)  Verify  that  the  functions  ||  • ||i, ||  • lb,  and  ||  • ||oo defined  in  (10.11),  (10.12),  and 
(10.10), respectively, each  satisfy  the axioms of a norm. 
(c)  Prove the relations (D-i), (D-ii), (D-iii) given at the beginning of Subsection  1 .IOC. 
1.17.  Let  g{t)  =  [g\(t),...,  gn(t)V  be  defined  on  some  interval  J  C  R  and  assume  that 
gi  : J  ^  R  is  integrable  over  J,i  =  I,..  .,n.  Prove  that  for  b  >  a, \\\^  g(t)dt\\  < 
J  11^(011 dt,"  where ||  • || denotes a norm on 7?"". "
1.18.  (a)  Show that x^  =  (0, 0) is a solution of the system of  equations 
Xi  =  x\  +  x\  +  X2 cos  X\ 
X2 =  {\  + X\)x\  +  (1 +  X2)x2 +  xi  sinx2. 
Linearize this system  about the point  x^  =  (0, 0). By means  of computer  simula 
tions, compare solutions corresponding to different  initial conditions in the vicinity 
of the origin of the above system of equations  and its  linearization. 
(b)  Linearize the (bilinear control)  system 
jc +  (3 +  x^)x  +  (1 +  jc +  x^)u  =  0 
about the solution ;c  =  0, i  =  0, and the input u{t)  =  0. As in part (a), compare (by 
means of computer simulations) solutions of the above equation with corresponding 
solutions of its  linearization. 
(c)  In the  circuit  given  in Fig.  1.23,  v/(0  is a voltage  source  and the nonlinear  resis 
tor obeys the relation  IR  =  1.5v|  [Vi(t)  is the circuit  input  and  v/?(0  is the  circuit 
output]. Derive the differential  equation  for this circuit. Linearize this  differential 
equation for the case when the circuit operates about the point v/  =  14. 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
1 Q 
-MAr 
'fl(0 
1  F. 
VR(t) 
.(.) Q 
FIGURE  1.23 
Nonlinear  circuit 
1.19.  Consider a system whose state-space description is given by 
X =  —k\k2j^+ 
k2u(t) 
y  =  ki  Jx. 
Linearize this system about the nominal  solution 
Wo  =  0, 
2 Vxo(0  =  2 Jk  —  ki k2t, 
where xo(0)  =  k. 
1.20.  (Inverted  pendulum)  The  inverted  pendulum  on  a moving  carriage  subjected  to  an 
external force  ix{t) is depicted in Fig.  1.24. 
The moment of inertia with respect to the center of gravity is /  and the  coefficient 
of friction  of the carriage  (see Fig.  1.24)  is F. From Fig.  1.25  we obtain the  following 
equations for the dynamics of this  system: 
m—r(5'  +  Lsin(/>)  =  H 
(20.11a) 
90 
Linear  Systems 
(Center of gravity) 
FIGURE  1.24 
Inverted  pendulum 
m-r^{Lcos^) 
dfi 
=  Y  -  mg 
J—p2  ^  LY  sin (j)  -  LH  COS (I) 
Assuming that m  «  M,  (20.lid)  reduces to 
,^d^S 
,, 
dS 
(20.11b) 
(20.11c) 
(20. lid) 
(20. lie) 
Eliminating H  and  Y from  (20.11a) to (20.11c), we obtain 
(/  +  mL^)cf>  =  mgL  sin (/) -  mLS  cos (/>. 
(20.1If) 
Thus, the system of Fig.  1.24  is described by the  equations 
4>  -  (77 )sin(^ +  (^]scos(t>  =  0, 
(20.11g) 
MS  +  F5  =  fji(t), 
FIGURE  1.25 
where 
L'  = 
J  +  mL'^ 
mL 
denotes the effective  pendulum  length. 
Linearize  system (20.11g)  about cj) 
0. 
91 
CHAPTER 1: 
Mathematical 
Descriptions of 
Systems 
1.21.  (Magnetic ball suspension system) Figure  1.26  depicts a schematic diagram of a ball 
suspension  control  system.  The steel  ball  is suspended  in air by the electromagnetic 
force  generated by the electromagnet.  The objective of the control is to keep the steel 
ball  suspended  at a desired  equilibrium  position by controlling the current  i(t) in the 
magnet coil by means of the applied voltage v(0, where r >  0 denotes time. The resis 
tance and inductance of the coil are R and L(s(t))  =  L/s(t),  respectively, where L > 0 
is a constant and s(t)  denotes the distance between the center of the ball and the magnet 
at time t. The force  produced by the magnet is Kfl(t)/s^(t),  where  jfiT >  0 is a propor 
tional constant and g denotes acceleration  due to gravity. 
(a)  Determine the differential  equations governing the dynamics of this  system. 
(b)  Let v(t) = Veq,2i nominal  (desired) value of v{t).  Determine  the resulting  equilib 
rium of this  system. 
(c)  Linearize the equation  obtained  in (a) about the equilibrium  solution  determined 
in (b). 
y//////////^ 
"NsN\^  ns^S^—^*--o""^ "
R 
L 
v{t) 
Electromagnet 
Steel ball 
FIGURE 1.26 
Magnetic ball suspension  system 
1.22.  (a)  For the mechanical  system  given in Exercise  1.2a, we view  /i  and /i  as making 
up the system  input  vector, and y\  and y2 the system  output  vector.  Determine a 
state-space description for this  system. 
(b)  For the same mechanical  system, we view  (/i, 5/2)^  as the system  input and we 
view  83^1 +  10^2 as the (scalar-valued)  system  output.  Determine  a  state-space 
description for this  system. 
(c)  For part (a), determine the input-output  description of the  system. 
(d)  For part (b), determine the input-output  description of the  system. 
92 
1.23.  For  the  magnetic  ball  suspension  system  given  in  Exercise  1.21,  we  view  v and  s  as 
Linear  Systems 
the system input and output,  respectively. 
(a)  Determine  a state-space representation  for this  system. 
(b)  Using the linearized equation obtained in part (c) of Exercise 1.21, obtain the input-
output description of this  system. 
1.24.  In Example 4.3, we view  Ca  and 9 as the system input and output,  respectively. 
(a)  Determine a state-space representation  for this  system. 
(b)  Determine the input-output  description  of this  system. 
1.25.  For the second-order  section digital filter in direct form,  given in Fig.  1.13,  determine 
the input-output description, where xi(k)  and u(k)  denote the output and input, respec 
tively. 
1.26.  In  the  circuit  of Fig.  1.27,  Vi{t)  and  Vo(t)  are voltages  (at time  t)  and  Ri  and  R2  are 
resistors.  There  is  also  an  ideal  diode  that  acts  as  a  short  circuit  when  V/  is  positive 
and as an open circuit when Vi is negative. We view  Vi and  VQ as the system input and 
output,  respectively. 
(a)  Determine an input-output  description  of this  system. 
(b)  Is  this  system  Hnear?  Is  it  time-varying  or  time-invariant?  Is  it  causal?  Explain 
your answers. 
Diode 
i{t) 
^o(0 
^•(0  O 
FIGURE  1.27 
Diode circuit 
1.27.  We consider the truncation  operator  given by 
y{t)  =  Tr(u(t)) 
as a system, where r  E  7? is fixed, u and y denote system input and output, respectively, 
t denotes time, and Tr(  • ) is specified  by 
Tr(u(t)) 
u{t), 
0, 
t  <  T, 
t  >  T. 
Is  this  system  causal?  Is  it  linear?  Is  it  time-invariant?  What  is  its  impulse  re 
sponse? 
1.28.  We consider the shift  operator  given by 
y{t)  =  Qr(u(t))  =  u(t  -  T) 
as  a  system,  where  r  ^  R  is  fixed,  u  and  y  denote  system  input  and  system  output, 
respectively, and t den  tes time. Is this system causal? Is it linear? Is it time-invariant? 
What is its impulse  response? 
1.29.  Consider the system whose input-output  description is given by 
y(t)  =  min{wi (0,^2(01, 
where  u(t)  =  [ui(t),  U2(t)]^  denotes the system input and y(t)  is the system output. Is 
this system  linear? 
1.30.  Suppose  it  is  known  that  a  linear  system  has  impulse  response  given  by  h(t, r)  = 
exp(-|r  -  T|).  IS this system causal? Is it  time-invariant? 
93 
CHAPTER  1: 
Mathematical 
Descriptions of 
Systems 
1.31.  Consider a system with input-output  description  given by 
y(k)  =  3u(k  +  1) +  1, 
kGZ, 
where y and u denote the output and input, respectively  (recall that Z denotes the inte 
gers). Is this system causal? Is it linear? 
1.32.  Use expression  (16.8), 
x(n)  =  ^ 
x(k)8(n  -  k), 
and 8(n)  =  p(n)  -  p(n  -  1) to express the system response y(n)  due to any input  u{k), 
as a function  of the unit step response of the system  [i.e., due to u{k)  =  p(k)]. 
1.33.  (Simple  pendulum)  A  system  of first-order  ordinary  differential  equations  that  char 
acterize the simple pendulum considered in Exercise  1.1b  is given by 
X2 
— J  smjJCi 
where xi  =  6 and X2 =  6 with xi(0)  =  0(0)  and ^2(0)  =  6(0)  specified.  A linearized 
model of this system about the solution x  =  [0," 0]""^ is given by "
Xi 
X2\ 
0 
11 
1  ° 
Xi 
X2\ 
Let ^  =  10 (m/sec^) and /  =  1 (m). 
(a)  For the case when  x(0)  =  [OQ, Of  with  ^o  =  ^/18, 77/12, 7r/6, and  7r/3, plot  the 
states for t  >  0, for the nonlinear model. 
(b)  Repeat  (a) for the linear model. 
(c)  Compare the results in (a) and (b). 
CHAPTER  2 
Response of Linear  Systems 
In system theory it is important to clearly understand how inputs and initial condi 
tions affect the response of a system. There are many reasons for this. For example, 
in control theory, it is important to be able to select an input that will cause the sys 
tem output to satisfy certain properties [e.g., to remain bounded (stability), to follow 
a given trajectory  (tracking), and the like]. This is in stark contrast to the study of 
ordinary differential  equations, where it is usually assumed that the forcing  function 
(input) is given. 
2.1 
INTRODUCTION 
The goal of this chapter is to study the response of linear systems in greater detail 
than  was done in Chapter  1. To this  end,  solutions  of linear  ordinary  differential 
equations  are reexamined,  this  time with  an emphasis  on characterizing  all solu 
tions using bases (of the solution vector space) and on determining  such solutions. 
For convenience, certain results from Chapter 1  are repeated, and time-varying and 
time-invariant cases are treated separately, as are continuous-time and discrete-time 
cases. Whereas in Chapter  1 certain fundamental  issues that include  input-output 
system  descriptions,  causality,  linearity,  and  time-invariance  are emphasized,  we 
will here address in greater detail impulse (and pulse) response and transfer  func 
tions for continuous-time systems and discrete-time systems. 
A.  Chapter Description 
As  in  Chapter  1, we  will  concern  ourselves  with  linear,  continuous-time, finite-
dimensional systems represented by the state and output equations (internal descrip 
tion) 
94 
X =  A(t)x  +  B(t)u, 
y  =  C(t)x  +  D(t)u 
and the corresponding  input-output  description  (external  description) 
y(t) 
H{t,T)u{T)dT, 
(1.1) 
(1.2) 
95 
CHAPTER 2: 
Response of 
Linear Systems 
where H{t, r)  denotes the impulse response matrix. As pointed out in Chapter  1, in 
the  special  case  when  A{t)  =  A, B(t)  =  B,  C{t)  =  C,  and  D(t)  =  D,  with  initial 
time to  =  0, the external description  (1.2) can be represented  equivalently  in terms 
of Laplace transform  variables 
y(s)  =  H(s)u(s), 
(1.3) 
where H(s)  denotes the transfer  function  matrix of the system. We will examine  in 
greater detail the relationship between the internal description (1.1) and the external 
description  (1.2) here and in subsequent  chapters. 
Again, as in Chapter  1, we will also concern ourselves with linear, discrete-time, 
finite-dimensional  systems  represented  by  the  state  and  output  equations  (internal 
description) 
x(k  +  1)  =  A(k)x(k)  +  B(kMk), 
y(k)  -  C(k)x(k)  +  D(k)u(k) 
(1.4) 
and the corresponding input-output description  (external  description) 
n 
y(n)  =  ^H{n,k)u{k\ 
k =  h 
(1.5) 
where H{n,  k) denotes the unit pulse response. In the time-invariant case, with k^  = 
0, (1.5) can be represented  equivalently  (in terms of z-transform  variables)  as 
y(z)  =  H(z)u(zl 
(1.6) 
where H(z)  denotes the system transfer  function  matrix. 
In the following,  we provide a brief outline of the contents of this  chapter. 
In  the  second  section  we  provide  some  mathematical  background  material 
on  linear  algebra  and  matrix  theory.  In  the  third  section  we  further  study  sys 
tems  of  linear  homogeneous  and  nonhomogeneous  ordinary  differential  equations. 
Specifically,  in  this  section  we  develop  a  general  characterization  of  the  solu 
tions  of  such  equations  and  we  study  the  properties  of  the  solutions  by  inves 
tigating  the  properties  of  fundamental  matrices  and  state  transition  matrices.  In 
section  four  we  further  investigate  systems  of  linear,  autonomous,  homogeneous 
ordinary  differential  equations.  In  particular,  in  this  section  we  emphasize  sev 
eral  methods  of  determining  the  state  transition  matrix  of  such  systems  and  we 
study  the  asymptotic  behavior  of  the  solutions  of  such  systems.  In  the  fifth  sec 
tion  we  study  systems  of  linear,  periodic  ordinary  differential  equations  (Floquet 
theory).  In  the  sixth  and  seventh  sections  we  further  investigate  the  properties  of 
the  state  representations  and  the  input-output  representations  of  continuous-time 
and  discrete-time  finite-dimensional  systems.  Specifically,  in  these  sections  we 
study  equivalent  representations  of  such  systems,  we  investigate  the  properties  of 
transfer  function  matrices, and for  the discrete-time  case we also address  sampled-
data  systems  and the asymptotic behavior  of the  system response  of  time-invariant 
systems. 
96 
Linear Systems 
B.  Guidelines  for the  Reader 
In  a first reading,  the background  material  on linear  algebra,  given  in  Section  2.2, 
can be reviewed rather quickly. In the study of the subsequent material of this book, 
selective detailed coverage of topics in Section 2.2 may  also be desirable. 
A typical beginning graduate course in linear systems will include Theorem  3.1 
in Subsection 2.3 A, which shows that the set of solutions of the linear homogeneous 
equation x  =  A(t)x  forms an n-dimensional vector space. This theorem provides the 
basis for the definitions  of the fundamental  and the state transition matrix  (Subsec 
tions  2.3A,  2.3B,  and  2.3D). These  results  enable  us  to  determine  solutions  of  the 
nonhomogeneous  equation  x  =  A(t)x  +  g(t)  in  Subsection  2.3C.  Background  re 
quired for the above topics includes material on vector spaces, linear  independence 
of vectors, bases for  vector  spaces, and linear transformations  (Subsections  2.2A to 
2.2E). 
A typical beginning graduate course in linear systems will also address the ma 
terial on time-invariant systems given in Section 2.4, including solutions of the equa 
tion X  =  Ax-\-  g(t),  various methods of determining the matrix exponential e^\  and 
asymptotic behavior of time-invariant systems x  =  Ax  (including system modes and 
stability properties of an equilibrium). Background required for these topics includes 
material  on equivalence  and  similarity,  eigenvalues  and  eigenvectors  (Subsections 
2.21 and 2.2J). 
In  addition  to  the  above,  a  beginning  graduate  course  on  linear  systems  will 
also  treat  the  input-output  description  of  continuous-time  systems  and  its  relation 
to state-space representations, including  the impulse response for time-varying  and 
time-invariant  systems, the transfer  function  matrix for time-invariant  systems, and 
the equivalence of state-space representations  (Section 2.6). 
Finally,  such a course will also cover state-space  and input-output  descriptions 
of discrete-time  systems  (Section 2.7). 
2.2 
BACKGROUND  MATERIAL 
In this  section we consider material  from  linear  algebra  and matrix  theory.  We as 
sume that the reader has some background in these areas, and therefore,  our presen 
tation will constitute a summary  rather than  a development  of the subject  matter on 
hand. 
This section consists of fifteen subsections. In the first three subsections we con 
sider Hnear subspaces of vector spaces, linear independence of a set of vectors, and 
bases of vector spaces, respectively. In the next five subsections, we address general 
linear transformations  defined  on vector spaces, the representation  of such  transfor 
mations by matrices, some of the properties  of matrices  and determinants  of matri 
ces, and  solutions of linear  algebraic  equations, respectively.  In the ninth  and  tenth 
subsections, we address equivalence and similarity of matrices and eigenvalues  and 
eigenvectors, respectively. In the eleventh  subsection  we digress by considering di 
rect sums of linear  subspaces. In the last four  subsections  we address,  respectively, 
certain canonical forms  of matrices, minimal polynomials of matrices, nilpotent op 
erators, and the Jordan canonical  form. 
97 
CHAPTER  2: 
Response of 
Linear Systems 
A.  Linear  Subspaces 
In Section  1.10 we gave the formal definition of vector space over afield,  say, (K F), 
where V denotes the set of vectors and F denotes the set of scalars. When F (the field) 
is clear from context, we usually speak of a vector space V (or a linear space  V) rather 
than {V, F). 
A nonempty subset W of a vector space V is called a linear subspace  (or a linear 
manifold)  in  V if (i) w\  +  W2 is in W whenever w\  and W2 are in W, and (ii) aw  is in 
W  whenever a  G F  and w  ^  W.li  is an easy matter to verify  that a linear  subspace 
W  satisfies  all the axioms of a vector space and may  as such be regarded  as a linear 
space itself. 
Two  trivial  examples  of  linear  subspaces  include  the  null  vector  (i.e.,  the  set 
W  =  {0} is a linear  subspace  of  V) and the vector  space  V itself. Another  example 
of  a linear  subspace  is  the  set  of  all  real-valued  polynomials  defined  on  the  inter 
val  [a, b], that is a linear  subspace  of the vector  space consisting  of  all  real-valued 
continuous functions  defined  on the interval  [a, b] (refer to Example  10.4 in Chapter 
1). 
As another example of a linear subspace (of R^),  we cite the set of all points on 
a straight line passing through the origin. On the other hand, a straight line that does 
not pass through the origin is not a linear subspace of R^  (why?). 
It is an easy  matter  to show that if  Wi  and  W2 are linear  subspaces  of a vector 
space  V, then  Vl^i Pi 1^2. the intersection  of  Wi  and  W2, is also a linear  subspace of 
V. A  similar statement cannot be made, however, for the union of Wi  and W2 (prove 
this). Note that to show that a set  V is a vector  space, it suffices  to show that it is a 
linear subspace of some vector  space. 
B.  Linear  Independence 
Throughout  the  remainder  of  this  section,  we  let  { a i , . . .,  a„}, at  G  F,  denote  an 
indexed  set  of  scalars  and  we  let  {v\  ...,"  v""}", v'  E  V,  denote  an  indexed  set  of 
vectors. 
Now let  W be a set in a linear space  V (W may be a finite set or an infinite  set). 
We say that a vector v E  V is 3. finite linear  combination  of vectors  in  W if there is 
a finite set of elements {w^,...,  w^] in W and a finite set of scalars { a i , . . ., an)  in F 
such that 
V =  a\w^  +  •• • +  a^w^. 
Now let Ty be a nonempty subset of a linear space V and let S{W)  be the set of all 
finite linear combinations  of the vectors from  W, i.e., w  G S{W)  if and only if there 
is  some  set  of  scalars  {a\,..., 
a^}  and  some  finite  subset  {w^,...,  w^}  of  W  such 
that w  =  aiw^  ^ 
h a^v^^, where m may be any positive integer. Then it is easily 
shown that S(W)  is a linear subspace of  V, called the linear  subspace  generated  by 
the set  W. 
Now  if  t/  is  a linear  subspace  of  a vector  space  V  and  if  there  exists  a  set of 
vectors  W  CV  such that the linear  space S{W)  generated  by  W is  U, then  we  say 
that  W  spans  U. It  is  easily  shown  that  S(W)  is  the  smallest  Hnear  subspace  of  a 
vector  space  V containing  the subset  W of  V. Specifically,  if  t/  is a linear  subspace 
of  V and if  U contains  W, then  U also contains  S(W). 
98 
Linear  Systems 
As  an  example,  in  the  space  (R^,  R)  the  set  Si  =  {e^}  =  {(1, 0)^} spans  the  set 
consisting  of all vectors  of the form  (a,  0)^, a  EL R,  while  the  set ^2  =  {e^,  e^},  e^  = 
(0,1)^  spans  all  of 7^2. 
We  are  now  in  a position  to  introduce  the  notion  of  linear  dependence. 
DEFINITION  2.1.  Let 5  =  {v\  ...,"  v'""} be a finite nonempty  set in a linear space V. If "
there exist scalars ai,..., 
a^,  not all zero, such that 
aiv^  +  •••  + a ^ v^  =  0, 
(2.1) 
then the set S is said to be linearly  dependent  (over F)- If a set is not linearly  dependent, 
then  it  is  said  to be  linearly  independent.  In  this  case relation  (2.1)  implies  that  a\  = 
• • •  =  am  =  0.  An  infinite  set  of  vectors  T^ in  V is  said  to  be  linearly  independent  if 
every finite subset of  W is linearly independent. 
• 
EXAMPLE  2.1.  Consider  the  linear  space  (R^,R) 
(see  Example  10.1  in  Chapter 
1),  and  let  e^  =  (1, 0 , . . .,  0)^, e^  =  (0, 1, 0 , . . .,  0 ) ^ , . . .,"  ^""  =  ( 0 ", . . .,  0,1)^.  Clearly, 
"S""^i  <^/^'  =  0 implies that at  =  0", /  =  I,..  .,n.  Therefore,"  the set 5"" =  {e^",...,"  ^""} is "
a linearly  independent  set of vectors in R^ over the field of real numbers R. 
• 
EXAMPLE  2.2.  Let  V be the set of 2-tuples  whose entries are complex-valued  rational 
functions  over the field of complex-valued  rational functions.  Let 
1 
s-h  1 
1 
^s  + 2 
s + 2 
(s  +  1)(^ +  3) 
1 
s + 3 
and  let «!  ==  - 1,  0^2  =  (s  + 3)/(s  + 2). Then  aiv^  + a^v^  =  0,  and  therefore,  the  set 
S  =  {v\ v^} is linearly  dependent  over the field of rational functions.  On the other hand, 
since aiv^  +0:2 v^  =  0 when ai, 0:2  ^  ^  is true if and only if ai  =  0:2  =  0, it  follows 
that  S  is  linearly  independent  over  the  field  of  real  numbers  (which  is  a  subset  of  the 
field of rational  functions).  This  shows  that  linear  dependence  of  a set  of  vectors  in  V 
depends on the field F. 
m 
Linear  independence  of  functions  of  time 
EXAMPLE  2.3.  Let  V  =  C{{a, b)," R"""")", let  F  =  R,  and  for  x,y  EV  mda  E  F,  de 
fine addition  of elements  in  V and multiplication  of elements  in  V by  elements  in F by 
(x  +  y)(t)  =  x(t)  +  y(t)  for all t  G (a, b) and iax){t)  =  ax(t)  for all t  E  (a, b). Then as 
in Example  10.4 of Chapter  1, we can easily show that (V, F)  is a vector space. An inter 
esting question that arises is whether for this space, linear dependence  (and linear inde 
pendence)  of  a set of vectors  can be phrased  in some testable form.  The  answer  is yes. 
Indeed,  it can readily be verified  that for  the present vector  space  (K F),  linear  depen 
dence  of a set of vectors S  =  {(f)i,...,  (f)k} in V  =  C{{a," b\  7?"") over F  =  Ris  equivalent "
to the requirement that there exist scalars a/  G F, /  =  1,...,  ^, not all zero, such that 
ai4>i(t)  +  • • • +  ak(i)k(t)  =  0 
for  all t  G (a, b). 
Otherwise, S is linearly  independent. 
To  see  how  the  above  example  applies  to  specific  cases,  let  V  =  C((-^,  00), R^) 
and  consider  the  vectors  (/)i(0  =  [1, tY,  <p2(t)  =  [L t^]^.  To  show  that  the  set  S  = 
{</>b (f>2} is linearly independent (over F  =  R), assume for purposes of contradiction that 
S  is  linearly  dependent.  Then  there  must  exist  scalars  ai  and  a2,  not  both  zero,  such 
that Q!i[l, tf  +  a2[l, t^f  =  [0, 0]^ for  all t  G  ( - ^,  00). But in particular, for t  =  2, the 
above equation is satisfied if and only if a 1 =  a2  =  0, which contradicts the assumption. 
Therefore,"  5"" =  {(^1", (/)2} is linearly  independent. 
As another specific case of the above example, let V  =  C((-<^, ^), R^) and consider 
99 
the set S  = {</>!, ^2, h> </>4}, where cj^iit)  =  [1, tf,  (j)2{t)  =  [1, fl  (jy^it)  =  [0, 1]^, and 
CHAPTER  2: 
04(0  =  [e~^, 0].  The  set S is  clearly  independent  over R  since  aiipiit)  + 0L2(t>2{t)  + 
Response of 
0^303(0 + 0L4r4>A{t)  = 0 for all t G (-00, 00) if and only if ai  =  0:2  =  0:3  =  0:4  =  0. 
Linear Systems 
• 
hy^~^v'~^ +y^+iyi+i -^ 
Next,  let 5  =  {v^ . . .,  v^} be a linearly  independent  set in a vector  space  V. If 
Xr= 1 ^^^^  ^  2 r=  1 i^i^^ t^^^ it is readily  shown that at  =  j8/, for all /  =  1,...,  m. 
Also,  it  is  easily  shown  that  the  set  S  is  linearly  dependent  if  and  only  if  for 
some index  /,  1 <  /  <  m, we  can  find  scalars  y i , . . ., 7/-1, 7/+1,...,  ym  such  that 
v'  =  yiv^ H 
hy^v'^. Furthermore, it is not hard to ver 
ify  that a finite nonempty  set  V^ in a linear space is linearly independent if and only 
if for each v G 5(W), v 7^ 0, there is a unique finite subset of W, say, {v^ v^,...,  v^} 
and  a unique  set of nonzero  scalars {81,...,  S^}, such that v  =  Si v^  +  • • • +  8mV^. 
Finally,  if  t/  is  a  finite  set  in  a  linear  space  V,  then  it  is  easily  shown  that  U 
is  linearly  independent  if  and  only  if  there  is  no  proper  subset  Z  of  U  such  that 
S(U)  =  S(Z).  (Recall  that Z is  a proper  subset  of  U if  there  is  a  w  G  6^ such  that 
u  ^ Z .) 
C.  Bases 
We are now in a position to introduce another important  concept. 
DEFINITION 2.2.  A set W in a linear space V is called a basis for V if 
(i)  W is linearly independent, 
(ii)  The span of W is the linear space V itself, i.e., S(W)  = V. 
• 
An immediate  consequence  of the above definition  is that if  W is a linearly  in 
dependent  set in a vector space  V, then  T^ is a basis for  S(W). 
To introduce the notion of dimension of a vector space, it is shown that if a linear 
space  V is generated by  a finite number of linearly  independent  elements, then  this 
number of elements must be unique. The following  results lead up to this. 
Let {v^ . . .,"  v""} be a basis for  a linear  space  V. Then it is easily  shown that  for "
each vector v  EV, 
there exist unique  scalars a\,.  ..,an  such that 
any linearly independent  set of vectors in V, then m  < 
Furthermore, ifu^,...,u^is 
n. Moreover,  any other basis of  V consists of exactly  n elements. These facts  allow 
the definitions  given in the  following. 
If  a  linear  space  V  has  a  basis  consisting  of  a  finite  number  of  vectors,  say, 
{v^ ...,  v'^}, then  V is  said  to be  di finite-dimensional vector  space  and  the  dimen 
sion  of  V is n,  abbreviated  dim V  =  n.ln 
this  case  we  speak  of  an  n-dimensional 
vector  space.  If  V is not a  finite-dimensional  vector space, it is said to be an infinite-
dimensional  vector  space. 
By convention, the linear space consisting of the null vector is  finite-dimensional 
with dimension  equal to zero. 
An alternative to the above definition of dimension of a (finite-dimensional)  vec 
tor space is given by the following  result, which is easily verified:  let  V be a vector 
space that contains n linearly independent vectors. If every set of n +  1 vectors in V 
is linearly dependent, then  V is  finite-dimensional  and dim V  =  n. 
100 
Linear Systems 
The preceding results enable us now to introduce the concept of coordinates of a 
vector. We let {v^ . . .,  v'^} be a basis of a vector space V and let v E  V be represented 
by 
The unique  scalars ^ i , . . .,  ^^^  are called the coordinates  ofv  with  respect to the  basis 
EXAMPLE  2.4.  For  the  linear  space  (/?^/?),  let  S  =  {e\...,e''},  where  the  e' G 
R^, i  =  1,..., n, were defined earlier (following Defintion 2.1). Then S is clearly a basis 
"for (/?""", R) since it is linearly independent and since given any v G R^, there exist unique 
real scalars at, i  =  1,..., n," such that v =  X""=i ocie^  = (ai",...,  a:„)^, i.e.," S spans /?"". "
It follows that with every vector v E  /?^, we can associate a unique n-tuple of scalars 
ai 
or 
(ai,  ...,a„) 
relative to the basis {e^,...,  e^}," the coordinate representation of the vector v E  /?"" with "
"respect  to the basis  5"" =  {e\  ...","  ^""}.  Henceforth",  we will refer  to the basis S of this 
example as the natural basis for  R^. 
• 
EXAMPLE2.5.  We note that the vector space of all (complex-valued) polynomials with 
real coefficients  of degree less than n is an ^-dimensional  vector  space over the  field 
of real numbers. A basis  for  this  space is given by S  = {I, s,...,  s'^~^},  where ^ is a 
complex variable. Associated  with  a given  element  of this  vector space, say, p(s)  = 
ao + ais  + ' • • + an-\s^~^,  we have the unique fz-tuple given by (ao, OL\, ...,  ocn-iY, 
which constitutes the coordinate representation of p{s) with respect to the basis S given 
above. 
• 
EXAMPLE 2.6.  We note that the space (V, /?), where V  =  C([a, b], R), given in Exam 
ple 10.4 of Chapter 1, is an infinite-dimensional  vector space (why?). 
• 
D.  Linear  Transformations 
In  Subsection  1.IDA  we  introduced  the  notion  of  linear  transformation  ST from  a 
vector  space  V  (over  the fiield F)  into  a  vector  space  W  (over  the  same fiield F). 
Henceforth,  we  will  write  ST E  L(V, W)  to  express  this.  It  is  our  objective  in  this 
subsection to identify  some of the important properties of linear  transformations. 
Linear  equations 
With  Sr E  L(V; ^)  we define  the null space  of 3'  as the set 
J<(^)  =  {v E  y  : STv =  0} 
and the range space  of?)  as the set 
"91(9"")  =  {w E  W : w  =  STv", V E  y}. 
Note  that  since  STO =  0," }({^)  and  2/1(9"")  are  never  empty.  It  is  easily  verified "
"that M{^)  is a linear  subspace of  V and that 91(9"") is a linear subspace of W. If  V is "
finite-dimensional  (of dimension n)," then it is easily shown that dim 91(9"") <  n. Also", 
if  V is  finite-dimensional  and  if  {w^ ...,"  w^} is  a basis  for  91(9"") and  v^ is  defined "
by  ^V  w  i  =  I,..  .,n,  then  it is readily  proved  that  the  vectors  v^  ...,  v^  are 
Hnearly  independent. 
One of the important  results  of linear  algebra,  called  iht  fundamental 
theorem 
of linear  equations,  states that for  ^  G L{V, W)  with  V  finite-dimensional,  we have 
101 
CHAPTER  2: 
Response of 
Linear Systems 
dim>r(2r)  +  dimSlCST)  =  dim V. 
For the proof  of this result, refer  to any  of the references  on linear  algebra  cited  at 
the end of this  chapter. 
The above result gives rise to the notions of the rank,  p{^),  of a linear  transfor 
mation  ST of  a  finite-dimensional  vector  space  V into  a vector  space  W,  which  we 
define  as the dimension of the range space 9l(2r), and the nullity,  v{?F), of ST, which 
we define  as the dimension of the null space 
}^{^). 
With the above machinery in place, it is now easy to establish the following  im 
portant results concerning  linear  equations.  We let ST E  L{V, W),  where  V is finite-
dimensional,  let s  =  dim>r(2r),  and  let {v^ ...,  v^} be  a basis  for  >r(2r). Then  it is 
easily  verified  that  (i)  a vector  v G  V satisfies  the  equation  STv  =  0 if  and  only  if 
V =  XJ= 1 <^/v^ for some set of scalars {ai,...,  as}, and furthermore,  for each v G V 
such that  STv  =  0 is true, the set of scalars {ai,...,  a^} is unique; (ii) ifw^GW 
is 
a  fixed  vector,  then  STv  =  w^ holds  for  at least  one  vector  v G  V (called  the  solu 
"tion of the equation  STv =  w^) if and only if w^  G 5/1(9""); and (iii) if w^ is any fixed "
vector in  W and if  v^ is some vector in  V such that  STv^  =  w^  (i.e., v^ is a  solution 
of  the  equation  STv^  =  w^), then  a vector  v G  V satisfies  STv  =  w^  if  and  only  if 
V =  v^ +  X/ = i PiV^  for  some set of scalars {/3i,..., Ps}, and furthermore,  for  each 
V  G  V such that  STv  =  WQ, the set of scalars {j8i,..., jS^} is unique. 
General properties of linear  transformations 
Before  proceeding  further,  we  briefly  digress  by  recalling  certain  elementary 
properties  of a function/  from  a set X to a set  7, written  f  : X  ^  Y. Letting  2/l(/) 
denote the range of/,  we can classify/  in the following  manner: if 9l(/)  =  F, then 
/  is  said  to be  surjective  or  a surjection  and  we  say  t h a t/  maps  X  onto  Y; iff 
is 
such that for  every  xi,  X2 G X, f(xi)  =  f(x2)  implies  that  xi  =  X2, then/  is  said 
to be injective  or an injection  or a one-to-one  mapping;  and if/  is both injective  and 
surjective,  we say that/ is bijective  or a one-to-one  and onto mapping  or a bijection. 
When/  is injective,  its inverse  f'^ 
=  x  for 
all  X G X  and  f{f~^(y))  =  y  for  all  y  G 9l(/).  Note that  w h e n/  is bijective,  we 
h a v e / -I  :Y^ 
: 2/l(/)  -^  X  exists, so that  f~^(f(x)) 
X. 
Returning now to the subject on hand, we note that since a linear  transformation 
ST of a linear space V into a linear space W is a mapping, we distinguish in particular 
among  linear  transformations  that  are  surjective,  injective,  and  bijective.  We  will 
often  be particularly  interested  in knowing  when  a linear  transformation  ST  has  an 
inverse  2r~^  When  this is the case," we  say that  9"" is  invertible","  that  ST""^ exists",  or 
"that  9"" is nonsingular.  A  linear transformation  that  is not nonsingular  is  said  to be "
singular. 
Concerning  the  inverse  of  a  linear  transformation  ST G  L(V, W),  it  is  eas 
"ily  shown  that  ST""^  exists  if  and  only  if  STv  =  0  implies  v  =  0",  and  further 
more,  if  2r~^  exists,"  then  ST""^  is  a  linear  transformation  from  9l(2r)  onto  V  [i.e.", 
S''^  G L(2ft(2r),  V)]. Moreover,  if  V is  finite-dimensional,"  then  S"" has  an inverse if "
"and  only  if  91(9"") has  the  same  dimension  as  V",  i.e.,  p(9')  =  dim V.  Also, if  both 
102 
Linear Systems 
V and  W are  finite-dimensional  and of the same dimension, then 9l(2r)  =  W  if  and 
only if ST has an inverse. 
In the next few results, which are phrased in terms of equivalent statements, we 
summarize  some of the important properties of linear  transformations. 
"(Injective  linear  transformations)  For 9"" G L{V", W),  the following  statements 
are equivalent:  (i) ST is injective;  (ii) ST has an inverse; (iii)  STv  =  0 implies 
V =  0; (iv) for each w  G ?k('3'), there is a unique v G  V such that STv  =  w; 
(v) if  gTv^  =  STv^ then v^  -  v^; (vi) if v^  T^  V^  then  STv^  T^ STV^. If in 
addition,  V is  finite-dimensional,  then the following  are equivalent:  (i) ST  is 
injective;  (ii) p(2r)  =  dim  V. 
(Surjective  linear  transformations)  For ST G L{V, W),  the following  statements 
are equivalent:  (i) ST is surjective;  (ii) for each w  G  W, there is a v  G V 
such that STv  =  w. If in addition,  V and  W are  finite-dimensional,  then the 
following  are equivalent:  (i) ST is surjective;  (ii) dim W  =  pi^f). 
(Bijective linear transformations)¥or3'  G L(V, W), the following are equivalent: 
"(i)  9"" is bijective;  (ii) for every w  G  W", there is a unique v  E  V  such that 
9'v  =  w. If in addition y and Ware  finite-dimensional,  then the following  are 
equivalent: (i) ST is bijective; (ii) dim V  =  dim W  = p(?J'). 
(Injective,  surjective,  and  bijective  linear  transformations)  For S'  E  L(V,  W) 
with  V and  W  finite-dimensional  and with dim V  =  dim W,  the  following 
are equivalent:  (i) ST is injective;  (ii) ST is surjective;  (iii) ST is bijective; 
(iv) ST has an inverse. 
Next, we examine  some of the properties  of L(V, W),  the set of all linear trans 
formations  from  a vector  space  V into a vector space  W. As before,  we assume that 
V  and  W are linear spaces over the same field F. 
We let ^,"  3"" G L(V", W)  and we define the sum  of^  and  ST by 
(^  +  2r)v  =  SPv +  STv 
(2.2) 
for all V  G  y. Also, with a  G F  and ST G L(V; W), we define multiplication  of ST by 
a scalar  a  as 
{a^)v  =  a^v 
(2.3) 
for all V  G  y. It is easily shown that (&'-\-^)G  L(V, W) and also that aST G L(V,  W). 
We further  note that there exists a zero element in L(V, W),  called the zero  transfor 
mation,  denoted by 0  and defined  by 
Cv  =  0 
(2.4) 
for  all V  G  y.  Furthermore,  we note that to each  ST G L(V, W)  there corresponds  a 
"unique linear transformation  - 9""  G L(V", W)  defined  by 
(-oj-)v  ^  -STv 
(2.5) 
for  all V  G  y.  In this case it follows  trivially that  -ST  +  ST =  0. 
With these definitions  in place, it is easily proved that L(V, W)  is a linear  space 
over F,  called  the space  of linear  transformations  [with vector addition  defined  by 
(2.2) and multiplication  of vectors by scalars defined  by  (2.3)]. 
To explore the properties of the space of linear transformations further, we briefly 
digress to recall the definition of an algebra. Specifically,  a set V is called an  algebra 
103 
CHAPTER  2: 
Response of 
Linear Systems 
if it is a linear space and if in addition to each v,w  GV  there corresponds an element 
in  V, denoted by v •  w and called  the product  ofv  times  w, satisfying  the  following 
axioms: 
1.  V •  (w +  w)  =  V •  w +  V •  w for  all V, w, w  G  y. 
2.  (v + w)  • u  =  V ' u -\-  w ' u for dill V, w, u  E: V. 
3.  (av)'  (f3w)  =  (cj^/3)(v •  w) for all v, w E  V and for all a,  p  G  F. 
If in addition to the above, 
4.  (v'w)'  u  =  V'(w-  u) for all v,w,uG  V, then  V is called an associative  algebra. 
If there exists an element /  G  V such that i-v  =  v  i  =  v for every v G  V, then 
/ is  called  the  identity  of  the  algebra.  It  can  readily  be  shown  that  if  / exists,  then 
it  is  unique.  Furthermore,  if  v • w  =  w •  v for  all  v, w  G  V, then  V is  said  to  be  a 
commutative  algebra. 
Returning  to the  subject  on hand,  let V,  W,  and  U be linear  spaces  over F,  and 
consider the vector spaces L(V, W)  and L(W, U). If S/^ G L{W, U) and ST G LiV,  W), 
then we define  the product  5f ST  as the mapping of  V into  U by the relation 
(^2r)v  =  ^(STv) 
(2.6) 
for all V  G  y.  It is easily verified  that ^ST  G L{V, U). 
Next,  let  y  =  \y  =  f/.  If  ^,^,^E 
LiV,  V)  and  if a,  jS  G F,  then  it is  easily 
shown that 
and 
^(sra)  =  (SP2r)a 
(^  + 2r)a  =  jf a  +  gra 
(aSf)(/32r)  =  (af3)&'^. 
(2.7) 
(2.8) 
(2.9) 
(2.10) 
We  emphasize  that,  in  general,  commutativity  of  linear  transformations  does  not 
hold, i.e., in general 
spsr 7^  srsp. 
(2.11) 
There  is  a  special  mapping  from  a  linear  space  V  into  V,  called  the  identity 
transformation,  defined  by 
3v  =  V 
(2.12) 
for all V  G  y.  We note that J^ G L(V, V),  that ^  T^ 0 if and only if  V T^ {0}, that 3  is 
unique, and that 
aj-^  =  ^Gj-  ^  aj- 
(2.13) 
for  all ST G L(V, V).  Also, we can readily verify  that the transformation  a J^, a  G  F, 
defined  by 
(a^)v  =  aS>v =  av 
(2.14) 
is also a linear  transformation. 
Relations  (2.7)  to  (2.14)  now  give  rise  to  the  following  result:  L(V,V) 
is 
an  associative  algebra  with  identity  ^.  This  algebra  is  in  general  not  commu 
tative. 
104 
Linear Systems 
Concerning  invertible linear transformations  we note that if  J  G L(V; V) is bi-
jective," then  ST""^  G L(V", V), and  furthermore, 
of-^oj-  =  g-gj-1  ^  ^^ 
(2.15) 
where ^  denotes the identity transformation  defined  in (2.12). 
Next,  if  V is  a  finite-dimensional  vector  space  and  ST G  L(V, V),  then  we  can 
readily show that the following are equivalent: (i) ST is invertible; (ii) pCJ)  =  dim V; 
(iii)  ST is one-to-one; (iv)  ST is onto; and (v) STv  =  0 implies that v  =  0. 
For  bijective  linear  transformations,  we  can  easily  verify  the  following  char 
"acterizations.  Let  £/""", ST, a  G  L(V, V)  and  let  ^  denote  the  identity  transformation. 
Then  (i)  if  SPST =  aSP  -  J^, then  £P is  bijective  and  Sf ~i  =  ST =  1;  (ii)  if  ^  and 
Sr  are  bijective,  then  if?r  is  bijective,  and  (S^^y^  =  ^T'^if-^;  (iii)  if  ^  is  bi 
jective,  then  (S^'^y^  =  ^;  and  (iv)  if  ^  is  bijective,  then  a^  is  bijective  and 
(aSP)-i  =  ( l / a ) y -i  for  all a  G F, a  T^ 0. 
With  the  aid  of  the  above  concepts  and  results  we  can  now  construct  certain 
classes  of functions  of  linear  transformations.  Since  (2.7)  allows  us  to  write  the 
product  of three  or more linear  transformations  without  the use  of parentheses,  we 
can define  3'^,"  where  9"" G L(V", V)  and n is a positive integer,  as 
aj-n  A  Of  ,0}-  .  .,. 
.oj-^^ 
(2.16) 
n times 
Similarly, if ST  Ms the inverse of ST," then we can define  9""  ^", where m is a positive 
integer,  as 
aj-m A (2r-i)^  =.  ^-^  ^or-\' 
"'""  -gr-y "
(2.17) 
Using these definitions,  the usual laws of exponents  can be verified.  Thus, 
m  times 
aj-m  ,aj-n  ^  oj-m+n  ^  aj-n ,  aj-m 
/(jrm\n  __  oj-mn  __  arnm  _  rarnyn 
and 
where m and n are positive integers. Consistent with the above, we also have 
"ST""' • 9""-""  =  gT'""-""", 
(2.I8) 
/o  1 Q\ 
(2.20) 
and 
(2.21) 
(2.22) 
We are now in a position to consider polynomials  of linear  transformations.  For 
"3""!  =  Sr "
Sro  =  3>. 
example, if /(A)  is a polynomial, i.e., 
"/(A)  =  ao  +  aiA  +  ---+a„A""", 
(2.23) 
where oio,...,  Q!^  G i^, then by  f(^)  we mean 
/(ST)  =  a oi  +  aiSr  +  • • • +  A^gr^ 
(2.24) 
The  reader  is  cautioned  that  in  general  the  above  concept  cannot  be  extended  to 
functions  of  two  or more  linear  transformations,  because  linear  transformations  in 
general do not commute. 
E.  Representation  of Linear  Transformations  by  Matrices 
In the following,  we let  (V, F)  and  (W, F)  be vector  spaces  over the same  field  and 
we let ^  : y  -^  W denote a linear mapping. We let {v^ ...,"  v""} be a basis for  V and "
we set v^  =  ^ v^  . . .,"  v""  =  siv^.  Then  it is an easy  matter  to  show that  if  v is  any "
vector in  V and if  ( a i , . . ., a^)  are the coordinates  of v with respect  to {v^ . . .,"  v""}", 
"then  ^v  =  aiv^  +  • • •  +  a„v"".  Indeed","  we  have  siv  =  si(aiv^  +  • • • +  a^v"")  = "
"ai^v^  4- • • • +  a„64v""  =  aiv^  +  • • • +  a„v"". "
Next,  we  let  {v^ ...,  v'^} be  any  set  of  vectors  in  W.  Then  it  can  be  shown 
that there  exists  a unique  Hnear transformation  si  from  V into  W  such that  ^v^  = 
v^  . . .,"  ^^v'^  =  v"". To show this", we first observe that for each v E  V we have unique 
scalars ai,.. 
.,an  such that 
105 
CHAPTER  2: 
Response of 
Linear Systems 
Now define  a mapping  M : V ^  W as 
"V =  aiv^  +  •••  +  a„v"". "
1,..  .,n.  We first must show that d- is Hnear and, then, that 
"aiv^  +  • • • +  a„v""  and  w  =  /3iv^  +  • • • +  jS^v'^", we  have 
Clearly, ^ ( v^  =  v^ / 
^  is unique.  Given v 
"^(v + w)  =  6 4 [ ( a i + ) 8 iy  +  --- + (a^ + i 8 > ""]  =  (aj+/3i)v^  +  •••+ (a„ + iS^)v^ "
On the other hand,  d(v)  =  aiv^  +  • • • +  a^v'^," d(w)  =  /3iv^  +  • • • +  j8„v"". Thus", 
^(v)  +  ^(w)  =  (aiyi  +  • • • + a^v^)  +  (jSiv^  +  • • • +  ^^v^)  =  (^i  +  f3i)v^  +  • • • + 
"(a„  +  i8„)v""  =  62i(v +  w). In a similar manner", it is easily established that ad(v)  = 
d(av)  for  all  Q: G F  and  v G  V. Therefore,  ^  is linear.  Finally,  to  show  that  ^  is 
unique,  suppose  there  exists  a linear  transformation  ^  : V ^  W  such  that  ^v^  = 
v^ /  =  1,...,  /2. It  follows  that  (d  -  ^)v^  =  0, /  =  1,...,  n,  and,  therefore,  that 
These  results  show  that  a  linear  transformation  is  completely  determined  by 
knowing  how it transforms  the basis vectors  in its domain,  and that this linear  trans 
formation  is uniquely  determined  in this  way. These  results  enable  us to  represent 
linear transformations  defined  on  finite-dimensional  spaces in an unambiguous  way 
by means of matrices. We will use this fact  in the  following. 
Let  (V, F)  and  {W, F)  denote  n-dimensional  and  m-dimensional  vector  spaces, 
respectively  and  let  {v^ ...,  v^} and  {w\  ...,  w^} be  bases  for  V  and  W,  respec 
tively.  Let 
Since {w^ 
1,...,  n, such that 
V  ^  W be  a  linear  transformation  and  let  v'  =  siv\  /  =  1, 
w^} is a basis for  W, there are unique scalars {aij}, i  =  I,..  .,m,  j 
n. 
siv  =  V  =  aiiw  +  a2iw  +  • • • +  a^iw^ 
siv^  =  Sp'  =  a\2W^ 4- a22>v^ +  • • • +  a^2>^^ 
(2.25) 
"^v^  =  y""  =  aiyiW^  +  a2nW^ +  • • • + amn""^^' "
Next, let V  G  V. Then v has the unique representation v  =  aiv^  + 0:2v^ H 
"h a^v"" "
with respect to the basis {v^ ...,"  v""}. In view of the result given at the beginning of "
this subsection, we now have 
"^v  =  aiv^  +  • • • +  anv"""". "
(2.26) 
Since ^^v G W, d-v has a unique representation with respect to the basis {w^ . . ., w^}, 
say, 
^v  =  jiw^  +  72W^ +  • • • +  7mw'^. 
(2.27) 
106 
Linear Systems 
Combining  (2.25) and (2.26), we have 
^^,  -  rv (n 
^A^  -u 
4. ^  ^^^^\ 
+  ^2(^121^^  +  • • • + Clm2^^) 
+  aniainW^ 
+  • • • + 
"amn^""^)' "
Rearranging this expression, we have 
^v  =  (cin^i  +  ^i2<^2 +  • • • +  ai^a„)w^ 
+  (^21 a; 1 +  a22<^2 +  • * *  +  a2nOin)'^^ 
In view of the uniqueness  of the representation  in (2.27), we have 
+  (amiai 
+  am20^2  +  • • • +  amnO^n)'^'^' 
71  =  a\\a\  +  ^120:2 +  • • • +  ainOLn 
72  ==  Cl2\0i-\ +  <322«2  +  • • •  +  a2^Q^Az 
(2.28) 
Tm  =  ^ m l «l  +  Clm20^2  +  * *  •  +  ^m^Q^m 
where ( a i , . . ., anf  and  ( 7 1 , . . .,  7m)^ are coordinate representations  of v E  V and 
siv  ^  W  with  respect  to  the  bases  {v^ ...,"  v""} of  V and  {w^",...,  w^}  of  W,  re 
spectively.  This  set  of  equations  enables  us  to  represent  the  linear  transformation 
si  from  the linear  space  V into the  linear  space  W by  the unique  scalars  {atj}, i  = 
I,..  .,m,  j  =  !,...,/!.  For convenience we let 
an 
CI21 
ai2 
^ 22 
... 
•  • • 
ain 
^2n 
[atj] 
(2.29) 
^m\ 
^m2 
' •  • 
^mn 
We see that once the bases {v^ . . .,  v^}, {w^ . . .,  w^}  are fixed, we can represent  the 
linear transformation  d- by the array of scalars in (2.29) that are uniquely  determined 
by (2.25). Note  that thejth  column  of A is the coordinate  representation  of the  vector 
Av^  G  W  with  respect  to the basis  [w^,...,  w^}. 
In  view  of  the  results  given  at  the  beginning  of  this  subsection,  the  converse 
to the preceding  statement  also holds. Specifically,  with the bases for  V and  W  still 
fixed, the array given in (2.29) is uniquely  associated with the linear  transformation 
^ of  Vinto  W. 
The above discussion gives rise to the following  important  definition. 
DEFINITION 2.3.  The array given in (2.29) is called the matrix A of the linear trans 
formation si from a linear space V into a linear space W (over F) with respect to the 
basis {v^ ...," v""} of V and the basis {w\ ...", w^} of W. 
• 
If in Definition  2.3, V  =  W, and if for both  V and  W the same basis {v^ ..., v'^} 
is used,  then  we  simply  speak  of the matrix  A  of  the  linear  transformation  si  with 
respect  to the basis  {v^ ...," v""}. "
In  (2.29)  the  scalars  (an,  ai2,...,  atn)  form  the  /th  row  of  A  and  the  scalars 
(aij,  a2j,...,  amj)^  form thejth  column  of A.  The scalar atj refers to that element of 
107 
CHAPTER  2: 
Response of 
Linear Systems 
matrix A  that can be found  in the ith row and jth  column of A. The array in (2.29) is 
said to be an m X n matrix.  If  m  =  n, we speak of a square  matrix.  Consistent  with 
the above, an ^ X 1  matrix is called a column  vector, column  matrix,  or n-vector,  and 
a  1 X n matrix  is  called  a row vector.  Finally,  if  A  === [a/y]  and  B  =  [btj] are  two 
mX  n matrices, then A  =  B,  i.e., A and B are equal  if and only if aij  =  btj  for  all 
/  =  1,...,  m,  and  for  all  j  =  1,...,  n.  Furthermore,  we  call  A^  =  [ciijV  =  l^ji] 
the transpose  of A. 
The  preceding  discussion  shows  in  particular  that  if  ^  is  a  linear  transfor 
mation  of  an  n-dimensional  vector  space  V  into  an  m-dimensional  vector  space 
W, 
W  ==  SiVy 
(2.30) 
if 7  =  ( y i , . . ., ymV  denotes the coordinate representation  of w with respect to the 
basis {w^,...,  w^},  if  a  =  ( ^ i , . . .,  a„)^  denotes the coordinate representation  of v 
with respect  to the basis {v\  ...,"  v""}", and if A denotes the matrix  of ^  with  respect 
to the bases {v^ . . .,"  v""}", {w^ . . .,"  w""^}", then 
or equivalently. 
7  =  Aa, 
=  1,...  , m, 
(2.31) 
(2.32) 
which are alternative ways to write (2.28). 
Some important  remarks 
1.  Throughout  this  section  we  use,  in  the  interests  of  clarity  of  presentation,  low 
ercase  Greek  letters  to  denote  the  coordinate  representations  of  vectors  [see 
(2.31)]. In the interests of simplicity, however, we will use common (Latin) low 
ercase  letters  to  denote  vectors  throughout  the remainder  of  this  book,  whether 
they  are  coordinate  representations  of  vectors  or  underlying  objects  (elements 
ofV). 
2.  We note that  if,  in particular,  V  =  R^,  then  v  E.V  and  its  coordinate  represen 
tation  7]  with  respect  to  the  natural  basis  {^^  ...,  ^^} of  V will  have  the  same 
form. 
*F.  Some Properties  of  Matrices 
The rank of a matrix 
We  first  consider  the  characterization  of  the  rank  of  a  hnear  transformation 
in  terms  of  its  matrix  representation.  To  this  end,  let  ^  be  a  linear  transforma 
tion  from  a  vector  space  V  into  a  vector  space  W.  It  is  easily  shown  that  d-  has 
rank  r if  and  only  if  it  is  possible  to  choose  a  basis  {v^ ...,"  v""} for  V  and  a  basis "
{w^ . . .,  w^}  for  W  such  that  the  matrix  A  of  ^  with  respect  to  these  bases  is  of 
the  form 
108 
Linear Systems 
rioo  •• 
010 
•• 
000 
• 
000  • 
••  oT 
••  0 
A  = 
000 
000 
•• 
•• 
100  • 
000 
• 
•• 
•• 
° 
0 
> m  =  dim  W. 
000 
•• 
000 
• 
••  0  J 
Y 
n = dim  V 
More directly, if A is the matrix representation  of ^  E  L(V, W)  with respect to 
some arbitrary bases {v^ . . .,"  v""} and {w^",...,"  w'""}", then (i) the rank of ^  is the num 
ber of vectors  in the largest possible  linearly  independent  set of columns  of A; and 
(ii) the rank of ^  is the number of vectors in the smallest possible set of columns of 
A that has the property  that  all columns  not in it can be expressed  as linear  combi 
nations of the columns in it. 
The  above result  enables  us now  to make  the following  definition:  the  rank  of 
an mX  n matrix A  is the largest number of linearly independent  columns of A. 
General properties of  matrices 
Since matrices are representations of linear transformations on  finite-dimensional 
vector  spaces  (in the sense defined  in Subsection  E of this  section), it is  reasonable 
to suspect that matrices inherit the properties  of the transformations  they  represent. 
In the following,  we address this issue. 
Let V and W be ^-dimensional  and m-dimensional vector spaces over F, respec 
tively,  and  let  ^  and  ^  be  linear  transformations  of  V  into  W.  Let  A  =  [atj]  and 
B  =  [bij] be the matrix representation  of si  and 2^, respectively, with respect to the 
bases  {v^ ...,"  v""} in  V and  {w^ . . .",  w^}  in  W.  Using  (2.2)  and  Definition  2.3, the 
reader  can  readily  verify  that  the matrix  of the linear  transformation  ^  +  2S (with 
respect to the above bases), is given by 
A  + B  =  [atj] +  [bij]  =  [atj  +  btj]  =  [dj]  =  C. 
(2.33) 
Also,  using  (2.3)  and  Definition  2.3, the reader  can  easily  show  that  the matrix  of 
a A,  denoted by D = a A, is given as 
a A  -=  a[aij]  =  [aatj]  =  [dfj]  =  D. 
(2.34) 
From (2.33) we note that for two matrices A and B to be added, they must have the 
same number  of rows and  columns. When  this is the case, we say that A and B  are 
comparable  matrices. Clearly, if A is an m X n matrix, then  so is  aA. 
Next,  let  U be  an  r-dimensional  vector  space,  let  si  E  L(K  W),  and  let  2^ G 
L{W, U).  Let A be  the  matrix  of  d^ with  respect  to  the  basis  {v^ . . .,"  v""} in  V and "
with respect  to the basis  {w^,...,  w^}  in  W. Let  SS be the matrix  of B  with  respect 
to the basis  {w^ ...,  w^}  in  W  and  with  respect  to the basis  {u^,..  .,u^}m  U. The 
product mapping  SS^ as defined  by (2.6) is a linear transformation  of  V into  U. By 
applying  definitions,  it is readily  verified  that the matrix  of ^^  with respect  to the 
bases {v^ ..  .,v^}ofVand 
{u^,..  .,u^}of  Uis  given by 
where 
C  =  [Cij] =  BA, 
Cij  =  ^ 
bikakj 
k=i 
109 
CHAPTER  2: 
Response of 
Linear Systems 
(2.35) 
(2.36) 
for /  =  1,...,  r, and j  =  I,..  .,n.  Clearly, two matrices A and B can be multiplied to 
form the product BA  if and only if the number of columns of B is equal to the number 
of  rows  of A.  When  this  is  true,  we  say  that  the  matrices  B  and A  are  conformal 
matrices. 
As  mentioned  earlier,  the  properties  of  general  transformations  established  in 
Subsection  D hold of course in the case of their matrix representations  as well. We 
summarize  some of these in the  following: 
1.  Let A  and BhemX 
n matrices, and let C be an n X r matrix; then 
2.  Let A be an m X n matrix, and let B and  ChtnXr  matrices; then 
(A +  B)C  =  AC  + BC. 
A{B  + C)  =  AB  + AC. 
(2.37) 
(2.38) 
3.  Let A be an m X n matrix, let 5  be an ^  X r matrix," and let C be an r  X 5"" matrix; "
then 
A{BC)  =  (AB)C 
4.  Let a,  (3 E  F,  and let A be an m X n matrix; then 
5.  Let a  G F,  and let A and BhQ  mX  n matrices; then 
(a  +  /3)A  =  aA  +  j8A. 
a(A  +  B)  =  aA  +  aB. 
(2.39) 
(2.40) 
(2.41) 
6.  Let a,  (3 E:  F,  let A be an m X n matrix, and let 5  be an n X r matrix; then 
(aAXfiB)  =  (aPXAB). 
7.  Let A and Bbe  mX  n matrices; then 
8.  Let A, B,  and  ChtmXn  matrices; then 
A  + B  =  B  + A. 
{A + B)  + C  =  A  + {B-^C). 
(2.42) 
(2.43) 
(2.44) 
Next, let 0  G L{V, W) be the zero transformation  defined  by (2.4). Then for any 
bases {v^ . . .,"  v""} and {w^ . . .",  w^} for V and W, respectively, the zero  transformation 
is represented by the m X n matrix 
O  = 
Too 
00 
•••  0 
•••  0 
00 
0 
(2.45) 
called  the  null  matrix.  Further,  let  3  E:  L(V, V)  be  the  identity  transformation  de 
fined  by  (2.12)  and  let  {v\  ...,  v'^} be  an  arbitrary  basis  for  V.  Then  the  matrix 
110 
Linear Systems 
"representation  of the linear transformation  3""  from  V into  V with respect to the basis "
{v\  • • •, v«} is given by 
' 1 00 
/  =  0 10 
0 00 
••• 
••• 
••• 
0 
0 
1 
called the n X n identity  matrix. 
For any mX  n matrix A  we have that 
A^O  =  0  + A  =  A, 
and for  any nX  n matrix B we have 
where /  is the n  X n identity  matrix. 
BI  =  IB  =  B, 
(2.46) 
(2.47) 
(2.48) 
If  A  =  [uij] is  a matrix  representation  of  a linear  transformation  ^4, then  it  is 
easily  verified  that the matrix  -A  ==  ( - l )A  =  [-a/y]  is the corresponding  matrix 
representation  of the linear transformation  -s^.  In this case it follows  immediately 
that A  -\-  (-A)  =  O, where  O denotes the null matrix. By convention we write that 
A + (-A)  =  A-A. 
Next, let A  and Bhe  nX  n matrices. Then we have in general that 
AB  7^ BA, 
(2.49) 
as was the case in (2.11). 
Further,  let ^  G L(V, V),  and  assume  that  si  is nonsingular  with inverse  ^ ~^ 
so that MM~^  =  si~^si  =  ^.  Now if A is the n X n matrix of si  with respect to the 
basis  {v^ ...  ," v""} in  V", then  there  is  an  n  X ^  matrix  B  of  M~^  with respect  to  the 
basis {v\  ...,  v'^} in  y  such that 
BA  =  AB  =  I. 
(2.50) 
We call B the inverse of A and we denote it by A~ ^  Under the present  circumstances 
we say that A~^  exists,  or A has an inverse,  or A is invertible,  or A is nonsingular.  If 
"A""^  does not exist", we say that A is  singular 
From corresponding properties given in Subsection D for  arbitrary linear trans 
formations,  several  properties  of  matrices  are  evident.  In  particular,  for  an  n  X n 
matrix,  the following  are equivalent:  (i)  rank  A  — n\  (ii) Aa  =  0 implies  a  =  0; 
(iii)  for  every  yo  ^  F^,  there  is  a  unique  ao  E  F^  such  that  yo  =  Aao;  (iv)  the 
columns of A are linearly independent;  and (v) A~^  exists. 
In  Subsection  E  it  was  shown  that  we  can  represent  n  linear  equations  by  the 
matrix equation  (2.32) 
y  =  Aa. 
(2.51) 
Now  assume that A is nonsingular. If we premultiply  both  sides of this equation by 
A~^  we obtain 
a  =  A-^y, 
(2.52) 
the  solution  to Eq.  (2.51). Thus, knowledge  of the inverse  of A enables  us to  solve 
the system of linear equations  (2.51). 
Concerning  inverses  of  matrices,  the following  facts  are easily  verified:  (i)  an 
nXn  nonsingular matrix has one and only one inverse; (ii) if A and B are nonsingular 
nX  n matrices, then (AB)~^  =  B~^A~^',  and (iii) if A and B diVQnX  n matrices  and 
if AB  is nonsingular,  then so are A  and  B. 
Next,  we  consider  the principal  properties  of the transpose  of matrices,  which 
follow  readily from  definitions:  (i) for  any matrix A,  (A^)^  =  A; (ii) if A and B  are 
conformal  matrices,  then  (ABY  =  B^A^;  (iii)  if A  is  a  nonsingular  matrix,  then 
"(A^)""^  =  (A~^)^'",  (iv) if A is an n X n matrix, then A^ is nonsingular if and only if 
A is nonsingular; (v) if A and B are comparable matrices, then (A + B)^  =  A^  +  B^; 
and (vi) if a  G F  and A is a matrix, then (aA)^  =  aA^. 
Next,  we  let A  he  an n  X  n  matrix,  and  we  let  m be  a positive  integer.  As  in 
(2.16), we define  the  nX  n matrix A^  by 
A^  =  /{'A 
4, 
"""Y"" "
m  times 
(2.53) 
and if A  ^ exists, then as in (2.17) we define  the  nX  n matrix A  '^ as 
111 
CHAPTER  2: 
Response of 
Linear Systems 
A-^  = 
(A-'y 
l\m  A 
"••  -A"" "
(2.54) 
V 
m  times 
As in the case of Eqs.  (2.18) to (2.20), the usual laws of exponents follow  from  the 
above  definitions.  Specifically,  if A is  an  n  X n  matrix  and  if  r  and  s  are  positive 
integers, then 
A'--A'  =  A'^'  =  A'^'  =  A' • 
"(Ay  =  A""  =  A''  =  (A'Y", 
A' 
"and if A""'  exists", then 
Consistent with this notation, we have 
A'  • A-'  =  A'-'. 
(2.55) 
(2.56) 
(2.57) 
A'  =  A 
lO 
(2.58) 
and 
(2.59) 
We are now once more in a position to consider functions  of linear  transformations, 
where in the present case the linear transformations  are represented by matrices. For 
example, if /(A) is the polynomial in A given in (2.23), and if A is any nXn  matrix, 
then by /(A)  we mean 
^ 
/(A)  =  ao/  +  aiA  +  • • • +  a^A^. 
(2.60) 
Finally, we noted earlier that, in general, linear transformations  (and in particu 
lar, matrices) do not commute [see (2.11) and (2.49)]. However, in the case of square 
matrices, the following  facts  are easily  verified:  let A, B, C  denote  nX  n matrices; 
let O denote the  nX  n null matrix; and let /  denote the n X n identity  matrix. Then 
(i)  O commutes  with  any A; (ii) A^ commutes  with A^, where/?  and q are positive 
integers; (iii) a I  commutes with any A, where a  E: F', and (iv) if A commutes  with 
B and if A commutes with  C, then A commutes with aB  -\-  pC,  where a,  (3 E  F. 
*G.  Determinants  of  Matrices 
Definition  of  determinant 
In  this  section  we  recall  and  summarize  some  of  the  important  properties  of 
.,n}  and  recall  that  a 
determinants  of  a  matrix.  To  this  end  we  let  N  =  {1,2,.. 
112 
Linear  Systems 
permutation  on A/^ is a one-to-one mapping  ofN  onto itself. For example," if  O"" denotes "
a  permutation  on N,  then  we  can  represent  it  symbolically  as 
1  2---  n 
(2.61) 
where  ji  G A/^ for  / =  1, 
(7 more  compactly  as 
, n,  and  jr  ^  jk  whenever  r  ^  k.  Henceforth,  we  represent 
(y  = 
JlJ2---jn-
Clearly,  there  are  nl  possible  permutations  on  N.  We  let  P{N)  denote  the  set  of  all 
permutations  on N,  and  we  distinguish  between  odd  and  even  permutations.  Specif 
ically,  if  there  is  an  even  number  of  pairs  (/," k)  such  that  / >  k  but  / precedes  k  in O""", 
then  we  say  that  a  is  even.  Otherwise,  a  is  said  to  be  odd.  Finally,  we  define  the 
function  sgn  from  P{N)  into  F  by 
sgn  (cj) 
+1, 
if  (7 is  even 
if  a  is  odd 
forallcJGP(A^). 
As  a  specific  example,  foxN= 
{1,2,3},  there  are  six  different  permutations, 
even  and  odd,  on N  given  in  the  following  table: 
G 
123 
132 
213 
231 
312 
321 
Uuh) 
(1,2) 
(1,3) 
(2,1) 
(2,3) 
(3,1) 
(3,2) 
Uuh) 
(1,3) 
(1,2) 
(2,3) 
(2,1) 
(3,2) 
(3,1) 
G  is 
U2J3) 
odd  or  even 
sgn(G) 
(2,3) 
(3,2) 
(1,3) 
(3,1) 
(1,2) 
(2,1) 
Even 
Odd 
Odd 
Even 
Even 
Odd 
-1 
Now  let A  denote  the  nxn  matrix  given  by 
'an 
ail 
an 
ail 
\_afii 
a^ii 
a\n 
ain 
ann. 
We  form  the  product  of  n  elements  from  A  by  taking  one  and  only  one  element  from 
each  row  and  one  and  only  one element  from  each  column.  We represent this  product 
as 
^Ijl  '^2J2 
anj^^ 
where  {jiji 
• • • jn)  ^  ^ ( ^ )-  H is  possible  to  find  n\  such  products,  one  for  each  a  G 
P{N).  We  are  now  in  a  position  to  define  the  determinant  of  A,  denoted  by  det{A), 
by  the  sum 
det{A)  = 
^ 
sgn{G)  • aij^  • ay^ 
oePiN) 
^njn^ 
(2.62) 
where a  =  jvin-  We frequently  denote the determinant  of A by 
det{A)  = 
Cl\n 
Clin  =  \A[ 
113 
CHAPTER  2: 
Response of 
Linear Systems 
(2.63) 
Properties of  determinants 
We now enumerate some of the common properties of determinants. The proofs 
of these follow  mostly from  definitions. 
Let A and BhonXn  matrices. Then (i) det (A^)  =  det (A); (ii) if all elements of 
a column  (or row) of A are zero, then det (A)  =  0; (iii) if the matrix B is the matrix 
obtained  by  multiplying  every  element  in  a column  (or row)  of A by  a constant  a, 
while  all  other  columns  of B  are the  same  as those  of A, then  det(B)  =  a  det{A)\ 
(iv) if JB is the same as A, except that two columns  (or rows) are interchanged,  then 
det(B)  ==  -J^f  (A); (v) if two columns (or rows) of A are identical, then J^^( A)  =  0; 
and (vi) if the columns  (or rows) of A are linearly  dependent, then det (A)  =  0. 
We now  introduce  some  additional  concepts  for  determinants.  To this  end,  let 
A  =  [aij] be  an  /I X n  matrix.  If  the  /th row  andjth  column  of A are  deleted,  the 
remaining (n -  1) rows and (n -  1) columns can be used to form another matrix  Mij 
whose  determinant  is det (Mij).  We call det {Mij)  the minor  of  aij.  If  the  diagonal 
elementsofM/y  are diagonal elements of A, i.e., if /  = 
j,  then we speak of aprmc/pa/ 
minor  of A.  The cofactor  of aij  is defined  as (-  ly^^det 
As a specific  example, if A is a 3 X 3 matrix, then 
(Mij). 
the minor of element ^23 is 
and the cofactor  of ^23 is 
det (A)  = 
an 
^21 
^31 
ai2 
^22 
au 
Cl23 
^ 32 
<^33 
det(M23)  =  an 
«31 
ai2 
CI31 
CTh 
(-1)  a\\ 
<23i 
a\2 
(332 
Next,  for  an  arbitrary  nXn  matrix A, let  c/y  denote the  cofactor  of  aij,  i, j  = 
I,..  .,n.lt  can be  shown  from  definitions  that the  determinant  of A is equal  to  the 
sum of the products of the elements of any column (or row) of A, each by its cofactor. 
Specifically, 
det (A)  =  ^ 
^ijCij, 
j  =  \,.. 
.,n, 
i = \ 
or 
det (A)  =  ^^aijCij, 
i  =  1,.. 
For example, if A is a 2 X 2 matrix, we have 
det  (A) 
an 
<^2i 
a\2 
^ 22 
"-  <2ll^22  "" "
^ 1 2 ^ 2b 
(2.64) 
(2.65) 
114 
Linear  Systems 
and if A is a 3 X 3 matrix, we have 
det{A) 
= 
k ll 
\a2i 
1^31 
^12 
^13 
^22  <^23 
^32  ^33! 
=  an 
Cl22 
^ 32 
<^23 
(233 
- 
^ 12 
(221 
^31 
=  ancn  +  ^21^21 -^ cisic^i. 
^ 23 
<^33  +  a\2> 
Cl2\ 
(331 
'^22 
^ 32 
We now consider a few additional useful properties of determinants. In particular 
from basic definitions it can be shown that if the ith row of an n X ^ matrix A  consists 
of elements of the form  an  +  a'-p ai2 +  a[2,..  .,ain  + a\^, i.e., if 
an 
<221 
(212 
<322 
^ 1« 
^2n 
A  = 
(an  + a'.^) 
((2,-2 +  ^;2) 
(atn  +  (2;^) 
then 
det(A)  = 
an 
a\2 
<321 
<322 
<3/l 
(2/2 
<^/22 
^2n 
an 
Cl2\ 
a\^ 
a\2 
C122 
^a 
(^n\ 
Cln2 
(^2n 
<2«1 
^ n2 
Next,  if A  and B  axe n  X  n matrices,  and  if B  is  obtained  from  A  by  adding  a 
constant  a  times  any  column  (or row)  to any other column  (or row)  of A, then  it is 
easily  shown that (i^r (A)  =  det(B). 
Further, if ctj  denotes the cofactor  of atj,  i, j  =  1,...,  n, for annX  n matrix A, 
then it is easily  shown that 
and 
^atjCik 
i = \ 
^^CLijCkj 
7 = 1 
=- 0 
foxJT^k 
=  0 
for  /  7^  k. 
(2.66) 
(2.67) 
We can combine (2.64) with (2.66) and (2.65) with (2.67) to obtain the relations 
n 
^atjCij^  =  det(A)Sjk, 
/ =  i 
^atjCkj  =  det(A)81^, 
7 = 1 
j, k  =  \,...,n, 
(2.68) 
i, k  =  \,.. 
.,n, 
(2.69) 
and 
respectively, where 8mn denotes the Kronecker delta (i.e., 8mn =  1  when m  =  n and 
^mn =  0 Otherwise). 
An  extremely  useful  result  concerning  determinants  (which  can  be  proved  by 
using  the  definition  of  determinant  and  some  of the  properties  enumerated  above) 
states that the determinant  of the product  of two matrices  is equal to the product of 
the determinants  of the matrices. Thus, if A and B are nX  n matrices, then 
det(AB)  = 
det(A)det(B). 
(2.70) 
It is  easily  verified  that  for  the  n  X n identity  matrix  /  and  for  the  n  X  n  zero 
matrix  O, we have det (I)  =  1 and det (O)  =  0. 
Finally, we can readily  show that  annX  n matrix A  is nonsingular  if  and  only 
if det (A)  ¥=0. 
We conclude this discussion by considering a means of determining the inverse, 
A~^  of a nonsingular  nX  n matrix. To this end, let c/y be the cofactor  of atj,  i, j  = 
1,...,  n, for the matrix A, and let C be the matrix formed  by the cofactors  of A, i.e., 
C  =  [cij]. The  matrix  C^  is  called  the  (classical)  adjoint  of A, and  is denoted  by 
adj (A). It is easily verified  that 
A •  [adj (A)]  =  [adj (A)]  • A  -  [det (A)]  • /, 
(2.71) 
115 
CHAPTER  2: 
Response of 
Linear Systems 
from  which it follows  that 
1 
adj  (A). 
det  (A) 
(2.72) 
As a specific  case, consider 
A  = 
0 
1 
1 
1  1 
2  2 
0 
-1 
Then  det (A)  -  - 1, 
adj (A)  = 
and 
"A"" "
2 
2 
3 
2 
2 
3 
-1 
-1 
1 
1 
1 
-1 
0' 
1 
-1 
"0"" "
-1 
1 
H.  Solving Linear Algebraic  Equations 
Now consider the linear system of equations given by 
Aa  =  y, 
(2.73) 
"where A  E  R^^^  and y  E. R^  are given  and a  G /?"" is to be determined.  By  using "
the results  of the preceding  subsections,  especially  Subsection  2.2D, the  following 
important results can readily be  established. 
1.  For a given y, a solution a  of (2.73) exists (not necessarily unique) if and only if 
7  G 2^(A), or equivalently, if and only if 
2.  A solution a  of (2.73) exists for any y  if and only if 
p{[A,y^)  =  p{Ar 
p(A)  =  m. 
(in  A) 
(2.75) 
If (2.75) is satisfied,  a solution of (2.73) can be found  by using the relation 
a  =  A'^(AA^y^y. 
(2.76) 
116 
Linear Systems 
When  in  (2.73),  p(A)  =  m  =  n,  then  A  G 
unique  solution of (2.76) is given by 
j^nxn  ^^^  jg  nonsingular  and  the 
a  =  A~^y, 
3.  Every  solution a  of (2.73) can be expressed  as a sum 
a  =  ap-\-  ah, 
(2.77) 
(2.78) 
where  ap  is  a  specific  solution  of  (2.73)  and  ah  satisfies  Aah  =  0. This  result 
allows us to span the space of all solutions of (2.73). Note that there are 
dim>f(A)  =  n-  p{A) 
(2.79) 
linearly independent  solutions of the system of equations AjS  =  0. 
EXAMPLE 2.7.  Consider 
Aa  = 
0 
0 
.0 
0 
0 
0 
"0"" "
1 
0. 
r-
(2.80) 
It is easily verified  that {(0, 1, 0)^} is a basis for S/l(A). Since a solution of (2.80) exists 
if and only if y  G ^(A), y  must be of the form y  = (0, k,0), k G R. Note that 
p(A)  =  I  = p([A, y])  = rank 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
k 
0 
as expected. To determine all solutions of (2.80), we need to determine an a^  and an 
ah  [see (2.78)]. In particular,  ap  =  (0,0, Z:)^ will  do. To determine  an, we consider 
AjS  =  0. There are dim >r(A)  =  2 linearly independent solutions of A/3  =  0. In partic 
ular, {(1, 0, 0)^, (0, 1, 0)^} is a basis for M(A). Therefore,  any solution of (2.80) can be 
expressed as 
ap  -\- ah 
0' 
0 
.k. 
+ 
T  01 
0  1 
.0  oj 
\ci 
l_<^2. 
where ci, C2 are appropriately chosen real numbers. 
• 
We conclude by noting that an extensive discussion of determining  solutions of 
the linear system of equations  (2.73) is provided in the  Appendix. 
I.  Equivalence  and  Similarity 
From  our previous  discussion  it  is  clear  that  a linear  transformation  ^4 of  a  finite-
dimensional  vector  space  V into  a  finite-dimensional  vector  space  W can be repre 
sented by means of different  matrices, depending on the particular choice of bases in 
V and W. The choice of bases may in different  cases result in matrices that are easy or 
"hard to utilize. Many of the resulting ""standard"" forms of matrices", called  canonical 
forms,  arise because of practical considerations. Such canonical forms  often  exhibit 
inherent characteristics  of the underlying transformation  si. 
Throughout the present subsection, V and W are finite-dimensional vector spaces 
over the same field F, dim V  =  n, and dim W  =  m. 
Change of bases: Vector case 
Our  first  aim  will  be  to  consider  the  change  of  bases  in  the  coordinate  repre- 
sentation  of vectors. Let {v^ . . .,"  v""""} be a basis  for  V and let {v^ . . .",  v'^} be  a set of 
vectors in  V given by 
117 
CHAPTER 2: 
Response of 
Linear Systems 
=  ^Pn 
i  =  \,.. 
(2.81) 
where  pij  G F  for  all  i, j  =  1,...,  n.  It  is  easily  verified  that  the  set  {v^ ...,"  v""} "
forms  a basis for  V if and only if the n X n matrix P  =  [pij] is nonsingular. We call 
P the matrix  of the basis  {v\  ...,"  v""} with  respect  to the basis  {v^ . . .","  v""}. Note that "
the  /th  column  of P  is  the  coordinate  representation  of  v'  with  respect  to the  basis 
Continuing  the  above  discussion,  let {v^ . . .,"  v""} and  {v\  ...",  v'^} be  two  bases 
for  y,  and  let  P  be  the  matrix  of  the  basis  {v^ ...,"  v""} with  respect  to  the  basis "
{v^ . . .,"  v""}. Then  it is easily  shown  that  P~^  is the matrix  of the basis  {v^ ...", v'^} 
with respect to the basis {v^ ...,"  v""}. "
Next,  let  the  sets  of  vectors  {v^ . . .,"  v""}", {v^ . . .,  v^},  and  {v^ ...,  v^} be  bases 
for  V. If P is the matrix of the basis {v^ . . .,"  v""} with respect to the basis {v^ ...","  v""} "
and if  Q is the matrix  of the basis {v V  • •," v""} with respect to the basis {v^ . . .",  v'^}, 
then it is easily verified  that PQ is the matrix of the basis {v^ ...,"  v""} with respect to "
the basis {v^ ...,  v^}. 
Continuing  further,  let  {v^ ...,"  v""} and  {v^ ...","  v""} be  two  bases  for  V  and  let "
P  be  the  matrix  of  the  basis  {v^ . . .,"  v""} with  respect  to  the  basis  {v^ . . .",  v'^}.  Let 
a  ^  V  and  let  a^  =  ( a i , . . ., a„)  denote  the  coordinate  representation  of  a  with 
respect to the basis {v^ ...,"  v""} (i.e.", a  =  XJ^= i cav^)- Let d^  =  (di,..., 
dn)  denote 
the  coordinate  representation  of  a  with  respect  to  the  basis  {v^ ...,"  v""}.  Then  it  is "
readily verified  that 
Pd  =  a. 
R^  be given. Let 
EXAMPLE  2.8.  Let  V  =  R^ md  F  =  R, and let a  =  (1, 2, 3)^  ( 
=  (1,0, Of,  ^2  ^ 
{v\ v^, v-^} =  {e^, e^, e^} denote  the  natural  basis  for  R^,  i.e., e^ 
(0, 1, 0)^, e^ =  (0,0,1)^. Clearly, the coordinate representation  a  of a with respect to 
the natural basis is (1, 2, 3)^. 
Now let {v\ v^, v^} be another basis for R^, given by v^  =  (1, 0,  1)^ 
= (0, 1, l)'^. From the relation 
, v2 = (0, 1, 0)^, 
(1,0,1)^  =  v^  = 
rii 
0 
0 
=  Pii 
P\\V^  +  PllV^  +  P3lV^ 
roi 
0 
1 
"ro"" "
1 
0 
+  P21 
+  P31 
we conclude that pn  =  1, p2i  = 0, and psi  =  1. Similarly, from 
(0,  1, 0)^  =  v'^  =  pnV^  +  P22V^  +  P32V^ 
roi 
0 
1 
roi 
1 
0 
\l~ 
0 
0 
+  P32 
+  Pll 
P\2 
118 
Linear Systems 
we conclude that pu  = 0, P22  =  1, and P32  = 0. Finally, from the relation 
(0,1,1)^ 
r ii 
0 
0 
Pl3 
+  P23 
+  P33 
roi 
1 
0 
roi 
0 
1 
we obtain that pu  = 0, P23  =  1, and P33  = 1. 
The matrix P  =  [ptj] of the basis {v\ v^, v^} with respect to the basis {v^ v^, v^} is 
therefore determined to be 
ri  0  01 
p  =  \o  1  1, 
ij 
[1  0 
and the coordinate representation  of a with respect to the basis {v^ v^, v^} is given by 
d  = P~^a, or 
ri  0  01 
0  1  1 
.1  0  1, 
r  1  0 
1 1 -1 
. -1  0 
-1  r  11 
r 
L: 
3j 
rr 
01 
2 
L3. 
oj 
= 
Ml 
0 
_2_ 
Change of bases: Matrix  case 
Having  addressed  the relationship  between  the coordinate  representations  of  a 
given  vector  with  respect  to different  bases,  we  next  consider  the  relationship  be 
tween  the  matrix  representations  of  a  given  linear  transformation  relative  to  dif 
ferent  bases. To this  end  let  ^  G L(V, W)  and  let {v^ . . .,  v^} and  {w^ . . .,"  w""^} be "
bases for  V and  W, respectively. Let A  be the matrix of si  with respect to the bases 
{v^ . . .,"  v""} and {w^",...,"  w""^}. Let {v^ . . .",  v^} be another basis for  V, and let the ma 
trix of {v^ ...,  v'^} with respect to {v^ ...,  v'^} be P. Let {w^,...,  w^]  be another basis 
for  W,  and  let  Q be the matrix  of {w^ ...,  w^}  with respect  to {vP^ ...,  w^}.  Let  A 
be the matrix of ^  with respect to the bases {v^ . . .,  v'^} and {w^ . . .,  w^}.  Then it is 
readily verified  that 
A  =  QAR 
(2.82) 
This result is depicted  schematically  in Fig. 2.1. 
V-^  W 
A 
—* 
V  =  PV 
Pt 
"{v\  • • •. v""} "
A 
V 
0)  =  Av 
\  Q 
cb = Qo) 
FIGURE 2.1 
Schematic diagram of the equivalence of 
two matrices 
Equivalence of matrices 
The preceding discussion motivates the following  definition. 
119 
CHAPTER  2: 
Response of 
Linear Systems 
DEFINITION 2.4.  Anm  X n matrix A is said to be equivalent to an m X ^ matrix A if 
there exists an m X m nonsingular matrix Q and an /i x ^ nonsingular matrix P such that 
• 
(2.82) is true. If A is equivalent to A, we write A ~  A. 
Thus, an m X ^ matrix A is equivalent to an m X n matrix A if and only if A and 
A can be interpreted  as both being matrices  of the same linear transformation  ^4 of 
a linear space V into a linear space W, but v^ith respect to possibly different  choices 
of bases. 
It is clear that  a matrix A is always  equivalent  to itself  (i.e., A ~  A). Also, if a 
matrix A is equivalent to a matrix 5, then clearly B is equivalent to A (i.e., if A ~  5, 
then 5  —  A). Furthermore, if A is equivalent to B and B is equivalent to a matrix C, 
then it is evident that A is equivalent  to C (i.e., if A ~  5  and B  — C, then A ~  C). 
This shows that  ~  is an equivalence  relation. 
The reader can easily verify  that every m X n matrix is equivalent to a matrix of 
the  form 
"""100 "
010 
000 
000 
•• 
•• 
•• 
•• 
"••  0  "" "
••  0 
}  r  =  rank  A 
100 
000 
••  0 
••  0 
000 
•• 
000 
•• 
0-
From this it follows  that two  mX  n matrices A  and B  are equivalent  if  and  only if 
they have the same rank, and furthermore,  that A  and A^  have the same rank. 
The definition of rank of a matrix that we used in Section 2.2 is sometimes called 
the column  rank  of a matrix.  Sometimes, an analogous  definition  for  row rank  of a 
matrix  is also used. The result given in the above paragraph  shows that row rank of 
a matrix  is equal  to its column  rank. 
Similarity of matrices 
Next, let  V  =  W, let 5i  e  L{V, V), let {v^,...," v""} be a basis for  V", and let A be 
the matrix  of d.  with  respect  to {v^ ...,"  v""}. Let {v'",...," v""} be  another basis  for  V "
whose matrix with respect to {v^ . . .,"  v""} is P. Let A be the matrix of ai with respect "
to {v^ . . .,"  v""}. Then it follows  immediately  from  (2.82) that "
A  =  P'^AP. 
(2.83) 
The meaning of this result is depicted  schematically  in Fig. 2.2. 
This discussion  motivates the following  definition. 
{v\...,"v""} "
t  P 
V 
{v\...,"v""} "
IP-' 
{v  , . . .,"  v""} "
A 
-^ 
{v  ,...,"  v""} "
FIGURE 2.2 
Schematic diagram of the similarity of two matrices 
120 
Linear Systems 
DEFINITION 2.5.  knnXn  matrix A is said to be similar to em nXn matrix A if there 
exists SinnX  n nonsingular matrix P such that 
A  =  P-^AP. 
If A is similar to A, we write A -- A. We call P a similarity transformation. 
• 
It is easily verified  that if A is similar to A  [i.e., (2.83) is true], then A is similar 
to A, i.e., 
A = PAp-\ 
(2.84) 
In view  of this," there is no ambiguity  in  saying  ""two matrices  are similar","""  and  we "
could just as well have used (2.84) [in place of (2.83)] to define similarity of matrices. 
To  sum  up, if two  matrices A and  A represent  the  same  linear  transformation 
d^ G L{V, y),  possibly  with  respect  to two  different  bases  for  V, then A and  A are 
similar matrices. 
Since the similarity of two matrices is a special case of the equivalence of matri 
ces, it follows that (i) a matrix A is similar to A; (ii) if A is similar to a matrix B, then 
B is similar to A; and (iii) if A is similar to B and B is similar to a matrix C, then A is 
similar to C. Therefore, the similarity relation of matrices is an equivalence relation. 
Now let A be an n X fz matrix that is similar to a matrix B. Then it is easily shown 
that A^ is similar to B^, where k denotes a positive integer, i.e., B^  = P~^A^P.  This 
can be extended further  by  letting 
and by verifying  that 
m 
i = 0 
"ao + aiX + • • • + a^A"" "
(2.85) 
f(p-'AP)  = p-'f{A)P, 
(2.86) 
where  a o , . . ., a^ E F. This  shows  that if B is similar  to A,  then  f{B) is similar 
to /(A),  where in fact  the same  similarity  transformation  P is involved. Further, if 
A is similar  to A  and if /(A)  is as given in (2.85),  then  /(A)  =  O if and  only if 
/(A)  ==  O. 
Next,  let ^4 G L(K  V)  and  let  A be the  matrix  of ^4 with  respect  to a basis 
{v\  . . .,"  v""} in y. Let  /(A)  denote  the polynomial  given  in  (2.85)  and  let A be  any "
matrix of si.  Then it is readily verified  that f{d)  = 0 if and only if /(A)  = O, 
We can use results such as the preceding to good advantage. For example, let A 
denote the diagonal  matrix  given by 
'Ai  0  0  •••  0 
0  A2  0  ••• 
0 
0 
0 
A  = ' 
0 
0 
0  0  •• 
0  0  •• 
•  A„-i 
Then 
{Af  = 
\x\ 
0 
0  0  • 
A^  0  • 
0 
0  0  • 
0  0  • 
0 
An J 
0 
0 
0 
AS 
0 
0 
0 
0 
121 
CHAPTER  2: 
Response of 
Linear Systems 
Now let /(A) be given by (2.85). Then 
[l  0  ••• 
0  1 
••• 
...  0 
...  0 
Ai 
0 
0 
A2 
• 
• 
f{A)  =  ao 
+  ai 
0  0 
|_0  0 
••• 
••• 
1 
0 
0 
1 
0 
[0 
0-
0 
••  A „ -i 
0 
• 
0 
0 
0 
An 
+ ••• 
+  a„ 
"""AY* "
0 
0  A-
0 
.0 
0 
0 
01 
0 
0 
"A""* "
0 
7(Ai) 
0 
0 
/(Ai) 
• 
0 
0 
0 
0 
0 
0 
0 
/(A„-i) 
0 
/(A„) 
Next, let ^  E  L{V, V), let A be the matrix of si  with respect to a basis {v^ . . .,"  v""} "
in y, and let A be the matrix of si  with respect to another basis {v^ . . .,  v'^} in V. Then 
it is easily verified that det (A)  =  del (A). From this it follows that for any two similar 
matrices A and B, we have det (A)  =  det  (B). 
In view  of these results, there is no ambiguity  in defining  the determinant  of a 
linear  transformation  6^^ of a  finite-dimensional  vector  space  V into  V as the  deter 
minant of any matrix A representing  it, i.e., det(^)  =  det  (A). 
J.  Eigenvalues  and  Eigenvectors 
Definitions 
Throughout  this  subsection,  V  denotes  an  n-dimensional  vector  space  over  a 
field  F. 
Let  ^  E  L(V, V)  and  let us  assume  that  there  exist  sets  of  vectors  {v^ . . .,"  v""} "
and {v^ . . .,"  v""} that are bases for  V such that "
V 
= 
v2  = 
=  Aiv' 
= W 
"v«  =  siv""  =  A„v""", 
where  Xi ^  F,i  =  I,...,  n. If this is the case, then the matrix  Aof  d.  with  respect 
to the given bases is 
A  = 
[Ai 
0 
0 
A„ 
This motivates the following  result that is easily verified:  for M G LiV, V)  and A  G 
F,  the set of all v G  V such that 
siv  = Av 
(2.87) 
122 
Linear Systems 
is  a  linear  subspace  of  V.  In  fact,  it  is  the  null  space  of  the  linear  transformation 
(^  ~~  ^^)^  where ^  is the identity element of L(V, V).  Henceforth,  we let 
JVTA =  {v  G  y  : (^  -  Ai)v  =  0}. 
(2.88) 
The above gives rise to several important concepts that we introduce in the fol 
lowing  definition. 
DEFINITION 2.6.  A scalar A such that Kx [given in (2.88)] contains more than just the 
zero vector is called an eigenvalue of ^4 (i.e., if there is a v T^ 0 such that siv  = Av, then 
A is called an eigenvalue of si). When A is an eigenvalue of si, then each v T^ 0 in J^TA 
is called an eigenvector of ^  corresponding to the eigenvalue A. The dimension of the 
linear subspace JVA is called the (geometric) multiplicity of the eigenvalue A. If JVA is of 
dimension one, then A is called a simple eigenvalue.  The set of all eigenvalues of d^ is 
called the spectrum of si. 
• 
Other  names  for  eigenvalue  that  are in use include proper  value,  characteris 
tic value,  latent  value,  or secular  value.  Similarly, other names for eigenvectors  are 
proper  vector  or characteristic  vector.  The  space Mx is  called  the  Ath proper  sub-
space  of  V. For matrices, we give the following  corresponding  definition. 
DEFINITION 2.7.  Let A be an « X ^ matrix whose elements belong to the field F. If 
"there exists A E F  and a nonzero vector a  E F""^ such that "
Aa  = Xa, 
(2.89) 
then A is called an eigenvalue of A and a is called an eigenvector of A corresponding to 
the eigenvalue A. 
• 
The connection between Definitions  2.6 and 2.7 is given in the following  result 
that the reader can verify  easily: let d^ E:  L{V,V)  and let A  be the matrix of ^  with 
respect to the basis {v^ . . .,"  v""}. Then  A is an eigenvalue  of d^ if and only if A is an "
eigenvalue of A. Also, a  G  V is an eigenvector of si  corresponding  to A if and only 
if  the  coordinate  representation  of  a  with  respect  to the basis  {v^ . . .,"  v""}",  a,  is  an 
eigenvector of A corresponding to A. 
We note that if a (or a)  is an eigenvector of si  (of A), then any nonzero  multiple 
of a  (of a)  is also an eigenvector of si  (of A). 
In the case of matrices, in place of (2.89), one can also consider the relationship 
aA  =  Xa, 
(2.90) 
where a  denotes a  1 X n row vector. In this context, a. in (2.89) and a  in (2.90)  are 
referred  to as a right eigenvector  and a left eigenvector,  respectively. Unless explic 
itly stated, we will have in mind a right eigenvector when using the term eigenvector 
of a matrix. 
Now let si  G L{V, V)  and let A denote the matrix of si  with respect to the basis 
{v^ ...,"  v""} in y. Then it is easily shown that A E  F  is an eigenvalue of d^ (and hence", 
of A) if diViA only if det {si-X3>)  =  0, orequivalently, if andonly if J^r(A-A/)  =  0. 
Characteristic  polynomial 
The above result enables  us to determine the eigenvalues  of d  (or A) in a sys 
tematic manner. So let us examine the  equation 
det{si-  X3)  =  0 
(2.91) 
or equivalently, the equation 
in terms of the parameter  A. We first rewrite (2.92) as 
det{A- 
\I)  = 0 
1(^11  -  A) 
(212 
Clll 
(Cl22  -  A) 
Clin 
^2n 
det(A-\I) 
= 
123 
CHAPTER  2: 
Response of 
Linear Systems 
(2.92) 
(2.93) 
^nl 
^n2 
"'"" "
(^nn  ~  A)| 
It is clear from  (2.62) that the expansion  of the determinant  (2.93) yields a polyno 
mial  in  A  of  degree  n. For  A  to be  an eigenvalue  of si  (or A)  it must  satisfy  (2.91) 
[or (2.92)]  and it must belong to F. Note that in general  we have no assurance  that 
the fzth-degree  polynomial  given by  (2.92) has any roots in F. There is, however,  a 
special class of fields for which this requirement is automatically  satisfied:  a field F 
is  said  to be algebraically  closed  if  for  every polynomial  p(X)  there is at least  one 
A G F  such that 
p{X)  =  0. 
(2.94) 
Any A that satisfies  (2.94) is said to be a root of the polynomial equation (2.94). 
In particular  the field of complex  numbers  is algebraically  closed,  whereas  the 
field of real numbers is not (e.g., consider the equation A^ +  1  =  0). There are other 
fields besides the field of complex numbers that are algebraically  closed.  However, 
since  we  will  not  require  these,  we  will  restrict  ourselves  to  the  field  of  complex 
numbers, C, whenever the algebraic closure property is required. When  considering 
results  that  are valid  for  a vector  space  over  an  arbitrary  field,  we  will,  as  before, 
make use of the symbol F, or make no reference  to F at all. 
Summarizing  the  above  discussion,  we  have  the  following  result.  Let  ^  G 
L(V, V) and let A be the matrix of ^  with respect to the basis {v^ . . .,"  v""} in V. Then "
(i) det (^  -  \3)  =  det (A -  A/) is a polynomial of degree n in the parameter A, i.e., 
there exist scalars ao, a i , . . ., a„,  depending on d^ (and therefore  on A)  such that 
det{d^ -  X3)  =  det (A  -  A/)  =  ao  +  o^i^  +  «2A^ +  •••  +  a^A'^ 
(2.95) 
[note that ao  =  det (si)  and an  =  (-l)'^]; (ii) the eigenvalues of ^  are precisely the 
roots of the equation 
det(M  -  A^)  =  det (A  -  A/)  =  ao  +  aiA  +  a2A^  +  • • • +  a^A'^  =  0; 
(2.96) 
and (iii) M^ has, at most, n distinct  eigenvalues. 
We call  (2.95) the characteristic  polynomial  of si  (or of A) and  call  (2.96)  the 
characteristic  equation  ofd 
(or of A). 
An important remark concerning  notation 
The above definition of characteristic polynomial is the one usually used in texts 
on linear algebra and matrix theory  (refer,  e.g., to some of the books on this  subject 
cited  at the  end  of this  chapter). An  alternative  to the  above  definition  is given  by 
the  expression 
a(A)  -  det(X3  -A)  =  det{XI  -  A). 
One of the reasons for using this convention is that this polynomial arises in a natural 
manner when solving systems of ordinary differential  equations by operator methods 
124 
Linear Systems 
[e.g., system  (LH)].  Since the reader  may  have many  occasions to consult texts on 
linear algebra and matrix theory, we will employ in this section  the definition  given 
in (2.95). Throughout  the remainder  of this book, however,  we will follow  the con 
vention used in linear  systems texts by utilizing the expression det (A/  -  A) for  the 
characteristic polynomial. We note that because of the relationship 
det (A  -  XI)  =  {-If 
det {XI -  AX 
either  definition  can  be  used  to  develop  the  results  considered  herein.  Note  that 
det (XI  -  A) is a monic polynomial, i.e., its leading coefficient  equals  1. 
From the fundamental  properties of polynomials over the field of complex num 
bers,  there  now  follows  the  next  important  result:  if  V  is  an  n-dimensional  vector 
space over C and if ^^i E  LiV, V),  then it is possible to write the characteristic  poly 
nomial of d^ in the  form 
det  (d  -  X3)  =  (Ai  -  A)^i(A2  -  A)^^.. .(^^  _  x)'^p, 
(2.97) 
where  Xu i  =  I,...,  p,  are  the  distinct  roots  of  (2.96)  (i.e..  A/ T^ XJ, if  /  T^ j).  In 
(2.97),  Mi is  called  the  algebraic  multiplicity  of  the  root  A/. The  m/  are  positive 
integers, and S f =i  ^/  =  ^• 
The reader should make note of the distinction between the concept of algebraic 
multiplicity of A^, given above, and the (geometric) multiplicity of an eigenvalue A/, 
given earlier. In general these need not be the same, as will be seen later. 
The Cayley-Hamilton  Theorem and  appUcations 
We now state and prove a result that is very important in linear systems theory. 
THEOREM  2.1. (CAYLEY-HAMILTON  THEOREM)  Every  square matrix  satisfies 
its characteristic equation. More specifically, if A is an n X n matrix and p(X)  = det (A  -
XI) is the characteristic polynomial of A, then p(A)  = O. 
Proof. Let the characteristic polynomial for A be p{X) = ao + aiX-\ 
"h a„A"" and let "
B{X) =  [bij(X)] be the classical adjoint of (A -  XI) (refer to Subsection 2.2G). Since the 
bij(X) are cofactors of the matrix A -  A/, they are polynomials in A of degree not more 
than n-l.  Thus, bij(X) =  Ptjo  + ptjiX  +  ••• + Ptj^n-DX^'-K  Letting Bj, =  Wtjk] for 
A:  =  0, 1,..., n -  1," we have B(X) =  BQ + XBi +  ""  + A^~^5„-i. By (2.71)", we have 
(A~XI)B(X)  =  [det(A-XI)]LThus,"(A-XI)[Bo  + XBi-h""'  + X''-^Bn-i]  =  (ao+Q:iA+ "
• • •  + anX^)I. Expanding the left-hand  side of this equation and equating like powers of 
A, we have -Bni  = oLnL AB^i  -  Bn-2 = 0Ln-\I,..., AB\  -  Bo = ail,  ABQ  =  a^I. 
"Premultiplying the above matrix equations by A"""," A""~\ ...", A, /, respectively, we have 
-A^Bn-i  -  Qf„A«,"A«5„-i-A""-i5„-2  =  a„-iA""-i",  . . . , A 2 B I - A 5O  =  a^AAB^  = 
aol.  Adding these matrix equations," we obtain O = a^I  + aiA  +  • • •  + anA""^  = p(A)", 
which was to be shown. 
• 
As  an immediate  consequence  of  the  Cayley-Hamilton  Theorem,  we have  the 
following  results: let A be an n  X n matrix  with characteristic  polynomial  given by 
"(2.96). Then (i) A^  -  (-l)""+i[«o/  + ^lA  +  • • • + an-iA""""-^];  and (ii) if/(A)  is any "
polynomial in A, then there exist  JSQ, jSi,..., /3„_i  G F  such that 
f(A)  =  /3o/ +  iSiA  +  • • • +  /3n-iA'~\ 
(2.98) 
Part  (i)  follows  froir  the  Cayley-Hamilton  Theorem  and  from  the  fact  that 
"an  =  (-1)"".  To prove part (ii)", let /(A) be any polynomial in A and let p(X)  denote 
the characteristic polynomial of A. From a result for polynomials (called the  division 
algorithm),  we know that there exist two unique polynomials g{X)  and r(A) such that 
fil)  = p{l)gil)  + r{l), 
(2.99) 
where the degree  of  r(A)  <n—l.  Now  since p(A)  =  O, we have that /(A)  =  r(A) 
and the result  follows. 
Finally,  we also note that if  ^  G L(V,V)  and if p(A)  denotes the  characteristic 
polynomial of ^,  then p ( ^)  =  ^. 
As  a  specific  application  of  the  Cayley-Hamilton  Theorem,  we  evaluate  the 
125 
CHAPTER  2: 
Response  of 
Linear  Systems 
q7 
[l  Ol 
matrix  A ^\  where  A  =  L 
^  .  Since  n  =  2,  we  assume,  in  view  of  (2.98), 
that  A^^  is  of  the  form  A^^  =  JSQ/ +  /3iA.  The characteristic  polynomial  of A  is 
p{X)  =  (1 — A) (2 — A)  and  the  eigenvalues  of A  are  Ai  =  1 and  X2 =  2. In the  present 
case  / ( A)  =  A^^  and r(A)  in (2.99)  is r(A)  =  /3o +/3iA.  To determine  /3o  and  /3i we 
use the fact  that p(Ai)  =  p{^2)  =  0 to conclude  that / ( A i)  =  r(Ai)  and  /(A2)  =  r(A2). 
Therefore,  we  have  that  /3o + / 3i  =  1^^ =  1  and  j8o +  2/3i  =  2^^.  Hence,  j8i  = 
2^^  -  1  and /3o =  2 -  2^^.  Therefore,  A^^ =  (2 -  2^^)/ +  (2^^ -  1)A,  or A^^  = 
1 
237-1 
0] 
237j-
The Cayley-Hamilton Theorem can also be used to express matrix-valued power 
series  (as  well  as  other  kinds  of  functions)  as  matrix  polynomials  of  degree  n— 1. 
Consider in particular the matrix exponential  e^^  defined  by 
^At  1 
k=0 
A^ 
t  G  {—a,a). 
(2.100) 
In view of the Cayley-Hamilton  Theorem, we can write 
/(A) 
^At 
i=0 
(2.101) 
In the following,  we present  a method  to determine the coefficients  ai{t)  in  (2.101) 
[or/3/in (2.98)]. 
In  accordance  with  (2.97),  let  p(A)  =  det{A -  XI)  =  Uf=i{^i  -  ^T'  be  the 
characteristic  polynomial  of A.  Also,  let /(A)  and  g(A)  be  two  analytic  functions. 
Now if 
/«(A,0=g«(A,0, 
/ =  0 , . . . , m , - - l , / = l , . . . , p, 
(2.102) 
where f^^\Xi)  =  ((i7/^^0(^)U=Aplf=i  m  = n, then /(A)  =  g{A).  To see this, we 
note that condition (2.102) written as (/  -  g)^^^ (A/)  =  0 impUes that /(A)  -  g{X)  has 
p(A)  as  a  factor,  i.e.,  /(A)  — g(A)  =  w(A)p(A)  for  some  analytic  function  w(A). 
From  the  Cayley-Hamilton  Theorem  we have  that  p{A)  =  O and  therefore  /(A) — 
g{A)  =  0. 
E X A M P LE  2.9.  Let  A 
and let /(A)  =  e^\f{X)  = e^\  and g{X) =  aiA+ 
OQ. The matrix A has an eigenvalue  A =  Ai =  A2 =  0 with multiplicity m\  =2.  Con 
ditions (2.102) are given by /(Ai)  = ^(Ai) =  1 and f^^\X\)  = g^^\h)  and imply that 
-1  1 
-1  1 
126 
Linear Systems 
ao  =  1  andai  =  f. Therefore, 
(^)  ^  ^^  + 
^A. ^  f^^^  ^ 
j  ^  [-«!  + «o 
a^ 
] l l ~t 
t 
In the final result of this  section we let F  =  C, we let A be an n X n matrix of 
A  G L(V; y), and we let det{A  -  A/)  -  det(A  -  \3)  be given by (2.97). It is read 
ily  verified  that  (i) det(A)  =  [ l ^ .i  ^J\ 
(ii) trace  (A)  =  X^^iau  =  Zy = i m^Ay, 
(iii)  if  B  is  any  matrix  similar  to A,  then  trace  (B)  =  trace  (A),  and  (iv)  if  /(A) 
denotes the polynomial /(A)  =  7o + 7i A H 
\- 7mA^, then the roots of the charac 
teristic polynomial  of /(A)  are / ( A i ) , . . ., /(A^), and J^^ [/(A)  -  A/]  =  [/(Ai)  -
Ar---[/(A;,)-An. 
K.  Direct  Sums  of Linear  Subspaces 
One of the important topics in matrix theory is the development of canonical  forms, 
including the lower (upper) triangular form, the block diagonal form, and the Jordan 
canonical  form  of matrices. Before  presenting  these, we need  to address  additional 
topics  which  are  of  interest  and  importance  to us  in  their  own  right.  One  of  these 
concerns direct sums of linear subspaces and linear transformations  defined  on such 
sums. 
Let  y  be a linear  space and let  W and  U be arbitrary  subsets  of  V. The sum  of 
sets  W and  U, denoted by  W  -\-  U, is the  set of  all vectors in  V that are of the  form 
w +  w, where  w  E. W  and  u  E  U.  If  in  particular,  W  and  U are  linear  subspaces 
of  y,  then  it is easily  shown  that  W  -\-  U is  also  a linear  subspace. If  W  and  U are 
linear  subspaces  of  V, and ifWnU 
=  {0} (the singleton  set consisting  of the null 
vector of V), then we say that W and  U are disjoint.  Note that this terminology is not 
consistent with that used in connection with sets. If W and  U are linear subspaces of 
y,  then  it is easily  verified  that  for  every  v  E  U  +  W,  there  exist  unique  elements 
w  ELW and  u E  U such that v  =  u -\-  wif  and only ifUHW 
= {0}. 
The preceding discussion is readily extended to any number of linear  subspaces 
of  y  and  gives rise to the following  concept.  Let  y i , . . .,  y^ be linear  subspaces of 
a vector  space  V. The  sum  yi  +  • • • +  y^ is said to be  a direct  sum  if for  each v G 
+ Vr there is a unique set v^ G  Vi, i  =  1,...,  r, such that v  =  v^ +  • • •  + v'*. 
Vi  -\ 
Henceforth,  we will denote the direct sum of  y i , . . .,  y^ by  yi  ©  • • • ©  y^. 
Now let y  be the direct sum of linear spaces  Vi  and  V2, i.e.,  y  =^ yi  © V2, and 
let V =  v^ -h v^ be the unique representation of v G  y,  where v^  G  yi  and v^  G  y2. 
We say that the projection  on  Vi  along  V2 is the transformation  defined  by 
2^(v)  =  v^ 
(2.103) 
We can easily verify  that (i) ^  G L(y  y), (ii) 31(2^)  -  Vu  and  (ii) J{{^)  =  V2. 
More generally, we can show that if 2P G L(V, V), then 2^ is a projection on 9l(SP) 
along X(&)  if and only if 2^2P  =  ?P^  =  ?P.  This gives rise to the following  concept: 
^  G L(V; V) is said to be idempotent  if 2P^  =  9^. 
We can also verify  easily that 2^ is a projection  on a linear subspace if and only 
if  (J^ -  2P) is  a projection.  If  in particular  2P is the projection  on  Vi  along  V2, then 
(3  -  ^)  is the projection  on V2 along  Vi. 
In view of the preceding results, there is no ambiguity in simply saying a trans 
formation  9^ is a projection  (rather than 9^ is a projection  on  V\  along  V2). We em-
phasize that if 2?^ is a projection,  then 
This is not necessarily the case for arbitrary linear transformations ST 
in general, 9l(2r) and J^CJ) need not be  disjoint. 
(2.104) 
L(K  V),  for 
127 
CHAPTER 2: 
Response of 
Linear Systems 
Next,  let  ST G L(V; y). A linear  subspace  W of  V is  said to be  invariant  under 
the  linear  transformation  ST  if  w G  W implies  that  ^w  G  W.  From  this  definition 
it follows  trivially  that  (i)  V is invariant  under  ST, (ii) {0} is invariant under  ST, (iii) 
"2/1(9"") is invariant under  ST", and (iv) ^{'J) 
is invariant under ST. 
Next,  let  y  be  a linear  space  that  is the  direct  sum  of two  linear  subspaces  W 
and  U. If W and  U are both invariant under a linear transformation  ST, then ST is said 
to be reduced by  W and  U. It is readily verified,  using definitions, that ST G L{V, V) 
is reduced  by  W  and  U if  and  only  if  S^ST  =  ST9^, where  9^ is the projection  on W 
along  U. 
Next we consider briefly the matrix representation of projections. To this end, let 
V  be an ^-dimensional  vector  space and let 9^ G L( V, V). It is easily verified  [using 
(2.104)] that if 9^ is a projection, then there exists a basis {v^ . . .,  v'^} for  V such that 
the matrix P  of 9^ with respect to this basis is of the  form 
1 
0 
0 
1 
0 
0 
0 
0 
1 
(2.105) 
> r 
0 
0 
0 
0 
0 
0 
where r  =  dim 91(9^). 
We conclude with the following  interesting result. Let V be a  finite-dimensional 
vector  space  and let ^  G L{V, V).  If  W is a/^-dimensional  invariant  subspace  of V 
and ifV  =  W®U, 
then there exists a basis for  V such that the matrix A of ^^i with 
respect to this basis is of the  form 
A  = 
0 
M2 
122 
(2.106) 
where  An  is  a. p  X  p  matrix  and  the remaining  submatrices  are of  appropriate  di 
mension. 
The  canonical  form  (2.106)  will  be  used  in  Chapter  3 in  developing  standard 
forms  for uncontrollable  and unobservable  systems. 
L.  Some  Canonical  Forms  of  Matrices 
In this  subsection  we investigate under  which conditions  a linear transformation  of 
a  vector  space  into  itself  can  be  represented  by  (i)  a  diagonal  matrix,  (ii)  a  block 
128 
Linear Systems 
diagonal matrix, (iii) a triangular matrix, and (iv) a companion matrix. We will also 
investigate when a linear transformation  cannot be represented by a diagonal matrix. 
Throughout  this  subsection,  V  denotes  an  fz-dimensional  vector  space  over  a 
field  F. 
Diagonal  form 
We begin  with the following  fundamental  result. Let  Ai,..., A^ be the  distinct 
eigenvalues  of  a linear  transformation  ^  G  L(V, V)  and  let  v^  7^ 0 , . . .,  v^  7^ 0  be 
corresponding  eigenvectors  of si.  Then it is easily  shown that the set {v^ . . .,  v^} is 
linearly independent. We note that if in particular ^  has n distinct eigenvalues, then 
the  corresponding  n  eigenvectors  span  the  linear  space  and,  as  such,  form  a  basis 
forV. 
The  above  gives  immediate  rise to the next  important  result.  Let  si  E  L(V,  V) 
and assume that the characteristic polynomial of si  has n distinct roots, so that 
det  (si  -  X3)  =  (Ai  -  A)(A2 -  A)- • -(A^ -  A), 
(2.107) 
where Ai,..., A„ are distinct eigenvalues. Then there exists a basis {v^ ...,  v'^} of V 
such that v^ is an eigenvector corresponding  to A/ for  /  =  1,...,  n. The matrix A  of 
^  with respect to the basis {v^ . . .,"  v""} is "
A2 
A  = 
[Ai 
0 
0 
Xn 
=  diag{Ki,...,\n\ 
(2.108) 
In  the  same  spirit  as  above,  we  can  also  easily  establish  the  next  result.  Let 
si  G L{V, V), and let A be the matrix of 6?^ with respect to the basis {v^ ...,"  v""}. If the "
characteristic polynomial det {si — \3)  =  ao + ^i A H 
"h a^A"" has n distinct roots", 
Ai,...,  \n,  then A is similar to the matrix A of ^4 with respect to the basis {v^ ...,  v^}, 
where A is given in (2.108). In this case there exists a nonsingular matrix P such that 
A  =  P'^AP. 
The  matrix  P  is  the  matrix  of  the  basis  {v^...,"v""}  with  respect  to  the  basis "
{v^ . . .,"  v""}", and  P~^  is the matrix  of the basis {v^ . . .,  v^} with respect to the basis 
{v^ . . .,"  v""}. The matrix P can be constructed by letting its columns be  eigenvectors "
of A corresponding  to Ai,..., A„, respectively; that is, 
P  =  [^1  ,^2^,^,^^«]^ 
(2.109) 
where TT^ . . .,  77^ are eigenvectors of A corresponding to the eigenvalues Ai,..., A„, 
respectively  (verify  this). 
The similarity transformation  P given in (2.109) is called a modal  matrix.  If the 
conditions  of the  above result  are  satisfied  and if,  in particular,  (2.108)  holds,  then 
we say that the matrix A  has been  diagonalized. 
As  a specific  case, let  V be a two-dimensional  vector  space over the real  num 
bers,  let  si  G L{V, V), and  let {v^ v^} be  a basis  for  V.  Suppose  the matrix A of ^4 
with respect  to this basis is given by  A  = 
\-2 
. 
4l 
.  . The characteristic  polynomial 
of ^  is p{X)  =  det(si  -  A^)  =  det{A  -  \I)  =  A^ + X-6  =  (\-  2)(A +  3), and 
the eigenvalues  of 62^ are A1 =  2 and A2 =  - 3. 
Let  77 =  (r/i, 772)^ denote  the  coordinate  representation  of  v  G V witli  respect  to 
tlie  basis  {v  ,v  }.  To  find  eigenvectors  corresponding  to  A/,/  = 1 , 2, 
we  solve  the 
=  (1,1)^  and 
system  of  equations  (A — A/) 77 =  O.  An  easy  computation  yields 77^ 
77^ =  (4, — 1)  as  eigenvectors  corresponding  to  Ai  and  A2, respectively.  The  diagonal 
129 
CHAPTER  2: 
Response of 
Linear  Systems 
matrix  A  given  in  (2.108)  is  A 
(2.109)  and  its inverse  P~^  are 
0 
0 
The  matrix  P  given  in 
"[n\n"" "
'1 
1 
"4"" "
-1 
5 
1  _ 
P-
""".2 "
.2 
".8"" "
- .2 
As  expected,  we  have  P  AP 
"""2 "
0 
"0"" "
3 
-
= 
"""Ai "
0 
0' 
X2_ 
•  By 
By  (2.81),  the  basis 
{ v\  v^} C y  with respect to which A  represents 
sz/ is given by  v^  =  Xj=i Pji ^^  = 
772)^ is the coordinate  representa-
(r]i 
P~^77  is the  coordinate  representation 
tion  of  V with  respect  to  { v\  v^},  then 77 
of  V with  respect  to  { v\  v^}.  The  vectors  v\  v^  are  of  course  eigenvectors  of  ^ 
corresponding to Ai and A2, respectively. 
When  the  algebraic  multiplicity  of  one  or  more  of  the  eigenvalues  of  a  linear 
transformation  is  greater  than  one,  then  the  linear  transformation  is  said  to  have 
repeated  eigenvalues.  In  this  case  it  is  not  always  possible  to  represent  the  lin 
ear  transformation  by  a  diagonal  matrix.  However,  from  the  preceding  results  of 
this  section  it  should  be  clear  that  a  linear  transformation  with  repeated  eigenval 
ues  can  be  represented  by  a diagonal  matrix  if  the  number  of  linearly  independent 
eigenvectors  corresponding  to  any  eigenvalue  is  the  same  as  the  algebraic  multi 
plicity  of  the  eigenvalue.  We  consider  two  specific  cases  to  shed  additional  light 
on this. 
First, we consider the matrix 
1 
0 
0 
3 
4 
3 
-2 
-2 
-1 
with  characteristic  equation  det{A  — XI)  =  (1—A)^(2  — A ) =0  and  eigenvalues 
Ai  =  1 and  A2 =  2.  The  algebraic  multiplicity  of  Ai  is  two.  Corresponding  to  Ai 
we can find two linearly  independent  eigenvectors  (1,2,3)^  and  (1,0,0)^,  and cor 
responding to A2 we have an eigenvector  (1,1,1)^. Letting P denote a modal matrix, 
we obtain 
1 
2 
3 
1 
0 
0 
1 
1 
1 
, 
P-'  = 
0 
1 
0 
— 1 
-2 
3 
1 
1 
-2 
and 
A = P-^AP  = 
"""1  0 "
0 
1 
0  0 
"0"" "
0 
2 
In this example, dim ^^  =  2, which happens to be the same as the algebraic multi 
plicity of Ai. For this reason, we were able to diagonalize A. 
130 
Linear Systems 
As a second example, consider the matrix 
2 
0 
0 
1 
2 
0 
-2 
-1 
1 
with  characteristic  equation  det(A  — XI)  =  (1—A)(2  — A)^  =  0  and  eigenvalues 
Ai  =  1 and  X2 =  2. The  algebraic  multiplicity  of  X2 is two  and  an eigenvector  cor 
responding to Ai is  (1,1,1)^. It is easily verified  that any eigenvector  corresponding 
to A2 must be of the form  (vi, 0,0), Vi 7^ 0. We see that dim ^^  =  1, and thus, we 
are  not  able  to  determine  a basis  for  the  three-dimensional  vector  space  V,  which 
consists of eigenvectors. Consequently, we are unable to diagonalize A. 
Block diagonal  form 
When  a matrix  cannot  be  diagonalized,  we  seek,  for  practical  reasons,  to rep 
resent  a  linear  trasformation  by  a  matrix  that  is  as  nearly  diagonal  as  possible. 
The  next  result  provides  the  basis  of  representing  linear  transformations  by  such 
matrices,  called  block  diagonal  matrices.  In  Subsection  O  of  this  section  we  will 
"consider  the  ""simplest""  type  of block  diagonal  matrix",  called  the Jordan  canonical 
form. 
We let V  be an n-dimensional  vector  space and we let ^  G L(y, V).  IfV  is the 
direct sum of p linear subspaces, Vi,..., Vp, which are invariant under ^,  then it can 
be readily shown that there exists a basis for V such that the matrix representation  for 
^ 
is in the block diagonal form given by 
Ui  I 
0 
(2.110) 
A  = 
Ai 
0 
Moreover, A/ is a matrix representation  of s^i, the restriction  of ^ 
Also, 
to Vi, / =  1,..., p. 
p 
det[A)=Wdet{A^). 
i=\ 
(2.111) 
From the above it is clear that to carry out a block diagonalization  of a matrix A, 
we need to find an appropriate  set of invariant  subspaces  of V, and furthermore,  we 
need to find a simple matrix representation  on each of these subspaces. 
As a specific  case for the above, let V be an n-dimensional  vector space. If ^  G 
L(y, y)  has n distinct eigenvalues Ai,..., A^, and if we let ^-  =  { v : (^  — Aj J^) v  = 
0}, 7 =  1,..., n, then jVj is an invariant linear subspace under ^  and V =  ^  0  • • • 0 
JVn. For any v G  JVJ, we have s^v  =  AyV, and hence, s^jV  =  A v for  v G  JVJ. A  basis 
for  ^j 
is  represented 
by the matrix  Xj  (in this case,  simply  a scalar). With respect to a basis of n linearly 
independent eigenvectors, { v \ . . .,  v^},  ^ 
is  any  nonzero  Vj G ^j.  Thus,  with  respect  to this basis,  ^j 
is represented by (2.108). 
Triangular  form 
In addition to the diagonal form and the  block diagonal form, there are many other 
useful  forms  of  matrices  to  represent  linear  transformations  on  finite-dimensional 
vector spaces. One of these canonical forms  involves triangular matrices with one of 
131 
CHAPTER  2: 
Response of 
Linear Systems 
the two forms given by 
an 
0 
<3l2 
Cl22 
ai3 
(323 
0 
0 
0 
0 
0 
0 
. 
• 
. 
. 
ain 
Clin 
^n-l,n 
^nn 
or 
an 
Cl2\ 
I 
<^n-l,l 
^nl 
0 
a22 
0 
0 
Cln-1,2 
^n2 
Cln-1,3 
UnS 
'  • ' 
"0  "" "
0 
0 
0 
(2.112) 
We call the matrix on the left  an upper  triangular  matrix  and the matrix on the right 
a lower  triangular  matrix. 
Now let V be an n-dimensional vector space over C, and let ^  G L(V,V)At  can 
be  shown that there exists  a basis  for  V such that ^  is represented  by  an upper  (or 
by a lower) triangular matrix with respect to that basis. 
We note that if A is in triangular form,  then 
det(A  -  A/)  =  (an  -  A)(a22 -  A)- • -(ann  -  A), 
(2.113) 
i.e., the diagonal elements of A are in this case the eigenvalues of A. 
Companion  form 
We  conclude  this  subsection  by  considering  a  canonical  form  for  real  square 
matrices that arises frequently  in systems theory, called companion form.  As a mat 
ter of fact,  a given  matrix  A  ^  R^^^  can be transformed  via  appropriate  similarity 
transformations  into four  different  forms  of this type given by 
"""0 "
/ 
x' 
0  ' 
/ 
0  ' 
"""x "
/ 
"""x "
X 
"""0 "
X 
x' 
X 
/ 
X 
' 
-an-i,  determined  by  (-iydet(A 
where  the  rows  or  columns  denoted  by  (XX)  are  made  up  of  the  coefficients 
-  A/)  =  det(XI  -  A)  =  A'^  + 
-ao,  —ai,..., 
"an-iX""""-^ +  • • • +  ao"," where /  G 7^(""-i)x(""-i)",  and where the 0 denotes  an  (n  -  1)-
dimensional  column  or  row  vector.  For  example,  the  matrix  on  the  left,  which  is 
perhaps  the  most  commonly  used  companion  form,  and  which  henceforth  we  will 
identify  as A^, is given by 
Ac  = 
0 
0 
1 
0 
.. 
0 
1 
0 
-ao 
0 
— Ui 
0 
- ( 32 
.. 
• 
•  • 
0 
0 
1 
""" f l n -l "
In the following,  we confine  our discussion to this matrix. Similar treatments  apply 
to the other three companion  forms. 
"Given  A  G  R""-^""-",  it  can  be  shown  that  there  exists  a similarity  transformation 
P that transforms  A to the companion  form  Ac  given  above if  and only  if there  ex 
ists  a vector  b  EL  R^  such that the matrix %  =  [b, Ab,...,  A^~^b]  is of full  rank  n. 
Furthermore, P is given by 
n -l 
qA 
P  = 
[qA n-\ 
^^^ 
Linear Systems 
where q is the nth row of ^ -^  and 
>.  _  p - i / ip 
A  matrix A  for  which  such  a vector  Z?  exists  is  called  cyclic.  It  can  be  shown  that 
A  is  cyclic  if  and  only  if  the  geometric  multiplicity  of  each  of  its  n eigenvalues  is 
one,  or  equivalently,  if  and  only  if  the  n  eigenvalues  of A  are  exactly  the  roots  of 
its minimal polynomial  (refer  to Subsections M and O, which follow). Finally, if A/ 
is  an  eigenvalue  of  Ac  (or  of A),  then  it  can  be  verified  that  (1, A/,...,  Ap^)^  is  a 
corresponding  eigenvector. 
M.  Minimal  Polynomials 
One of our goals in this  section is to develop the Jordan canonical form.  To accom 
plish this we first need to introduce  and  study minimal polynomials  (which  will be 
accomplished  in  the  present  subsection)  and  nilpotent  operators  (to be  considered 
in  Subsection  N).  Throughout  this  subsection,  V  denotes  an  n-dimensional  vector 
space. 
For purposes  of motivation, consider the matrix 
A  = 
1 
0 
0 
3 
4 
3 
-2 
-2 
-1 
The  characteristic  polynomial  of A  is p(\)  =  (1  -  A)^(2 -  A), and  we know  from 
the Cayley-Hamilton  Theorem  that 
p(A)  =  O. 
(2.114) 
Now let us consider the polynomial  m(A)  =  (1 -  A)(2 -  A)  =  2 -  3A +  A^. Then 
m(A)  =  2/  -  3A +  A^  -  O. 
(2.115) 
Thus, matrix A satisfies  (2.115), which is of lower degree than  (2.114), the charac 
teristic equation of A. 
More generally, it can be shown that for annX  n matrix A there exists a unique 
polynomial  m(A)  such  that  (i)  m(A)  =  O,  (ii)  m(A)  is  monic  (i.e.,  if  m  is  an  nth-
degree polynomial  in A," then the coefficient  of A"" is unity)", and  (iii) if  m\X)  is any 
other polynomial  such  that  m\A)  =  O, then  the degree  of  m(A) is less  or equal  to 
the  degree  of  m'(A)  [i.e.,  m(A)  is  of  the  lowest  degree  such  that  m(A)  =  O].  The 
polynomial  m(A) is called the minimal  polynomial  of  A. 
In the remainder of this section we let p(X)  denote the characteristic  polynomial 
of an n X n matrix A and we let m(A) denote the minimal polynomial  of A. In  what 
follows,  we develop an explicit form  for the minimal polynomial  of A that makes it 
possible to determine it  systematically. 
Let  /(A)  be any polynomial  such that  /(A)  =  O (e.g., the characteristic  poly 
nomial). Then it is easily  shown  that  m(A) divides  /(A)  [i.e., there is a polynomial 
^(A) such that /(A)  =  ^(A)m(A)]. In particular, the minimal polynomial of A, m(A), 
divides  the  characteristic  polynomial  of  A, p(X).  Also,  it  can  be  shown  that  p(X) 
divides [m(A)]^ 
133 
CHAPTER  2: 
Response of 
Linear Systems 
Next, let p(X)  be given by 
p(X)  =  (Ai  -  ArHA2  -  Ar  • • -(A^ -  A r^ 
(2.116) 
where m i , . . .,  m^^ are the algebraic multiplicities of the distinct eigenvalues  Ai,..., 
\p  of A,  respectively. It can be shown that 
m(A)  =  (A -  AO^KA -  A2)^^---(A  -  A . r^ 
(2.117) 
where  1 <  /i/  <  mt, i  =  \,..., 
p. 
The only unknowns  left  to determine the minimal polynomial  of A are  )Lti,..., 
fjip in (2.117). These can be determined in several ways. 
The  next  result  is  a  direct  consequence  of  (2.86).  Let  A  be  similar  to A  and 
let  m(A) be the minimal  polynomial  of A. Then  m(A)  =  m(A). This result,  in  turn, 
justifies  the following  definition.  Let d^  G L{V, V).  The minimal polynomial  of si  is 
the minimal polynomial of any matrix A that represents  M. 
To develop the Jordan canonical form  (for  linear transformations  with  repeated 
eigenvalues), we need to consider several additional preliminary results that are im 
portant in their own right. 
Let ^  G L(V; V)  and let /(A)  be any polynomial in A. Let M'f  =  {v : f(A)v  = 
0}. It can be shown that Xf  is an invariant linear subspace of V under ^.  In particular 
let Ai,..., Ap be the distinct eigenvalues  of ^4 G L(V, V)  and for  j  =  1,..., p,  and 
for any positive integer q, let 
Xj  =  {v : (^  -  Xj^)^v  = 0}. 
(2.118) 
In view  of the  above result,  it follows  that Xj  is  an invariant  linear  subspace  of V 
under  ^. 
Next,  let  ^  G  L(V, V),  let  Vi  and  V2 be  Hnear  subspaces  of  V  such  that  V  = 
Vi  0  V2, and let ^1  be the restriction  of 6?^ to Vi. Let /(A)  be any polynomial in A. 
It can be shown that if si  is reduced by  Vi  and  V2 then, for all v^  G  V\,  f(sii)v^  = 
f(d)vK 
Next,  let  y  be  a  vector  space  over  ^  and  let  M  G  L(V,V).  Let  m(A)  be  the 
minimal  polynomial  of  ^  as  given  in  (2.117). Let  ^(A)  =  (A -  Ai)^i,  let  /z(A)  = 
(A -  A2)^2.. .(A -  Ap)^/' if/?  >  2, and let /z(A)  =  1 if p  =  1. Let 6^1  be the restric 
tion of si  to jNff S i.e., div  =  siv  for  all v G >f/'\  Let J/t  =  {v G  V : h(si)v  = 0}. 
Using the preceding results, we can show that (i) V  =  X{^^  ®M,  and (ii) (A -  AO^^ 
is the minimal polynomial of  ^ 1. 
These  make  it  possible  to  prove  the  next  result,  which  is  called  the  primary 
decomposition  theorem for  linear  transformations  and which we state next. 
Let  V be  an  n-dimensional  vector  space  over  C,  let  Ai,..., A^ be  the  distinct 
L{V, V), let the characteristic  and minimal polynomials of ^  be 
eigenvalues ofsi^ 
k^p 
and 
m(A)  =  (A -  AO^^ • • -(A -  A.)^^ 
respectively.  Let 
Vi  =  {v : 
A^-i)A^'v  =  0}, 
i  = 
l...,p. 
(2.119) 
Then  (i)  Vi, i  =  1,...,/?  are  invariant  linear  subspaces  of  V  under  si,  (ii)  V  = 
Vi  ©  • • •  0  Vp,  (iii)  (A -  A/)^'  is  the  minimal  polynomial  of  sit,  where  ^i  is  the 
restriction  of si  to Vi, and (iv) dim Vi  =  mi, i  =  \,..., 
p. 
134 
Linear Systems 
The above result  shows that we can  always present  ^  G L(y, V)  by  a matrix in 
block  diagonal  form,  where  the  number  of  diagonal  blocks  is  equal  to  the  number 
of distinct  eigenvalues  of  ^.  We will next consider  a convenient  representation  for 
each of the diagonal  submatrices A/. It may turn out that one or more of the  subma-
trices A/ will be diagonal.  The next result tells us  specifically  when  ^  G L(y, V)  is 
representable by a diagonal matrix. 
Let  V  be  an  n-dimensional  vector  space  over  C  and  let  ^  G L(V,V).  Let 
Ai,...,Ap,p  <  n,  be  the  distinct  eigenvalues  of  ^.  Then  there  exists  a  basis  for 
V  such that the matrix A of ^  with respect to this basis is diagonal if and only if the 
minimal polynomial for ^ 
is of the  form 
m(A)  =  (A-Ai)(A-A2)---(A-Ap). 
(2.120) 
N.  Nilpotent Operators 
Let us now proceed by considering  a representation  for  each  of the ^-  G L(Vi-, Vi) in 
the primary  decomposition  theorem presented in Subsection M so that the block diag 
onal  matrix  representation  of  ^  G L(y, V)  is  as  simple  as possible.  To  accomplish 
this, we need to define  and examine nilpotent operators. 
Let ^  G L(y, V).  Then ^ 
is said to be nilpotent  if there exists an integer  q>Q 
such  that  ^^  =  ^.  A  nilpotent  operator  is  said  to  be  of  index  q  if  ^^  =  ^  but 
Recall that the primary decomposition theorem enables us to write V =  Vi 0  • • • 0 
is nilpotent  on  Vi. If  we  let 
then ^-  =  A /^  + JVi. Now A /^  is clearly represented by a diagonal 
Vp. Furthermore,  the linear  transformation  (^-  — Xi/) 
JVi = £^i — Xi/, 
matrix. However, the transformation  jVi forces  the matrix representation  of ^-  to be 
in general nondiagonal. Therefore, the next task is to seek a simple representation of 
the nilpotent operator jVi. 
In the next few  results, which are concerned  with properties  of nilpotent  opera 
tors, we drop the subscript / for  convenience. 
Let JV  G L(W, W ),  where W is an m-dimensional  vector  space. It can be  shown 
is  a nilpotent  linear  transformation  of  index  q and  if  w G W is  such  that 
that  if  ^ 
JV^~^W  7^ 0, then the vectors w, JVw^...,  JV^~^w  in W are linearly  independent. 
Next, we examine the matrix representation  of nilpotent  transformations. 
Let  W be  a  ^-dimensional  vector  space  and  let  JV  G L(W,W)  be  nilpotent  of 
index q. Let w^ G W be such that JV^~^w^  ^  0. It can be shown that the matrix N  of 
^  with respect to the basis 
.,Mp}^m^^ 
A'l-^w^,. 
is  [J^i-
{^^ 
•VO, 
N-
0 
0 
0 
0 
1 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
0 
... 
... 
... 
... 
0 
0 
0 
0 
0 
0 
1 
0 
(2.121) 
The  above result  characterizes  the matrix  representation  of  a nilpotent  linear trans 
formation  of index ^ on a ^-dimensional  vector  space. The next task is to  determine 
the representation  of a nilpotent  operator of index  7 on a vector  space of  dimension 
m,  where  y  <  m.  It  is  easily  shown  that  we  can  dismiss  the  case  y  >  m,  i.e.,  if 
^  G L(W, W)  is nilpotent of index  7, where dim W  = m, then  y<m. 
Now  let  W be  an  m-dimensional  vector  space,  let J{  G  L(W,W),  let  y  be  any 
positive integer, and let 
W^  =  {w:  J^w  =  0}, dim Wi  =  h 
W2  =  {w\  M^w  =  0}, dim W2  =  h 
Wy  =  {w:  X^w  =  0}, dim W^  =  L. 
(2.122) 
135 
CHAPTER  2: 
Response of 
Linear Systems 
Also,  for  any  /  such  that  1 <  /  <  7,  let  {w^,...,  w^}  be  a  basis  for  W  such  that 
{w^,...,  w^'}  is  a basis  for  Wi.  It  can  be  shown  that  (i)  Wi  C  W2 C  ---  C  Wy  and 
(ii) {w^,...,  w^'-i, Xw^^^^,...,  Xw^^+^} is a linearly independent  set of vectors in  Wi. 
The next result, which is the principal result of this subsection, is a consequence 
of the above results. 
Let W be an m-dimensional vector space over C and let X  ^  L(W, W) be nilpo-
tent  of  index  7.  Let  Wi  =  {w  : J^w  =  0},..  .,Wy  =  {w  : Ji^w  =  0}, and  let  //  = 
dim Wi, i  =  1,..., 7. Then there exists  a basis in  W such that the matrix A^ of >r is 
of block diagonal  form. 
A^i 
A^  -
0 
Nr 
0 
0 
0 
0 
1 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
0 
. 
. 
. 
. 
.  0 
.  0 
.  0 
.  0 
0 
0 
1 
0 
(2.123) 
(2.124) 
where 
Ni  = 
/  =  1,...,  r, where r  == /i, Ni is a ki X ki matrix,  1 < fc^ <  7, and  ki is determined 
in the following  manner: there are 
ly  -  ly_i 
2li  -  li+i -  li-i 
2 / 1 - /2 
7 X7  matrices, 
i X / matrices, 
1 x1  matrices. 
/  =  2 , . . . , 7-  \, 
(2.125) 
The basis for W consists of strings of vectors of the form M^^ ^w^,...,  w^ J^^^  iy^;2^ 
..  .,w' \  . . .,K^'  ^W^ 
...,W\ 
O.  The Jordan  Canonical  Form 
The results of the preceding  three  subsections  can be used to prove the next  result, 
which yields the Jordan canonical form  of matrices. 
Let  Y  be  an  /i-dimensional  vector  space  over  C  and  let  ^  G  L(V; V). Let  the 
characteristic polynomial of ^4 be p{K)  =  (Ai -  X)^^ • • -(A^ -  A)^^ and let the mini 
mal polynomial of d  be m(A)  == (A -  Ai)^i • • -(A -  A^,)^^, where Ai,..., Ap are the 
distinct eigenvalues of 6^. Let Vi  =  {v G  V  : (si-Ai3)^^v  =  0}. Then (i)  Vu...,Vp 
are invariant subspaces of y under 5i; (ii) y  == y i © - - - © ^ ^; (iii)dim V/  =  m/, /  = 
\,...,  p\  and (iv) there exists a basis for  V such that the matrix Aof  d^ with respect 
136 
Linear Systems 
to this basis is of the  form 
"""Ai "
0 
0  A2 
• 
• 
• 
• 
0 
0 
A  = 
0 
0 
• 
•  Ap 
(2.126) 
where A,- is an m,  X m,- matrix of the  form 
Ai  -  A//  +  Ni 
(2.127) 
and  where Ni  is the  matrix  of  the nilpotent  operator  {sit  -  A/^)  of index  [xi on V/ 
given by (2.123) and (2.124). 
Parts (i) to (iii) of the above result are restatements of the primary  decomposition 
theorem. From this theorem we also know that (A -  A/)^' is the minimal  polynomial 
of sii,  the restriction of d^ to Vi. Hence, if we let Mi =  sii-Xi3, 
operator of index  />t/ on Vi. We are thus able to represent Xi  as shown in (2.124). 
then J^T/ is a nilpotent 
A little extra work  shows that the representation  of ^  G L(V; V) by a matrix  A 
of the form  given in (2.126)  and (2.127) is unique except for the order in which  the 
block diagonals  Ai,., 
The matrix A  of ^ 
canonical form  ofd. 
,Ap  appear in A. 
G  L(K  V)  given by (2.126) and (2.127) is called the  Jordan 
An  example 
We conclude this section by considering  a specific  case. 
We let  V  =  R^,  we  let {e^,...,  ^^} be the natural  basis  for  V,  and  we  let, 
L(V, V) be represented by the matrix 
A  -
1 
0 
2 
2 
0 
0 
1 
0 
1 
1 
0 
0 
0 
-1 
-1 
0 
2 
-1 
0 
0 
0 
1 
0 
-1 
2 
0 
0 
1 
1 
0 
-1 
1 
1 
0 
2 
3 
0 
-6 
3 
0 
1 
4 
0 
0 
0 
0 
0 
0 
1 
with respect to {e^,...,  e^}. We wish to determine the matrix A that represents si  in 
the Jordan canonical  form. 
We  first  determine  that  the  characteristic  polynomial  of  si  is  det (A  -  A/)  = 
det(si  -  \3)  =  (1 -  A)^. This indicates that Ai  =  1 is the only distinct  eigenvalue 
of d,  having  algebraic  multiplicity  m\  =  7. To find the minimal polynomial  of  si, 
we let >r  =  ^  -  Ai^, where 3  is the identity operator in L{V,V).  The representation 
of Ji  with respect to the natural basis is 
N  =  A-I 
= 
-2 
0 
2 
-2 
0 
0 
-1 
0 
0 
1 
0 
0 
0 
-1 
-1 
0 
1 
-1 
0 
0 
0 
1 
0 
-1 
1 
0 
0 
1 
1 
0 
-1 
1 
0 
0 
2 
3 
0 
-6 
3 
0 
0 
4 
0 
0 
0 
0 
0 
0 
0 
137 
CHAPTER 2: 
Response of 
Linear Systems 
The minimal polynomial will be of the form m(A)  =  (X-iyK  We need to determine 
the smallest  vi  such that m(A  —  A/)  =  m(N)  =  O. We first obtain 
'2  _ 
"""0 "
0 
0 
0 
0 
0 
0 
-1 
0 
1 
-1 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
3 
0 
-3 
3 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
Next,  we  obtain  N^  =  0,  and  therefore,  z^i  =  3  and  Jvf  is  a  nilpotent  operator 
of  index  3.  We  see  that  V  =  J{f  [refer  to  (2.118)  for  the  notation  >ff].  We  will 
now  apply  the  results  of  Subsection  F  to  obtain  a  representation  for  M  in  this 
space. 
We  let  Wi  =  {v  : Xv  =  0}, W2  =  {v  : J^^v  =  0}, and  W3  =  {v  : J{\  = 0}, 
and  we  observe  that  A^  has  three  linearly  independent  rows.  This  means  that  the 
rank  of  jf  is  3,  and  therefore,  dim(Wi)  =  h  =  4.  Similarly,  the  rank  of  X^  is  1 
(since  N^  has  one  linearly  independent  row),  and  so dim (^2)  =  h  =  6.  Clearly, 
dim(W3)  =  h  =  1. We conclude  that }(  will have  a representation  N  of the  form 
(2.123) with r  =  A. Each of the Nt will be of the form (2,124). There will be h-h  = 
1 (3 X 3) matrix, Ik  - h -h  =  1 (2 X 2) matrix,  and 2/i  -  fc  -  2 (1 X 1) matri 
ces  [see  (2.125)]. Hence, there is a basis  for  V such that >f  may be represented  by 
the matrix 
0  0  0  0 
0  10 
0  0  10 
0  0  0 
0  0  0  0  0  0  0 
7 V = |0 
0 00 
1 00 
0  0  0  0  0  0  0 
0  0  0  0  0  0  0 
0  0  0  0  0  0  0 
The corresponding basis will consist of strings of vectors of the form X'^v^,  Xv^,  v^ 
>fv^, v^, v^, v^. 
We  will  represent  the  vectors  v^v^, v-^,  and  v^  by  17^17^,17^,  and  iq^,  their 
coordinate  representations,  respectively,  with  respect  to  the  natural  basis  {e^,  e^, 
e^,  e^,  e^,  e^,  e^}  in  V.  We  begin  by  choosing  v^  G  W3  such  that  v^  ^  W2, 
i.e.,  we  determine  a  iq^  such  that  N^rj^  =  0  but  N^r]^  9^ 0.  The  vector  TJ^ = 
(0, 1, 0, 0, 0, 0, 0)^  will  do. We  see  that  Nr]^  =  (0, 0, 1, 0, 0, 0, - 1 )^  and  A^^^^  = 
( - 1,  0, 1, - 1,  0, 0, 0)^. Hence, Jiv^  E  W2 but Xv^  ^  Wi  and  X^v^  G  Wj. We  see 
there  will  be  only  one  string  of  length  3,  and  therefore  we  choose  next  v^  E  W2 
such that v^  ^W\.  Also, the pair {Jfv^  v^} must be linearly independent. The vector 
T/2  - 
(1, 0, 0, 0, 0, 0, 0)^  will  do.  Next,  we  have  Nr]^  -  (-2,  0, 2, - 2, 0, 0, - 1 ) ^, 
and therefore,  Xv'^  E  Wi.  We complete the basis for  V by  selecting  two more vec 
tors, v^," v""^  E  Wi",  such that {Ji^v^, M'v^, v^, v^} are linearly independent. The vectors 
7]^ =  (0, 0, - 1 , - 2,  1, 0, 0)^ and  ry^  =  (1, 3, 1, 0, 0, 1, 0)^ will do. 
It now follows  that the matrix P  =  [N^rj^, Nrj^,  17^ Nrj'^, 17^, 17^," r]""^] is the ma "
trix of the new basis with respect to the natural basis. The reader can readily  verify 
138 
Linear Systems 
thatA^  =  P~^NP,whQYQ 
P  = 
1 
0 
1 
1 
0 
0 
0 
0 
0 
1 
0 
0 
0 
-1 
0 
1 
0 
0 
0 
0 
0 
-2 
0 
2 
-2 
0 
0 
-1 
1 
0 
0 
0 
0 
0 
0 
0 
0 
-1 
-2 
1 
0 
0 
1 
3 
1 
0 
0 
1 
0 
,p-'  = 
0 
0 
0 
0 
1 
0 
0 
0 
0 
1 
0 
0 
0 
0 
2 
1 
0 
-1 
0 
0 
0 
1 
1 
0 
-1 
-1 
0 
0 
4 
3 
0 
-3 
-2 
1 
0 
-2 
-1 
-3 
1 
-1 
0 
1 
2 
0 
0 
-1 
0 
0 
0 
Finally, the Jordan canonical form  for A  is now given by A  =  A^  +  /  (recalling 
that  the matrix  representation  for  ^  is the  same  for  any basis  in  V). Therefore,  we 
have 
A  = 
1 
0 
0 
0 
0 
0 
0 
1 
1 
0 
0 
0 
0 
0 
0 :0 
1  i  0 
1  1  0 
o! 1 
O 'O 
0  0 
0  0 
0 
0 
0 
1 
1 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
0 
0 
1 
It is easily verified  that A  =  P  ^AP.  In general it is more convenient  as a check to 
show that PA  =  AP. 
2.3 
LINEAR HOMOGENEOUS AND 
NONHOMOGENEOUS  EQUATIONS 
In this section we consider systems of linear homogeneous ordinary differential  equa 
tions 
X =  A(t)x 
and linear nonhomogeneous  ordinary differential  equations 
X =  A(t)x  +  ^(0. 
(LH) 
(LN) 
In Theorem 12.1 of Chapter 1 it was shown that these systems of equations, subject to 
initial conditions x(to)  =  XQ, possess unique solutions for every (to, XQ) E  D,  where 
D  =  {(t, x):t  GJ  =  (a,b),"xE  R""""} and where it is assumed that A  G  C(/"," i?""^'"") "
and g  E  C(J, R^),  These solutions exist over the entire interval /  =  (a, b) and they 
depend  continuously  on the initial  conditions.  Typically,  we  will  assume  that  /  = 
(-00, 00). We note that (/)(0  =  0, for  all r E  /,  is a solution of (LH),  with (l)(to)  =  0. 
We call this the trivial solution.  As in Chapter  1  (refer to Section 1.13), we recall that 
the preceding  statements  are also true when A(t)  and g(t)  are piecewise  continuous 
o n /. 
In the sequel, we sometimes will encounter the case where A(t)  =  A is in Jordan 
canonical  form  that  may  have  entries  in  the  complex  plane  C. For  this  reason,  we 
will  allow  D  =  {(t, x):t  E  J  =  (a,b\xE 
"/?""(or  x  E  C"")}  and  A  E  C(J","  JR""^^'^) "
[or A  E  C(J, C^^^)],  as needed. For the case of real vectors, the field of  scalars  for 
the X-space  will  be  the  field  of  real  numbers  {F  =  R),  while  for  the  case  of  complex 
vectors,  the  field  of  scalars  for  the  x-space  will  be  the  field  of  complex  numbers 
(F  =  C).  For  the  latter  case,  the  theory  concerning  the  existence  and  uniqueness  of 
solutions  for  (LH),  as presented  in Chapter  1, carries  over  and  can be modified  in the 
obvious  way. 
139 
CHAPTER 2: 
Response of 
Linear  Systems 
A.  The  Fundamental  Matrix 
Solution  space 
We  will  require  the  following  result. 
THEOREM  3.1.  The set of solutions of  (LH)  on the interval /  forms  an  ^-dimensional 
vector  space. 
Proof,  Let  V  denote  the  set  of  all  solutions  of  (LH)  on  /.  Let  a i , a2  G F  and 
let  01,02  G V.  Then  ai0i  +  0(202  ^  V  since  {d/dt)[ai(l)i  +  0(202]  =  a\{d/dt)(\)\{t)  + 
a2{d/dt)(^2{t)  =  aiA(r)0i(r)  +  a2A(r)02(O  =  A(r)[ai0i(r)  +  0(202(0]  for  ^^  ^ ^  J-
"This shows that V is a linear subspace of/?"". Hence", V is a vector  space. 
To complete the proof  of the theorem,  we must  show that V  is of dimension  n. To 
accomplish this, we must find n linearly independent solutions 0 i , . . ., 0„ that span V. To 
this  end,  we  choose  a  set  of  n  linearly  independent  vectors  XQ,...,XQ 
in  the 
^-dimensional x-space (i.e.," in R""^ or C""). By the existence results in Chapter  1", if ^o  ^J^ 
then there exist n solutions 0 i , . . ., 0„ of  (LH)  such that 0i (^o) =  -^O' • • •' ^«(^o) =  -^0-  ^^ 
first  show  that  these  solutions  are  linearly  independent.  If  on  the  contrary,  these  solu 
tions  are  linearly  dependent,  there  exist  scalars  a i , . . ., a„  G F,  not  all  zero,  such  that 
E Li  ^?0KO  = 0 for all t  G /.  This implies in particular that ^4=1  oci^i{to)  = E Li  ^i^o  ^ 
0.  But  this  contradicts  the  assumption  that  {XQ, ...  ,XQ}  is  a  linearly  independent  set. 
Therefore,  the solutions  0 i , . . ., 0„ are linearly  independent. 
To conclude  the  proof,  we  must  show  that  the  solutions  0 i , . . ., 0„  span  V.  Let  0 
be any  solution  of  (LH)  on the interval /  such that  0(^o)  =  -^o-  Then there exist  unique 
scalars  a i , . . ., a„  G F  such that 
xo  •• 
Z^^i^Qy 
since, by assumption, the vectors XQ, ...  ,XQ form  a basis for the x-space. Now 
n 
is  a  solution  of  (LH)  on  /  such  that  \j/{^o) =  ^o-  ^^t  by  the  uniqueness  results  of 
Chapter  1 we have that 
„ 
Since 0  was chosen arbitrarily, it follows  that the solutions  0 i , . . ., 0„ span V. 
• 
EXAMPLE  3.1.  Let A (t)  for  (LH)  be given by 
Ait): 
-1 
0 
e^n 
-1 
(3.122) 
It  is  easily  verified  by  direct  substitution  that  0i(O  =  (e  \0) 
are  solutions  oi  {LH)  onJ= 
^) 
(—00^00)  for  the  present case.  Furthermore,  it  is  easily 
and  (1)2  =  {\e\e 
140 
Linear  Systems 
shown  that  (pi and (p2  [defined  on /  =  (—^,^)]  are hnearly  independent  (using,  e.g., 
the  method  in Subsection  2.2B).  In view  of Theorem  3.1, the solutions  of  (LH)  with 
A{t)  specified  by (3.1) form  a two-dimensional  vector  space and {0i, ^2} is a basis for 
this  solution  space.  Since  {0i,02}  spans  this  vector  space,  all  solutions  of  (LH) 
with  A{t)  specified  by  (3.1)  are  of  the  form  ^(t)  =  ai^i{t)  +  ^202(0  =  {oc\e~^ + 
0^2 '].\J e^, 0^2^  0 
, where  a i, 0^2 G R. 
Fundamental  matrix  a nd  properties 
Theorem  3.1 enables  us to make  the following  definition. 
DEFINITION  3.1. A set of n linearly independent solutions of {LH) on /, {0i,..., 0„}, 
is called di fundamental  set of solutions  of {LH), and ihQnxn  matrix 
O=[0i,02,...,0n] 
"""011 "
021 
012 
022 
••• 
••• 
01n 
02n 
is called a. fundamental  matrix  of  {LH). 
Pnl (t>n2 
We  note  that  there  are infinitely  many  different  fundamental  sets  of  solutions  of 
{LH)  and, hence,  infinitely  many  different  fundamental  matrices  for  {LH).  We now 
study  some  of the basic  properties  of fundamental  matrix. 
In the next  result, X  =  [xij] denotes  an n x n matrix,  and the derivative  ofX  with 
respect  to  t  is  defined  as X  =  [xij]. Let A{t)  be  the nx  n  matrix  given  in  {LH).  We 
call the system  of n^  equations 
X=A{t)X 
(3.2) 
a  matrix  differential 
equation. 
THEOREM  3.2.  A fundamental  matrix  O of  {LH)  satisfies  the matrix  equation (3.2) 
on the interval  /. 
Proof,  WehaveO=[0i,02,...,0n]  =  [A(O0i,A(O02,...,A(O0n]=A(O[0i,02,...,0n] 
=  A{t)^. 
• 
The  next  result is cailcd  Abel's 
formula. 
THEOREM  3.3.  If O is a solution of the matrix  equation  (3.2) on an interval /  and T 
is any point of /,  then 
det 0{t)  = det 0 ( T) exp 
/ 
trA{s)ds 
for  every  t  e  J.  [tr  A{s)  =  tr  [aij{s)]  denotes  the  trace  of  A{s),  i.e.,  tr  A{s) 
"I""=i«;7(*)-] "
Proof, Let ^  =  [(j^ijl Then ^tj  = Zl=i  atkit^kj^  Now 
[det<^(t)]  = 
dt 
</>ii 
021 
<P 12 
022 
• 
. 
.. 
.. 
01« 
02n 
011 
021 
012 
022 
. 
• 
. •  01n 
•• 
02n 
+ 
</>nl 
0n2 
• 
..  0«n 
0nl 
0n2 
• 
•  <Pnn 
141 
CHAPTER  2: 
Response of 
Linear Systems 
011 
021 
012 
022 
. -. 
01« 
• •  •  02n 
f  ••• 
+ 
0nl 
0«2  • 
0nn 
021 
0nl 
022 
0-•n2 
011 
012 
T.l^iaik{t)(j>kn{t) 
02n 
(t>nn 
01« 
Y.l=iCl2k{t)4>k\ 
2 ^ =1  a2k(t)<Pk2 
• 
Y.l=iCl2k{t)4>kn 
032 
0 ril 
4>'in 
4>n 
011 
021 
012 
022 
01n 
02n 
031 
0nl 
+ 
0n-l,l 
0«-l,2 
\Y.l=\Clnk(t)4>kl 
Y.l=\Clnk{t)(f)k2 
. .. 
• •. 
0n-l,n 
YJ[=iClnk{t)(j>kn 
The first term in the above sum of determinants is unchanged if we subtract from the 
\-{ain 
first  row the quantity {an times the second row) + (^13 times the third row) + 
times the nth row).  This yields 
011 
021 
012 
022 
. 
. 
. . 
. . 
01n 
02n 
(2ii(O011 
ai 
021 
zzz 
l(O012 
022 
0nl 
0n2 
. 
..  0«n 
(knl 
0n2 
= 
2n(t)det<^(t). 
i 
. 
. 
a\ l(O01« 
02n 
(f>nn 
Repeating the above procedure for the remaining terms in the above sum of determinants, 
we have (d/dt)[det ^(t)]  =  an(t)det  ^(t)  + a22(t)det ^(t)  +  • • • + UnniOdet ^(0  = 
[tr A(t)] det ^{t).  This imphes that det <l>(0 =  det ^(r) exp [{/ tr A{s)  ds]. 
m 
Since  in  Theorem  3.3  r  is  arbitrary,  it  follows  that  either  det  0 (0  7^ 0  for  all 
t  E  J  or det  0 (0  =  0 for each t  ^  J.  The next result provides  a test on whether  an 
nX  n matrix 0 (0  is a fundamental  matrix of  {LH), 
THEOREM 3.4.  A solution O of the matrix equation (3.2) is a fundamental  matrix of 
{LH) if and only if its  determinant is nonzero for alH E  /. 
142 
Linear Systems 
Proof,  If <l> =  [(/>i, (/)2,..., (/>n] is a fundamental  matrix for (L//), then the columns of 
$, (/)i,...,  (/>„, form  a  hnearly  independent  set. Now let (/> be a nontrivial  solution of 
{LH).  Then by Theorem 3.1 there exist unique scalars a i , . . ., a„  E  F, not all zero, such 
that  (f) =  2 ; =! oij4'j  =  ^^» where  a^  =  (ai,...,  an). Let t  =  T G J.  Then  ^ ( T)  = 
<I>(T)(2, which is a system of n linear algebraic equations. By construction, this system of 
equations has a unique solution for any choice of (^(r). Therefore,  det 0 ( T)  T^ 0. It now 
follows  from  Theorem 3.3 that det ^(t)  ^  0 for any t G  /. 
Conversely, let ^  be a solution of (3.2) and assume that det ^{f)  T^ 0 for all ^ G  /. 
Then the columns of <I> are linearly independent for all ? G /. Hence, ^  is a fundamental 
matrix of {LH). 
• 
It is emphasized  that  a matrix  may have  identically  zero  determinant  over  some 
interval, even though its columns are linearly independent. For example, the columns 
of the  matrix 
0(0  = 
'1 
t 
0  1 
0  0 
f 
t 
0 
are  linearly  independent,  yet det  4>(0  =  0  for  all t  G  (-oo, oo). In  accordance  with 
Theorem  3.4, the above matrix  cannot be a fundamental  solution of the matrix  equa 
tion  (3.2) for any continuous  matrix  A{f). 
EXAMPLE 3.2.  Using the linearly independent  solutions <p 1,4*2 given in Example 3.1, 
we obtain 
0(0 
"2"" "
e~ 
0 
t  G  ( - 0 0, 00), 
as  a  fundamental  matrix  of  {LH)  with  A{t)  given  by  (3.1).  It  is  easily  verified  that 
the  matrix  O  satisfies  the matrix  equation  O  =  AO. Furthermore,  det 0 (0  =  e~^^  ¥^ 
0,t  G  (-00,00),  and det  0 (0  =  det  0(T)exp[|/rr  A{s)ds]  =  ^ ~ ^ ^ e x p [ | / -2 J^]  = 
^-2r^-2(r-T)  ^  ^-2t^ f ^  ^_Qo^ 00^^ ^g expected. 
• 
THEOREMS.5.  If O is a fundamental  matrix of {LH) and if C is any nonsingular con 
stant nXn  matrix, then OC is also a fundamental  matrix of {LH).  Moreover, if ^  is any 
other fundamental  matrix of {LH), then there exists a constant nX  n nonsingular  matrix 
P such that ^  = OP. 
Proof.  For the matrix OC we have  {d/dt){^C)  =  OC  =  [A(0O]C  =  A(0(OC), and 
therefore, OC is a solution of the matrix equation (3.2). Furthermore, since det 0 (0  ^  0 
for ? G /  and det C 7^ 0, it follows  that det [O(0C]  =  [det ^{t)]{det  C) 7^ 0, ^ G 7. By 
Theorem 3.4, OC is a fundamental  matrix. 
Next,  let  '^  be  any  other  fundamental  matrix  of  {LH)  and  consider  the  prod 
"uct  O'HO""^.  [Notice  that  since  det^{t)  7^ 0 for  all t  G 7","  then  O""H0  exists  for all "
t  G J.]  Also,  consider  0 0 ~^  =  /,  where  /  denotes  the ^  X n identity  matrix.  Differ 
entiating  both  sides,"  we  obtain  [(<i/J0O]O""^  -H O[(J/^0O""M  =  0  or  {d/dt)^~^  = "
- 0 - ^ ( ^ / ^ 0 0 1 0 - 1.  Therefore,  we  can  compute  {d/dt){^-^'¥)  =  <^~^[{d/dt)'i^] + 
[ ( J / J O O - ^^  = 0 - ^ ( 0 ^ - { O - i [ ( ^ / J 0 O ] O - i }^  =  O - i A ( 0 ^ - ( O - i A ( 0 O O - i )^ 
• 
=  0-1 A ( 0^  -  0-1 A ( 0^  =  0. Hence, O ' ^^  =  P or ^  =  OP. 
EXAMPLES.3.  It is easily verified  that the system of equations 
XI  =  5x, -  2x2 
X2  =  4Xl  —  X2 
(33) 
has two linearly independent solutions given by 4>i(t)  = {e^\ e^^Y, <^2(0 ^  (^^ 2^0^. 
and therefore, the matrix 
^(0 
2e' 
(3.4) 
is a fundamental  matrix of (3.3). 
"Using Theorem 3.5 we can find the particular fundamental  matrix ""^ of (3.3) that "
satisfies  the initial condition '^(0)  = / by using 0(0  given in (3.4). We have '^(0) = 
/  = O(0)C or C = 0-1(0), and therefore, 
143 
CHAPTER 2: 
Response of 
Linear Systems 
II 
II 
C = 
and 
^(0  = OC = 
{2e^' -e') 
i-e^'  -he') 
{2e^' -  2e')  {-e^'  + 2e') 
B.  The State Transition Matrix 
In Chapter  1 we used the Method  of Successive  Approximations  (Theorem  10.9) to 
prove that for every  {t^,  XQ) G J X R^, 
X = A(t)x 
(LH) 
possesses  a unique solution of the  form 
(/)(/, to, Xo)  =  ^(t, 
to)Xo, 
such  that  (l)(to, to, xo)  = xo,  which  exists  for all t G J, where  <E>(r, ^o) is the  state 
transition  matrix  (see Section  1.13). We derived  an expression  for ^(t, to) in  series 
form,  called the Peano-Baker  series  [see Eq.  (13.3) of Chapter  1], and we  showed 
that 0(r, ^o) is the unique solution of the matrix differential  equation 
^-^(t, to) =  A(t)^(t,  to\ 
dt 
where 
^{to,  to) = I 
for all t G  / 
(3.5) 
(3.6) 
We provide an alternative  formulation  of state  transition  matrix  and  we  study 
some of the properties of such matrices. In the following definition, we use the natural 
basis {ei,  e2,...,  Cn) that was defined  in Section 2.2. 
DEFINITIONS.2.  A fundamental matrix O of (LH) whose columns are determined by 
the linearly independent solutions (^i,..., (/>„ with 
^ l ( ^)  =  ei,  . ..,(f)n{tQ)  =  en. 
to E  /, 
is called the state transition matrix O for (LH). Equivalently, if ^  is any fundamental 
matrix of (LH), then the matrix O determined by 
<t>(t," to) =  ^ ( 0 ^ "" k ^) "
for all t, to  G /, 
is said to be the state transition matrix of(LH). 
• 
We  note  that  the  state  transition  matrix  of (LH)  is uniquely  determined by 
the  matrix  A(t) and  is  independent  of the  particular  choice  of the  fundamental 
144 
Linear  Systems 
matrix.  To  show  this,  let  ^i  and  ^2  be  two  different  fundamental  matrices  of 
(LH).  Then  by  Theorem  3.5  there  exists  a  constant  n  X  n  nonsingular  matrix 
P  such  that  ^2  =  ^iP.  Now  by  the  definition  of  state  transition  matrix,  we 
h a v e 3 ) ( U o)  =  ^ 2 ( 0 [ ^ 2 ( ^ ) ] -'  =  %(t)PP-'[%(to)]-' 
"=  ^ i ( 0 [ ^ i a o ) ] ""^  This "
shows  that  ^(t, 
to) is  independent  of  the  fundamental  matrix  chosen. 
EXAMPLE  3.4.  In  Examples  3.1  and  3.2  we  showed  that  for  (LH)  with  A(t)  given 
by (3.1), 
^(0 = 
2^ 
0 
tG(-
-X 
is  a  fundamental  matrix.  For  this  case,  the  state  transition  matrix  ^(t,  to)  is  com 
puted  as 
^(t,to)  = 
^(t)^-\to) 
0 
0 
-t+3to 
The reader  should verify  that this matrix  satisfies  Eqs. (3.5) and (3.6). 
Properties  of  the  state  transition  matrix 
In the following,  we  summarize  some of the properties  of  state transition  matrix. 
THEOREM  3.6.  Let  ^o ^  J,  let  (l>(to)  =  XQ, and let 0(^, ^o) denote  the  state  transition 
matrix for  (LH)  for all /  E  J.  Then the following  statements  are true: 
(i)  0(f,  ^0) is  the  unique  solution  of  the  matrix  equation  (dldt)^(t, 
to)  =  A(t)^(t,  to) 
with 0 ( ^,  to)  =  I,the  nX  n identity  matrix, 
(ii)  <l>(r, ^0) is nonsingular for  all ^ E  /. 
(iii)  For any t,a,TE 
(iv)  [<t>(t, to)V^  =  ^-\t, 
(v)  The unique  solution (/>(r, to, xo) of  (LH),  with  (/)(^, ^o, xo) 
to)  =  <^(to, t) for  all t, to E  /. 
/,  we have (^(t, r)  =  ^(t,  cr)^(cr, r)  (semigroup property), 
Xo specified,  is  given 
by 
Proof 
4>(t, to, Xo) =  ^(t,  to)xo 
for all t  E  /. 
(3.7) 
(i)  For  any  fundamental  matrix  of  (LH),  say,  ^,  we  have,  by  definition,  ^(t,  to)  = 
= 
^(toJo)  = 
"the  choice  of  ""¥.  Therefore",  d^(t,to)ldt 
=  A(t)^(t,to)' 
Furthermore, 
^ ( 0 ^ ~ H ^ ), 
^(t)'^-\to) 
^(to)^-\to) 
independent  of 
=  A(t)^(t)^-\to) 
=  L 
"(ii)  For any fundamental  matrix of (LH)  we have that det ""^(t)  7^ 0 for all ^ E  7. There "
fore, det ^(t,  to)  =  det  [^(0^~H^o)]  =  det  'i^(t)det'i^~\to)  7^  0 for  all t, to E  /. 
"(iii)  For any fundamental  matrix ""^ of (LH)  and for the state transition matrix O of  (LH)", 
for 
=  ^(t,a)<i>(a,r) 
wehave^(r,"T)  =  - ^ ( 0 ^ "" ^ ^)  =  'i^(t)^-\a)'¥(a)^~\T) "
any t,a,TE. 
J. 
(iv)  Let '^  be any fundamental  matrix  of (LH)  and let O be the  state transition  matrix 
"of  (LH).  Then  [^(tJo)]'^  =  WO^(^o)""M""^  =  ^ ( r o ) ^ "" kO  =  0 ( ^",  0  for  any 
t, to E  7. 
(v)  By the results established  in Chapter  1, we know that for every  (^0. ^0)  ^  D,  (LH) 
has  a unique  solution  0 (0  for  all  r E  7  with  </)(?o)  =  XQ. To verify  (3.7), we  note 
that 4)(t)  =  [d^(t,  to)/dt]xo  =  A(t)<^(t, to)xo  =  A(t)(l)(t). 
m 
EXAMPLE 3.5.  Let x(^o) =  (ai, a2)^. In view of Example 3.4, we have for (L//) given 
in Example 3.1, 
(/)(r, to, Xo)  = 
0 
^-(^-^o) 
and therefore, 
145 
CHAPTER  2: 
Response of 
Linear Systems 
(t>2(t, to, Xo)  =  e-^'-'^^a2. 
(3.8) 
(3.9) 
We  can  verify  the  above  example  by  simple  integration.  In  doing  so, we  first 
"obtain  (^2(^> ^> -^o) by  integrating  both  sides  of  i:2  ""=  ~-^2  and  by  using  the  initial "
condition X2(to) =  CLI- Next, we obtain (piit, to, XQ) by integrating both sides of ii  = 
-x\  +  e^^cl)2(t, to, XQ)  and  using  the  initial  condition  (x\(to),  ^2(^0))^  =  (ai, ^2)^. 
Note that this procedure for  solving an initial-value problem determined by (LH)  is 
valid for any triangular matrix  A(t). 
In  Chapter  1 we  pointed  out  that  the  state  transition  matrix  ^(t,  to) maps  the 
solution (state) of (LH)  at time to to the solution (state) of (LH)  at time t. Since there 
is no restriction  on  t relative  to  to (i.e., we  may  have  t  <  to,t  =  to, or t  >  to), we 
"can ""move forward  or backward"" in time. Indeed", given the solution (state) of  (LH) 
at time  t, we can  solve the  solution  (state)  of  (LH)  at time  to- Thus,  x(to)  =  xo  = 
[^(t,  to)V^(l>(t, to, Xo) =  0(^0, t)(l)(t, to," Xo). This  ""reversibility  in  time"" is  possible "
because  ^~^(t,  to)  always  exists.  [In  the  case  of  discrete-time  systems  described 
by  difference  equations,  this  reversibility  in  time  does  in  general  not  exist  (refer 
to Section  2.7).] 
C.  Nonhomogeneous  Equations 
In Section  1.13, we proved the following  result  [refer to Eqs. (13.8) to (13.10)]. 
THEOREM 3.7.  Let to E 7, let (to, Xo)  E D, and let ^(t,  to) denote the state transition 
matrix for  (LH) for  all r E  /.  Then the unique solution (/)(r, to, xo) of (LN)  satisfying 
</>(^, to, Xo)  = Xo is given by 
^(^, ^0, ^o)  = ^(t,  to)xo  + 
^(t,  v)8(v)dV' 
(3.10) 
As pointed out in Section  1.13, when  xo  =  0, (3.10) reduces to 
ct>(t,to,0) ^  cl>p(t)  =  f  ^(t,s)g(s)ds. 
(3.11) 
Jto 
and when xo  #  0, but g(t)  =  0, (3.10) reduces to 
ct)(t, to, Xo) =  (l>h(t)  =  ^(t,  to)xo. 
(3.12) 
and  the  solution  of  (LN)  may  be  viewed  as  consisting  of  a component  that  is  due 
to the initial data xo and another component that is due to the forcing  term g(t).  We 
recall  that  cffp  is called  a particular  solution  of the nonhomogeneous  system  (LN), 
while (f)h is called the homogeneous  solution. 
There are of course other methods of solving (LN).  For example, in the common 
approach  to solving  linear  differential  equations,  all  solutions  (^(0  of  i  -  A(t)x  = 
146 
Linear  Systems 
g{t)  are  assumed  to  be  of  the  form  0(f)  =  ^^{t)  +  ^p{t),  where  0/^(f)  is  the  solution 
of  the  homogeneous  equations  x  — A{t)x  =  0  and  ^p{t)  is  a  particular  solution.  It  is 
not difficult  to  see that  0/^(f)  =  0(f,  to)oc, where  a  eR^ 
is to be determined  [compare 
to  (3.12)].  Therefore,  (p{t)  =  <^{t,to)a-\- 
(pp{t).  The  vector  a  is  determined  using 
the  initial  conditions  on  the  solution  (p{t)  of  x  — A{t)x  =  g{t),  namely,  (p{to)  =  XQ. 
Substituting  (j){to) =  O(fo,^o)oj  +  0p(fo),  we obtain  a  =  (j){to)  -  0p(fo)  =  -^o - (t>p{to)' 
The  solution  to  (LN)  with  0(fo)  =  -^o is  therefore  given  by  0(f)  =  0/^(f)  +  ^p{t)  = 
O(f,fo)[0(^o)  -  0p(^o)] +  0p(O'  or 
0 ( O = O ( f , f o ) ^o  +  [0p(O-^(^^o)0p(^o)]. 
(3.13) 
As  expected,"  the  ""zero-state  response  of  {LN)''  obtained  by  letting  XQ =  0  in  (3.10) "
=  g{t)  with the  property 
and given in  (3.11), is a particular  solution  ^p{t)  ofx—A{t)x 
that  0p(fo)  =  0-  Furthermore,"  the  ""zero-input  response  of(LN)'' "
obtained  by  letting 
g(t)  =  0 in  (3.10), is the  solution  0/^(f)  ofx  — A{t)x  =  0.  It follows  that  the  variation 
of  constants  formula 
(3.10)  is  a  special  form  of  expression  (3.13),  corresponding  to 
the chosen  particular  solution  (pp{t)', for  a different  choice  of  (pp{t), a  correspondingly 
different  expression  for  the  solution  (p{t)  is  obtained. 
EXAMPLE3.6.  In  (LN),  \QtxeR^,to  =  0, and 
A(t). 
g(t)-
0 
X(0): 
The state transition matrix for A(f)  has been determined in Example  3.4  as 
Using  (3.12), we  obtain 
(l)h{t,to,xo)=^{t,0)x{0) 
W-e-^) 
using  (3.11), we have 
(i>p{t,tQ,XQ)  =  j 
^(t,ri)g(ri)dri 
te 
and using  (3.10), we  finally  obtain 
(l)(t,to,Xo)  =  (l)h(t,to,Xo)  +  (l)p(t,to,Xo)  = 
'e-'{t-\)  +  y 
D.  H ow  to  Determine  O(f,fo) 
To  solve  {LN)  or  {LN)  in  closed  form,  we  require  an  expression  for  the  state  tran 
sition  matrix  O(f,fo)-  We  have  seen  in  Example  3.5  that  when  A{t) 
is  triangular, 
we  can  solve  {LH)  [and  hence,  O(f,fo)]  by  sequential  integration  of  the  individual 
differential  equations.  Eor  the  general  case,  however,  closed-form  determination  of 
0(f  ,fo)  is not  possible. 
In  the  following,  we  identify  another  important  class  of  matrices A{t)  for  which 
a  closed-from  expression  of  0(f,  t^)  exists. 
THEOREM  3.8.  If for every  T,^ we have 
A(t) 
I  A{r\)dr\\  = 
JT 
\ 
j  A{n)dr\ 
\JT 
A(t), 
(3.14) 
Ul 
CHAPTER 2: 
Response of 
Linear  Systems 
then 
'^(t,T)  =  eirMv)dv  A^  +  y  _L 
CO 
^ 
A(r])d7] 
(3.15) 
Proof,  We  recall  that  the  general  term  of  the  Peano-Baker  series  [see  Eq.  (13.3)  in 
Chapter  1] is given by 
rt 
rsx 
A{si)\ 
"A{S2)""' "
AySm)  dSfn ClSfy, 
'ds]. 
(3.16) 
k=l 
We wish  to  show  that under  the present  assumptions,  expression  (3.16)  is equal  to  the 
expression 
1 
m! 
A(s)  ds 
To verify  (3.17), we will apply the identity 
A(r) 
A(s)  ds  dr  = 
1 
m +  1 
|W+1 
A(s)  ds 
(3.17) 
(3.18) 
repeatedly to (3.16). First, however, we verify  the validity of (3.18). To accomplish this, 
we first observe that (3.18) is true for any fixed t  =  r.  Differentiating  the left-hand  side 
of (3.18), we obtain 
[Air,  I  A(s)ds 
m 
d_ 
Jt 
dr  =  A(t)  I  A(s)ds 
(3.19) 
Differentiating  the right-hand  side of (3.18), we have that 
-im+O 
^\ 
dt 
1 
m  +  1 
[  A{s)ds 
1 
m +  1 
A{t) 
A{si)ds2' 
A{Sni^{)ds 
A{sx)dsAA{i) 
I  A{s^)ds^ 
A{Sm-^{)dSm^X  + 
+ 
A{s\)ds\' 
A{Sm)dSm\A{t)\ 
=  A(t) 
A(s)  ds 
(3.20) 
where in the last  step of  (3.20), the assumption  (3.14) has been used repeatedly.  Using 
(3.19) and (3.20), we obtain (3.18). 
To complete the proof of the theorem, we apply (3.18) repeatedly to (3.16) to obtain 
(3.17), the general term of the Peano-Baker series (13.13) in Chapter  1. Indeed, we have 
A(si) 
A(s2y 
A(Sm-1) 
A(Sm)  dSm  dSm-1  dSm-2' 
A(Sm-2)^  r 
Sm-4 
I 
A(Sm-3):^ 
"""  dSi "
A(s)  ds  ds. 'm-2'-'dSi 
"A(s)  ds  dStn-3'""dSi "
A(si)r 
A(s2y 
= 
^j'A(si)pA(s2y' 
=  •••  =  -^W 
ml  [J^ 
A(s)ds 
which was to be shown. This completes the proof of the theorem. 
148 
Linear Systems 
For the scalar case, i.e., when A(t)  =  a(t),  relation  (3.14) is always true. Also, 
when  A(t)  =  diag[aii(t)]  [i.e.,  A(t)  is  a  diagonal  matrix],  relation  (3.14)  is  true. 
Furthermore,  for  A(t)  =  A, a constant  matrix,  (3.14)  will  always  hold. The  reader 
can readily verify  that A(t)  given in Example  3.1 also satisfies  relation  (3.14). 
We  conclude  by  pointing  out  that  for  A  G  C[R, R''^''],  (3.14)  is  true  if  and 
only if 
for all t and r.  We ask the reader to verify  the validity of this  statement. 
A(t)A(T)  =  A ( T ) A (0 
(3.21) 
2.4 
LINEAR  SYSTEMS  WITH  CONSTANT  COEFFICIENTS 
In  this  section  we  consider  systems  of  linear,  autonomous,  homogeneous  ordinary 
differential  equations 
X =^  Ax 
and systems of linear nonhomogeneous  ordinary  differential  equations 
X =  Ax  + g(tl 
(L) 
(4.1) 
"where  ;c G  /?"""," A  G  i^^^""",  and  g  G  C(R,"  R""""). In  the  special  case  when  A(t)  =  A", 
system  (LH)  reduces to system  (L) and  system  (LN)  reduces to system  (4.1). Con 
sequently, the results  of  Section  2.3  are applicable  to (L) as well  as to (LH)  and to 
(4.1)  as  well  as  to  (LN).  However,  because  of  the  special  nature  of  (L)  and  (4.1), 
more detailed information  can be  determined. 
A.  Some Properties  of e^^ 
Let  D  =  {(t, x)  \ t  E. R,x  Ei R^}.  In  view  of  the results  of  Section  1.13,  it  follows 
that for every  (to, XQ) G D, the unique solution of (L) is given by 
(l)(t, to, Xo) =  ^ + 2 A*(f  -  ^o)* 
. =1 
^' 
Xo 
=  *(f,  to)xo  =  0(r  -  to)xo  =  e^^'-'^ho, 
(4.2) 
where  ^(t  —  to)  =  e^^^~^^^  denotes  the  state  transition  matrix  for  (L).  [By  writing 
^(ty  to)  =  ^(t  -  to), we are using a slight abuse of notation.] 
In  arriving  at  (4.2)  we invoked  Theorem  10.9 of  Chapter  1 in  Section  1.13,  to 
show that the sequence {</)m}, where 
(^m(r, fo, ^o)  = 
. =1 
^' 
^0  -  Sm(t -  to)xo, 
(4.3) 
converges  uniformly  and  absolutely  as m ^  oo to the unique  solution  ct)(t, to, xo) of 
(L)  given by  (4.2) on compact  subsets of R.  In the process of arriving  at this result, 
we also proved the following  results. 
THEOREM4.1.  Let A be a constant nX n matrix  (which may be real or complex)  and 
let Sfn(t) denote the partial sum of matrices defined  by 
Sm(t) 
m 
. 
k=l  k\ 
(4.4) 
Then each element of the matrix Sm(t) converges absolutely and uniformly  on any finite 
t  interval  (-a, a), a > 0,  SLS  m ^  oo. Furthermore,  Sm(t)  =  ASm-i(t)  = Sm-i(t)A,  and 
thus, the  limit  of Sm(t)  SLS t ^  oo is a C^  function  on R.  Moreover,  this  limit  commutes 
with A. 
• 
In  view  of  the  above  result,  the  following  definition  makes  sense  (see  also  Sec 
149 
CHAPTER  2: 
Response of 
Linear  Systems 
tion  1.13). 
DEFINITION  4.1.  Let A be a constant nX  n matrix  (which may  be real or complex). 
We define  e^^ to be the matrix 
°°  fk 
e^^  =  1 + ^  LA' 
k=l  k\ 
(4.5) 
for  any  -co < ^ < oo, and we call e^^ a matrix  exponential. 
We  are  now  in a position  to provide  the  following  characterizations  of  e^^. 
THEOREM  4.2.  Let /  =  RJQ ^  J, and let A be a given constant matrix for  (L). Then 
(i)  0 (0  -  e^^ is a fundamental  matrix for all t  < 
(ii)  The  state  transition  matrix  for  (L) is  given  by  ^(t, to) 
<^(t -  tol  t G /. 
(iii)  ^^^i^^^2  =  ^A(fi+f2)  for  all tu  t2 G /. 
"(iv)  Ae""^' = e^'A  for all t G /. "
(v)  {e^')-^  =  ^-^^ for alU  G 7. 
Proof.  By (4.5) and Theorem 4.1 we have that (d/dt)[e'^^]  = hm^^oo ASm(t) = 
hm^_^oo Sm(t)A  =  Ae^^  = e^^A. Therefore,  0 (0  =  e^^ is a solution of the matrix  equa 
tion 6  = AO. Next, observe that 0(0)  =  /. It follows from Theorem 3.3 that J^^[^^^  = 
^tr(At)  -^ Q fQ^ ^Y[ t G R. Therefore,  by Theorem 3.4 0 (0  =  e^^ is a fundamental  matrix 
for  (L). We have proved parts  (i) and (iv). 
To prove (iii), we note that in view of Theorem  3.6(iii), we have for  any  ti,t2  ^ R 
that 0(^1, t2) = 0(^1, 0)0(0, t2). By Theorem  3.6(i)  we  see that 0(f,  to) solves  (L)  with 
^Oo,  to)  = 1' It was  just  proved  that  ^ (0  = ^^(^~^o)  is also  a  solution.  By unique 
ness,  it  follows  that  0(r,  to)  = e^^^'^^K  For  t  =  ti, to  =  —t2, we therefore  obtain 
eMti+t2)  = ^(^f^^  _^2)  =:  (^(t^)i^(-t2)-\ 
e^h  = ^{ti).  Also,  for ^ =  0, ^  =  -^2,  we obtain  0(0,  -^2)  =  e^^^ = 0(-^2)~^. 
Therefore,  ^^(^1+^2)  =  ^^^^^^2 for all ti, t2 G R. 
and  for t  = tiJo  = 0, we  have  O(fi,0)  = 
Finally, to prove (ii), we note that by (iii) we have 0(^, to) = ^^(^~^o)  = /  + 
XI=i[(^  -  to)'/k\]A''  = 0(f -  to) is a fundamental  matrix  for  (L)  with  O(^o, k)  = L 
Therefore,  it is a state transition matrix for  (L). 
• 
We  conclude  this  section  by  stating  the  solution  of  (4.1), 
(f){t, to, xo)  =  0 (r  -  to)xo + 
0(^  -  s)g(s) ds 
e^^'-'\g{s)ds 
to 
At 
e-^'g{s)ds, 
(4.6) 
150 
Linear Systems 
for  all t  Ei R.ln  arriving  at (4.6), we have used  expression  (13.8) of Chapter  1 and 
the fact that in the present case, 0(r,  to)  =  ^^(^~^o) 
B.  How  to Determine  e At 
We begin by considering the specific  case 
A  = 
0  a 
0  0 
From (4.5) it follows  immediately  that 
"e""^' =  I  ^tA  =  1 "
0 
at 
1 
As another example, we consider 
Ai 
0 
0  A2 
where Ai, A2 E  R. Again, from  (4.5) it follows  that 
k 
^At  ^ 
0 
oht 
0 
0 
e^^' 
k=l  k\ 
(4.7) 
(4.8) 
(4.9) 
(4.10) 
Unfortunately,  in general it is much more difficult  to evaluate the matrix expo 
nential than the preceding  examples  suggest.  In the following,  we consider  several 
methods of evaluating e^K 
The infinite  series method 
In this case we evaluate the partial  sum Sm{t) (see Theorem  4.1) 
m  ^k 
SM-1  +  Y.T^' 
k=l  k\ 
for  some  fixed  t, say, ti,  and for  m  =  1, 2 , . ..  until no  significant  changes  occur  in 
succeeding  sums. This yields the matrix e^^^. This method works reasonably well if 
the smallest and largest eigenvalues  of A are not widely  separated. 
In the  same  spirit  as above, we could use any  of the vector differential  solvers 
to  solve  X  =  Ax,  using  the  natural  basis  for  R^  as  n  linearly  independent  initial 
conditions  [i.e.,  using  as  initial  conditions  the  vectors  ei  =  (1, 0 , . . .,  0)^, ^2  = 
(0,1,0,..., 0)^, ...,en  =  (0,...,  0,1)^]  and  observing  that  in  view  of  (4.2),  the 
resulting  solutions are the columns of e^^ (with ^o =  0). 
EXAMPLE  4.1.  There  are cases  when  the  definition  of  e^^  (in  series form)  directly 
produces a closed-form  expression. This occurs for example when A^  =  0 for some k. 
In particular, if all the eigenvalues of A are at the origin, then A^ =  0 for some A: <  n. In 
this case, only a finite number of terms in (4.5) will be nonzero and e^^ can be evaluated 
• 
in closed form. This was precisely the case in (4.7). 
151 
CHAPTER  2: 
Response of 
Linear Systems 
The similarity transformation  method 
Let us consider the initial-value  problem 
X =  Ax, 
x(to)  =  xo, 
(4.11) 
let P be a real nXn  nonsingular matrix, and consider the transformation  x  =  Py,  or 
equivalently, y  =  P~^x.  Differentiating  both sides with respect to t, we obtain y  = 
p-^x  =  P~~^APy  =  Jy,y(to)  =  yo  =  P'^^o-  The  solution  of the  above  equation 
is given by 
il^(t,to,yo)  =  e'^'-'^^p-^xo. 
Using (4.12) and x  =  Py,  we obtain for the solution of (4.11) 
cl>(tJo.xo) =  Pe^^'-'^^p-^xo. 
(4.12) 
(4.13) 
Now suppose that the similarity transformation  P given above has been  chosen 
in such a manner  that 
/  =  p-^AP 
(4.14) 
is in Jordan canonical form (see Subsection 2.20). We first consider the case when A 
has n linearly  independent  eigenvectors,  say, v/, that correspond  to the  eigenvalues 
A/ (not necessarily  distinct),  /  =  1,...,  n.  (Necessary  and  sufficient  conditions  for 
this to be the case are given in Section 2.2. A sufficient  condition for the eigenvectors 
Vi, i  =  1,...,  ^, to be linearly independent is that the eigenvalues of A, Ai,..., A„, be 
distinct.) Then P can be chosen so that P  =  [vi,...,  v„] and the matrix /  =  P~^AP 
assumes the  form 
/  = 
0 
0 
Afj 
Using the power series  representation 
we immediately  obtain the  expression 
00 
k=i 
Jt 
,Ai« 
0 
^A„r 
(4.15) 
(4.16) 
(4.17) 
Accordingly, the solution of the initial-value problem (4.11) is now given by 
rgAi(/-/o) 
0 
(t)(t, to, Xo) =  P 
P~'xo. 
(4.18) 
0 
g,A„(r-?o) 
In the general case when A has repeated eigenvalues, it is no longer possible to 
diagonalize A (see Subsection 2.2L). However, we can generate n linearly  indepen 
dent vectors v i , . . ., v„ and an n X n similarity transformation  P  =  [vi,..., v„] that 
takes A into the Jordan canonical form /  =  P~^AP.  Here /  is in the block diagonal 
152 
Linear Systems 
form  given by 
/  = 
Ji 
Jo 
0 
(4.19) 
where  Jo  is  a  diagonal  matrix  with  diagonal  elements  Ai,..., A^ (not  necessarily 
distinct), and each 7,, /  >  1, is an n,  X m  matrix of the  form 
'h+i 
1 
0  A k+i 
0 
1 
... 
0 
0 
Ji  = 
(4.20) 
0 
0 
0 
0 
... 
• 
0. 
1 
^k+i 
where X^+i need not be different  from A,t+; if i ^  7» and where k + ni-\ 
h n^  =  n. 
Now since for any square block diagonal  matrix 
c = 
0 
with  Ci,i  =  I,...,  I, square, we have that 
cf 
0 
C'  = 
0 
it follows  from  the power series representation of e-^' that 
\gJot 
pJ\t 
e''  = 
t  E. R. As  shown earlier, we have 
„Jot  = 
Alt 
0 
0 
oJ st 
0 
For Ji, i  =  I,..  .,s,we  have 
/,•  =  Xk+ili + Ni, 
(4.21) 
(4.22) 
(4.23) 
where 7, denotes  the  n,  X n,  identity  matrix  and A^, is the  «,  X n,  nilpotent  matrix 
given by 
[O 
1 
...  Ol 
Ni 
: 
0 
•• 
1 
0 
(4.24) 
Since  \k+iU  and  Nt  commute,  we  have  that 
^Jit  ^ 
^Xk+it^Nit^ 
(4.25) 
Repeated  multiplication  of  Nt  by  itself  results  in  Nf  =  0  for  all  k^ 
the  series  defining  e^^'  terminates,  resulting  in 
ni.  Therefore, 
153 
CHAPTER 2: 
Response of 
Linear  Systems 
\ 
t 
. 
JJi 
o^k+it  0  1 
fUi-l 
(«,•  - 
1 )! 
{ni  -  2)! 
/  =  1 , . . .,  5. 
(4.26) 
It now follows  that the solution of (4.11) is given  by 
0  0 
1 
4>it, to, xo)  =  P 
0 
pJ\(t-to) 
0 
0 
0 
0 
(fJs{t-to) 
P'^xo. 
(4.27) 
EXAMPLE 4.2.  In system (4.11), let A  = 
-1  2 
0  1 
. The eigenvalues of A are A i  =  -1 
and  A2  =  1,  and  corresponding  eigenvectors  for  A  are  given  by  vi  =  (1,0)^  and 
V2  =  (1, 1)^,  respectively.  Then  P  =  [vi, V2]  = 
1  1 
.0  1 
,P~'  = 
1 
0 
-1 
1 
and  /  = 
P-^AP  = 
-1  2 
0  1 
1  1 
0  1 
-1  0 
0  1 
0 
Ai 
0  A2 
as  expected.  We  obtain 
^At  =  Pe-^'P-^  = 
1  1 
0  1  0 
0 
1 
0 
-1 
1 
0 
Suppose  next  that  in  (4.11)  the  matrix  A  is  either  in  companion 
form  or  that  it 
has  been  transformed  into  this  form  via  some  suitable  similarity  transformation  P, 
so that  A  =  Ac,  where 
Ar  = 
0 
0 
1 
0 
0 
-flO 
0 
-ai 
0 
1 
0 
- «2 
0 
0 
1 
(4.28) 
Since  in  this  case  we  have  xt+i  =  Xi,i  =  1 , . . .,  n  -  1, it  should  be  clear  that in  the 
"calculation  of  e""^^  we  need  to  determine",  via  some  method,  only  the  first  row  of  e^^. 
We  demonstrate  this  by  means  of  a  specific  example. 
EXAMPLE 4.3.  In system (4.11), assume that A  =  Ac  = 
0 
L-2 
11 
-3J 
, which is in com-
panion  form.  To demonstrate  the  above  observation,  let us  compute  e^^ by  some  other 
method, say, diagonalization. The eigenvalues of A are Ai  =  -1  and A2 =  - 2, and a set 
of corresponding  eigenvectors is given by vi  =  (1, - 1 )^  and V2 =  (1, - 2 ) ^. We obtain 
154 
Linear Systems 
P  =  [vi,V2]  = 
1 
-1 
,P-'  = 
1 
-1 
lip-^  ^  IM  ^ 
2 
-1 
-2jL0 
^-^'JL-l  - 1. 
i-2e-'  + 2^-20 
and J  =  p-^ArP  = 
-1 
0 
0 
-2 
, e At  _ 
We note that the second row of the above matrix is the derivative of the first row,  as 
expected. 
• 
The Cayley-Hamilton  Theorem  method 
If a(A)  =  det(\I 
-  A)  is the characteristic  polynomial  of an n X n matrix A, 
then in viev^ of the Cayley-Hamilton  Theorem,  we have that a(A)  =  0, i.e., every 
nXn  matrix satisfies its characteristic equation (refer to Subsection 2.2J). Using this 
result, along with the series definition of the matrix exponential 6^^ it is easily shown 
that 
n-l 
e^'  = 
^ai{t)A\ 
i = 0 
[Refer to Subsection 2.2J for the details on how to determine the terms  adt).] 
The Laplace transform  method 
We assume that the reader is familiar  with the basics of the (one-sided)  Laplace 
transform.  If  / ( /)  =  [fi(tl..., 
R,i  =  I,...,  n, and 
if  each  fi  is  Laplace  transformable,  then  we define  the Laplace  transform  of the 
vector/  componentwise, i.e., f{s)  =  [fi{s\ 
. ..,fn{s)Y,  where fi{s)  =  X[Mt)]  = 
fn(t)f,  where  ft  : [0,^)-^ 
We  define  the Laplace  transform  of  a matrix  C(t)  =  [cij(t)]  similarly.  Thus, 
if  each  ctj  : [0, ^)  —>  R and if each  c/y is Laplace  transformable,  then the Laplace 
transform  of C(0 is defined  as C(5') =  iE[cij(t)]  =  [i£cij(t)]  =  [cij(s)]. 
Laplace transforms  of some of the common time signals are enumerated in Ta 
ble 4.1.  Also, in Table 4.2 we summarize  some of the more important properties of 
the Laplace  transform.  In Table 4.1, 8(t)  denotes  the Dirac  delta  distribution  (see 
Subsection  1.16C) and pit)  represents the unit step  function. 
Now consider once more the initial-value problem (4.11), letting to  =  0, i.e.. 
X =  Ax, 
x(0)  = XQ. 
(4.29) 
TABLE  4.1 
Laplace transforms 
ma  ^ 0) 
fis)  = Wit)] 
8(t) 
Pit) 
t^lk\ 
^-at 
fk^-at 
"e~""^ sin bt "
e~''^ cos bt 
1 
1/s 
1/^^+1 
l/(^  +  a) 
Wis + af^^ 
bilis  +  af  + /?2] 
is  + a)l\_is  +  of-\-b'^] 
155 
CHAPTER 2: 
Response of 
Linear  Systems 
.+fik- i)(0)] 
TABLE4.2 
Laplace transform  properties 
Time  differentiation 
Frequency  shift 
Time shift 
Scahng 
Convolution 
Initial value 
Final value 
df{t)/dt 
d^f{t)/dt^ 
e--^f{t) 
f{t  — a)p{t — a),a  > 0 
f{t/a),a>0 
Jl>f(T)g(t-T)dT  =  f{t)*g{t) 
lim,^o+/W=/(0+) 
lim,^^/(f) 
*/(^)-/(o) 
,*/(,) _ [ / - i / ( 0)  + . 
/> + «) 
"e-""'f(s) "
af(as) 
fim^) 
linis^^  sf{sy 
lims^o sf{s)^'' 
^ If the limit exists. 
"•'""'• If sf{s) has no singularities on the imaginary axis or in the right half s plane. "
Taking  the Laplace  transform  of  both  sides  of i  = Ax,  and taking  into  account  the 
initial  condition x(0)  =  XQ, we obtain  sx{s)  —xo=  Ax{s),  or {sI—A)x{s)  =  XQ, or 
x{s)  =  {sI-A)-^xo. 
(4.30) 
It  can be  shown  by  analytic  continuation  that  {si — A)~^  exists  for  all s,  except  at 
the  eigenvalues  of A.  Taking  the inverse  Laplace  transform  of  (4.30),  we obtain the 
solution 
0 (0  =  ^~^[{sI-A)-^]xo 
= O(f,0)jco  =  e^'xQ. 
(4.31) 
It follows  from  (4.29)  and (4.31)  that 6{s)  =  (sI-A)-^ 
and that 
O ( f ," 0 ) = O ( f - 0 ) = O ( 0 = ^ "" M ( ^ / - A ) - ^ ] = /^ "
(4.32) 
Finally,  note  that  when  to ^  0, we can immediately  compute  0(f  ,fo)  =  ^ (^ — ^o)  = 
EXAMPLE  4.4.  In (4.29), let A 
^ -1  2] 
0  1 
. Then 
(sI-A)-
5 +1 
0 
-2 
s-l 
1 
5 +1 
0 
Using Table 4.1, we obtain if'^ 
[{si-A 
2 
( 5 + l ) ( 5 - l) 
1 
5 +1 
1 
\S-l 
1 
5 +1 
s-l 
0 
{e'-e-') 
1 
0 
Before  concluding  this  subsection,  we  briefly  consider  initial-value  problems 
determined  by (4.1), i.e., 
x=Ax^g{t), 
x{to)=xo. 
(4.33) 
We  wish  to apply  the Laplace  transform  method  discussed  above  in  solving  (4.33). 
To  this  end we  assume  ^o =  0  and we take  the Laplace  transform  of  both  sides  of 
(4.33) to obtain  sx{s)  —XQ =AX{S) 
-\-g{s)  or {si — A)x{s)  =xo-\-g{s),  or 
x{s)  = 
{sI-A)-\^{sI-A)-^g{s) 
= 
^{s)xo^^{s)g{s) 
^  ^h{s)^^p{s). 
(4.34) 
156 
Linear  Systems 
Taking  the  inverse  Laplace  transform  of  both  sides  of  (4.34)  and  using  (4.6) 
with  ^0  =  0,  we  obtain  0 (0  =  0/z(O  +  </>p(0  =  i^~^[(sl 
-
=  ^(t)xo  +  IQ  ^(t  ~  r])g(r])drj,  where  0/^  denotes  the  homogeneous 
Ay^g(s)] 
solution  and  (l)p  is  the particular  solution,  as  expected. 
-  A)~'^]xo  +  iE~^[(sI 
EXAMPLE4.5.  Consider the initial-value problem given by 
Xi  =  — Xi  +  X2 
X2  = 
- 2 ^2  +  U(t) 
with xi(0)  =  -I,  X2(0)  =  0, and 
u(t)  = 
for  t  >  0, 
for  t  <  0. 
It is easily verified  that in this case 
1 /1 
s + 1 
s +I 
1 
s  + 2 
0 
0 
e  ^ 
0 
1 
5+  1 
0 
1 
s  -h2 
-It 
(e  ^  —  e 
-e 
0 
^0' 
-1 
0. 
1 
s  + 2 
e-' 
/  1 
5 +1 
1 
s + 2 
2e- +  i^-2^-
Ct>p{t)  = 
1 
'  2' 
2 
-2t 
_ 
2 
2' 
and 
0 (0  =  0/,(O  +  0p(O 
2 i J '^  2\5 + 2 
1  /  1 
2  1^ +  2 
2U 
s + 1 
C.  M o d es  and  Asymptotic  Behavior  of  Time-Invariant  Systems 
In  this  subsection  we  study  the  qualitative  behavior  of  the  solutions  of  linear,  au 
tonomous,  homogeneous  ordinary  differential  equations  (L)  by  means  of  the  modes 
of  such  systems,  to  be  introduced  shortly.  Although  we  will  not  address  the  stabil 
ity  of  systems  in  detail  until  Chapter  6,  the  results  here  will  enable  us  to  give  some 
general  stability  characterizations  for  such  systems. 
Modes:  General  case 
We  begin  by  recalling  that  the  unique  solution  of 
i:  =  Ax, 
(L) 
satisfying  x(0)  =  JCQ, is  given  by 
(/>(r, 0, jco)  =  $(r,  O)x(O)  =  0(r,  0)xo  =  e'^'xQ. 
(4.35) 
We also recall  that  det(sl 
-  A)  =  YlJ^i(s  -  KT\  where  Ai,..., A^- denote the  a 
distinct eigenvalues  of A, where  A/ with  /  =  1,..., cr, is assumed to be repeated  nt 
times (i.e., nt is the algebraic multiplicity  of A/), and Xf^im  =  n. 
To introduce the modes for  (L), we must show that 
157 
CHAPTER!: 
Response of 
Linear Systems 
^At 
(T 
flj-l 
= 1  ^ = 0 
=  J][Aioe^^'  +  Ante^^'  +  • • • + A,-(„,.-
-ix^t 
(4.36) 
where 
1 
Afk  =  -^-z 
1 
^ 
j-r  lim{[(s  -  XiT^sI  -  A)'  i^im-i-k)  }. 
(4.37) 
In (4.37), [  • ]^^^ denotes the /th derivative with respect to s. 
"Equation (4.36) shows that e""^^ can be expressed as the sum of terms of the form "
Aikt^e^'\  where A/^  E  R^^^,  We call Ai^t^e^'^ a mode of system  (L). If an eigenvalue 
A/ is  repeated  nt  times,  there  are  nt  modes,  At^t^e^'^  k  =  0, I,...,  rii — \,  in e^^ 
associated  with  A/. Accordingly,  the  solution  (4.35)  of  (L)  is  determined  by  the  n 
modes of (L) corresponding to the n eigenvalues of A and by the initial condition x(0). 
We note that by selecting  x(0) appropriately, modes can be combined or eliminated 
[Aikx{Q) ^  0], thus affecting  the behavior of <^(t, 0, XQ). 
"To verify  (4.36) we recall that  e^^  =  i£~^[(sl  -  A)""^]  and we make use of the "
partial fraction  expansion method to determine the inverse Laplace transform.  As in 
the scalar case, it can be shown that 
{si  -  A)-'  =  X  ^(klAaXs 
-  Xir^'^'\ 
(4.38) 
i =  l  k^O 
where the (klAfk)  are the coefficients  of the partial fractions  (k\  is for  scaling). It is 
known that these coefficients  can be evaluated  for  each  / by multiplying both  sides 
of (4.38) by (s -  \iY\  differentiating  {nt -  \  -  k) times with respect to s, and then 
evaluating the resulting expression dXs  — A/. This yields (4.37). Taking the inverse 
"Laplace transform of (4.38) and using the fact that ie[^^^^^n  =  ^!(^-A/)""^^+^^  (refer "
to Table 4.1) results in (4.36). 
When  all n eigenvalues  kt  of A are distinct,  then  cr  =  n, n/  =  1, /  ^  1,...,  n, 
and (4.36) reduces to the expression 
where 
l i m [ ( ^ - A / ) ( ^ / - A ) - ^ ]. 
^At  =  Y.^ie M 
i =  l 
(4.39) 
(4.40) 
Expression  (4.40) can also be derived  directly, using a partial fraction  expansion of 
"(si  -  A)""^  given in (4.38) (verify  this). "
EXAMPLE 4.6.  For (L) we let A 
1] 
0 
-4  -4J 
, for which the eigenvalue Ai 
-2 is 
repeated twice, i.e., ni  =  2. Applying (4.36) and (4.37), we obtain 
Aioe^^^  ^  Ante ht 
- 1  0 
0  1 
e-^^  + 
te 
158 
Linear  Systems 
EXAMPLE  4.7.  For  (L)  we  let  A  = 
by  (the complex  conjugate  pair)  Ai  = 
(4.39) and (4.40), we obtain 
0 
-1 
_i 
2 
for  which  the  eigenvalues  are  given 
+  j( V3/2), A2  =  -i  -  7( V3/2).  Applying 
A^  = 
1 
Ai  +  1  1 
Ai  -  A2 
A2  = 
A2 +  1  1 
-1 
_1 
-J 73 
2 
1 
.73 
. 
^J~3 
-1 
1 
.73 
"-""2  +  ^-2 "
7^ 
^~2 
-1 
1 
2 
7^ 
-^  2  J 
[i.e., Ai  =  A2, where (• )* denotes the complex conjugate  of (•)], and 
e^^  =  Aie^^'  +  A2e^^'  =  Aie^^'  + A\e^*i' 
=  2(Re  Ai)(Re  e^^')  - 
"=  2e-^""^^'  2 "
0 
2(ImAi)(Ime^'') 
1 
273 
1 
75 
-
COS -—t 
[  7^ 
0 
1 
-: 
2J 
1 
• 
~7i 
1 
273. 
sinM.j 
/ 
\ 
The  last  expression  involves  only  real  numbers,  as  expected,  since A  and  e^^ are  real 
• 
matrices. 
EXAMPLE  4.8.  For  (L)  we  let  A  = 
ri  01 
[0 
ij 
for  which  the  eigenvalue  Ai  =  1 is  re-
peated twice, i.e., n\  =  2. Applying  (4.36) and (4.37), we obtain 
Aioe^^^ +  Aute^^^ 
1  0 
0  1 
e'  + 
0  0 
0  0 
te'  =  Ie\ 
This  example  shows  that  not  all  modes  of  the  system  are  necessarily  present  in e^K 
What is present depends in fact  on the number  and dimensions  of the individual  blocks 
of the  Jordan  canonical  form  of A  corresponding  to identical  eigenvalues.  To  illustrate 
this  further,  we  let  for  (L),  A  = 
0  1 
,  where  the  two  repeated  eigenvalues  Ai  =  1 
belong to the same Jordan block. Then e^ 
1  0 
0  1 
e'  + 
0  1 
0  0 
te'. 
Stability  of  an  equilibrium 
In  Chapter  6  we  will  study  the  qualitative  properties  of  linear  dynamical  sys 
tems,  including  systems  described  by  (L).  This  will  be  accomplished  by  studying 
the stability  properties  of  such  systems,  or more  specifically,  the stability 
properties 
of  an  equilibrium  of  such  systems. 
If  0(/, 0, Xe)  denotes  the  solution  of  system  (L)  with  x(0)  ==  Xe, then  Xe is  said 
to  be  an  equilibrium  of  (L)  if  (j){t, 0, Xe)  ^  Xe  for  all  f  >  0.  Clearly,  jc^  =  0  is  an 
equilibrium  of  (L).  In  discussing  the  qualitative  properties,  it  is  often  customary  to 
speak,  somewhat  loosely,  of  the  stability  properties  of  system  (L),  rather  than  the 
stability  properties  of  the  equilibrium  x^  =  0  of  system  (L). 
We  will  show  in  Chapter  6  that  the  following  qualitative  characterizations  of 
system (L) are actually equivalent to more fundamental  qualitative  characterizations 
of the equilibrium  Xe  =  0 of system (L): 
1.  The  system  (L) is said to be stable  if all solutions of (L) are bounded  for  all t  > 
159 
CHAPTER  2: 
Response of 
Linear Systems 
0  [i.e., for  any  solution  (f){t, 0, XQ)  =  (4>i{t, 0, XQ), ...,  4>n{h 0. -^o))^  of  i^)^  there 
exist constants Mi, i  =  I,..  .,n  (which in general will depend on the solution on 
hand)  such that  \(f)i{t, 0, xo)| <  M/ for all t  >  0]. 
2.  The  system  (L)  is  said  to  be  asymptotically  stable  if  it  is  stable  and  if  all  so 
lutions  of  (L)  tend  to  the  origin  as  t  tends  to  infinity  [i.e.,  for  any  solution 
4>{t, 0, XQ)  =  {4>\{t, 0, xo),..., (l)n{t, 0, xo)Y  of (L), we have lim^_^oo 4>i{t, 0, xo)  = 
0,i  =  1,...,^]. 
3.  The system (L) is said to be unstable  if it is not stable. 
By  inspecting  the  modes  of  (L)  given  by  (4.36),  (4.37)  and  (4.39),  (4.40),  the 
following  stability criteria for  system (L) are now  evident: 
1.  The  system  (L) is asymptotically  stable  if  and  only  if  all eigenvalues  of A  have 
negative real parts (i.e.. Re Xj  <0,  j  =  1,...,  a). 
2.  The system (L) is stable if and only if Re A^ <  0, j  =  1,..., a,  and for all eigen 
values with Re Xj  =  0 having multiplicity  HJ >  I,  it is true that 
lim [(s 
k= 
I, 
1.  (4.41) 
3.  System (L) is unstable  if and only if (2) is not true. 
We note  in particular  that  if  Re Xj  =  0  and  nj  >  1, then  there  will  be  modes 
-  1, that  will  yield  terms  in  (4.36)  whose  norm  will  tend  to 
^jkl^y  k  =  0,..  .,nj 
infinity  as ^ ^  oo, unless  their  coefficients  are zero. This  shows  why  the  necessary 
and sufficient  conditions for  stability of (L) include condition  (4.41). 
EXAMPLE  4.9.  The  systems  in  Examples  4.6  and 4.7  are  asymptotically  stable. A 
ro  n 
-1 
[0 
system  (L) with  A 
is  stable,  since the eigenvalues  of A  above are Ai  = 
0, A2 =  - 1.  A system (L) with A 
-1  01 
0  1 
is unstable since the eigenvalues of A are 
1,A2 
-1. The system of Example 4.8 is also unstable. 
Modes: Distinct eigenvalue  case 
When the eigenvalues A/ of A are distinct, there is an alternative way to (4.40) of 
computing the matrix coefficients  A/, expressed in terms of the corresponding  right 
and left  eigenvectors of A. This method offers  great insight in questions  concerning 
the presence or absence of modes in the response of a system. Specifically,  if A has 
n distinct eigenvalues  A^, then 
where 
^At  -X^i  M 
Ai 
ViVi, 
(4.42) 
(4.43) 
where vi  G R^  and {viY  E  R^  are right and left  eigenvectors  of A corresponding to 
the eigenvalue  A/, respectively. 
160 
Linear Systems 
To prove the above assertions, we recall that ( A / /- A)v/  =  0 and v ^ A / /-  A)  = 
O.lf  Q=  [vi,..., Vn], then the v/ are the rows of 
The matrix Q is of course nonsingular, since the eigenvalues A/, /  =  1,...,  n, are 
by  assumption  distinct  and  since the  corresponding  eigenvectors  are linearly  inde 
pendent.  Notice  that  Qdiag[k\,.. 
.,Xn\  =  ^Q  and  that diag[k\,...,  A„]P  =  PA. 
Also, notice that v/Vj  =  5/y,  where 
8ij  = 
1  when  /  =  j, 
0  when  /  T^ j. 
We now have (^/-A)-^  =  [si-Qdiag 
K]r'Q-' 
now take the inverse Laplace transform  of the above expression, we obtain (4.42). 
..., 
=  Sf=iV,vK^-AO-i.Ifwe 
-  Qdiag[(s-X,r\...,(s-Xnr']Q-' 
[\u  ,..,  XnlQ'^T 
=  Q[sl-diag[Xu 
If we choose the initial value x(0)  for (L) to be cohnear with an eigenvector vj of 
A [i.e., x(0)  =  avj  for some real a  ¥=  0], then e^j^ is the only mode that will appear 
in the  solution  cf)  of  (L). This  can  easily  be  seen from  our preceding  discussion.  In 
particular if x(0)  =  aVj,  then  (4.42) and  (4.43) yield 
(/>(^, 0, x(0))  =  e'^'xiO)  =  vivi40)^^^' +  • • • + VnVnX(0)e 
"^""'  -  avie^J' "
(4.44) 
since v/Vy  =  1 when  /  =  y, and v/Vy  =  0 otherwise. 
r-1  1 
0  1 
1  1 
0  2 
EXAMPLE  4.10.  In  (L)  we  let  A  = 
.  The  eigenvalues  of A  are given  by 
M~ 
Ai  =  - 1, A2 =  1 and Q  =  [vi,V2] 
v\V\e^^^  + V2V2e^'^^  =  1  -i 
0 
(a, 0)^, then (pit, 0, x(0))  =  e^^x(0) = a(l, O^e'^  which contains only the mode cor 
responding to the eigenvalue Ai  =  - 1.  Thus, for this particular choice of initial vector, 
the unstable behavior of the system is suppressed. 
• 
^Mfin particular we choose x(0)  =  avi  = 
". Then  e""^' "
0 
1  -i 
0 
Remark 
We conclude  our discussion  of modes  and  asymptotic  behavior by briefly  con 
sidering systems of linear, nonhomogeneous, ordinary differential  equations (4.1) for 
the special case where g(t)  =  Bu{t), 
X =  Ax^  Bu(t\ 
(4.45) 
where B  G R^^^^  ^  - R^  Rm  ^^^  where it is assumed that the Laplace  transform 
of  u  exists.  Taking  the  Laplace  transform  of  both  sides  of  (4.45)  and  rearranging 
yields 
x{s)  =  (si  -  A)-'x(0)  +  (si  -  A)~'Bu(s). 
(4.46) 
By taking the inverse Laplace transform  of (4.46), we see that the solution  cf) is the 
sum of modes that correspond to the singularities or poles of (si  -  A)~ ^ x(0)  and (si  -
A)~^Bu(s).  If  in  particular  (L)  is  asymptotically  stable  (i.e., for  x  =  Ax,  Re Xi  < 
0, /  =  1,..  .,n)  and if u in (4.45) is bounded (i.e., there is an M such that 1^^(01 <  M 
for  all  r >  0, /  =  1,...,  m),  then  it  is  easily  seen  that  the  solutions  of  (4.45)  are 
bounded as well. Thus, the fact that the system (L) is asymptotically stable has reper- 
cussions on the asymptotic behavior of the solution of (4.45). Issues of this type will 
be addressed in greater detail in Chapter 6. 
161 
CHAPTER 2: 
Response of 
Linear Systems 
*2.5 
LINEAR  PERIODIC  SYSTEMS 
We  now  consider  linear  homogeneous  systems  of  first-order  ordinary  differential 
equations 
X =  A(t)x, 
-co  <t  <oo^ 
where A  G  C(R,"  /?""^"")  and "
A(t)  =  A(t  +  T), 
-00  <  ^  <  00, 
(P) 
(5.1) 
for  some T  >  0. We call (P) a. periodic  system  and T a. period  for  system  (P). 
The  principal  result  of  this  section  involves  the  notion  of  the  logarithm  of  a 
matrix, which we introduce in the following  result. 
THEOREM 5.1.  For every nonsingular matrix B there exists a matrix A, called a loga 
rithm ofB,  with the property that 
B. 
(5.2) 
The matrix A is not unique. 
Proof. Let  B  be  similar  to  B.  Then  there  exists  a  nonsingular  matrix  P  such  that 
P-^BP  =  B.  Now  if  e^  =  B,  then  we have  B  =  PBP'^  =  Pe^P'^  =  e^^^~\  It 
follows that PAP'^  is also a logarithm of 5. Therefore, it suffices  to prove the theorem 
when the matrix B is in suitable canonical form. 
Let Ai,..., Ayt denote the distinct  eigenvalues  of B with respective  multiplicities 
ni,..  .,nk.  Without loss of generality, we may assume that B is in the block diagonal 
form 
B = 
r^i 
0 
0 
Hj 
=  OJ  =  h...,  k.  We  note  that  A^  T^ 0, y  = 
where  Bj  =  Ay[/„.  +  (1/\J)NJIN''/ 
l,...,k, 
since  B  is  nonsingular.  Using  the  power  series  expansion  log(l  +  x)  = 
Z^p=i[(-iy^^/p]xP,\x\  <  1,  we  formally  write  A^  =  logBj  =  /„.logAy  + 
log[/,.  +  (l/\j)Nj]  =  InjlogXj  +  X;=d(-^y^'^PWAjy> 
since  7V7  =  0  we 
actually have 
Aj = /„^logA, + X  L ^ / ^ T, 
j  =  i,„„k, 
(5.3) 
where we note that logA^ is defined,  since Xj 7^  0. Now recall that e'°8(i+j:)  =  I +  x. 
Performing  the  same  operations  with  matrices,  we  obtain  the  same  terms  and  there 
162 
Linear Systems 
is  no problem  with  convergence,  since  the  series  (5.3)  for  Aj  =  ^ogBj  terminates. 
Accordingly,  we  obtain  e^J  =  exp(Inj log\j)Qxp{Z.''J~^[(-l)P^^/p](Nj/Xj)P}  = 
\j[Inj  + (Nj/\j)]  = Bj, j  =  1,..., ^. If now we let 
A = 
0 
where Aj  is defined in (5.3), we obtain 
0 
e^i 
.A 
^ 
=  B, 
0 
e^k 
0 
Bk 
which is the desired result. 
We conclude by noting that the matrix A is not unique, since for example, e^^^'^^^^  = 
^A^iTTj  ^  ^A f^j. ^u integers k (where j  =  v - 1 ). 
• 
We are now  in  a position  to  state  and prove one of the principal  results  of  this 
section. 
THEOREM 5.2.  Assume that (5.1) is true and that A E  C{R," /?"">^""). If <|)(0 is a funda "
mental matrix for (P), then so is ^{t  +T),t  EL  R. Furthermore, for every ^  there exists 
a nonsingular matrix P that is also periodic with period T and a constant nXn  matrix R, 
such that 
^(0  =  P{t)e'^. 
Proof. Let ^(0  =  ^(?  + T\t  E  R. Since i>(0  =  A(t)^(t\  t  E  R, we have ^ (0  = 
4)(^ + 7)  =  A(t + T)^(t  + r)  =  A{t)<i>(t + T),tE  R. Therefore, ^  is also a solution 
of ^  =  A(0^, A(t)  = A{t + T\t  E R. Furthermore, since ^{t  + T) is nonsingular for 
all t E R/ii  follows that ^  is a fundamental matrix for (P). Therefore, by Theorem 2.5, 
there exists a nonsingular matrix C such that ^{t  + T)  = ^{t)C,  and by Theorem 5.1, 
there exists a constant matrix R such that e^^  =  C. Therefore, 
Defining P by 
^(t  + T)  =  ^(t)e TR 
P(t)  =  ^(0^  -tR 
(5.4) 
(5.5) 
and using (5.4) and (5.5), we now obtain P{t + T)  = ^(r  +  T)e-^^-^^^^  = ^{t)e^^  X 
^-(t+T)R  ^  (^(t)e-tR =  p{t).  Therefore,  P{t)  is  nonsingular  for  dll t  E  R  and  it  is 
periodic. 
• 
The above result allows us to conclude that the determination  of a  fundamental 
matrix  O for  system  (P)  over  any  time  interval  of  length  T  leads  at  once  to  the 
determination  o/O  over (-oo, oo). To show this, assume that ^(t)  is known only over 
the interval  [^o. to>  -^T],  Since ^(t  + T)  =  ^(t)C,  we obtain by setting t  =  to,C  = 
0(^)~iO(ro  +  T)  and  R  =  T~^ log C. It follows  that  P(t)  -  $(0^~^^  is now  also 
known  over  [to, to -\-  T].  However,  P(t)  is periodic over (-00,00). Therefore,  4>(0 is 
givenover  (-00, 00) by $ (0  =  P(t)e^^. 
Next,  let  0  be  any  other  fundamental  matrix  for  (P)  with  A(t)  =  A(t  +  T). 
^(t)e^^, 
Then O  =  $5  for  some constant nonsingular matrix S. Since ^(t  +  T)  = 
163 
CHAPTER  2: 
Response of 
Linear Systems 
we have that ^(t  + T)S  =  Mt)Se'^^,  or 
(5.6) 
This  shows  that  every fundamental  matrix  O  of(P)  determines  a matrix  Se^^S~^ 
that is similar  to the matrix  e^^. 
Conversely,  let S be  any  constant  nonsingular  matrix.  Then  there  exists  a  fun 
damental matrix of (P) such that Eq. (5.6) holds. Therefore, even though $  does not 
determine  R  uniquely,  the  set  of  all  fundamental  matrices  of  (P),  and  hence  of A, 
determines  uniquely  all parameters  associated  with  e^^  that  are  invariant  under  a 
similarity transformation. In particular the set of all fundamental  matrices of A deter 
mines a unique set of eigenvalues  of the matrix  e^^,  denoted by Ai,..., A„, that are 
called the Floquet  multipliers  associated with A. Note that none of these vanish, since 
nf=i  A/  =  dete^^  #  0. The eigenvalues of P are called the c/z^rac^^mr/c ^x/76>/i^n/5'. 
Next, we let 2  be a constant nonsingular matrix that transforms R into its Jordan 
canonical form,  i.e., /  ^  Q~^RQ,  where 
/  = 
Jo 
0 
0 
/i 
0 
0 
Now let O  =  <i>Q and let P  =  PQ.  In view of Theorem 5.2, we have that 
^ (0  -  P{t)e'\ 
Pit)  =  Pit  +  T). 
(5.7) 
Let the eigenvalues of R be denoted by p i , . . .,  p^. Then 
0 
0 
e'^' 
0 
JJ 
0 
0 
e'P' 
0 
0 
e'P^ 
0 
0 
ptJs 
0 
0 
e'Pi 
O^JO 
= 
where 
and 
' 
^ 
jJi 
_ 
Jpq^i 
0  1 
2 
t 
(n -  1)! 
fn-2 
in -  2)! 
0  0  0 
1 
i  = 
l,...,s, 
q  + ^rt 
i=l 
-=  n. 
Now  A;  =  e^P'. Therefore,  even  though  the  p,  are  not  uniquely  determined,  their 
"real  parts  are.  It  follows  from  (5.7)  that  the  columns  4>\>--->4>n  of  ""J* are  linearly "
independent  solutions  of  {P).  Let  pi,...,  p„  denote  the  periodic  column  vectors 
164 
Linear Systems 
of P.  Then 
01 (0  =  e^'^piit) 
hit)  =  e'P^p2(t) 
4>q{t)  =  e'P^Pqit) 
4>q+\{t)  =  e'P^-'pg+i(t) 
4>q+2(t)  =  e'P^-'(tPg+i(t)  + Pq+2(t)) 
(5.8) 
^q-,n(t)  = e''^-^ 
(^  -  iyPq+l(t)  +  •••  +  tpg+r,-l(t)  + Pq+r,(t) 
4 - r,  + l (0  =  e'P^-^ Pn-rs +  l(t\ 
fVs-l 
4>n(t) 
otPq+s 
Pn-rs + l(0  +  • • • +  tpn-\{t)  +  pnit) 
(rs -  1)! 
From  (5.8)  it  is  easy  to  see  that  when  Re pt  — at  <  0,  or equivalently,  when 
|A/| <  1, there exists a A:, >  0 such that \h(t)\  <  kie^'^^''^^^ ->  0 as f ^  oo. This shows 
that if the eigenvalues  pu i  =  I,...,  n, of R have negative real parts, then any norm 
of any solution of (P) tends to zero as ^ -^  -\-^ at an exponential  rate. 
From  (5.5),  we  can  easily  verify  by  direct  computation  that  AP  -  P  =  PR. 
Accordingly, for the  transformation 
X =  Pit)y, 
(5.9) 
we  obtain  x  =  A(t)x  =  A(t)P(t)y  =  P(t)y  +  P(t)y  =  (d/dt)[P(t)y]  or  j  = 
P~\t)  X [A(t)P(t)  -  P(t)]y  =  p-\t)[P(t)R]y 
=  Ry.  In  other  words,  the  trans 
formation  (5.9) reduces  the linear, homogeneous,  periodic  system  (P)  to the  system 
y  =  Ry,  a linear  homogeneous  system  with  constant  coefficients. 
We conclude this section with a specific  example. 
EXAMPLES.1.  Consider the scalar system 
X =  -(sin/  + 2)x 
(5.10) 
Then A(t)  =  -(sin/  + 2), and A(t)  is periodic  with period  T  =  ITT. A  fundamental 
matrix for (5.10) is given by 0(0  =  exp(cosr  -  1 -  2/) as can be verified  by substi 
tuting into the relation i>(0  =  A(t)^(t).  Letting t  = 0 and T  =  ITT in (5.4), we obtain 
"0(27r)  -  ^""^^  =  0(0)^^''^  =  e^""""^  or R  =  - 2. The equivalence matrix P(t) is now "
given by (5.5) as P{t) =  exp (cos t - l-  2t)e^^  = e^^^^~^, which is clearly periodic with 
period  T  =  ITT. The given system (5.10) is transformed  by P{t) into the system y  = 
(^i-^«^0[(-l)(sin/  + 2)^'^°^^-i  + smte''''''-^]y  =  -(e^-^^'')(2e'''''-^)y  =  -2y  =  Ry. 
We will address some of the qualitative properties of periodic systems in  further 
detail in Chapter 6. 
2.6 
STATE EQUATION  AND  INPUT-OUTPUT  DESCRIPTION 
OF  CONTINUOUS-TIME  SYSTEMS 
165 
CHAPTER 2: 
Response of 
Linear Systems 
This section consists of three subsections. Using the material of the preceeding  sec 
tions of this chapter,  we first study the response  of Hnear continuous-time  systems. 
Next, we examine transfer functions  of Unear time-invariant systems, given the state 
equations of such systems. Finally, we explore the equivalence of internal represen 
tations of systems. 
A.  Response  of Linear  Continuous-Time  Systems 
Returning  now to Sections  1.1  and  1.14,  we consider  once more systems  described 
by linear time-varying  equations of the  form 
X =  A(t)x  -h  B(t)u 
y  =  C(t)x  -h  D(t)u, 
(6.1a) 
(6.1b) 
where  A  G  C(R,"  R'""'""'')", B  G  C(R,  /?^><^), C  G  C(R,  RP''''\  D  G  C(R,"  RP""""""^)",  and 
u  : R-^  R^  is  assumed  to be  continuous  or piecewise  continuous.  We recall  that 
in  (6.1a)  and  (6.1b), x  denotes  the  state  vector,  u denotes  the  system  input,  and  y 
denotes the system output. From Section  1.14  we recall that for  given initial condi 
tions ^0 ^  R> ^(to)  =  XQ  E:  R^  and for  a given input u, the unique solution of  (6.1a) 
is given by 
(l)(t, to, xo)  =  0(r,  to)xo + 
^(t, 
s)Bis)u(s)ds 
(6.2) 
for t  E:  R, where O denotes the state transition matrix of A(0. Furthermore, by sub 
stituting  (6.2)  into  (6.1b), we  obtain  [as in  (14.6)  of  Chapter  1], for  all  t  G  R,  the 
total system  response  given by 
y(t)  =  C(t)^(t,  to)xo +  C(t) 
Jto 
0(^, s)B(s)u(s)ds  +  D(t)u(t). 
(6.3) 
Recall  that the total response  (6.3)  may  be viewed  as consisting  of the  sum of two 
components, the zero-input  response  given by the term 
il/(t, to, Xo, 0)  =  C(t)<^(t, to)xo 
(6.4) 
and the zero-state  response  given by the term 
p(t, to, 0, u)  =  C{t) 
^{t,  s)B(s)u(s)ds 
-h D(t)u(t). 
(6.5) 
Jto 
The cause  of the former  is the initial  condition  xo  [and  can be  obtained  from  (6.3) 
by letting u(t)  =  0], while for the latter the cause is the input u [and can be obtained 
by setting  XQ  =  0 in  (6.3)]. 
The  zero-state  response  can  be  used  to  introduce  the  impulse  response  of  the 
system  (6.1a),  (6.1b). Returning  to  Subsection  1.16C,  we  recall  that  by  using  the 
166 
Linear Systems 
Dirac delta distribution  S,  we can rewrite (6.3) with  XQ  =  0 as 
y(t)  =  f  [C(tmt,  T)B(T)  + D(t)8(t  -  T)]u(T)dT 
Jto 
=  [  H(t,T)u(T)dT, 
Jto 
(6.6) 
where H(t,  r) denotes the impulse response matrix of system (6.1a), (6.1b) given by 
H{t, T) 
[  C(t)<^(h  T)B{T)  +  D{t)8{t  -  r), 
[0, 
t^  T, 
t<  T. 
(6.7) 
When in (6.1a), (6.1b), A{t)  =  A, B(t)  =  B, C(t)  =  C, and D(t)  =  D, we obtain 
the time-invariant  system 
X =  Ax  +  Bu 
y  =  Cx  -^ Du. 
We recall that in this case the solution of (6.8a) is given by 
(6.8a) 
(6.8b) 
(6.9) 
the total  response  of system (6.8a), (6.8b) is given by 
y{t)  =  Ce'^^'-'^ho  +  C  [  e^^'-'^Bu{s)ds  +  Du{t\ 
(6.10) 
and  the  zero-state  response  of  (6.8a),  (6.8b)  is  given  by  ^(0  =  /^^[C^^^^~'^^B+ 
\l  H{t,T)u{T)dT  =  1^ H(t  -  T)u(T)dT,  where  the  impulse 
D8(t  -  T)]u(T)dT  - 
response  matrix  H of system (6.8a), (6.8b) is given by 
Ce^^'-^^B  +  D8(t  -  r), 
0, 
or, as is more commonly  written, 
H(t  -T)  = 
t^ 
r, 
t  <T, 
H(t)  = 
Ce^'B  +  D8{t\ 
0, 
t>  0, 
^ < 0. 
(6.11) 
(6.12) 
At this point it may be worthwhile to consider  some specific  cases. 
EXAMPLE  6.1.  In (6.1a), (6.1b), let 
A{t)  = 
-1 
^2n 
€' 
0 
-1 
B{t)  =  0 
C(0  =  [e\ 1], 
D  =  0 
and  consider  the  case  when  t^  =  0, x(0)  =  (0, 1)^, u is  the  unit  step  function,  and 
r >  0. Referring to Example 3.6, we obtain (p(t, to, XQ) = (f)h{t, t^, XQ)  + (j)p{t, to, xo) = 
2 {e'  - 
with  ^  =  0 and  for  ^ >  0. The  total system response  y(t)  = 
€-') 
te-' 
0 
C(t)x(t)  is  given  by the  sum of the  zero-input  response  and  the zero-state response, 
y(t, to, Xo, u)  = il/(t, to, Xo, 0) + p(t, to, 0, u)  =  [\{e'^^ -  1) + e~^] + t,t>  ^. Note that the 
zero-input response ip is due to the homogeneous part of the solution 4>  (given by (f)h) 
while  the zero-state  response  p  is  due to the particular  solution  of (/> (given  by (/)p). 
EXAMPLE  6.2.  In  (6.8a),  (6.8b),  let  A 
[o  o} ^ - [y 
C  =  [0,1],  D  =  0  and 
consider  the  case  when  to  =  0, x(0)  =  (1, - 1 ) ^,  u is the unit  step, and  t  >  0. We  can 
easily compute the solution of (6.8a) as 
167 
CHAPTER  2: 
Response of 
Linear  Systems 
(/)(^, to,  Xo)  =  (t)h(t,  to,  Xo)  +  (l>p(t, to,  Xo)  = 
n -^1 
-1  + 
^t^ 
with ^0 =  0 and for ? >  0. The total system response y(t)  =  C(t)x(t)  is given by the sum 
of  the  zero-input  response  and  the  zero-state  response,  y(t,  to, xo, u)  =  il/(t, to, xo, 0)  + 
p(t, to,0,u)=-l-\-t,t>0. 
• 
We  note  that  when  x(0)  =  0,  Example  6.1  (a time-varying  system)  and  Exam 
ple  6.2  (a time-invariant  system)  have  identical  output  responses  given  by  y(t)  =  t, 
r  >  0,  when  u(t)  is the  unit  step.  [Is this  true  for  any  input  u(t)l] 
EXAMPLE6.3.  Consider the time-varying  system given above in Example 6.1. In this 
case we have 0(?, T)B(T)  =  [e~\  0]^, and the impulse response has the rather  unusual 
form 
Hit,  T)  = 
C{t)^{t,  T)B(T)  =  1, 
0, 
t^ 
T, 
t<T. 
In other words, the response of this system to an impulse input, for zero initial conditions, 
is the unit  step,  and  this  is  independent  of the  time  r  at which  the  impulse  is  applied! 
Note that in the present case the response to a step is a ramp  t, as can easily be  verified 
from  (6.6) (see also Example 6.1). Therefore,  this system behaves to the outside  world, 
for  zero initial conditions, as a time-invariant  system. This is interesting; however, it is 
• 
not a typical  situation when dealing with time-varying  systems. 
EXAMPLE  6.4.  Consider  the time-invariant  system  given  above in Example  6.2. It is 
easily verified  that in the present  case 
(^(t)  =  e^'  = 
n  ^1 
0  1 
Then H(t,  r)  =  Ce'^^'-^'^B =  I  for t  >  r  and H{t,  r)  =  OfoYt< 
r.  Thus, the  response 
of this system to an impulse input for zero initial conditions is the unit step.  Comparing 
this with the impulse response of the system given above, in Example 6.3, we note that 
they are identical. In other words, the behavior of these two systems to the outside world, 
one a time-varying  system and the other a time-invariant  system, is characterized by the 
same response to an impulse input, when the initial conditions are zeros. Indeed, in this 
case,  both  systems  behave  like  a time-invariant  system  with  H(t,  r)  =  H(t  -  r, 0)  = 
H(t,  0)  =  1. Note, however, that when the initial conditions  are not zero, the  responses 
of these two systems are quite different. 
• 
finite-dimensional 
The  preceding  two  examples  demonstrate,  as  one  might  expect,  that  external 
descriptions  of 
linear  systems  are  not  as  complete  as  internal  de 
scriptions  of  such  systems.  Indeed,  the  utility  of  impulse  responses  is  found  in  the 
fact  that  they  represent  the  input-output  relations  of  a  system  quite  well,  assuming 
that  the  system  is  at  rest.  To  describe  other  dynamic  behavior,  one  needs  in  general 
additional  information  [e.g., the initial  state vector  (or perhaps  the past history  of  the 
system  input  since  the  last  time  instant  when  the  system  was  at  rest)  as  well  as  the 
internal  structure  of  the  system]. 
Internal  descriptions,  such  as  state-space  representations,  constitute  more  com 
plete descriptions than external descriptions. However,  the latter are simpler to  apply 
168 
Linear Systems 
than the former.  Both types  of representations  are useful.  It is quite  straightforward 
to obtain external descriptions  of systems from  internal descriptions, as was demon 
strated in this  section. The reverse process, however, is not quite as  straightforward. 
The process of determining  an internal  system description  from  an external descrip 
tion  is called  realization  and  will be  addressed  in  Chapter  5.  The principal  issue  in 
system realization is to obtain minimal order internal descriptions that model a given 
system, avoiding the generation of unnecessary  dynamics. 
B. Transfer  Functions 
Next,  if  as in  (16.51)  in  Chapter  1, we take the Laplace  transform  of both  sides of 
(6.12), we obtain the input-output  relation 
y{s)=H{s)u{s). 
(6.13) 
We recall  from  Section  1.16  that H{s)  is called  the  transfer function  matrix  of 
system  (6.8a),  (6.8b).  We  can  evaluate  this  matrix  in  a  straightforward  manner  by 
first taking the Laplace transform  of both sides of (6.8a) and (6.8b) to obtain 
sx{s) - x ( 0)  =Ax{s)  +Bu{s) 
y{s)  =  Cx{s)  +Du{s). 
Using (6.14) to solve foxx{s),  we obtain 
x{s)  =  {sI-A)-^x(Qi)  + 
{sI-A)-^Bu{s). 
Substituting  (6.16) into (6.15) yields 
y{s)  = C{sl-A)-^x{0) 
^C{sI-A)-^Bu{s) 
+Du{s) 
and 
y{t)  = ^~^y(s)  = C/'jc(0)  +C  / 
Jo 
e^^'-'^Bu(s)ds^Du(t), 
as expected. 
(6.14) 
(6.15) 
(6.16) 
(6.17) 
(6.18) 
If  in  (6.17)  we  let x(0)  =  0,  we  obtain  the  Laplace  transform  of  the  zero-state 
response given by 
y{s)  = 
[C{sI-A)-^B^D]u{s) 
=  H{s)u{s), 
where H{s)  denotes the transfer  function  of system (6.8a), (6.8b), given by 
H{s)=C{sI-A)-^B^D. 
(6.19) 
(6.20) 
Recalling that ^[e^^]  =  O(^)  =  {si—A)  ^ [refer to (4.32)], we could of course have 
obtained (6.20) directly by taking the Laplace transform  of H{t)  given in (6.12). 
EXAMPLE 6.5.  In Example 6.2, let ^o = 0 and x(0) = 0. Then 
H{s) = C{sI-A)-^B  + D =  [0,"1] '  "" "
rl 
s 
^[0,1] 
l1 
1 
s 
and H{t)  = ^ 
^H{s) =  1  for ^ > 0, as expected (see Example 6.2). 
169 
CHAPTER  2: 
Response of 
Linear Systems 
Next, as in Example 6.2, let x(0)  =  (1,-1)^ and let u be the unit step. Then y(s)  = 
C(sl  -  A)-ix(O) + H(s)u(s)  =  [0, 1/^](1, -1)^ + (l/s)(l/s)  =  -1/s  + 1/s^ and y(t)  = 
• 
^~^[y(s)]  =  -1  + ^ for / >  0, as expected (see Example 6.2). 
We note  that  the  eigenvalues  of  the  matrix A  in  Example  6.5  are  the  roots  of 
the  equation  det  (si  -  A)  =  s'^ =  0,  and  are  given  by  ^-i  =  0, ^2  =  0,  while  the 
transfer function  H(s)  in this example has only one pole (the zero of its denominator 
polynomial), located at the origin. It will be shown in Chapter 5 (on realization) that 
the poles  of  the  transfer function  H(s)  (of  a  SISO  system)  are  in  general  a  subset 
of  the  eigenvalues  of A.  In  Chapter  3  we  will  introduce  and  study  two  important 
system theoretic concepts, called controllability  and observability.  We will show in 
Chapter  5 that  the eigenvalues  of A are precisely  the poles  of the transfer  function 
H(s)  =  C(sl  -  Ay^B  + D if and only if the system (6.8a), (6.8b) is observable and 
controllable. This is demonstrated  in the next example. 
r 
,5  = 
-2^ 
EXAMPLE 6.6.  In (6.8a), (6.8b), let A = 
0' w  C  =  [-3,3],/)  =  0. 
The eigenvalues ofA are the roots of the equation J^r (5/-A)  =  s^ + 2s+l  =  (^+1)^  = 
0 given by ^i  =  - 1,  5*2  =  - 1,  and the transfer function of this SISO system is given by 
0 
[-1 
H(s)  = C(sl-A)-^B  + D  = 
[-3,3]^ s 
. - 11 
_. 
-1 
1  ^ + 2 
=  3 [ - l , l] 
1 
(S  +  1)2 
5 + 2  1 
-1 
s 
3(s -  1) 
(S+ 
1 ) 2' 
with poles (the zeros of the denominator polynomial) also given by si 
-1,^2  = - 1. 
If  in  Example  6.6  we  replace  B  =  [0, 1]^ and  D  =  0  by  B  = 
and 
D  =  [0, 0], then we have a multi-input  system whose transfer  function  is given by 
H(s)  = 
' 3 ( ^ - 1) 
(S+  1)2^(^+1) 
3 
The concepts  of poles and  zeros for  MIMO  systems  (also called  multivariable  sys 
tems)  will be introduced  in Chapter 4. The determination  of the poles  of  such  sys 
tems  is  not  as  straightforward  as  in  the  case  of  SISO  systems.  It  turns  out  that  in 
the  present  case  the  poles  of  H(s)  axe si  =  -1,S2  =  - 1, the  same  as  the  eigen 
values of A. 
Before proceeding to our next topic, the equivalence of internal representations, 
an observation concerning the transfer  function  H(s)  of system (6.8a), (6.8b), given 
by (6.20), H(s)  =  C(sl  — A)~^B  +  D is in order. Since the numerator matrix poly 
"nomial  of  (si  —  A)""^  is of degree  (n  -  1) (refer  to Subsection  2.1G)", while its de 
nominator  polynomial,  the characteristic  polynomial  a(s)  of A, is of degree  n, it is 
clear that 
\im H(s)  =  D, 
a real-valued mXn  matrix, and in particular," when the  ''direct link matrix""  D in the "
output equation  (6.8b) is zero, then 
lim^(^)  =  0, 
170 
Linear Systems 
the m X n matrix with zeros as its entries. In the former case (when D 7^  OorD  =  0), 
^(^)  i^ ^^^^ ^^ ^^  di proper  transfer function,  while in the latter case (when D  =  0), 
H(s)  is said to be a strictly proper  transfer  function. 
When discussing the realization of transfer functions by state-space descriptions 
(in  Chapter  5), we  will  study  the  properties  of  transfer  functions  in  greater  detail. 
In this connection,  we will also encounter  systems that can be described by  models 
corresponding to transfer functions H(s)  that are not proper  The differential  equation 
representation  of a differentiator  (or an inductor)  given by  y(t)  =  (d/dt)u{t)  is one 
such example. Indeed, in this case the system cannot be represented by Eqs. (6.8a), 
(6.8b) and the transfer  function,  given by H(s)  =  s is not proper. Such systems will 
be discussed in Chapter 7. 
C.  Equivalence  of Internal  Representations 
In  Subsection  2.4B  it  was  shown  that  when  a  linear,  autonomous,  homogeneous 
system  of  first-order  ordinary  differential  equations  i  =  Ax  is  subjected  to an  ap 
propriately  chosen  similarity  transformation,  the resulting  set  of  equations  may  be 
considerably  easier to use  and may  exhibit  latent properties  of the  system  of  equa 
tions. It is therefore natural that we consider a similar course of action in the case of 
the linear systems (6.1a), (6.1b) and (6.8a), (6.8b). 
We begin by considering  (6.8a), (6.8b) first, letting 
X =  Px, 
(6.21) 
where P  is a real, nonsingular matrix (i.e., P is a similarity transformation).  Consis 
tent with what has been  said thus far,  we see that  such transformations  bring  about 
a change  of basis  for  the state space of system  (6.8a), (6.8b). Application  of  (6.21) 
to this  system will result,  as will be  seen, in a system description  of the  same  form 
as (6.8a), (6.8b), but involving different  state variables. We will say that the  system 
(6.8a), (6.8b), and the system obtained by subjecting (6.8a), (6.8b) to the transforma 
tion  (6.21), constitute  equivalent  internal  representations  of an underlying  system. 
We will  show that equivalent  internal representations  (of the same system)  possess 
identical  external  descriptions,  as  one  would  expect,  by  showing  that  they  have 
identical  impulse responses  and transfer  function  matrices. In connection  with  this 
discussion,  two  important  notions  called  zero-input  equivalence  and  zero-state 
equivalence  of a system will arise in a natural  manner. 
If  we  differentiate  both  sides  of  (6.21),  and  if  we  apply  x  =  P~^x  to  (6.8a), 
(6.8b), we obtain the equivalent internal representation  of (6.8a), (6.8b) given by 
where 
A  =  PAP-\ 
B  =  PB, 
C  =  CP-\ 
D  =  D 
k  =^  Ax  + Bu 
y  =  Cx  + Du, 
(6.22a) 
(6.22b) 
(6.23) 
and where x is given by (6.21). It is now easily verified that the system (6.8a), (6.8b) 
and  the  system  (6.22a),  (6.22b)  have  the  same  external  representation.  Recall  that 
for  (6.8a), (6.8b) and for  (6.22a), (6.22b), we have for the impulse  response 
H(t,  T)  ^  Hit  -  T," 0)  =  { ^'""""""'^ "
+  ^^(' 
-  ^)' 
;  J  ;> 
(6.24) 
and 
H{t,  r)  =  H{t  -  r, 0) 
C^ia-T)^  +  D8(t  -  T), 
0, 
(6.25) 
t  <  T. 
Recalling from  Subsection  2.4B  [see Eq. (4.13)] that 
p^A(t-T)p-l 
^A(r-T)  ^ 
(6.26) 
171 
CHAPTER  2: 
Response of 
Linear Systems 
weobtainfrom  (6.23) to (6.25) that C^^~^^-^)B+DS(r-T)  = 
CP-^Pe^^'-'^p-^PB^-
DS(t  -T)  =  Ce^^^-'^^B + D8(t  -  r), which proves, in view of (6.24) and (6.25), that 
and this in turn shows that 
H(t,  T)  -  H(t,  T), 
His)  =  H(s\ 
(6.27) 
(6.28) 
This last relationship can also be verified  by observing that^(^)  == C(sl  -  A)  ^  X 
B  -{-  D  =  CP-\sI 
-  A)-^p-^PB  +  D  = 
C(sl  -  A)-^B  +  D  -  H(s). 
-  PAP-^)-^PB  +  D  =  CP-^P(sI 
Next, recall that in view of (6.10) we have for  (6.8a), (6.8b) that 
y(t)  =  Ce^^'-'^^xo  +\  Hit- 
T,0)u(T)dT 
J to 
=  il/(t, to, XQ, 0) +  p(t, to, 0, u) 
(6.29) 
and for  (6.22a), (6.22b) that 
y(t)  =  Ce^^'-'^ho  + 
H(t-T,0)u(T)dT 
=  {{/(t, to, xo, 0) +  p(t, to, 0, u), 
(6.30) 
where ifj and ^  denote the zero-input response of (6.8a), (6.8b) and (6.22a), (6.22b), 
respectively,  while  p  and  p  denote  the  zero-state  response  of  (6.8a),  (6.8b)  and 
(6.22a),  (6.22b),  respectively.  The  relations  (6.29)  and  (6.30)  give  rise  to  the  fol 
lowing  concepts:  Two  state-space  representations  are zero-state  equivalent  if  they 
give  rise  to the  same  impulse  response  (the  same  external  description).  Also,  two 
state-space representations are zero-input  equivalent  if for any initial state vector for 
one representation  there  exists  an  initial  state  vector  for  the  second  representation 
such that the zero-input responses for the two representations  are identical. 
The following  result is now clear:  if two state-space  representations  are  equiv 
alent,  then  they  are  both  zero-state  and  zero-input  equivalent.  They  are  clearly 
zero-state  equivalent  since  H{t, r)  ^  H{t,  r).  Also,  in  view  of  (6.29)  and  (6.30), 
we  have  Ce^^'-'^^xo  =  (CP-^)[Pe^^'-'^^p-^]xo  =  Ce'^^'-'^ho,  where  (6.26)  was 
used. Therefore,  the two state representations  are also zero-input  equivalent. 
The  converse  to  the  above  result  is  in  general  not  true,  since  there  are  repre 
sentations  that  are both  zero-state  and  zero-input  equivalent,  yet not equivalent.  In 
Chapter  5, which  deals  with  state-space  realizations  of  transfer  functions,  we  will 
consider this topic  further. 
EXAMPLE 6.7.  System (6.8a), (6.8b) with 
0 
-2 
1 
- 3. 
B = 
0 
.1. 
C  =  [-1,-5], 
D  = 1 
172 
Linear  Systems 
has the transfer  function 
H{s)=C{sI-A)-^B 
+ D 
Using the similarity  transformation 
- 5 ^ -1 
5^ +  35 +  2 
+  1 
( . - 1 )^ 
(5+l)(5 +  2)' 
1 
-1 
-1 
"1"" "
-2 
2 
-1 
"1"" "
-1 
yields the equivalent representation  of the system given by 
PAP-
B =  PB-
c = cp-
^[4,9], 
and  D  =  D  =  1.  Note  that  the  columns  of  P~^,  given  by  [1,-1]^  and  [1,-2]^,  are 
eigenvectors  of A corresponding  to  the  eigenvalues  Ai  =  —1,^2  =  —2 of A,  that  is,  P 
was chosen to diagonalize A. Notice that A is in companion form so that its characteristic 
polynomial  is  given  by  5^ +  3^ +  2 =  {s-\-1){s-\-2).  Notice  also  that  the  eigenvectors 
given  above  are  of  the  form  [1,A;]^,/  =  1,2.  The  transfer  function  of  the  equivalent 
representation  of the system is now given by 
1 
H(s)  = C{sI-A)-^B  + D =  [4,0]  5 +1 
0 
0 
1 
5 +  2. 
+  1 
- 5 5 -1 
(5+l)(5 +  2) 
+  1 =  H(s). 
Finally, it is easily verified  that e^' 
Pe^'p-K 
From  the  above  discussion  it  should  be  clear  that  systems  [of  the  form  (6.8a), 
(6.8b)]  described  by  equivalent  representations  have identical  behavior  to the  outside 
world,  since both  their  zero-input  and  zero-state responses  are the  same. Their  states, 
however,  are  in  general  not  identical,  but  are  related  by  the  transformation  x{t)  = 
Px{t). 
In the time-invariant  case considered  above, transformation  P preserves the  qual 
itative properties  of the equivalent  representations  of a system,  since in particular,  the 
eigenvalues  of A  and A  are  identical. 
Next,  we  consider  time-varying  systems,  given  by 
x=A{t)x  + B{t)u 
y =  C{t)x  + D{t)u, 
(6.31a) 
(6.31b) 
where  all  symbols  are  defined  as  in  (6.1a),  (6.1b).  Let  P  G C^{R^R^^^)  and  assume 
that P~^  (t)  exists  for  dllt  eR  and  is continuous.  Let 
X =  P(t)x. 
(6.32) 
T\\Qnx  =  P{t)x  + P{t)x= 
+  B{t)udind 
y  =  C{t)P~^{t)x  +  D{t)u  =  C{t)x  +  D{t)u.  These  relations  motivate  the  following 
definition:  the  system 
[P{t)+P{t)A{t)]p-^{t)x 
+ P{t)B{t)u=A{t)x 
x=A{t)x  + B{t)u 
y =  C{t)x  + D{t)u, 
(6.33a) 
(6.33b) 
where x  =  P{t)x,  P  E  C^{R, R^^^),  and P  ^ is assumed to exist and be continuous 
for  all  t  G  R,  and  where  A(t)  =  [P(t)A(t)  +  P(t)]p-\tX  Bit)  =  P(t)B(t),  C(t)  = 
C{t)P~^{t),  bit)  =  D(t),  is said to be equivalent  to the system  (6.31a), (6.31b). 
As in the time-invariant case, the relations between the state transition  matrices 
173 
CHAPTER  2: 
Response of 
Linear Systems 
^{t,  to) and ^(t,  to) for the systems of  equations 
and 
X =  A(t)x 
X =  A(t)x, 
(6.34) 
(6.35) 
respectively,  and the relations between the impulse responses H(t,  r)  and H(t,  r)  of 
(6.31a),  (6.31b)  and  (6.33a),  (6.33b),  respectively,  are  easily  established.  Indeed, 
since  the  solutions  of  (6.34)  and  (6.35)  are  given  by  (pit, to, xo)  =  ^it,  to)xo  and 
4>it, to, Xo)  =  ^(t,  to)xo,  respectively,  we  have  in  view  of  (6.32)  (assuming  that 
P~^  exists  for  all  t  G  R),  P~\t)4>it,  to, xo)  =  ^it,  to)[P~\to)xo]  or  4>it, to, xo)  = 
to)P~^ito)xo.  Since the  solutions  of  (6.34)  and  (6.35)  are unique, we  have 
Pit)^it, 
that 
0(r,T)  = 
Pit)<^it,T)p-\T) 
for  all t,T 
^R, 
"Recalling  that  the  columns  of  a fundamental  matrix  ""^  of  (6.34)  and  a  funda "
mental  matrix  #  of  (6.35)  are  linearly  independent,  it  is  not  hard  to  show,  using 
(6.32), that # (0  -  P ( 0 ^ (0  for  all t  G  R, 
Next,  recalling  that  the  impulse  responses  of  the  equivalent  systems  (6.31a), 
(6.31b) and (6.33a), (6.33b) are given by 
Hit,  T)  = 
Cit)^it,  T)BiT)  +  Dit)8it 
0 
- T ), 
and 
Hit,  T)  ^  J  Cit)^it,  T)BiT)  +  Dit)8it  -T) 
0 
respectively, it is easily  shown that 
Hit,  T)  =  Hit,  T). 
Indeed, we have that 
Hit,  T)  =  Cit)^it,  T)BiT)  +  Dit)8it  -  T) 
t^  T, 
r <  T, 
t^  T, 
t<T, 
=  Cit)p-\t)Pit)^it, 
=  Cit)^it,  T)BiT)  +  Dit)8it  -  T) 
=  Hit,  T) 
T)p-\T)PiT)BiT) 
+  Dit)8it  -  T) 
for t  >  T. 
We conclude by noting that the notions of zero-state  equivalence  and  zero-input 
equivalence  introduced  for  time-invariant  systems  of  the  form  (6.8a),  (6.8b)  carry 
over  without  changes  for  time-varying  systems  of  the  form  (6.31a),  (6.31b).  Fur 
thermore,  identically  to  the  time-invariant  case,  it  can  be  shown  that  in  the  case 
of time-varying  systems, if  two  state representations  [such  as  (6.31a),  (6.31b)  and 
(6.33a), (6.33b)]  are equivalent,  then they are both zero-state and zero-input  equiv 
alent. The converse to this statement, however, is not true. 
174 
Lhi^Systems 
2.7 
STATE EQUATION  AND  INPUT-OUTPUT  DESCRIPTION 
OF DISCRETE-TIME  SYSTEMS 
In this section, which consists of five subsections, we address the state equation  and 
input-output  description  of  Hnear  discrete-time  systems.  In  the  first  subsection  we 
study the response of Hnear time-varying  systems and linear time-invariant  systems 
described  by  the  difference  equations  (1.15.3a),  (1.15.3b)  [or  (1.1.7a),  (1.1.7b)] 
and  (1.15.4a),  (1.15.4b)  [or  (1.1.8a),  (1.1.8b)], respectively.  In  the  second  subsec 
tion  we  consider  transfer  functions  for  linear  time-invariant  systems,  while  in  the 
third  subsection  we address the equivalence  of the internal representations  of time-
varying  and  time-invariant  linear  discrete-time  systems  [described  by  (1.15.3a), 
(1.15.3b) and (1.15.4a), (1.15.4b), respectively]. Some of the most important classes 
of discrete-time systems include linear sampled-data systems that we develop in the 
fourth  subsection. In the final part of this section, we address modes and  asymptotic 
behavior of linear time-invariant  discrete-time  systems. 
A.  Response  of Linear Discrete-Time  Systems 
We now return  to  Section  1.15  to consider  once  again  systems  described  by  linear 
time-varying  equations of the  form 
x(k  +1)  =  A(k)x(k)  +  B(k)u(k) 
y(k)  =  C(k)x(k)  +  D{k)u{k), 
(7.1a) 
(7.1b) 
/?^><^, B  : Z-^  T^^^^," C  : Z-^  RP""""^","  md  D  : Z  ^  RP""""""^.  When "
where  A:Z^ 
A(k)  =  A,B(k)  =  B,C(k)  =  C, and/)(/:)  =  Z), we have systems described by linear 
time-invariant  equations given by 
x(k  +  1)  =  Ax(k)  +  Bu(k) 
y(k)  =  Cx(k)  +  Du(k). 
(7.2a) 
(7.2b) 
We recall that in (7.1a), (7.1b) and in (7.2a), (7.2b), x denotes the state vector, u de 
notes the system input, and y denotes the system output. For given initial conditions 
ko E  Z, x(ko)  =  Xk^ G R^  and for  a given input w, both equations  (7.1a) and  (7.2a) 
possess unique solutions x(k)  that are defined  for  all  k  >  ^o^ and thus, the response 
y(k)  for  (7.1b) and for  (7.2b) is also defined  for all  k  >  ko. 
Associated  with  (7.1a)  is  the  linear  homogeneous  system  of  equations  given 
by 
xik  +  1)  =  A(k)xik). 
We recall from  Section  1.15  that the solution of the initial-value  problem 
x(k+l)  =  A(k)x(k), 
x(ko)  =  Xk, 
(7.3) 
(7.4) 
is given by 
x(k)  =  ^{k,  ko)xk,  =  n  Mj)xk,, 
k  >  ko, 
(7.5) 
where  ^(k,  ko)  denotes  the  state  transition  matrix  of  (7.3)  with 
^(h 
k)  =  I 
(7.6) 
[refer  to  (15.9)  to  (15.12)  in  Chapter  1]. 
Common  properties  of  the  state  transition  matrix  (&(/:, /),  such  as  for  example 
the  semigroup  property  given  by 
175 
CHAPTER 2: 
Response of 
Linear  Systems 
^{k, 
/)  =  0 ( ^,  m)<^(m,  I), 
k>  m> 
I, 
can quite easily be derived from  (7.5), (7.6). We caution the reader, however, that  not 
all  the  properties  of  the  state  transition  matrix  $(f,  r)  for  continuous-time  systems 
X  =  A(t)x  carry  over  to  the  discrete-time  case  (7.3).  In  particular  we  recall  that  if 
for  the  continuous-time  case  we  have  t  >  r,  then  future  values  of the  state  (p at  time 
t  can  be  obtained  from  past  values  of  the  state  cf) at  time  r,  and  vice  versa,  from  the 
relationships  (/)(0  =  ^(t,  T)(f){T)  and  (/)(T)  =^  ^~^{t,  r^t) 
=  0 ( T,  0</>(0.  i-e.,  for 
continuous-time  systems  a principle  of  time  reversibility  exists.  This  principle  is  in 
general  not  true  for  system  (7.3), unless  A~^(k)  exists  for  all  k  G  Z.  The  reason  for 
this  lies  in  the  fact  that  <i>(k,  I)  will  not be  nonsingular  if  A(k)  is not  nonsingular  for 
a l U. 
Associated  with  (7.2a)  is the linear,  autonomous,  homogeneous  system  of  equa 
tions  given  by 
x(k^ 
1)  =  Axik). 
From  (7.5)  it  follows  that  the  unique  solutions  of  the  initial-value  problem 
x(k  +  1)  =  Ax(k\ 
x(ko)  =  Xk^ 
are  given  by 
xik)  =  ^{h  ko)xk,  =  A^'-^'hk^, 
k  ^  ko. 
(7.7) 
(7.8) 
(7.9) 
EXAMPLE  7.1.  In  (7.3),  we  let  ^o  =  0,  and  A(k) 
A(k- 
"1)-""A(0)  = "
\(k  -  1) 
(k-  1)2 +  1 
x(3)  =  A(2)  • A(l)  • A(0)  •  x(0) 
0 
a)'-' 
[2  5 
0 
Ik 
0 
(k^  +  1)1 
a)' 
Then  ^(k,  0) 
If,  for  example,  k  =  3,  then 
x(0) 
"""0 "
0 
x(0).  Given 
x(0),  we  can  now  readily  determine  x(3).  In  view  of  the  form  A(0),  we  have  for  any 
To  xl 
0 
^  >  0,  ^{h  0) 
zero  for  any  k.  Clearly  then,  for  any  initial  condition  x(0)  = 
,  that  is  to  say,  the  first  column  of  0(^, 0)  will  always  be 
a  E  /?,  we  have 
\0] 
x(k) 
for  all 
k>0. 
EXAMPLE  7.2.  In  (7.5), let A  = 
1  0 
0  0 
x(0)  = 
a  E: R.  The initial  state  x(0)  at 
ko  ^  0 for any a  G R will map into the state  x(l) 
. Accordingly, in this case time 
reversibility  will not apply. 
EXAMPLE  7.3.  In  (7.8),  let  A  = 
1  2 
0  1 
.  In  view  of  (7.9)  we  have  that  A^^  ^o^  = 
1 
0 
1 
k  >  ^0,  i.e.,  A^^  ^o)  =  A  when  (k  -  ko)  is  odd,  and 
176 
Linear Systems 
j^(k  kQ)  ^  /when(^-/:o)iseven. Therefore, given ^0 = Oandx(O) 
thQnx(k)  = 
Ax(0) 
,k=  1,3,5,  ...,andx(y^)  -  /x(0) 
, ^  =  2, 4, 6,  ....A  plot of the 
states x(k)  =  [xi(k), X2(k)]^ is given in Fig. 2.3. 
i W| 
I 
x^ik) 
2.OH 
^ 
f 
T 
T 
f  ^-^ 
1.0-
—•- - •- —•- -•— 
0  1 2 3 4 5 6 7 8— 
FIGURE 2.3 
Plots of states for Example 7.3 
1.0 
k 
0 12 
3 45 
6 7 8' 
Continuing,  we  recall  that  the  solutions  of  initial-value  problems  determined 
by  linear  nonhomogeneous  systems  (15.13)  of  Chapter  1 are  given  by  expression 
(15.14). Utilizing (15.13), the solution of (7.1a) for given x(ko)  and  u(k)  is given as 
x(k)  =  ^(k,  ko)x(ko)  +  X  ^(^> J  +  ^)B(jMjX 
k  >  ko, 
(7.10) 
This expression in turn can be used to determine  [as in (15.17) and (15.18) of Chap 
ter  1] the system response for  system (7.1a), (7.1b) as 
y(k)  =  C(kmk, 
ko)x(ko) 
k-\ 
+  ^  C(k)<^(k  j  +  l)B(j)u(j)  +  D{k)u{k), 
k  >  ko, 
y(ko)  =  C(ko)x(ko)  +  D{ko)u(ko). 
(7.11) 
Furthermore,  for  the time-invariant  case  (7.2a),  (7.2b), we have  for  the  system re 
sponse the expression 
y(k)  =  CA^^'-^'hiko)  +  ^  CA^-^J-'^^Bu(j)  +  Du(k), 
k  >  k^, 
k-i 
y(ko)  =  Cx(ko)  +  Du(ko). 
(7.12) 
Since the system  (7.2a), (7.2b) is time-invariant,  we can let  ^Q  =  0 without loss of 
generality  to obtain from  (7.12) the expression 
y(k)  =  CA^x(0)  +  ^  CA^-^J^^^Bu(j)  +  Du(kX 
k  >  0. 
(7.13) 
k-i 
j=o 
As in the continuous-time case, the total system  response  (7.11) may be viewed 
as consisting of two components, the zero-input  response,  given by 
il/(k)  =  C(k)^(k,  kQ)x(kol 
k  >  ko, 
and the zero-state  response,  given by 
k-\ 
p(k) = X  C(kmk,  j + l)B(j)u(j)  +  D(kMkl 
p(ko) 
D(ko)u(koX 
177 
CHAPTER 2: 
Response of 
Linear Systems 
k>  k 
0. 
k  =  ko 
(7.14) 
Finally, in view  of  (16.20)  of Chapter  1, we recall that the  (discrete-time)  unit 
impulse response matrix of system (7.1a), (7.1b) is given by 
r C(k)^(k, 
I + l)B(ll 
H(kJ)  =  loikl 
[0, 
k>U 
k=l 
k<l 
and the unit impulse response matrix of system (7.2a), (7.2b) is given by 
H{kJ)^lD, 
[0, 
k = h 
k<l, 
and in particular,  when /  =  0 (i.e., when the pulse is applied  at time / = 0), 
\  CA k- 'B, 
Hik,0)  = { D, U 
EXAMPLE  7.4.  In (7.2a), (7.2b), let 
k>0, 
k=^0. 
k<0. 
(7.15) 
(7.16) 
(7.17) 
A = 
"0  1"" "
0 - 1. 
B = 
0 
1. ' 
C^  = 
"""11 "
oj 
D  = 0. 
We first determine A^ by using the Cay ley-Hamilton Theorem (Theorem 3.1 of Chap 
ter  2).  To this  end  we  compute  the  eigenvalues  of  A as  Ai  = 0, A2 ^  - 1, we  let 
A^ = /(A),  where  f(s)  = s^, and we let g(s)  = ais  + ao. Then  /(Ai)  == ^(Ai), or 
ao  = 0 and  /(A2)  = gi^i),  or (-1)^  = -ai  + ao. Therefore,  A^ = aiA  + aol  = 
-(-1) 
0 
0 
0,  1,2, 
,k=  1,2,  ...,or A^ 
(-1)' 
8(k) 
0 
(-l)'-'p(k-l) 
(-l)'p(k) 
, where A^ = /, and where p(k) denotes the unit step given by 
p(k) 
1,  k^O, 
0, 
i^ < 0. 
The above expression for A^ is now substituted into (7.12) to determine the response 
y(k) for /: >  0 for a given initial condition x(0) and a given input u(k), ^ >  0. To deter 
mine the unit impulse response, we note that H(k, 0) = 0 for  ^ <  0 and k  = 0. When 
k>0,  H(h  0) = CA'^-^B = (- l)^-^p(k  -  2) for i^ >  0 or H(K 0) = 0 for i^ =  1  and 
H(k  0) = (-1)^-^ for y^  =  2, 3,  .... 
• 
B.  The Transfer  Function  and the  z-Transform 
We assume that the reader is familiar with the concept and properties of the  one-sided 
z-transform  of a real-valued  sequence {f(k)},  given by 
t{f{k)}  = f{z)  = 
J^z-JfU). 
(7.18) 
178 
Linear Systems 
An  important  property  of  this  transform,  useful  in  solving  difference  equations,  is 
given by the relation 
nf(k  + i)} = ^z-^fu  + i) =  ^z O'-i) / ( ;) 
.j=o 
(7.19) 
If we take the z-transform  of both  sides of Eq.  (7.2a), we obtain, in view of (7.19), 
zx(z)  -  zx(0)  =  Ax(z)  +  Bu(z)  or 
-  /(O)]  =  zf(z)  -  zf(0), 
=  zmf(k)} 
x(z)  =  (zl  -  AyhxiO)  +  (zl  -  Ay^Buizy 
(7.20) 
Next, by taking the z-transform  of both sides of Eq. (7.2b), and by substituting  (7.20) 
into the resulting expression, we obtain 
y(z)  =  C(zl  -  Arhx(0) 
+  [C(zI  -  Ay^B  +  D]u{z). 
(7.21) 
The time  sequence  {y{k)}  can be recovered  from  its  one-sided  z-transform  y{z)  by 
applying the inverse  z-transform,  denoted by 2E~^[};(z)]. 
In  Table  7.1  we  provide  the  one-sided  z-transforms  of  some  of  the  commonly 
used  sequences,  and  in  Table  7.2  we  enumerate  some  of  the  more  frequently  en 
countered properties of the one-sided  z-transform. 
The transfer function  matrix H(z)  of system (7.2a), (7.2b) relates the z-transform 
of the output y to the z-transform  of the input u under the assumption that  ;IL:(0)  =  0. 
We have 
where 
H(z)  =  C(zl  -  Ay^B  +  D. 
y(z)  =  H(z)u(zl 
(7.22) 
(7.23) 
To relate H(z)  to the impulse  response  matrix H(k,  /), we notice that ^{d(k 
-
/)}  =  z~K where 8  denotes the discrete-time  impulse  (or unit pulse  or unit  sample) 
defined  in (16.5) of Chapter  1, i.e., 
8{k  -  I) 
1, 
0, 
k  =  U 
k¥^L 
(7.24) 
TABLE 7.1 
Some commonly used z-transforms 
{f(k)},k^^ 
8(k) 
Pik) 
k 
e a' 
(k + 1V 
[(imxk+iy 
acosak  +  bsinak 
'(k + 
DW  />  1 
f(z)  = ^{f(k)} 
1 
1/(1-z-0 
z-V(l - z-')^ 
[z-'il  + 
1/(1-az-') 
1/(1-az-'f 
1/(1-az-'y^' 
[a + z~^(bsina  -  acosa)]/(l  --Iz  ^ cosa  + z ^) 
z-'Wil-z-'f 
TABLE7.2 
Some properties of z-transforms 
Time shift 
—Advance 
Time shift 
—Delay 
Scahng 
Convolution 
Initial value 
Final value 
{/(*)},*  >o 
f(k+l) 
fik  + l) 
fik-l) 
f{k-l) 
/ >1 
l>\ 
km 
lT=om8(k-l) 
= 
/(/)with/(fc)=0 
\imi,^„f{k) 
m* 
8(k) 
k<l 
179 
CHAPTER  2: 
Response of 
Linear Systems 
m 
zf{z)-zm 
z'fiz)-zlUz'-'fii--^) 
z-'f{z)+f(-l) 
z-'f{z)  + 
Kz/a) 
-z{d/dz)fiz) 
f(zmz) 
\im,^„  z'fizY 
lim,^i(l-z-i)/(z)tt 
l!i=iZ-'+'f{-i) 
^ If the limit exists. 
• ' • t i f ( i - ^ - i^ 
- z  ^ )f{z)  has no singularities on or outside the unit circle. 
This implies that the z-transform  of a unit pulse applied at time zero is ^  { 5 (^)} =  1. 
It is not difficult  to see nov^ that {H{k, 0)}  =  ^~^  [y{z)], v^here y{z)  = H{z)u{z)  with 
u{z) =  1. This shows that 
^-\H{z)] 
=  ^-\C{zJ-A)-^B 
+ D\={H{k,Qi)}, 
(7.25) 
where the unit impulse response matrix H{k^ 0) is given by  (1.11). 
The  above  result  can  also  be  derived  directly  by  taking  the  z-transform  of 
{H{k,0)}  given  in  (7.17)  (prove  this).  In  particular,  notice  that  the  z-transform  of 
{A^-^},k=  1,2,...  is  (zI-A)-^ 
since 
z 
- 1/ 
\I 
-1 
z  -A + z  ^A 
2A2  + •••) 
• 
z-Hl-z-'A) 
= 
{zI-A)-
-1 
(7.26) 
1 + A + A^  +  ---  was 
Above, the matrix  determined  by the expression  (1 — A)~^ 
used.  It is easily  shown that the corresponding  series involving A  converges.  Notice 
also that  ^{A^},k  =  0,1,2,...  is z{zl  — A)~^.  This fact can be used to show that the 
inverse z-transform  of (7.21) yields the time response (7.13), as expected. 
We conclude this subsection with a specific  example. 
EXAMPLE 7.5.  In system (7.2a), (7.2b), we let 
C=[1,0], 
D = 0. 
To verify that ^  ^[z{zl — A)  ^]  = A^, we compute 
1 
""" "
z(zi-Ay 
-1 
z +1 
= 
z(z+l) 
1 
zTT  . 
180 
Linear Systems 
and 
or 
-'[z{zI-Ar']  U  ^  8(k) 
0 
(-lY-'p(k-l) 
{-l)'p(k) 
A'  = 
1  0' 
0  1 
0 
0 
(-1)^-^ 
(-1)^ 
when k  = 0, 
when A:  =  1, 2,..., 
as expected from Example 7.4. 
Notice that 
-'[(zI-A)-'] 
1 
z 
0 
1 
z(z + 1) 
1 
z+l 
'' 
8(k -  l)p(k  -  1)  8(k -  l)p(k  -  1) -  (-l)^-^p(k  -  1) 
0 
for 
"""0  0 "
.0  0. 
0 
0 
-(-l)^-i' 
(-i)^-M 
and 
^-i[(z/-A)-i] h  ^ 
(-l)^-^p(k-l) 
and 
1  0 
0  1 
for k  = 1, 
for yl =  2, 3,..., 
which is equal to A^ /: >  0, delayed by one unit, i.e., it is equal to A^~^,  k  =  1,2,..., 
as expected. 
Next,  we  consider  the  system  response  with  x(0)  =  0  and  u(k)  =  p(k).  We 
have 
y(k)  = ^-'[y(z)]  = ^-'[C(zl 
-  AT'B  • u{z)] 
"^""^ "
= 
_  r 0, 
1 
(z +  l)(z -  1) 
z-  1 
z+  1 
\[{i)'-'-{-iY-']p{k-i) 
^  =  0, 
r 0,  k  = 0 
=  lo, 
[l, 
k= 
1,3,5,..., 
k  =  2,A,6,.... 
Note that if jc(0)  =  0 and M(^)  =  6(/:), then 
y{k)  =  %-'[C{zI-A)-'B] 
iRl  ^ 
1 
z{z + 1) 
8{k-\)p{k-\)~{-\f-'p{k-\) 
y^  = 0,1, 
= 
^  I 0, 
which is the unit impulse response of the system (refer to Example 7.4). 
C.  Equivalence  of Internal  Representations 
Equivalent  representations  of linear  discrete-time  systems  are defined  in  a  manner 
analogous to the continuous-time  case. 
181 
CHAPTER  2: 
Response of 
Linear Systems 
For systems (7.1 a), (7. lb), we let ^o denote initial time, we let P(k)  denote a real 
nX  n matrix that is nonsingular for  all  k  ^  ko, and  we consider the  transformation 
jc(^)  =  P(k)x(k).  Substituting  the above into (7.1a), (7.1b) yields the system 
where 
x(k  +  1)  =  Aik)x(k)  +  B{k)u{k) 
y(k)  =  C(k)x(k)  +  D{k)u{k), 
\)A(k)p-\k) 
A{k)  =  P(k  + 
B(k)  =  P(k  +  l}B{k) 
C(k)  =  C(k)p-^ 
D{k)  =  D{k). 
(7.27a) 
(7.27b) 
(7.28) 
We  say  that  system  (7.27a),  (7.27b)  is  equivalent  to  system  (7.1a),  (7.1b)  and  we 
call  P{k)  an equivalence  transformation  matrix. 
If <i>(^, /) denotes the state transition matrix of (7.3) and ^{k,  I) denotes the state 
transition matrix of 
then 
xik  +  1)  =  Aik)x(k), 
Mk,l)  = 
P{k)Mk,l)P~\l), 
(7.29) 
(7.30) 
as can be seen by observing that <J>(^,/)  =  A{k-\)---A{l) 
1)]-••[/>(/  +  1)A(1)P-\1)]  = 
P{k)^{k,l)p-\l). 
= 
[P(k)A(k-l)P-\k-
In a similar manner as above, it can also be shown that 
H{k,  I)  =  H(k,  I), 
(7.31) 
where H(k,  I) and H(k,  I) denote the unit pulse response matrices of systems (7.1a), 
(7.1b)  and  (7.27a),  (7.27b),  respectively.  [The  reader  should  verify  (7.31).]  Thus, 
equivalent  representations  of linear  discrete-time  system  (7.1a), (7.1b)  give rise to 
the same unit pulse response matrix. Furthermore, zero-state  equivalent  representa 
tions and zero-input  equivalent  representations  are defined  for system (7.1a), (7.1b) 
in a similar manner as in the case of linear continuous-time  systems. 
Turning  our  attention  now  briefly  to time-invariant  systems  (7.2a),  (7.2b),  we 
let P denote a real nonsingular  nX  n matrix and we  define 
x{k)  =  Px(k). 
(7.32) 
Substituting  (7.32) into (7.2a), (7.2b) yields the equivalent  system  representation 
where 
A  =  PAP-
x(k  +  1)  =  Axik)  +  Bu(k) 
y(k)  =  Cx(k)  +  Du(k), 
B  =  PB, 
c  = cp-
(7.33a) 
(7.33b) 
(7.34) 
D  =  D. 
We note that the terms in (7.34) are identical to corresponding terms obtained for the 
case of linear continuous-time  systems. 
We conclude by noting that if H(z)  and H(z)  denote the transfer functions  of the 
unit impulse response matrices of system (7.2a), (7.2b) and system (7.33a), (7.33b), 
respectively," then it is easily verified  that H(z)  ="" H(z). "
182 
Linear Systems 
D.  Sampled-Data  Systems 
Discrete-time  dynamical  systems  arise  in  a  variety  of  ways  in  the  modeling  pro 
cess.  There  are  systems  that  are inherently  defined  only  at  discrete  points  in  time, 
and there are representations  of continuous-time  systems  at discrete points in time. 
Examples  of the former  include  digital  computers  and  devices  (e.g., digital  filters) 
where the behavior of interest of a system is adequately described by values of vari 
ables  at  discrete-time  instants  (and  what  happens  between  the  discrete  instants  of 
time is quite irrelevant  to the problem  on hand); inventory  systems  where  only  the 
inventory  status at the end of each day  (or month) is of interest; economic  systems, 
such as banking, where, e.g., interests are calculated  and added to savings  accounts 
at  discrete  time  intervals  only,  and  so  forth.  Examples  of  the  latter  include  simu 
lations  of continuous-time  processes by means  of digital computers, making use of 
difference  equations that approximate the differential  equations  describing  the pro 
cess in question; feedback  control  systems  that  employ  digital  controllers  and  give 
rise to sampled-data  systems  (as discussed further  in the following);  and so forth. 
In  providing  a  short  discussion  of  sampled-data  systems,  we  make  use  of  the 
specific  class  of linear  feedback  control  systems  depicted  in  Fig.  2.4. This  system 
may be viewed  as an interconnection  of a subsystem S\,  called tht  plant  (the  object 
to be controlled)  and a subsystem ^2, called the digital  controller. 
u{t) 
x=A(t)x+ 
B{t)u 
y=  C(t)x+  D(t)u 
y{t  ) 
D/A 
i I 
u 
ik) 
FIGURE 2.4 
Digital control system 
w{l<+^)  = F(k)w(k)  + G{k)  y(k) 
u{k)  = H{k)w{k)  +  Q(k)y(k) 
\ 
A/D 
yik) 
The plant is described by the  equations 
X =  A(t)x  +  B(t)u 
y  =  C(t)x  +  D(t)u, 
(7.34a) 
(7.34b) 
where all symbols in (7.34a), (7.34b)  are defined  as in (6.1a), (6.1b)  and where  we 
assume that ^ >  ^  >  0. 
The  subsystem  ^2  accepts  the  continuous-time  signal  y{t)  as  its  input  and  it 
produces the piecewise continuous-time  signal  u(t)  as its output, where t  ^  to. The 
continuous-time  signal y  is  converted  into  a discrete-time  signal  {y(k)},  k> 
k{)> 
0, k, ko E  Z, by means of an analog-to-digital  (A/D) converter  and is processed  ac 
cording to a control algorithm given by the difference  equations 
w(k  +  1)  =  F(k)w(k)  +  G(k)y(k) 
u(k)  =  H(k)w(k)  +  Q(k)y(k), 
(7.35a) 
(7.35b) 
183 
CHAPTER  2: 
Response of 
Linear Systems 
where  the  w(k),  y{k),  u{k)  are  real  vectors  and  the  F{k),  G{k), H{k),  and  Q{k)  are 
real  matrices  with  a consistent  set  of  dimensions.  Finally,  the  discrete-time  signal 
{u{k)}, ^  >  ^0  — 0.  is  converted  into  the  continuous-time  signal  u by  means  of  a 
digital-to-analog  (D/A) converter. To simplify  our discussion, we assume in the fol 
lowing that ^0 =  t]^^. 
An (ideal) A/D  converter  is a device that has as input a continuous-time  signal, 
in  our  case  j,  and  as  output  a  sequence  of  real  numbers,  in  our  case  {y{k)}, k  = 
k{),  ko +  \,...,  determined by the relation 
y{k)  =  y(tk). 
(7.36) 
In  other  words,  the  (ideal)  A/D  converter  is  a  device  that  samples  an  input  sig 
nal,  in  our  case  y(t),  at  times  toJi,... 
producing  the  corresponding  sequence 
{y(tol  y(hl  •' •}• 
A D/A  converter  is a device that has as input a discrete-time  signal, in our case 
and as output  a continuous-time  signal, in 
the sequence {u{k)}, k  =  ki^,  k^  +  \,..,, 
our case w, determined by the relation 
u{t)  =  u(k), tk^ 
(7.37) 
In other words, the D/A converter is a device that keeps its output constant at the last 
value of the sequence entered. We also call such a device a zero-order  hold. 
k  =  ko, ko -\-  I,,... 
t  <  tk+h 
The  system  of  Fig.  2.4,  as  described  above,  is  an  example  of  a  sampled-data 
system,  since  it involves  truly  sampled  data  (i.e., sampled  signals), making  use of 
an  ideal A/D  converter.  In practice the  digital  controller  ^2 uses digital  signals  as 
variables. In the scalar case, such  signals  are represented  by real-valued  sequences 
whose numbers belong to a subset ofR  consisting of a discrete set of points. (In the 
vector case, the previous statement applies to the components of the vector.) Specif 
ically, in the present  case, after  the  signal  y{t)  has been  sampled,  it must be  quan 
tized (or digitized)  to yield a digital  signal,  since only such signals are representable 
in  a digital  computer.  If  a computer  uses,  e.g.,  8-bit words,  then  we  can  represent 
2^  =  256 distinct levels for a variable, which determine the signal quantization. By 
way of a specific  example, if we expect in the representation  of a function  a  signal 
that varies from  9 to 25 volts, we may choose a 0.1-volt  quantization  step. Then  2.3 
and  2.4 volts  are represented  by two different  numbers  (quantization  levels); how 
ever, 2.315, 2.308, and 2.3 are all represented by the bit combination  corresponding 
to 2.3. Quantization is an approximation,  and for short wordlengths may lead to sig 
nificant  errors. Problems  associated  with  quantization  effects  will not be  addressed 
in this book. 
In  addition  to  being  a  sampled-data  system,  the  system  represented  by  Eqs. 
(7.34)  to  (7.37)  constitutes  a  hybrid  system  as  well,  since  it  involves  descriptions 
given by ordinary differential  equations and ordinary difference  equations. The anal 
ysis  and  synthesis  of  such  systems  can  be  simplified  appreciably  by  replacing  the 
description  of  subsystem  Si  (the  plant)  by  a  set  of  ordinary  difference  equations, 
valid  only  at  discrete  points  in  time  t^,  k  =  0, 1, 2, 
[In  terms  of  the blocks  of 
Fig. 2.4, this corresponds to considering the plant Si,  together with the D/A and A/D 
devices, to obtain  a system  with  input  U(k) and  output  y(k),  as shown  in Fig.  2.5.] 
To accomplish this, we invoke the variation of constants formula in (7.34a) to obtain 
x(t)  =  ^(tJkXh) 
+  I  ^(t,T)B{T)u(T)dT, 
(7.38) 
184 
Linear Systems 
u(k)^ 
D/A  ^(0 
x=A(t)x+ 
B(t)u 
y=  C(t)x+  D(t)u 
y(t)  A/D 
y(k) 
FIGURE 2.5 
System described by (7.40) and (7.43) 
where  the  notation  ^{t,tk,x{tk))  = x{t)  has  been  used.  Since  the  input  u{t)  is  the 
output of the zero-order hold device (the D/A converter), given by  (131),  we obtain 
from  (7.38) the expression 
:^{tk+i)=^{tk+htk)x{tk)-
/ 
Jtj, 
0(f^+i,T)5(T)JT 
u{tk). 
(7.39) 
Since x{k)  =  x{tk)  and  u{k)  =  u{tk), we  obtain  a discrete-time  version  of the  state 
equation for the plant, given by 
where 
x{k^l) 
=A{k)x{k)+B{k)u{k), 
^{tk+i,T)B{T)dT. 
(7.40) 
(7.41) 
Next, we assume that the output of the plant is sampled at instants ?[ that do not 
necessarily  coincide  with  the instants  t^ at  which  the input  to the plant  is  adjusted, 
and we assume that h  <t'i^< f^+i.  Then (7.34) and (7.38) yield 
y{t'k)=c{ti)^it'„tk)x{tk)-
C(t',)f''0{tiT)B{T)d, 
Jth 
u{tk)+D{t'k)u{tk). 
(7.42) 
Defining y{k)  =  y{t'j^, we obtain from  (7.42), 
y{k)=C{k)x{k)  +  D{k)u{k), 
(7.43) 
where 
C{k)  ^ 
C{t',)^{ify) 
D{k)^C{t',) 
f'^{t[,x)B{x)dx 
+  D{t'^. 
(7.44) 
Summarizing,  (7.40)  and  (7.43)  constitute  a state-space representation,  valid  at 
discrete  points  in  time,  of  the  plant  [given  by  (7.34a)]  and  including  the  A/D  and 
D/A devices [given by (7.36) and (7.37); see Fig. 2.5]. Furthermore, the entire hybrid 
system  of Fig. 2.4,  valid  at discrete points in time,  can now be represented  by Eqs. 
(7.40), (7.43), (7.35a), and (7.35b). 
We  now  turn  briefly  to  the  case  of  the  time-invariant  plant,  where  A{t)  = 
A^B{t)  = 5,C{t)  =  C, and D{t)  =  D, and we assume that f/.+i  —tk = T and tj^ — tk =  a 
for alU  =  0,1,2,....  Then the expressions given in (7.40), (7.41), (7.43), and  (7.44) 
assume the  form 
x{k+l)=Ax{k)^Bu{k) 
y{k)=Cx{k)+Du{k), 
(7.45a) 
(7.45b) 
where 
"A  =  €""""",8  = 
„AT  dT\B, 
"C  =  C e ^ ""","  D  -^ij?""-dr  \B  +  D. "
185 
CHAPTER 2: 
Response of 
Linear  Systems 
(7.46) 
If  t[  =  tk,  or  a  = 0,  then  C  =  C  stnd D  =  D. 
In the preceding,  T  is called  the sampling  period  and  1/T  is called  the  sampling 
rate.  Sampled-data  systems  are  treated  in  great  detail  in  texts  dealing  with  digital 
control  systems  and  with  digital  signal  processing. 
EXAMPLE  7.6.  In the control system of Fig. 2.4, let 
A  = 
B  = 
C  =  [1,0], 
D  =  0, 
let T denote the sampling period, and assume that a  =  0. The discrete-time  state-space 
representation  of the plant, preceded by a zero-order hold (D/A converter) and  followed 
by  a  sampler  [an  (ideal)  A/D  converter],  both  sampling  at  a  rate  of  1/r,  is  given  by 
x(k  +  1)  =  Ax(k)  + Bu(k\  y(k)  =  Cx{k\  where 
A  =  „AT -m A^  = 
T  = 
B^[\ 
e^^dr\B  = 
dr 
2 
T 
[1,0]. 
0 
c =^  c 
The transfer  function  (relating  y to u) is given by 
H(z)  =  C(zl  -  Ay^B 
=  [1,0] 
[1,0] 
z -1 
0 
1 
iz-l) 
0 
T^  (z  +  1) 
2 
(z-ir 
1 
2 
T 
(z -  ly 
1 
7^ 
2 
T 
The transfer  function  of the continuous-time  system (continuous-time  description  of the 
plant) is determined  to be H(s)  =  C(sl  -  A)~^B  =  IIs^,  the double  integrator. 
The behavior  of the  system  between  the  discrete  instants,  t,tk  — t  <  tk+i, can  be 
• 
determined by using  (7.38), letting  x(tk)  =  x{k)  and  u(tk)  =  u{k). 
An  interesting  observation,  useful  when  calculating  A  and  B,  is that both can  be 
/-hrA-h(r^/2!)A^H-
-h  • • •  =  X^-=o(T^ 
-
T^(T)BAf 
expressedintermsofasingleseries.  In particular,  A  =  e^^  = 
• • •  =  /  -h  TA'i^iTX  where  ^ ( 7)  =  /  +  (r/2!)A  +  {T^IV.)A^ 
(j  +  l)!)AAThenJ5  -  {\^  e^'dr)B 
^ ( r)  is  determined  first,  then  both  A  and  B  can  easily  be  calculated. 
=  (Z^J=Q{TJ^^IU 
+  iyW)B 
= 
186 
Linear Systems 
EXAMPLE  7.7.  In  Example  7.6,  ^(7)  = I +  TA 
TA^iT)  =  1  T 
0  1 
and B = 7^(7)5 = 
\T^I2 
, as expected. 
1  T 
0  1 
.  Therefore, A = I + 
E.  Modes  and Asymptotic  Behavior  of Time-Invariant  Systems 
As in the case of continuous-time systems, we study in this subsection the qualitative 
behavior  of  the  solutions  of  linear,  autonomous,  homogeneous  ordinary  difference 
equations 
x{k  +  1) = Ax{k) 
(7.47) 
in  terms  of  the modes  of  such  systems,  where A  G R^^^  and  x{k)  G  R^  for  every 
k ^Z^.  From before, the unique solution of (7.47) satisfying  x(0)  =  XQ is given by 
(f>{k, 0, xo)  = A^jco. 
(7.48) 
Let Ai,..., Ao-, denote the a distinct eigenvalues  of A, where A/ with / =  1,..., cr, 
is assumed to be repeated  nt times so that Xr= i ^i  = n. Then 
"det(zI-A) =  f](z-AO""^ "
(7.49) 
i = i 
To introduce the modes for  (7.47), we first derive the  expressions 
A^ = X 
/ =1 
m-i 
/ =  i 
AioXfp{k)  + 2  Auk(k  - ! ) • • • ( / : - /+  l)\t^p(k 
-  /) 
-  X[^^o^'/^(^)  +  ^nfcAf-V(^  -  1) 
i = l 
+  • • • +  Ai^n,"-i)k(k  -l)'""(k-ni "
"+ 2)Af-^""^-iV(^ ""  m + 1)]", 
where 
A.7 = 
1 
II (Hi- 
1 
l-/)!z-.A, 
\im{[(z-Xir(zI-Ar'] U(ni-l-l) 
(7.50) 
(7.51) 
}. 
In (7.51), ['l^^^ denotes the ^th derivative with respect to z, and in (7.50), p(k)  denotes 
the  unit  step  [i.e.,  p(k)  = 0 for fc < 0 and  p(k)  = 1 for fc >  0]. Note  that if an 
eigenvalue A^  of A is zero, then (7.50) must be modified.  In this case, 
fii-i 
^Aul\8(k-l) 
/=o 
(7.52) 
are the terms in (7.50) corresponding to the zero eigenvalue. 
To prove  (7.50), (7.51), we proceed  as in the proof  of (4.36), (4.37). We recall 
that {A^} = '^'^[zizl  -  A)~^] and we use the partial fraction  expansion  method to 
determine  the  z-transform.  In  particular,  as  in  the  proof  of  (4.36),  (4.37),  we  can 
readily verify  that 
( = 1  / = 0 
(7.53) 
where the An  are given in (7.51). We now take the inverse z-transform  of both sides 
of (7.53). We first notice that 
e-1  [z(z-AO-^'+'^]  = 
r'[z-\i  - Xiz-'r^'-^'h  =  f(k - i)p(k - /) 
f(k  -  I) 
0 
for  k> 
I, 
otherwise. 
187 
CHAPTER  2: 
Response of 
Linear  Systems 
"Referring  to Tables 7.1 and 7.2 we note that f(k)p(k)  =  ^""^[(1  -  XiZ'^y^^-^^^]  = "
[l/n(k  +  1) • • • (yfc +  /)]Af  for Ai #  0 and /  ^  1. Therefore, ^-^[llziz 
llf{k-l)p(k-l) 
"A/z""^)~^]  =  Af.  This  shows that (7.50) is true when  A", #  0. Finally, if A,  =  0, we 
note that ^-^[l\z~^]  =  l\8(k  -  /), which implies (7.52). 
l.For/  =  0 , w e h a v e S - i [ ( l-
"=  k(k-l)'""(k-l "
+ l)Xf-Kl^ 
-  A/)-^^+i)]  = 
Note that one can derive several alternative but equivalent expressions for (7.50) 
that  correspond  to different  ways  of determining  the inverse z-transform  of  z(zl — 
A)~^  or of determining A^  via some other methods. 
In  complete  analogy  with  the  continuous-time  case,  we  call  the  terms 
"Aiik(k  -  I)'  ""(k  -  I -\-  l)Xf~^  the modes  of  the system  (7.47). There  are  ni  modes "
corresponding  to the eigenvalues  A/, /  =  0 , . . .,  n^ -  1, and the system  (7.47) has a 
total of/I  modes. 
It is particularly interesting to study the matrix A^,  k  =  0,1,2,... 
using the Jor 
dan  canonical  form  of A,  i.e.,  /  =  P~^AP,  where  the  similarity  transformation  P 
is constructed by using the generalized  eigenvectors of A. We recall once more that 
[/j],  where  each  rit X Ui  block  //  corresponds  to  the 
/  =  diag[Ji,..., 
eigenvalue  A/  and  where,  in  turn,  Ji  =  diaglJn,..., 
///.]  with  Jfj  being  smaller 
square blocks, the dimensions  of which  depend  on the length  of the chains of  gen-
erahzed  eigenvectors corresponding  to Ji  (refer  to Subsections  2.3G and 2.4B). Let 
Jij  denote a typical Jordan canonical form block. We shall investigate the matrix  J^j, 
since A^  -  p-^j'^P  =  P'^ 
diag[jfj]P. 
J(j\=diag 
Xi 
1 
0 
0  A/ 
'•. 
Let 
Jij  = 
=  A//  +  A^,-, 
(7.54) 
0 
0 
1 
A/ 
where 
Ni  = 
0  1 
0  0 
0  0 
and where we assume that Jij  is at  X  t matrix. Then 
(jijr  =  (A,-/ +  NiY 
=  Af/  +  kXf-'^Ni  +  '^'',,  ^'kf'-Nf 
^ ( ^ - l ) v i - 2 ^ r2 
+ 
+  kXiNf'  + Nf. 
(7.55) 
n 
Linear  Systems 
Now  since  A^^^  =  0  for  k  ^ 
t,  a. typical  t  X  t  Jordan  block  Jtj  will  generate 
terms  that  involve  only  the  scalars  Af, Af~^  . . ., Xf~^^~^\  Since  the  largest  pos 
sible block  associated  with the eigenvalue  A/ is of dimension  nt  X ut, the  expression 
of  A^  in  (7.50)  should  involve  at  most  the  terms  Af,  Xf~\ 
...,"  Af""^''''^^  which  it "
does. 
The  above  enables  us to prove  the following  useful  fact:  given  A^R^^^, 
there 
exists  an integer  k>  0  such  that 
A^  =  0 
(7.56) 
if and only if all the eigenvalues  A/ of A are at the origin. Furthermore, the smallest k 
for  which  (7.56) holds is equal to the dimension  of the largest block Jij  of the Jordan 
canonical  form  of A. 
The  second  part  of the above  assertion  follows  readily  from  (7.55). We ask the 
reader  to prove  the first  part  of the  assertion. 
We  conclude  by  observing  that  when  all  n  eigenvalues  A/  of  A  are  distinct, 
then 
n 
A*  =  ^ A / A f,  y t>  0, 
i = \ 
where 
A,-  = 
lim[(z  -  A / ) ( z /-  A r M- 
(7.57) 
(7.58) 
If \i  =  0, we use 8(k),  the unit pulse, in place of Af in (7.57). This  result is  straight 
forward,  in view  of (7.50),  (7.51). 
EXAMPLE 7.8.  In (7.47) we let A  = 
0  n 
1 
-'4 
The eigenvalues of A are Ai 
_  1 
and therefore,  rii  =  2 and a  =  I. Applying  (7.50), (7.51), we obtain 
Aio\'lp(k)  + 
1  0 
0  1 
P(k)  + 
AnkX\-'p(k-l) 
r_ 1 
1 
i  1 
4 
2 
(k) 
k-i 
p(k  -  1). 
EXAMPLE  7.9.  In  (7.47)  we let A  = 
-1  2 
0  1 
. The eigenvalues  of A  are A1  = - 1, 
A2 =  1 (so that a  =  2). Applying  (7.57), (7.58), we obtain 
ik  ^  AioAj  +  A20A2 k  _  1 
0 
-1 
0  ( - 1 )'  + 
0  1 
0  1 
k^O. 
Note that this same result was obtained by an entirely different  method in Example 7.3. 
EXAMPLE  7.10.  In  (7.47)  we  let  A  = 
[0 
[0 
1 
-1 
.  The  eigenvalues  of  A  are Ai 
0, A2 =  -1  and o-  =  2. Applying  (7.57), (7.58), we obtain 
Ai  =  l i m [ z ( z / - A ) - i]  = 
1 
, ^ 
z +1  1 
z 
0 
A2  =  lim  ( z + D-
1 
z(z  + 1) 
z+  1  1 
z 
0 
and 
A^  =  Ai8(k)  + A2(-lf 
= 
1  1 
0  0 
8{k)  + 
1  1 
0  0 
{-l)\k^ 
0. 
z = 0 
-1 
0 
0 
1 
"0  - 1"" "
1 
0 
189 
CHAPTER  2: 
Response of 
Linear Systems 
As  in  the  case  of  continuous-time  systems  described  by  (L),  various  notions 
of  stability  of  an  equilibrium  for  discrete-time  systems  described  by  linear,  au 
tonomous, homogeneous  ordinary  difference  equations  (7.47) will be studied in de 
tail in Chapter 6. If 4>(k, 0, Xe) denotes the solution of system (7.47) with x(0)  =  Xe, 
then  Xe is  said  to  be  an  equilibrium  of  (7.47)  if  (pik, 0, Xe)  =  Xe for  all  k>  0. 
Clearly, Xe =  0 is an equilibrium of (7.47). In discussing the qualitative properties, 
it is customary  to speak,  somewhat  informally,  of the  stability properties  of  (7.47), 
rather than the stability properties of the equilibrium  x^  =  0 of system (7.47). 
The  concepts  of stability,  asymptotic  stability,  and  instability  of  system  (7.47) 
are  now  defined  in  an  identical  manner  done  in  Subsection  2.4C  for  system  (L), 
except  that  in  this  case  continuous  time  t{t  E  7?+)  is  replaced  by  discrete  time 
k{k  G Z+). 
By inspecting  the modes of system  (7.47)  [given by (7.50) and  (7.51)], we can 
readily establish the following  stability  criteria: 
1.  The system (7.47) is asymptotically  stable  if and only if all eigenvalues  of A are 
within the unit circle of the complex plane (i.e., |Ay| <  1, j  =  1,...,  a). 
2.  The  system  (7.47)  is  stable  if  and  only  if  |Aj|  <  1,  j  =  1,..., cr,  and  for  all 
eigenvalues  with  \Xj\  =  1 having multiplicity  rij >  1, it is true that 
lim [[z -  XjTKzI  -  Ar^]^^J-^-^^]  =  0 
z-^Aj 
for/  =  l,..,,nj- 
1. 
(7.59) 
3.  The system (7.47) is unstable  if and only if (2) is not true. 
EXAMPLE?.11.  The system given in Example 7.8 is asymptotically stable. The system 
given in Example 7.9 is stable. In particular, note that the solution (j){k, 0, x(0))  = A^x(O) 
for Example 7.9 is bounded. 
• 
When  the eigenvalues  A/ of A  are distinct,  then  as in the continuous-time  case 
[refer to (4.42), (4.43)] we can readily  show that 
A'=Y.^j4^J='^J^J^ 
^ - 0, 
(7.60) 
where the vy and Vj are right and left  eigenvectors of A corresponding to Ay, respec 
tively. If Ay  =  0, we use 8{k),  the unit pulse, in place of A^ in (7.60). 
In proving (7.60), we use the same approach as in the proof of (4.42), (4.43). We 
have A^  =  Qdiag  [\\,...,  A^]g~^  where  the columns  of  Q are the n right  eigen 
vectors and the rows of Q~^ are the n left  eigenvectors  of A. 
As in the continuous-time case [system (L)], the initial condition x(0) for system 
(7.47)  can  be  selected  to be  colinear  with  the  eigenvector  vt to  eliminate  from  the 
solution of (7.47) all modes except the ones involving  Af. 
EXAMPLE 7.12.  As in Example 7.9, we let A = 
. Corresponding to the eigen 
1,A2 
1, we have the right  and left  eigenvectors  vi  =  (1, 0)^, V2 
-1  21 
ij 
0 
values  Ai  = 
(1,1)^ VI = (1, 
1), andv2  = (0,1). Then 
V I V I A[  +  V2V2A2 
"""1 "
0 
(-1)^  + 
-1 
0. 
0 
I 
0  1. 
(1)*, 
yfc>  0. 
190 
Linear Systems 
Choose x(0)  =  a(l, 0)^  -  avi  with a  9^ 0. Then 
which contains only the mode associated with Ai  = - 1. 
We conclude the discussion  of modes  and  asymptotic  behavior  by briefly  con 
sidering the state equation 
x(k  +  1)  =  Ax(k)  + Bu(k), 
(7.61) 
where  x, u, A, and B  are as defined  in  (7.2a). Taking  the 2X-transform  of both  sides 
of (7.61) and rearranging  yields 
x{z)  =  z(zl  -  Ar^x(0)  +  (zl  -  Ar^Bu(z). 
(7.62) 
By taking the inverse 2-transform  of  (7.62), we see that the  solution  cf) of  (7.61)  is 
the  sum  of  modes  that  correspond  to the  singularities  or poles  of  z(zl  -  A)~^x(0) 
and of (z/  -  A)~^Bu{z).  If in particular,  system  (7.47) is asymptotically  stable [i.e., 
for  x{k  +  1)  =  Ax{k),  all eigenvalues  A^ of A are such that  \Xj\ <  \,  j  =  \,.. 
.,n\ 
and  if  u{k)  in  (7.61)  is  bounded  [i.e.,  there  is  an  M  such  that  \ui{k)\  <  M  for  all 
k>  0,i  =  I,...,  m], then it is easily  seen that the solutions  of  (7.61)  are  bounded 
as well. 
2.8 
AN  IMPORTANT  COMMENT  ON  NOTATION 
For the most part Chapters  1 and 2 are concerned with the basic (qualitative) proper 
ties of systems of first-order ordinary differential  equations, such as, e.g., the system 
of equations given by 
X =  Ax, 
(8.1) 
where x  E. R^ and A G fi^xn^ ^^ ^^^ arguments and proofs to establish various prop 
erties for  such systems, we highlighted the solutions by using the (/)-notation. Thus, 
the  unique  solution  of  (8.1)  for  a  given  set  of  initial  data  (^Q, XQ)  was  written  as 
^{t,  to, XQ)  with  </)(^, to, xo)  =  XQ. A  similar  notation  was  used  in  the  case  of  the 
equation given by 
and the equations given by 
X =  fit,  X) 
X =  A(t)x  +  B(t)u 
y  =  C(t)x  +  D(t)u, 
(8.2) 
(8.3a) 
(8.3b) 
where in (8.2) and in (8.3a), (8.3b) all symbols are defined  as in (E)  (see Chapter  1) 
and as in (6.1a), (6.1b) of this chapter,  respectively. 
In the study of control systems such as system (8.3a), (8.3b), the center of atten 
tion is usually  the control  input  u and the resulting  evolution  of the system  state in 
the state-space and the system output. In the development of control systems theory, 
the x-notation has been adopted to express the solutions of systems. Thus, the solution 
of (8.3a) is denoted by x(t)  [or x(t,  to, XQ) when to and  XQ  are to be emphasized]  and 
the evolution  of the  system  output y  in  (8.3b)  is denoted  by  y(t).  In  all  subsequent 
chapters,  except  Chapter  6,  we  will  also  follow  this  practice,  employing  the  usual 
notation utilized  in the control systems  literature. In Chapter  6, which is  concerned 
with  the  stability  properties  of  systems,  we  will  use  the  (/)-notation  when  studying 
the Lyapunov  stability  of  an equilibrium  [such  as  system  (8.1)]  and  the  x-notation 
when  investigating  the  input-output  properties  of  control  systems  [such  as  system 
(8.3a), (8.3b)]. 
191 
CHAPTER  2: 
Response of 
Linear Systems 
2.9 
SUMMARY 
In  this  chapter  the  response  of  linear  systems  to  specific  inputs  (subject  to  partic 
ular  initial  conditions)  was  studied  in  detail.  State-space  descriptions,  as  well  as 
impulse  (resp., unit pulse)  response  descriptions  and transfer  functions  were  used. 
Continuous-time,  time-varying,  and  time-invariant  systems  characterized  by  state-
space  descriptions  were  studied  first.  The  time-invariant  case  was  covered  in  a 
separate  section  (Section  2.4)  to provide  flexibility  in the coverage  of the  material. 
Similarly,  discrete-time  systems  were  treated  in  a  separate  section  (Section  2.7). 
Background material on linear algebra for the present  and subsequent chapters  was 
presented in Section 2.2. 
In  greater  detail,  the  solutions  of  the  homogeneous  state  equation  x  =  A(t)x 
were characterized first, using fundamental  matrices  and the state transition  matrix 
0(/, to) in  Section  2.3. The  solutions  of  the  nonhomogeneous  state  equations  x  = 
A(t)x  +  B(t)u  were derived in the same  section. 
For time-varying  systems, the state transition matrix ^(t,  to) can be  determined 
in  closed  form  only  in  special  cases. One  such  case pertains  to time-invariant  sys 
tems  X  =  Ax,  where  0(r, ^o)  =  ^^(^-^o)  Methods  of  determining  the matrix  expo 
nential  e^^ were addressed  in Section  2.4. In addition, the asymptotic behavior  and 
the stability of an equilibrium of linear time-invariant  systems  x  =  Ax  (in terms of 
modes and eigenvalues) were also addressed in Section 2.4. Linear periodic  systems 
X =  A(t)x,  A{t)  =  A{t  + T),t  ^  R, were treated in Section 2.5. 
Impulse  response  representations  (resp.,  transfer  function  representations)  of 
linear  systems, in terms of state equation  and output equation parameters  were dis 
cussed  in  Section  2.6. In  addition,  equivalence  of  state-space  representations  were 
treated in Section 2.6. 
Discrete-time  systems  represented  by  state-space  descriptions  and by  the  unit 
pulse  response  descriptions  we  addressed  in  Section  2.7. Results  analogous  to  the 
continuous-time  case  were  derived.  Discrete-time  systems  arise  frequently  in  the 
description  of  sampled-data  systems. Such  systems  were briefly  treated  in  Subsec 
tion 2.7D. 
2.10 
NOTES 
As mentioned earlier in Chapter  1, standard references  on linear algebra and matrix 
theory include Birkhoff  and McLane [2], Halmos  [7], and Gantmacher  [6]. For more 
192 
Linear Systems 
recent  texts  on  this  subject,  refer  to  Strang  [16]  and  Michel  and  Herget  [10]. Our 
presentation  in Section 2.2 is in the spirit of the coverage given in [10]. 
Our treatment  of basic  aspects  of linear ordinary  differential  equations  in  Sec 
tions 2.3, 2.4, and 2.5 follows  along lines similar to the development  of this  subject 
given in Miller and Michel [11]. 
State-space  and  input-output  representations  of  continuous-time  systems  and 
discrete-time  systems, addressed  in  Sections  2.6  and  2.7, respectively,  are  covered 
in a variety of textbooks, including Kailath  [9], Chen  [4], Brockett  [3], DeCarlo [5], 
Rugh [14], and others. For further material on sampled-data systems, refer to Astrom 
and Wittenmark  [1] and to the early  works on this  subject  that include Jury  [8] and 
Ragazzini  and Franklin [12]. 
Detailed  treatments  of  the  Laplace  transform  and  the  z-transform,  discussed 
briefly  in Sections 2.4 and 2.7, respectively, can be found  in numerous texts on sig 
nals and linear systems, control systems, and signal processing. 
The state representation of systems received wide acceptance in systems theory 
beginning  in  the  late  1950s. This  was  primarily  due  to  the  work  of  R.  E.  Kalman 
and  others  in  filtering  theory  and  quadratic  control  theory  and  to  the  work  of  ap 
plied mathematicians  concerned with the stability theory of dynamical systems. For 
comments  and  extensive  references  on  some of the early  contributions  in these  ar 
eas, refer to Kailath  [9] and Sontag [15]. Of course, differential  equations have been 
used  to  describe  the  dynamical  behavior  of  artificial  systems  for  many  years.  For 
example, in  1868 J. C. Maxwell presented  a complete treatment  of the behavior of 
devices  that  regulate  the  steam  pressure  in  steam  engines  called  flyball  governors 
(Watt governors) to explain certain  phenomena. 
The use of state-space representations in the systems and control area opened the 
way for the systematic  study of systems with multi-inputs  and multi-outputs.  Since 
the  1960s an alternative description is also being used to characterize  time-invariant 
MIMO  control  systems  that  involves  usage  of  polynomial  matrices  or  differential 
operators. Some of the original references  on this approach include Rosenbrock  [13] 
and Wolovich [17]. This method, which corresponds to system descriptions by means 
of higher order ordinary differential  equations (rather than systems of first-order ordi 
nary differential  equations, as is the case in the state-space description) is addressed 
in Chapter 7. 
2.11 
REFERENCES 
1.  K.  J.  Astrom  and  B. Wittenmark,  Computer-Controlled  Systems. Theory and Design, 
Prentice-Hall, Englewood Cliffs, NJ, 1990. 
2.  G. Birkhoff  and S. MacLane, A Survey of Modern Algebra, Macmillan, New York, 1965. 
3.  R. W. Brockett, Finite Dimensional Linear Systems, Wiley, New York, 1970. 
4.  C. T. Chen, Linear System Theory and Design, Holt, Rinehart and Winston, New York, 
1984. 
5.  R. A. DeCarlo, Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1989. 
6.  F. R. Gantmacher, Theory of Matrices, Vols. I, II, Chelsea, New York, 1959. 
7.  P. R. Halmos, Finite Dimensional Vector Spaces, Van Nostrand, Princeton, NJ, 1958. 
8.  E. I. Jury, Sampled-Data Control Systems, Wiley, New York, 1958. 
9.  T. Kailath, Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1980. 
10.  A. N. Michel  and  C. J. Herget, Applied  Algebra  and  Functional  Analysis,  Dover,  New 
193 
CHAPTER 2: 
Response of 
Linear  Systems 
York,  1993. 
11.  R. K. Miller and A. N. Michel,  Ordinary  Differential  Equations,  Academic  Press, New 
York,  1982. 
12.  J. R. Ragazzini  and G. F. Franklin, Sampled-Data  Control  Systems,  McGraw-Hill,  New 
York,  1958. 
13.  H. H. Rosenbrock,  State  Space  and Multivariable  Theory,  Wiley, New York,  1970. 
14.  W. J. Rugh, Linear  System  Theory, Second Edition, Prentice-Hall, Englewood Cliffs, NJ, 
1996. 
15.  E. D. Sontag, Mathematical  Control  Theory. Deterministic  Finite  Dimensional  Systems, 
TAM 6, Springer-Verlag, New York,  1990. 
16.  G. Strang, Linear Algebra  and Its Applications,  Harcourt, Brace, Jovanovich, San Diego, 
1988. 
17.  W. A. Wolovich, Linear  Multivariable  Systems,  Springer-Verlag, New York,  1974. 
18.  L.  A.  Zadeh  and  C.  A.  Desoer,  Linear  System  Theory—The  State  Space  Approach, 
McGraw-Hill, New York, 1963. 
2.12 
EXERCISES 
2.1.  (a)  Let  {V,F)  =  (R^, R).  Determine  the representation  of v  =  (1, 4, 0)^  with  respect 
to the basis v^  =  (1, - 1,  0)^, v^  =  (1, 0, - 1 ) ^, and v^  =  (0,1, 0)^. 
(b)  Let  V  =  F^  and let F be the field of rational functions.  Determine the representa 
"tion of V =  (^s""  +  2", 1/5,  - 2 )^  with respect to the basis {v^ v^, v^} given in (a). 
2.2.  Find  the  relationship  between  the  two  bases  {v\ v^, v^}  and  {v^ v^, v^}  (i.e.,  find 
the  matrix  of  {v^ v^, v^}  with  respect  to  {v\ v^, v^}),  where  v^  =  (2, 1,0)^, v^  = 
( 1 , 0 , - l ) ^ v3  =  ( l , 0 , 0 / , vi  =  ( l , 0 , 0 f , v2  ^  (0,1,-1),  and  v^  =  (0,1,1).  De 
termine  the  representation  of  the  vector  ^2  =  (0, 1,0)^  with  respect  to  both  of  the 
above bases. 
2.3.  Let  a  E: R  he  fixed.  Show  that  the  set  of  all  vectors  (x, ax)^,  x  E  R,  determines  a 
vector  space of dimension  one over F  =  R,  where  vector  addition  and  multiplication 
of vectors by scalars is defined  in the usual manner. Determine  a basis for this space. 
2.4.  Show that the set of all real nX  n matrices with the usual operation of matrix  addition 
and  the  usual  operation  of  multiplication  of  matrices  by  scalars  constitutes  a  vector 
"space over the reals  [denoted by  (/?""^""", R)]. Determine  the dimension  and  a basis  for 
"this  space.  Is  the  above  statement  still  true  if  /?""^"" is  replaced  by  R^^^^  the  set  of "
"real  mX  n matrices? Is the above statement  still true if  i?""^"" is replaced by the set of "
nonsingular matrices? Justify  your answers. 
2.5.  Let  v^  =  (s'^, s)^  and  v^  =  (1,1/^)^. Is  the  set  {v\ v^} hnearly  independent  over  the 
field of rational functions?  Is it linearly independent  over the field of real  numbers? 
2.6.  Determine the rank of the following  matrices, carefully  specifying  the field: 
(b) 
1  4 
7  0 
(a) 
J 
-1 
where  j 
(c) 
s + 4 
^ 2 -1 
-2 
6 
0 
s 
2s+  3 
-s  + 4 
s+  1 
(d) 
194 
Linear  Systems 
2.7.  Let V and W be vector spaces over the same field F and let ^2/ : V ^  M^ be a linear trans 
is a linearly independent  set, then so is the set 
formation.  Show that if {^v^,..., 
{ v \ . . .," v""}.  Give an example to show that the converse of this statement is not true. "
^v^} 
2.8.  Let  V  and  W  be  vector  spaces  over  the  same  field  F  and  lot ^ 
:V  ^W 
ho  3.  linear 
transformation.  Show that ^2/ is a one-to-one mapping if and only if  J^{s^)  = {0}. 
2.9.  Let ^  =  [5,A5,...,"A""-i5]  and "
C 
CA 
"CA"""" "
"where A G /?""><""","5 G Z^^^^""'"," and C G /?^><"". "
(a)  Prove  that  if  7]^ G ^ ( ^ ), 
then  AT]^  G ^ ( ^ ).  (7]^  denotes  the  coordinate 
"representation  of a vector v^ G /?"" with respect to the natural basis  {^1",..., ^„}.) 
(b)  Prove that if  7]i  G ^ ( ^ ), then A7]i  G ^ ( ^ ). 
The  above  shows  that  J^{^) 
mation  s^  that is represented by the matrix A. 
and ^ ( ' ^)  are invariant  vector  spaces  under  a  transfor 
2.10.  Show that  a 
c 
b 
d 
d 
-c 
a 
, where /S. = ad —  bc^O. 
2.11.  Determine the determinant,  the (classical)  adjoint,  and the inverse of the matrix 
45+3 
s 2 -2 
3 
2.12.  Determine  the  matrix  X  in 
A 
5 
O  D 
"""A-i "
O 
X 
D-\ 
where  it  is  assumed  that A 
and Z) are nonsingular.  Also, determine the matrix 
1 
A  O 
C  D 
2.13.  (a)  Show that  J^r 
A  O 
C  Z) 
{detA){det  D),  where A and Z) are square matrices. 
Hint:  For Z) nonsingular, use the identity 
(b) 
If A is nonsingular,  show that 
A  O 
C  D 
A  O 
O  D 
I 
D-^C 
O 
I 
det 
A  B 
C  D 
(detA)det(D-CA-^B). 
Hint:  Note  that 
A  B 
C  D 
A  O 
O 
I 
I 
C 
A-^B 
D 
and 
/  O 
I 
-C 
I 
C 
A-^B 
D 
A-^B 
D-CA-^B\ 
\I 
[o 
In  part  (b),  derive  an  expression  for  the  case  when  it  is  known  only  that  D  is 
nonsingular. 
(c) 
2.14.  Show that ^(^1+^2)^ = e^i^e^^t  if A1A2 =  A2A1. 
2.15.  Determine the characteristic  and the minimal polynomials of the  matrices 
195 
0 
1 10 
1 10 
0 
0  0 
10 
0  0  0  1 
0 
1 10 
0 
0  10 
0  0 
10 
0  0  0  1 
A3  = 
0 
1 10 
0 
0  10 
0  0 
11 
0  0  0  1 
A4  =  h 
CHAPTER  2: 
Response of 
Linear  Systems 
Hint:  These matrices  are in Jordan canonical  form. 
2.16.  Determine the Jordan canonical form  of the  matrices 
Ax  = 
"""2  0 "
1  2 
.2  0 
0' 
0 
2. 
A2  = 
"""2 "
1 
.0 
"0  0"" "
2  0 
1  2_ 
A3  = 
"""2 "
0 
.0 
"0  0"" "
2  0 
1  2_ 
2.17.  Show that there exists a similarity transformation  matrix P such that 
0 
0 
1 
0 
•• 
0 
1 
PAP-^  =  Ar  = 
0 
-ao 
0 
- ai 
0 
-a2 
•• 
• 
-Oin-l 
0 
0 
1 
if and only if there exists a vector b  G  R^ such that the rank of  [b, Ab, 
i.e., p[/7,AZ?, ...,"A""-iZ7]  =  n. "
^b] isn, 
2.18, 
Show  that  if  A/ is  an  eigenvalue  of the  companion  matrix  Ac  given  in Exercise  2.17, 
then a corresponding  eigenvector is v'  =  (1, A/,...,  Af~^)^. 
2.19. 
Let  A/ be  an  eigenvalue  of  a matrix A  and  let  v'  be  a corresponding  eigenvector.  Let 
/(A)  =  S l =o  ^k^^  be a polynomial with real coefficients.  Show that /(A^) is an eigen 
value  of  the  matrix  function  /(A)  =  ^[==oOCkA^.  Determine  an  eigenvector  corre 
sponding to /(A/). 
2.20.  For the matrices 
Ai  = 
"""1  2 "
0  0 
.0  0 
"0"" "
2 
1. 
and 
A2  = 
0 
0  10 
0  0 
10 
0  0  0  1 
0  0  0  0 
"determine the matrices  A}"""""," A^""""", g^l^  and e^^\  t  E  /? 
2.21.  Determine  some bases for the range and null spaces of the  matrices 
Ai  =  [1  0  1], 
Ao  = 
ri 
0 
_i 
1] 
0 
0. 
and 
"""3 "
3 
.3 
2 
2 
2 
r 
1 
1. 
2.22. 
Determine all solutions of the equation Arj  =  v,  where 
ro 
A =  1 
[2 
1 
2 
0 
1 
3 
2 
-11 
2 
4 -1 
0 
2.23. 
Let (j)x{t) =  e~^ for  ^ G  [-1,1]  and let 
<t>2{t)  = 
and 
2J 
^ G [ - 1 , 0 ], 
t  G  [0,  1]. 
196 
Linear  Systems 
Show  that  (^1  and  (/)2  are  Hnearly  independent  over  the  field  of  the  real  numbers  on 
[-1,1],  but not on  [0,1]. 
Remark:  This  example  illustrates  the fact  that linear independence  of time  func 
tions over a time interval  [a, b] does not necessarily  imply linear independence over a 
time subinterval  [a\b']  C  [a, b]. 
2.24. 
Show that if two time functions  (t)\(t), (f)2{t)  are linearly  independent  over a field F on 
a  time  interval  [a, b\  then  they  are  linearly  independent  over  F  on  any  interval  that 
contains  [a, Z?]. Give a specific  example. 
2.25. 
Prove  that  for  A  G  C[R, /?«><«],  (3.14)  is  true  if  and  only  if  (3.21)  is  true  for  all 
t,T^R. 
2.26. 
Determine the state transition matrix ^{t,  to) for  (LH)  with 
A(t)  = 
[0  01 
0 
t 
by (a) directly  solving differential  equations, (b) using the Peano-Baker  series, and (c) 
using  (3.15). 
2.27. 
Determine  the  state transition  matrix  ^{t,  to) for  {LH)  with  A{t)  = 
mine in this case the solution for  (LH)  when  x(l)  =  (1,1)^. 
/ 
1 
0 
t 
and  deter-
2.28. 
Verify  that (/>i(0  =  (1/^^  - 1 / 0^  and <^2(0  =  (2/t\  -llff 
with 
are two solutions  oi{LH) 
A(0  = 
4 
2-
0 
(a)  Determine the state transition matrix ^(t,  r)  for this  system. 
(b)  Determine  a solution  (j) for  this  system  that  satisfies  the initial  conditions  x(l)  = 
2.29, 
Given is the system of first-order ordinary differential  equations x  =  f-Ax,  where A  E 
^nxn  ^^^  t  Ei R.  Determine  the  state  transition  matrix  ^{t,  to). Apply  your  answer  to 
the specific  case when  t^A 
2A  ^ 
0 
-t\ 
[2t^ 
2.30. 
Show that the two linear  systems 
and 
x(2)  = 
0 
2-t^ 
t 
1 
1 
t 
1 
It 
x(^>  ^  A2{t)x^^^ 
are equivalent  state-space representations  of the differential  equation 
y -  Ity  -  (2 -  i')y  =  0. 
(a)  For which choice is it easier to compute the state transition matrix ^{t,  toft  For this 
case, compute ^{t,  0). 
(b)  Determine the relation between  x^^^ and y  and between  x^^^  and  y. 
2.31.  Using the Peano-Balcer series, show that when A(0  =  A, then <l>(^, ^)  =  e^^^  ^o). 
2.32.  For {LH)  with A{t)  = 
[  0 
- Ij 
determine lim^^oo (f){t, to, XQ) if x(0)  =  (0,1)^. This 
example  shows  that  an  attempt  of  trying  to  extend  the  concept  of  eigenvalue  from  a 
constant matrix A to a time-varying  matrix  A{t),  for  the purpose  of characterizing  the 
asymptotic behavior of time-varying  systems  (LH),  will in general not work. 
197 
CHAPTER 2: 
Response of 
Linear  Systems 
2.33.  For the  system 
X =  A(t)x  +  B(t)u, 
(11.1) 
where  all  symbols  are  as  defined  in  (6.1a), derive  the  variation  of  constants  formula 
(3.10), using the change of variables z{t)  =  ^(to, 
t)x{t). 
2.34.  For (11.1) with x(fo)  =  Xo, show under what conditions it is possible to determine M(r) 
so that (f){t, to, xo)  =  xo for all t  >  to. Use your result to find such u{t) for the particular 
case X  =  X + e~^u. 
2.35.  Show that (d/dT)^(t,  r)  =  -0(^,  T)A(T)  for all 
t,T^R. 
2.36.  Determine  the  state  transition  matrix  ^{t,  to)  for  the  system  of  equations  x  — 
e~^^Be^^x,  where  A  E  R^^^  and  B  G  R^^^,  Investigate  the  case  when  in  particular 
AB  =  BA. 
2.37.  The adjoint  equation  of (LH)  is given by 
Let  0(r, to) and  ^a(t,  to) denote  the  state  transition  matrices  of  (LH)  and  its  adjoint 
equation, respectively.  Show that 0^(r,  ^o)  =  [^(to,  t)V-
z 
-A(t)^z. 
(11.2) 
2.38.  Consider the system described by 
A(t)x  +  B(t)u 
C(t)x, 
(11.3a) 
(11.3b) 
where all symbols are as in (6.1a), (6.1b) with D(t)  =  0, and consider the adjoint  equa 
tion of (11.3a), (11.3b), given by 
z  =  -A(tfz  +  C(tYv 
w  =  B(tfz. 
(11.4a) 
(11.4b) 
(a)  Let  H(t,  r)  and Ha(t, r)  denote  the  impulse  response  matrices  of  (11.3a),  (11.3b) 
and  (11.4a),  (11.4b),  respectively.  Show  that  at  the  times  when  the  impulse  re 
sponses are nonzero, they  satisfy  H(t,  r)  =  Ha(r,  tY. 
(b)  If  A(0  ^  A, B(t)  ^  B,  and  C(t)  ^  C,  show  that  H(s)  =  -Ha(-sf,  where  H(s) 
and Ha(s) are the transfer  matrices of (11.3a), (11.3b) and (11.4a), (11.4b), respec 
tively. 
2.39.  Show that if for  (L//), 
A(t)  = 
An(t) 
0 
An(t) 
A22(0. 
where A\i(t),  An(t),  and A22(t) are submatrices  of appropriate dimensions, then 
^(t,  to) 
[C|>ll(^,^)  Oi2(r,/o)l 
^22(tjQ)\ 
0 
198 
Linear  Systems 
satisfies  the  matrix  equation  {d/dt)^ii(t,to)  =Aii(t)^ii(t,to) 
where  ^uit) 
where 
^n{t,to)+An{t)^22{t,to) 
the  matrix  ^uit^to) 
satisfies 
the  equation  {d/dt)^i2(t,to) 
with 012(^0,^0)  =  O. 
and 
=Aii(t) 
Use the above result to determine the state transition matrix 0(r, 0) for 
2.40.  Compute  e^^ for 
2.41.  Given is the matrix 
A(t) 
-1 
0 
e^n 
-ly 
[1 
p 
[0 
4 
2 
0 
1 
2 
0 
0 
-1 
-1 
0 
10] 
0 
2] 
"0"" "
0 
-2 
(a)  Determine  e^\  using  the  different  methods  covered  in  this  text.  Discuss  the 
advantages  and disadvantages  of these  methods. 
(b)  For system  (L) let A be as given. Plot the components  of the solution  (p(t,to,xo) 
whenXQ  = x(0) =  (1,1,1)^  and XQ  = x(0) =  ( |,  1,0)^.  Discuss  the  differences 
in these plots, if any. 
2.42.  Show that for A: 
we have e^^ 
2.43.  Given is the system of  equations 
XI 
= 
-1 
0 
"0"" "
1 
cos bt 
-sinbt 
sinbt 
cos bt 
+  r 
1 
.•^2. 
withx(0)  =  (l,0)^and 
u{t)=p{t)-
ri, 
\ 0, 
>0 
t 
e 
elsewhere. 
Plot  the  components  of  the  solution  of  (j). For  different  initial  conditions  x(0) 
{a,bY,  investigate the changes in the asymptotic behavior of the  solutions. 
2.44.  The system  (L) with A 
0  1 
-1  0 
is  called  the harmonic  oscillator  (refer  to Chap 
ter  1) because  it has periodic  solutions  (\>{t)  =  (0i(^),02(O)^-  Simultaneously,  for 
the  same values of t, plot  (pi (t)  along the horizontal  axis and (p2(t)  along the vertical 
axis  in the X1-X2 plane  to  obtain  a  trajectory  for  this  system  for  the  specific  initial 
condition x(0) =xo =  (xi(0),X2(0))^  =  (1,1)^.  In plotting  such  trajectories,  time t 
is viewed  as a parameter,  and arrows  are used to indicate  increasing  time. When the 
horizontal  axis corresponds  to position  and the vertical  axis corresponds  to velocity, 
the  X1-X2 plane  is  called  the phase  plane  and  0i,02  (resp.  x\,X2)  are  called  phase 
variables. 
2.45.  There  are various  ways  of  obtaining  the coefficients  ai{t)  given  in  (2.101).  One of 
these was described in Subsection 2.2J. In the following,  we present another  method. 
We consider the relation  {d/dt)e^^  = Ae^^ and we use (2.101) to obtain 
J  n—\ 
n—2 
"2ay(OA^""=A2ay(OA^""  +  a „ _ i ( 0 [ - K - i A "" ""^  +  --- + «iA +  ao/)]", 
dt  7=0 
7=0 
(11.5) 
where  the  Cay ley-Hamilton  Theorem  was  used.  The  coefficients  ai(t) that  satisfy 
this  relation  generate  a matrix  O = T.cCj(t)AJ  that  satisfies  the  equation  O = AO. 
For O to equal e^\ we also require that 0(0)  = Eaj(0)A^  = /  (why?), 
(a)  Show that the  ccj{t) can be generated  as solutions of the system of  equations 
199 
CHAPTER 2: 
Response of 
Linear  Systems 
cco{t) 
ai{t) 
"""0  0 "
1  0 
-ao 
—a\ 
cco{t) 
ai{t) 
(11.6) 
0  0 
1 
-an-i 
with  ao(0) =  l,aj(0)  =OJ> 
(11.6) are linearly  independent, 
1.  Also,  show  that  the aj(t)  generated via 
(b)  Express the solution of the  equation 
X  =Ax-\-Bu, 
(11.7) 
where  all symbols  are as defined  in (6.8a)  and  x(0)  =  XQ, in terms  of  aj(t). 
Also,  show  that  for  x(0)  = XQ  = 0,0(^,0,0)  =  0(r)  = JJ'jZQAJBwj{t),  where 
Wj{t)=J^aj{t-T)u{T)dT. 
2.46.  First,  determine  the  solution  (j)  of 
XI 
= 
"""0  1"" "
1  0 
XI 
.•^2. 
withx(O)  =  (1,1)^.  Next, 
determine  the  solution  (j)  of the  above  system  for  x(0)  =  a ( l , — l ) ^ ,a  e R,a  7^0, 
and discuss the properties of the two  solutions. 
2.47. 
In Subsection  2.4C it is shown that when the n eigenvalues  Xi of a real nxn  matrix 
A  are distinct,  then e^^ = ^4=1^1^^'^  where A^ = lims^^.[{s  — Xi){sl  — A)~^]  = ViVi 
[refer to (4.39), (4.40), and (4.43)], where Vi,Vi  are the right and left  eigenvectors of 
A, respectively, corresponding to the eigenvalue A^. Show that (a) ELi^«  ^  ^' where 
/  denotes the nxn  identity  matrix,  (b) AAi  = XiAi, (c) AiA  = XiAi, (d) AiAj  =  dijAi, 
where  5ij = lif  i = j  and  5ij = 0 when  iy^j. 
2.48.  Show that two state-space representations  {A,B,C,D}  and {A,B,C,D}  are zero-state 
equivalent if and only if CA^B  = CA^B,k  = 0,1,2,...,  and Z) = 5. 
2.49.  Find  an equivalent  time-invariant  representation  for the  system  described  by  the 
scalar differential  equation x =  sinltx. 
2.50.  Consider the  system 
x =  Ax-\-Bu 
y =  Cx, 
(11.7a) 
(11.7b) 
where all symbols  are defined  as in (6.8a), (6.8b) with D = 0. Let 
0 
3 
0 
0 
1 
0 
0 
-2 
0 
0 
0 
0 
0 
2 
1 
0 
"""0 "
1 
0 
0 
"0"" "
0 
0 
1 
C=  [1,0,1,0]. 
(11.8) 
(a)  Find equivalent representations  for  system (11.7a), (11.7b), (11.8), given by 
x=Ax  + Bu 
y = Cx, 
(11.9a) 
(11.9b) 
200 
Linear  Systems 
where x  = Px,  when A is in (i) the Jordan canonical (or diagonal) form,  and (ii) 
the companion  form, 
(b)  Determine the transfer  function  matrix for this  system. 
2.51. 
Consider the system (11.7a), (11.7b) with B = 
(a)  Let 
0. 
A  = 
r -1 
"1 0"" "
0 - 10 
0 
0 
2 
and  C=  [1,1,1]. 
If possible, select x(0)  in such a manner  so that y(t)  = te~\t  > 0. 
(b)  Determine conditions under which it is possible to assign y{t),t>0,  using only 
the initial data x(0). 
2.52.  Consider the system given by 
+  0 
1 
7 
X2 
3'=  [1,0] 
(a)  Determine x(0)  so that for  u(t)  = e~^\y{t)  = ke~^\  where ^ is a real  constant. 
Determine  k  for  the present  case. Notice  that y{t)  does not have  any  transient 
components. 
(b)  Let  u{t)  =  e^K  Determine  x(0)  that  will result  in y{t)  =  ke^K  Determine  the 
conditions  on  a  for this to be true. What is k in this  case? 
2.53.  Consider the system (11.7a), (11.7b)  with 
0 
3 
-1 
1 
"0"" "
1 
1 
0 
,  B  = 
"""0 "
1 
0 
0 
"0"" "
0 
1 
0 
,  c = 
(a)  For  x(0)  =  [1,1,1,1]^  and  for  u{t)  =  [1,1]^,  ^ >  0,  determine  the  solution 
(p(t,0,x(0))  and  the  output  y(t)  for  this  system  and  plot  the  components 
0,(^O,x(O)),/=l,2,3,4and};,(O,/=l,2. 
(b)  Determine the transfer  function  matrix H{s)  for this  system. 
2.54. 
Consider the  system 
x{k+l)=Ax{k)+Bu{k) 
y{k)=Cx{k), 
(11.10a) 
(11.10b) 
where all symbols are defined  as in (7.2a), (7.2b) with Z) =  0. Let 
B 
C = [ l , l ], 
and let x(0)  =  0 and w(^) =  1, ^ >  0. 
(a)  Determine  {y{k)},k  >  0,  by  working  in  the  (i)  time  domain,  and  (ii)  z-
(b) 
transform  domain, using the transfer  function  //(z). 
If it is known that when  u{k)  = 0, then y(0)  =y{\)  =  1, can x(0)  be  uniquely 
determined? If your answer is affirmative,  determine x(0). 
2.55. 
Consider y{z)  = H{z)u{z)  with transfer  function  H{z)  =  l/(z  +  0.5). 
(a)  Determine  and plot the unit pulse response  {h(k)}. 
(b)  Determine  and plot the unit step response. 
201 
CHAPTER  2: 
Response of 
Linear  Systems 
(c)  If 
u(k)  {i: 
^ = 1 , 2, 
elsewhere, 
determine  {y{k)}  for  k  =  0,1,2,3,  and  4  via  (i)  convolution,  and  (ii)  the 
z-transform.  Plot your  answer. 
(d)  For u{k)  given in (c), determine y{k)  as ^ ^  oo. 
2.56.  Consider the system (11.1 Oa) with x(0)  =  XQ and ^ >  0. Determine conditions under 
which there  exists  a sequence  of inputs  so that the  state remains  at XQ, i.e.,  so that 
x{k)  = XQ for all ^ >  0. How is this input sequence determined? Apply your  method 
to the specific  case 
B-
XQ 
2.57.  For  system  (7.7)  with x(0)  = XQ  and ^  >  0,  it is desired  to have the  state  go to  the 
zero state for any initial condition XQ in at most n steps, i.e., we desire that x{k)  = 0 
for  any XQ  = x(0)  and for  all  k>n. 
(a)  Derive  conditions  in  terms  of  the  eigenvalues  of A  under  which  the  above  is 
true. Determine the minimum number of steps under which the above behavior 
will be true. 
(b)  For part (a), consider the specific  cases 
0 
0 
0 
1 
0 
0 
0 
1 
0 
A2-
0 
0 
0 
1 
0 
0 
0 
0 
0 
,  A3 
0 
0 
0 
0 
0 
0 
0 
1 
0 
Hint:  Use the Jordan canonical form for A. Results of this type are important in 
dead-beat  control,  where it is desired that a system variable attain some desired 
value and settle at that value in a finite number of time steps. 
2.58.  Consider the system representations  given by 
X(^+1): 
-1 
0 
0 
-2 
x{k)  + 
u(k), 
y{k)  =  [l,l]x{k)  +  u{k) 
and 
X(^+1): 
0 
-2 
1 
-3 
x{k)  + 
u(k), 
y{k)  =  [l,0]x{k). 
Are these representations  equivalent? Are they zero-input  equivalent? 
2.59.  For the Jordan block given by 
[Xi 
1 
0  A, 
0 
1 
••• 
"0"" "
0 
0 
0 
0 
0 
••• 
••• 
202 
Linear  Systems 
where Jtj  G  R^^ 
'Af 
[, show that 
af-' 
k{k -  1) 
/:(fc-l)---a-f  +2)  ._(,_!) 
0 
0 
0 
0 
Af 
0 
0 
0 
Uf-i 
Af 
0 
0 
A* 
when  ^  >  ^  -  1. //m^; Use expression  (7.55). 
2.60.  Consider  a  continuous-time  system  described  by  the  transfer  function  H{s)  = 
4/(^2  +  25 +  2), i.e., })(5)  =  H(s)u(s). 
(a)  Assume  that  the  system  is  at  rest  and  assume  a  unit  step  input,  i.e.,  u(t)  =  1, 
t  >  0, u(t)  =  0,t  <0,  Determine  and plot y(t)  for  t  >  0. 
(b)  Obtain  a  discrete-time  approximation  for  the  above  system  by  following  these 
steps:  (i)  determine  a  realization  of  the  form  (11.7a),  (11.7b)  of H(s)  (see  Exer 
cise 2.61); (ii) assuming  a sampler  and a zero-order hold with  sampling period  7, 
use (7.46) to obtain a discrete-time  system  representation 
x(k  +1)  =  Ax(k)  +  Bu(k) 
y(k)  =  Cx(k)  +  Du(k) 
(11.11a) 
(11.11b) 
and determine A, B,  and  C in terms of  T. 
(c)  For the unit step input, u(k)  =  1 for  /: >  0 and u(k)  =  0 for  /: <  0, determine and 
plot y(k),  A:  >  0, for different  values of T, assuming the system is at rest. Compare 
y(k)  with y(t)  obtained in part (a). 
(d)  Determine  for  (11.11 a)  and  (11.lib)  the  transfer  function  H(z)  in  terms  of  T. 
that  H(z)  = 
that  H(z)  =  C(zl  -  Ay^B  +  D.  It  can  be  shown 
Note 
(1 -  z~^M^-^[H(s)/sl^kT}. 
Verify  this for the given  H(s). 
2.61.  Given  a proper  rational  transfer  function  matrix  H(s),  the  state-space  representation 
{A, B, C, D}  is  called  a  realization  of  H(s)  if  H(s)  =  C(sl  -  Ay^B  + D.  Thus,  the 
system  (6.8a), (6.8b) is a realization  of H(s)  if its transfer  function  matrix  is equal to 
H(s).  Realizations  of H(s)  are  studied  at length  in Chapter  5. When  H(s)  is  scalar,  it 
is straightforward  to derive certain realizations, and in the following,  we consider  one 
such  realization. 
Given a proper rational scalar transfer  function  H(s),  let D  =  lim^^oo H(s)  and let 
H,p(s)  ^  H{s)  -  D 
bn-lS'' 
+  b\s  +  bo 
"s^  +  an-\s^  ^ +  '""  -\-  a\s  + ao "
a strictly proper rational  function, 
(a)  Let 
0 
0 
1 
0 
0 
-ao 
0 
-ai 
0 
1 
0 
-a2 
•• 
0 
0 
0 
0 
0 
-Cln-2 
1 
~(^n-l_ 
""" "
• 
B = 
0 
0 
0 
1 
C  =  [bo  by 
bn-l] 
and  show  that  {A,B,C,D} 
is indeed  a reahzation  of H{s).  Also,  show  that  {A  = 
is  a  reahzation  of  H(^s) as  well.  These  two  state- 
space representations are said to be in controller  (companion) form  and in observer 
(companion)  form,  respectively  (refer  to Subsection  3.4D). 
203 
CHAPTER 2: 
Response of 
Linear  Systems 
(b)  In particular find realizations  in controller  and observer  form  for  (i) H{s)  = 
\/s^, 
(ii) H{s)  =  (ol/{s^  + 2l^(OnS+(ol),  and (iii) H{s)  =  {s+  1)V(^ -  1)^-
2.62.  Given are the systems 5*1  and 5*2  described by the  equations 
X\=A\X\^B\U\ 
y\  =C\x\+  D\ u\ 
I 
\ 
X2=A2X2+B2U2 
y2=  C2X2 + D2U2 
(^2), 
where all symbols are defined  as in (6.8a), (6.8b) with an appropriate set of  dimensions 
for  all matrices and vectors. 
(a)  Determine  state-space representations  for the following  composite  systems. 
(i)  Systems connected in tandem  or in  series: 
u = u^ 
y = U2 
y2 = y 
S2 
FIGURE  2.6 
Two systems connected in  series 
(ii)  Systems connected in  parallel: 
u^ 
S^ 
yi 
*J 
> 
f 
U2 
Sz 
y2 
FIGURE  2.7 
Two systems connected in parallel 
f r s 
1 
(iii)  Systems connected in 3. feedback  configuration: 
^o^ 
y2 
FIGURE  2.8 
Feedback  configuration 
yi 
U2 
Hint:  In each case, use 
as the state of the composite  system. 
(b)  If Hi(s)  is the transfer  function  matrix  of  Si,i  = 1 , 2,  determine the transfer  func 
tion matrix for each of the above composite systems in terms of the Hi{s),i  = 1 , 2. 
204 
Linear  Systems 
2.63.  Assume that H(s)  is a p  X m proper rational transfer  function  matrix. Expand H(s)  in 
a Laurent  series about the origin to obtain 
H(s)  =  Ho+His'^ 
+  •••  +HkS~^  +  •••  = 
^HkS'K 
00 
k = 0 
The elements of the sequence {HQ, HI,  ...,  Hj,,...}  are called the Markov parameters  of 
the system. These parameters provide an alternative representation of the transfer  func 
tion matrix H(s)  (why?), and they are useful  in Realization Theory (refer to Chapter 5). 
(a)  Show that the impulse response H(t,  0) can be expressed  as 
H(t,0)  ==  Ho8(t) +  Y.Hk 
(k-l)\ 
In the following,  we assume that the system in question is described by (6.8a), (6.8b). 
(b)  Show that 
H(s)  =  D  + C(sl  -  A)-^B  =  D  + 
^[CA^-^B}s~^, 
which  shows  that  the  elements  of  the  sequence  {D, CB,  CAB,...,  CA^ 
^B,...} 
are  the  Markov  parameters  of  the  system,  i.e.,  HQ =  D  and  H^  =  CA^~^B, 
)^ =  1,2, 
(c)  Show that 
. . .. 
H(s)  =  D+  -^C[Rn-is''-^ 
a(s) 
+  • • • +  i?i^ +  Ro]B, 
"where  a(s)  =  s'^ +  a„_i5""~^  +  • • • + a\s  + ao  =  det  (si  -  A)", the  characteristic 
polynomial  of A, and Rn-i  =  /,  Rn-2  =  ARn-i  +  a„-i/  =  A  + a „ - i / ,. . .,  Ro  = 
"A«-i  +(2„_iA""-2  +  ... "
Hint: WviiQ (si-A)-^ 
=  [l/a(s)][adj  (si  -  A)]  =  [l/a(s)][Rn-is^-^+ 
RQ],  and equate the coefficients  of equal powers of s in the expression 
"'""  + Ris  + "
-^aiL 
"a(s)I  =  (si  -  AMn-is""""'^  +  '""  -hRis-h  Rol "
2.64.  Given  the  transfer  function  of  a  system,  suggest  different  methods  to  determine  its 
Markov parameters. Apply these methods to the specific  cases given by 
H(s)  =  (s^ -  l)/(s^  +  2 ^ + 1) 
and 
H(s) 
s 
1  1 
s+  1 
0 
2.65.  The frequency  response  matrix  of  a  system  described  by  its  p  X  m  transfer  function 
matrix evaluated  ats  =  jco, 
H(co)  ^  H(s)l=j^, 
is a very useful  means of characterizing  a system, since typically it can be  determined 
experimentally,  and  since  control  system  specifications  are  frequently  expressed  in 
terms  of  the  frequency  responses  of transfer  functions.  When  the poles  of H(s)  have 
negative real parts, the  system turns out to be bounded-input/bounded-output  (BIBO) 
stable (refer to Chapter 6). Under these conditions, the frequency  response H(co) has a 
clear physical meaning, and this fact  can be used to determine H(a))  experimentally. 
205 
CHAPTER  2: 
Response of 
Linear  Systems 
(a)  Consider  a  stable  SISO  system  given  by  y{s)  = H{s)u{s).  Show  that  if  u{t)  = 
ksm{(Oot +  (j))  with  k  constant,  then y{t)  at steady-state  (i.e.,  after  all  transients 
have died out) is given by 
yss{t)  = k\H{(Oo)\sm{(Oot +  0 +  0{(Oo)), 
where  \H{Q))\  denotes  the  magnitude  of  //(co)  and  6{Q)) =  arg  H{Q))  is  the 
argument or phase of the complex quantity  H{(o). 
From  the  above  it  follows  that  H{(o)  completely  characterizes  the  system 
response at steady-state  (of a stable system) to a sinusoidal input. Since u{t)  can 
be expressed  in terms  of  a series  of  sinusoidal terms via  a Fourier  series,  H{(o) 
characterizes  the  steady-state  response  of  a stable  system to  any bounded  input 
u{t).  This physical interpretation  does not apply when the system is not  stable. 
(b)  For  the  /? X m  transfer  function  matrix  H{s),  consider  the  frequency  response 
matrix  H{(o)  and  extend  the  discussion  of  part  (a)  above  to  MIMO  systems  to 
give a physical interpretation  of//(co). 
"2.66.  Let A G /?""><"" and B  e /?""><'^. "
(a)  Is  it  true  that  rank  [B,AB,...  ^A'^'^B]  =  rank  [5,A5,... ,"A""-i5","A""5]?  Justify "
your  answer. 
(b)  Determine  conditions  under  which  rank  [B,AB,..  .,"A""^~^B] =  rank  [A5",..., 
"A""~^5","A""5].  Hint:  Use  the  Sylvester  Rank  Inequality",  which  relates  the  rank 
of the product of two matrices to the ranks of the individual matrices, 
rankX  +  rankY  — n<  rank(XY)  < imn{rankX, 
rankY}, 
"where X  e  /?^><"" and Y  e /?""><'^. "
2.67.  (Double integrator)  (a) Plot the response of the double integrator of Example 7.6 to 
a unit step input. 
(b)  Consider the discrete-time  state-space representation  of the double integrator of 
Example 7.6 for  7  =  0.5,1,5  sec and plot the unit step responses. 
(c)  Compare your answers in (b) with your result in (a). 
2.68.  (Economic model for national income) [D. G. Luenberger, Introduction  to  Dynamic 
Systems,  Wiley,  1979.] A simple model describing the national income dynamics  can 
be formulated in discrete times as follows. The national income y{k)  in year k in terms 
of  consumer  expenditure  c{k),  private investment  i{k),  and  government  expenditure 
g{k)  is  assumed  to  be  given  by  y{k)  =  c{k)  +  i{k) + g{k),  where  the  interrelations 
between  these  quantities  are  specified  by  c ( ^+  1)  =  ccy{k) and  /(^+  1)  =  ^[c{k — 
1) — c{k)\.  The constant  a  is called the marginal propensity  to consume,  while /3 is a 
growth coefficient.  Typically, 0 <  a  <  1 and /3 >  0. 
From these assumptions  we obtain the difference  equations  c ( ^+  1) =  ac(^)  + 
ai{k)  -\- ag{k),i{k-\-1)  =  (Pa  — P)c{k)  -\-Pai{k)  + /3ag{k),  with discrete-time state-
space representation  given by 
XI  ( ^ + 1) 
X 2 ( ^ + l) 
a 
p{a-l) 
a 
pa 
xi{k) 
X2{k) 
a 
pa 
u{k) 
y{k)  =  [\A] 
XI  (k) 
X2{k) 
+  u{k), 
where x\ {k)  = 
values (i) a  = 
c{k),X2{k)  =  i{k),  and  u{k)  =  g{k).  Let the parameters  a,/3  take  the 
0.75,/3  =  1 (ii) a  = 0.75,/3  =  1.5,  and (iii)  a  =  1.25,p  =  1. 
206 
Linear  Systems 
(a)  Determine the eigenvalues of A for all cases and express x(k) when u  =  Oin terms 
of the initial conditions and the modes of the  system. 
(b)  Plot the states for /: >  0 when  u(k) is the unit  step and x(0)  =  [0, 0]^.  Comment 
on your results. 
(c)  Plot the states for/:  >  Owhenw  =  Oandx(O)  =  [5, 1]^. Comment on your results. 
2.69.  (Spring  mass  system)  Consider  the spring  mass  system  of Example  4.1 in  Chapter 
1.  For Ml  =  1 kg, M2  =  1 kg, K  =  0.091 N/m, Ki  = 0 .1 N/m, K2  =  OA  N/m, 
B  =  0.0036  N  sec/m,  Bi  =  0.05 N  sec/m,  and B2 =  0.05 N  sec/m  the  state-space 
representation of the system in (4.2) of Chapter  1 assumes the form 
0 
10 
0 
-0.1910 
-0.0536 
0.0910 
0.0036 
0 
0 
0 
1 
0.0910 
0.0036 
-0.1910 
-0.0536 
\xi 
\X2 
Us 
|_X4_ 
4-
"""0 "
1 
0 
0 
0] 
0 
0 
-ij 
r/r 
[/2. 
A 
where xi  =  yi,  X2 = yi 
(a)  Determine  the eigenvalues  and eigenvectors  of the matrix  A  of the system and 
express  x(t)  in terms  of the modes  and the initial  conditions  x(0) of the system, 
assuming that /i  =  /2  =  0. 
X3  =  y2,  and X4  =  y2. 
(b)  Forx(O)  -  [1,0, 
0.5, 0]^  and  /i 
(c)  Let y  =  Cx with C  = 
10 
0 
0  1  0 
=  f2  = 0 plot the states for t >  0. 
0] 
denote the output of the system.  Determine 
the transfer  function  between y and u  =  [fi,  fiV• 
(d)  For zero initial conditions, fi(t)  = 8(t) (the unit impulse), and f2(t)  = 0, plot the 
states for r >  0 and comment on your results. 
(e)  It is desirable to explore  what  happens  when the mass  ratio M2/M1  takes  on dif 
ferent  values. For this, let M2  =  OLM\ with Mi  =  1 kg and a  =  0.1, 0.5, 2, 5. All 
other parameter  values remain the same. Repeat (a) to (d) for the different  values 
of a  and discuss your results. 
2.70.  (RLC circuit) For the circuit  ofExample  4.2 in Chapter  1, let/?i  =  211, i?2 =  l i ^, 
Ci  =  1  mF, C2  =  1  mF, and L  -  0.5 H. 
(a)  Determine the eigenvalues of A and express x{i) when v  =  0 in terms of the initial 
conditions and the modes of the  system. 
(b)  Plot  the states  for ? >  0  when  v  -  0 and x(0)  =  [5, \, 0]^.  Repeat  for x(0)  = 
[0, 0, 5]^ and comment on your results. 
(c)  Compute the transfer  function  between  y  =  [vi, V2,  VB]^ and v. 
(d)  Plot the states when the input v is the unit step and x(0)  =  [0, 0, 0]^. Comment on 
your results. 
2.71.  (Armature  voltage-controlled  dc servomotor)  Using  a  consistent  set of  units  for 
the armature voltage-controlled  dc servomotor in Example 4.3 of Chapter  1, let Ra = 
2, La  =  0.5, J  =  I, B  =  I, KT  =  2, and Ke  =  I. The state-space  description  of this 
system is given by (4.8) of Chapter  1, and here assumes the form 
Xi~ 
X2 
•^3_ 
= 
"""0 "
0 
.0 
1 
-1 
-2 
01 
2 
-4J 
\xi' 
\X2 
1x3. 
+ 
"""0 "
0 
.2 
ea, 
where  xi  =  ^ is the shaft  position,  X2 =  ^ is the angular  velocity,  X3 =  ia is the ar 
mature current, and the input  w =  ^^ is the armature voltage. 
(a)  Determine the eigenvalues  and eigenvectors  of A  and express  x{t) in terms of the 
modes and the initial conditions of the system when  Ca = 0. 
(b)  Plot the  states for  r >  0 when  the input  Ca  is the unit  step, and  x(0) 
[0, 0, 0]^ 
207 
CHAPTER  2: 
Response of 
Linear  Systems 
Comment on your results. 
2.72  (Unit mass in an inverse square law force field) Consider Example  11.3 of Chapter 1 
where for a satellite, ro  -  4.218709065 X 10^ m and COQ =  7.29219108 X 10~^ rad/sec. 
The linearized  model about the orbit d{f)  =  COQ^ +  ^o is given by 
"0"" "
0 
0 
1 
'  0 
3col 
0 
1 
0 
0 
2CL)O 
"""0 "
1 
0 
r^i 
[^2 
0 
0 
0 
— 
+ 
-
Xi 
Xl 
is 
Xi\ 
0  1 
r 
\Xi 
2ro(0o 
U2 
Us X4 
-• 
1 
0 
0 
^ 
0 
^0 
0 
^0-' 
where xi(t)  =  r{t)  -  ro, X2{t) =  r{t), x^it)  =  0(t),  and ^4(0  -  ^(0  -  ^o-
(a)  Determine the eigenvalues of A. Is the system asymptotically  stable? Explain your 
answer. 
(b)  Plot the states for  x(0)  =  [100, 0,0,0]^  and zero input. Comment on your results. 
(c)  Plot the states for wi(0  =  0, U2(t) =  -land;\c(0)  =  0. If the input represents  force 
imposed on the satellite by friction,  comment on your results. 
2.73.  (Magnetic ball suspension system) Consider the magnetic ball suspension  system of 
Exercise 1.21 in Chapter  1. It can be shown that under certain simplifying  assumptions, 
a linearized model  x  =  Ax  + Bu, y  =  Cxof  this system is given by 
R 
L 
0 
2Kieq 
0 
0 
Ui 
U3 
L-^BJ 
+ 
r li 
z 
0 
.o_ 
y  =  [0,1,0] 
A  typical  set  of parameters  is Sgq  =  0.01  m,  ieq =  0.125  A, M  =  0.01058  kg,  K  = 
6.5906  X 10-4 N m^/A^, R  =  31.1 n,  and L  =  0.1097  H. 
(a)  Determine the eigenvalues  and a set of eigenvectors  of A. 
(b)  Compute the transfer  function. 
(c)  Plot the states for ^ >  0 if the ball is slightly higher than the equilibrium  position, 
namely, if x(0)  =  [0, 0.0025, 0]^.  Comment on your results. 
2.74.  (Automobile suspension system)  [M. L. James, G. M. Smith, and J. C. Wolford,  Ap 
plied  Numerical  Methods for  Digital  Computation,  Harper & Row, 1985, p. 667.] Con 
sider the spring mass system in Fig. 2.9, which describes part of the suspension  system 
of an automobile. The data for this system are given  as 
mi  =  \  X  (mass of automobile)  =  375 kg, 
m2  =  mass of one wheel  =  30 kg, 
ki  =  spring constant  =  1500 N/m, 
k2  =  linear spring constant of tire  =  6500 N/m, 
c  =  damping constant of dashpot  =  0, 375, 750, and  1125 N  sec/m, 
xi  =  displacement  of automobile body from  equilibrium position  m. 
208 
Linear  Systems 
,,v 
1  .  2nvt 
u(t)=  -sin  —— 
6 
20 
FIGURE  2.9 
Model of an automobile  suspension  system 
X2  = displacement  of wheel from  equilibrium position m, 
V  =  velocity of car =  9,  18,  27 or 36m/sec. 
0 
A linear model x  = Ax-\-Bu  for this system is given by 
0  ] 
c 
— 
m\ 
1 
0 
h 
m\ 
0 
1 
kl 
C 
m\ 
0 
c 
mi 
0 
h 
k\  +^2 
^  -, 
Xl 
+ 
^2 
X3 
X4 
r  0  1 
0 
0 
h 
Lm2^ 
u(t), 
_  1712 
ni2 
1712 
1712] 
where u{t)  =  ^ sin(27rv^/20)  describes the profile  of the roadway, 
(a)  Determine the eigenvalues of A for  all the above cases. 
(a)  Plot  the  states  for  r  >  0  when  the  input  u{t)  =  ^ sin(27rvr/20)  and  x(0)  = 
[0,0,0,0]^  for  all the above cases. Comment  on your results. 
2.75.  (Building  subjected  to an earthquake)  [M. L. James,  G. M. Smith,  and J. C. Wol-
ford.  Applied  Numerical  Methods  for  Digital  Computation,  Harper  &  Row,  1985, 
p.  686.]  A  three-story  building  is  modeled  by  a  lumped  mass  system  as  shown  in 
Fig. 2.10. For ground  acceleration  v, the differential  equations of motion in terms of 
mass displacements  [^1,^2,^3] relative to the ground are given in state-variable  form 
x =  Ax-\-Buhy 
XI 
X2 
X^ 
X4 
is 
xe 
— 
0 
ki  +^2 
mi 
0 
h. m2 
0 
0 
1 
2c 
mi 
0 
c 
m2 
0 
0 
0 
k2 
mi 
0 
^2 +  ^3 
m2 
0 
k3 
ms 
0 
c 
mi 
1 
2c 
m2 
0 
c 
ms 
0 
0 
0 
h. m2 
0 
k3 
ms 
0 
0 
0 
c 
m2 
1 
c 
m3_ 
XI 
X2 
X3 
X\ 
X5 
X6 
+ 
0 
-1 
0 
-1 
0 
-1 
w, 
where  x\  =  qi,X2  =  qi,X3  =  q2,M  =  q2,xs  =  q3,x^  =  ^3,  and  u  =  V.  Let  k  = 
3.5025  X lO^N/m,  m =  1.0508 x  10^kg,  and c =  4.2030 x  lO^N sec/m.  Investigate 
the dynamic response of the structure due to the ground acceleration ufoYT  =  0.4,0.6, 
and 0.8 sec (see Fig. 2.10). In  particular: 
(a)  Plot the  distortions 
yi 
yi 
y3 
= 
XI 
X3-XI 
X 5 - X3 
= 
1 
-1 
0 
0 
0 
0 
0 
1 
-1 
0 
0 
0 
0 
0 
1 
0 
0 
0 
[xi,X2,X3,X4,X5,X6]^. 
If serious damage occurs when a distortion exceeds 0.08 m, will the given ground 
acceleration due to the earthquake cause serious damage to the building? 
(b)  Repeat  (a)  for  different  values  of  the  damping  parameter  c.  In  particular,  let 
Qg^  =  acoid,  where  a  =  2,3,10,  and  repeat  (a)  for  each  value  of  a.  Also, 
determine the eigenvalues of A for each  a  and comment on your results. 
209 
CHAPTER  2: 
Response of 
Linear  Systems 
/C2 =  2/f 
1  gf =  10  m/sec^ 
FIGURE  2.10 
A model for the dynamics of a three-story  structure 
4.0 
2.76.  (Aircraft dynamics)  [B. Friedland,  Control System Design,  An Introduction  to State-
Space Methods,  McGraw-Hill,  1986.] For purposes of control system design,  aircraft 
dynamics are frequently linearized about  some  operating  condition, called  3. flight re 
gime,wh^YQ it is assumed that the aircraft velocity(Mach number)and attitude are con 
stant. The control  surfaces  and engine thrust are set, or trimmed,  to these  conditions 
210 
Linear Systems 
and the control system is designed to maintain these conditions, i.e., to force perturba 
tions (deviations) from these conditions to zero. 
It is customary to separate the longitudinal motion from the lateral motion, since 
in many  cases the longitudinal  and lateral  dynamics  are only lightly  coupled. As a 
consequence of this the control system can be designed by considering each channel 
independently. 
The aerodynamic variables of interest are summarized in Table 12.1 and Fig. 2.11. 
The aircraft body axes are denoted by x,y,  and z, with the origin fixed at some refer 
ence point (typically the center of gravity of the aircraft).  The positive directions of 
these axes are depicted in Fig. 2.11. Roll, pitch, and yaw motions constitute rotations 
about the x-, y-, and z-axes, respectively, using the following sign convention: looking 
at Fig. 2.11a we see that the pitch angle 6 increases with upward rotation in the side 
view shown; in Fig. 2.11c, which gives the top view of the aircraft,  yaw angle if/ in 
creases in the counterclockwise direction; and looking at Fig. 2.lid, which provides 
the front view of the aircraft, we see that roll angle (p increases in the counterclockwise 
direction. We let co^  =  r,(x)y  =  q, and (o^ = p  denote yaw rate, pitch rate, and roll 
rate, respectively. The velocity vector V is projected onto the body axes with w, v, and 
w being the projections onto the x-, y- and z-axes, respectively. The angle-of-attack a is 
the angle that the velocity vector makes with respect to the x-axis in the (positive) pitch 
direction, and the side-slip angle jS is the angle that it makes with respect to the x-axis 
in the (positive) yaw direction. Note that for small angles, a  —  w/u and ^  —  vlu. 
The aircraft  pitch motion is typically  controlled by a control  surface  called the 
elevator, roll is controlled by a pair of ailerons, and yaw is controlled by a rudder. 
Aircraft longitudinal motion.  As a specific example, consider the numerical data 
for an actual aircraft, the AFTI-16 (a modified version of the F-16 fighter) in the land 
ing approach configuration  (speed V =  139 mph). The components of the state-space 
equation x  = Ax  + Bu that describe the longitudinal motion of the aircraft  are given 
by 
"""xA "
i:21 
is  ~ 
X4 
"[""-0.0507 "
-0.00117 
-0.000129 
-3.861 
-0.5164 
1.4168 
0 
1 
-0.4932 
0 
0 
1 
32.2] 
0 
0 
0  J 
r^i 
\x2 
Us 
1x4 
0 
+ 
- 0 . 0 7 17 
- 1 . 6 45 
u, 
0 
where the control input  w =  5^ is the elevator  angle  and the  state variables  in the 
vector X = [Aw, a, q, 6]^ are the change in speed, angle of attack, pitch rate, and pitch, 
respectively. 
TABLE  12.1 
Aerodynamic variables 
Rates 
Positions 
Lateral 
p: 
n 
j8: 
roll rate 
yaw rate 
side-slip  angle 
0: 
roll  angle 
ij/:  yaw  angle 
x: 
y: 
forward  displacement 
cross-talk  displacement 
Longitudinal 
angle of  attack 
a: 
q:  pitch  rate 
Aw:  change in  speed 
9:  pitch  angle 
z: 
altitude 
Controls 
8A :  aileron  deflection 
8R: 
rudder  deflection 
8E :  elevator  deflection 
211 
CHAPTER  2: 
Response of 
Linear Systems 
(a) Side view 
(b) Angle-of-attack a and 
side-slip angle 
Deflected 
rudder 
Deflected 
aileron 
(d) Front View 
FIGURE 2.11 
Aircraft dynamics 
The longitudinal modes of the aircraft  are called short period and phugoid.  The 
phugoid eigenvalues, which are a pair of complex conjugate eigenvalues close to the 
imaginary axis, cause the phugoid motion, which is a slow oscillation in altitude, 
(a)  For the state-space model that describes the aircraft longitudinal motion, determine 
the eigenvalues and eigenvectors of A. Express x{t), when w  =  0, in terms of the 
initial conditions and the modes of the system. 
212 
Linear  Systems 
(b)  Let  the  elevator  deflection  §£  be  -1  for  t  E  [0, T]  and  zero  afterward,  where  T 
may  be  taken  to be  the  sampling  period  in  your  simulation.  This  corresponds  to 
the maneuver  made when  the pilot pulls back on the stick to raise the nose of  the 
airplane.  (The  minus  sign  conventionally  represents  pulling  the  stick back.)  The 
elevator must be restored to its original position when the desired new climbing an 
gle is reached or the plane will keep rotating. Plot the states for x(0)  =  [0, 0, 0, 0]^ 
and comment on your results. 
(c)  Plot  the  states  for  x(0)  =  [0,0, 0,0]^,  using  a  negative  unit  step  as  the  elevator 
input.  This  happens  when  the  elevator  is  reset  to  a  new  position  in  the  hope  of 
pitching the plane up and  climbing. Comment on your results. 
(d)  As a second example, consider the numerical data for a Boeing 747 jumbo jet flying 
near sea level at a speed of  190 mph. The state-space description  x  =  Ax  +  Buoi 
the longitudinal motion is now given by 
-0.0188 
-0.0007 
0.000048 
11.5959 
-0.5357 
-0.4944 
0 
0 
0 
1 
-0.4935 
1 
32.21 
0 
0 
0  J 
Ui 
\x2 
Us 
X4 
+ 
0 
0 
-0.5632 
0 
(C. E. Rohrs, J.  L. Melsa,  and  D.  G.  Schultz, Linear  Control  Systems,  McGraw-
Hill,  1993, p. 92). Repeat  (a) to (c) for  the present case and discuss your  answers 
in view of the corresponding results for the AFTI-16  fighter. 
Aircraft  lateral  motion.  As a specific  example consider the lateral motion of a 
fighter aircraft traveling at a certain speed and altitude with state-space description 
X =  Ax  + Bu  given by 
0.03690 
Ui 
\x2 
\X3 
\X4 
0 
0 
0  J 
Xi 
X2 
X3 
X4_ 
-0.746 
-12.9 
4,31 
0 
0.006 
-0.746 
0.024 
1 
- D.999 
0.387 
-0.174 
0 
+ 
0.0012 
6.05 
-0.416 
0 
O.OO92I 
0.952 
-1.76 
0 
[U2_ ' 
where  the  control  inputs  [ui, U2V  =  [^A,^RV 
denote  the  aileron  and  rudder  de 
flections,  respectively, and the state variables in the vector x = [/3, p, r, c^]^ are the 
side-slip angle, roll rate, yaw rate, and roll angle, respectively. 
(e)  The  eigenvalues  for  the  aircraft  lateral  motion  consist  typically  of  two  complex 
conjugate  eigenvalues with relatively low damping, and two real eigenvalues. The 
modes caused by complex eigenvalues  are called dutch-roll.  One real eigenvalue, 
relatively  far  from  the  origin,  defines  a  mode  called  roll  subsidence,  and  a  real 
eigenvalue near the origin defines  the spiral  mode. The spiral mode is  sometimes 
unstable  (spiral  divergence). Find  the modes  for  the  aircraft  lateral  motion  of  the 
fighter. 
(f)  Plot the states when x(0)  =  [0, 0, 0, 0]^, wi is the unit step and U2  =  0. Repeat  for 
ui  =  0 and  U2 the unit step. Comment on your results. 
2.77.  (Read/write head of a hard disk)  [MATLAB Control System Toolbox User's  Guide, 
The Math Works, Inc.,  1993.]  Using  Newton's  law, a simple model  for  the  read/write 
head of a hard disk is described by the differential  equation J6  + c0 + k0  =  Kj  /, where 
/  represents the inertia of the head assembly; c denotes the viscous damping  coefficient 
213 
CHAPTER  2: 
Response of 
Linear  Systems 
of the bearings; k is the return spring constant; Kj  is the motor torque constant; 6, 9, and 
6  are the angular acceleration, angular velocity, and position of the head,  respectively; 
and / is the input current. A state-space model x  =  Ax  + Bu  of this system is given by 
0 
k 
J 
1] 
c 
Ui 
U2.  + 
"""7-1 "
0 
Kj 
-T 
where xi  ^  e,X2  =  0, and u  =  i. Let J  =  0.01, c  =  0.004, k  =  10, and KT  =  0.05. 
(a)  Determine the eigenvalues  of A. With  w =  0, is the trivial solution x  =  0 asymp 
totically  stable?  Explain. 
(b)  Plot the states for r >  0 when the input is the unit step and x(0)  =  [0, 0]^. 
(c)  Let the plant be preceded by a zero-order hold  (D/A converter)  and followed  by a 
sampler (an ideal A/D converter), both sampling at a rate of 1/7,  where T  =  5 ms. 
Derive the discrete-time  state-space representation of the plant. Repeat (a) and (b) 
for the discrete-time  system and comment on your results. 
C H A P T ER  3 
Controllability, Observability, and Special Forms 
It  is  frequently  desirable  to  determine  an  input  that  causes  the  states  of  a  system 
to  assume  different  values  in  finite  time  (e.g.,  to transfer  the  state  vector  from  one 
specified  vector value to another). Such is the case, for  example, in  satellite  attitude 
control, where the  satellite must change its orientation.  This type of desirable prop 
erty  leads  naturally  to  the  concepts  of  state  reachability  and  controllability,  which 
will now be studied at length. 
Another  desirable property  of  systems is the ability to determine the  state  from 
output  measurements.  Since  it  is  frequently  difficult  or  impossible  to  measure  the 
state  of  a  system  directly  (for  example,  internal  temperatures  and  pressures  in  an 
internal  combustion  engine),  it  is  extremely  desirable  to  determine  such  states  by 
observing  the inputs  and  outputs  of the  system  over  some finite time interval.  This 
leads  to  the  concepts  of  state  observability  and  constructibility,  which  will  also  be 
studied here. 
The principal goals of this chapter are to introduce and study in depth the system 
properties  of controllability  and observability  (and of reachability  and  constructibil 
ity) as well as special forms for the state-space system descriptions when a system is 
controllable  or uncontrollable,  and observable or unobservable. These  special  forms 
are very useful  in the study of the relationships between  state-space and input-output 
descriptions  of  a  system.  Note  that  controllability  and  observability  play  a  central 
role when  a given impulse response  or a transfer  function  description  is realized by 
means  of  a  state-space  description,  as  will  be  shown  in  Chapter  5.  These  special 
forms  also provide  insight  into the mechanisms  concerning  capabilities  and  limita 
tions  of  state controllers  and  state  observers,  as will be demonstrated  in  Chapter  4. 
The concepts of controllability and observability are central in the study of state feed 
back  controllers  (resp.,  output  controllers)  and  state  observers.  State  controllability 
refers  to  the  ability  to  manipulate  the  state by  applying  appropriate  inputs  (in  par 
ticular, by steering the state vector from  one vector value to any other vector value in 
214 
finite time). It turns out that controllability is a necessary and sufficient  condition for 
complete eigenvalue assignment in the system matrix A by means of state  feedback. 
State  observability  refers  to  the  ability  to  determine  the  initial  state  vector  of  the 
system from  knowledge  of the input  and the corresponding  output over time.  State 
observability  is a necessary  and sufficient  condition for the arbitrary  eigenvalue as 
signment  in an asymptotic  state estimator,  or state observer that estimates  the  state 
of the system using input  and output measurements.  State feedback  controllers  and 
state observers  are studied in Chapter 4. 
215 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
3.1 
INTRODUCTION 
This  chapter  consists  of  two  parts.  In  Part  1,  consisting  of  Sections  3.2  and  3.3, 
the important concepts of state reachability  (controllability)  and observability  (con-
structibility)  are introduced. This is accomplished for continuous- and  discrete-time 
systems that may be time-varying or time-invariant. In Part 2, consisting of Sections 
3.4 and 3.5, special forms  for  state-space representations  are developed for  control 
lable or uncontrollable  and observable or unobservable  time-invariant  (continuous-
and  discrete-time)  systems.  In  addition,  the  Smith-McMillan  form  of  a  transfer 
function  matrix and the poles and zeros of a system are introduced  and  studied. 
In  Subsection  A  of  this  section,  the  concepts  of  reachability  and  controllabil 
ity  and  observability  and  constructibility  are introduced,  using  discrete-time  time-
invariant  systems. In this  way, significant  insight into the concepts  is gained  early, 
together  with  a  clear  understanding  of  what  these  properties  imply  for  a  system. 
Discrete-time  systems are selected for this exposition because the mathematical de 
velopment is simple in this case, allowing us to concentrate on explaining  concepts 
and their impUcations. The continuous-time  case is treated in detail in Sections  3.2 
and 3.3. 
A.  A Brief Introduction  to Reachability  and  Observability 
Reachability  and  controllability  are  introduced  first,  for  the  case  of  discrete-time 
time-invariant  systems, followed  by  observability  and  constructibility.  Finally,  du 
ality is briefly  discussed. 
1. Reachability  and  controllability 
The concepts of state  reachability  (or controllability-from-the-origin)  and  con 
trollability  (or controllability-to-the-origin)  are introduced here and are discussed at 
length in Section 3.2. In the case of time-invariant systems, a state xi  is called reach 
able  if there exists  an input that transfers  the state of the system  x{t)  from  the zero 
state to xi  in some finite time T. The definition  of reachability  for the  discrete-time 
case is completely  analogous. 
Figure 3.1 shows that different  control inputs ui{t)  and U2{t) may force the state 
of a continuous-time  system to reach the value  x\  from  the origin  at different  finite 
times,  following  different  paths.  Note  that  reachability  refers  to  the  ability  of  the 
216 
Linear Systems 
FIGURE 3.1 
A reachable state xi 
system to reach xi  from the origin in some finite time; it specifies  neither the time it 
takes to achieve this nor the trajectory to be followed. A state XQ is called  controllable 
if there exists an input that transfers  the state from  XQ to the zero state in some finite 
time  T.  See  Fig.  3.2.  The  definition  of  controllability  for  the  discrete-time  case  is 
completely  analogous. 
Similar to reachability, controllability refers to the ability of a system to transfer 
the  state  from  XQ to  the  zero  state  in  finite  time;  it  too  specifies  neither  the  time 
it takes to achieve the transfer  nor the trajectory  to be followed.  We note that  when 
particular types of trajectories to be followed are of interest, then one seeks particular 
control inputs that will achieve such transfers. This leads to various control problem 
formulations, including the Linear Quadratic (Optimal) Regulator (LQR). The LQR 
problem is discussed briefly  in the next  chapter. 
Section  3.2  shows that reachability  always  implies  controllabiHty,  but  control 
lability  implies  reachability  only  when  the  state transition  matrix  $  of the  system 
is  nonsingular.  This  is  always  true  for  continuous  time  systems,  but  it  is  true  for 
discrete-time systems only when the matrix A of the system  [or A(k)  for certain val 
ues of k] is nonsingular. If the system is state reachable, then there always exists an 
input that transfers  any state XQ  to any other state xi  in finite time. 
FIGURE 3.2 
A controllable state XQ 
In  the  time-invariant  case,  a  system  is  said  to  be  reachable  (or  controllable-
from-the-origin)  if and only if its controllability  matrix  ^, 
%  =  [B,AB,...,"A""-l5]G/^""><'^^ "
(1.1) 
has  full  row  rank  n,  that  is,"  rank  %  =  n.  The  matrices  A  G  R^^^  and  B  E  R^^""^ "
determine either the continuous-time  state  equations 
217 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
or the discrete-time  state equations 
X =  Ax-\-  Bu 
x(k  +  1)  =  Ax(k)  +  Bu(kl 
(1.2) 
(1.3) 
"fc  >  /^o  ""=  0.  Alternatively",  we  say  that  the  pair  (A, B)  is  reachable.  The  matrix 
"%  should  perhaps  more  appropriately  be  called  the  ""reachability  matrix""  or  the "
"""controllability-from-the-origin  matrix.""  The  term  ""controllability  matrix","""  how "
ever,  has  been  in  use  for  some  time  and  is  expected  to  stay  in  use. Therefore,  we 
"shall  call  % the  ""controllability  matrix","""  having  in  mind  the  ""controllability-from-"
"the-origin  matrix."" "
We  shall  now  discuss  reachability  and  controllability  for  discrete-time  time-
invariant  systems (1.3). 
If the state x{k)  in (1.3) is expressed in terms of the initial vector x(0), then (see 
Section  2.7) 
x(k)  =  A^x(0)  + ^A^-^'^^^Bu{i) 
(1.4) 
k-\ 
for  ^  >  0.  It  now  follows  that  it  is  possible  to  transfer  the  state  from  some  value 
x(0)  =  XQ  to  some  xi  in n  steps, that  is, x{n)  =  xi,  if there exists  an n-step  input 
sequence {w(0), w(l),..., u{n -  1)} which  satisfies  the equation 
where %n =  [B, AB, 
A^-i^]  =  ^  [see (1.1)] and 
Xi  -  A'^XQ  =  ^nUn, 
Un  =  [u^(n  -  1), u^(n  -  2 ) , . . ., w^(0)]^ 
(1.5) 
(1.6) 
From the theory of linear algebraic equations, (1.5) has a solution Un if and only if 
xi  -  A'^jco  E  gi(^), 
(1.7) 
where  9l(^)  =  range (%). Note  that  it  is  not  necessary  to  take  more  than  n  steps 
in  the  control  sequence  since  if  this  transfer  cannot  be  accomplished  in  n  steps,  it 
cannot be accomplished  at all. This follows  from  the Cayley-Hamilton  Theorem, in 
view of which it can be shown that 2/l(^^)  =  2/l(^^) for  k>  n. Also note that 9l(^„) 
includes ^C^k)  iox k  <  n  [i.e., 9l(^„)  D 9l(^y^), k  <  nl  (See Exercise  3.1.) 
It  is  now  easy  to  see  that  the  system  (1.3)  or  the  pair  {A,B)  is  reachable 
(controllable-from-the-origin), 
implying  that  any  state  xi  can  be  reached  from 
the  zero  state  (XQ =  0) in  finite  time  if  and  only  if  rank  ^  =  n,  since  in  this  case 
9l(^)  =  R^,  the entire  state  space. Note that  x\  G 9i{%) is the condition  for  a par 
ticular  state  x\  to  be  reachable  from  the  zero  state.  Since  2^(^)  contains  all  such 
states,  it is called  the  reachable  subspace  of the  system.  It is  also  clear  from  (1.5) 
that if the system is reachable, any  state  XQ can be transferred  to any other  state  xi 
in n steps. In addition, the input that accomplishes this transfer  is any solution  Un of 
218 
Linear  Systems 
(1.5).  Finally,  depending  on  xi  and  XQ,  this  transfer  may  be  accomplished  in  fewer 
than  n  steps  (see  Section  3.2). 
EXAMPLE  1.1.  Consider  x(k  +  1)  =  Ax(k)  +  Bu(k),  where  A 
B 
Here the controllability (-from-the-origin)  matrix ^  is ^  =  [B,AB]  = 
with rank 
^  =  2. Therefore  the system  [or the pair (A, B)] is reachable, meaning that any state  xi 
can  be  reached  from  the  zero  state  in  a  finite  number  of  steps  by  applying  at  most  n 
inputs {u(0\  w(l),..., u(n  -  1)} (presently, n  =  2). To see this, let xi 
-
Then  (1.5) 
implies that 
0  1  u(l) 
[1 
iJWO). 
u(l) 
[u(0)\ 
b  —  a 
a 
Thus, the control 
M(0)  =  a,u{V)  =  b  -  a will transfer  the  state from  the origin  at  A: =  0 to the  state 
a 
b 
at  ^  =  2.  To  verify  this,  we  observe  that  x(l)  =  Ax(0)  +  Bu(0)  = 
a  = 
and 
x(2)  =  Ax(l)  +  Bu(l) 
+ 
(b-a) 
Reachability  of  the  system  also  implies  that  a  state  xi  can  be  reached  from  any 
other  state  xo in  at most  n  =  2 steps. To illustrate  this, let  x(0)  = 
11 
. Then  (1.5)  im-
"plies that xi  -  A^XQ  =  L  ""~ L "
b-a- 
1 
a-2 
, which will drive the state  from 
a  —  2 
b~3 
1 
at /:  =  0 to 
u(l) 
u(0) 
. Solving, 
u(l) 
w(0) 
at  ^  =  2. 
Notice  that  in  general  the  solution  Un of  (1.5)  is not unique,  i.e.,  there  are  many 
inputs  which  can  accomplish  the  transfer  from  x(0)  =  XQ to  x(n)  =  x\,  each  cor 
responding  to  a particular  state  trajectory.  In  control  problems,  particular  inputs  are 
frequently  selected  that,  in  addition  to transferring  the  state,  satisfy  additional  crite 
ria,  such  as,  e.g.,  minimization  of  an  appropriate  performance  index  (optimal  con 
trol).  This  corresponds  to  selecting  a  particular  trajectory  that,  e.g.,  may  result  in 
minimum  dissipation  of control  energy. It is important  to remember  that  reachability 
and  controllability  guarantee  only the  ability  of  a system to transfer  an initial  state  to 
a  final  state  by  some  control  input  action  over  a  finite  time  interval.  By  themselves, 
reachability  and controllability  do not imply the capability  of a system to follow  some 
particular  trajectory. 
A  system  [or the pair  (A, 5 )]  is controllable,  or controllable-to-the-origin, 
when 
any  state  XQ can  be  driven  to  the  zero  state  in  a  finite  number  of  steps.  From  (1.5) 
we  see  that  a  system  is  controllable  when  A^XQ  G  9l(^)  for  any  XQ.  If  rank  A  =  n, 
a  system  is  controllable  when  rank  ^  =  n,  i.e.,  when  the  reachability  condition  is 
satisfied.  In  this  case  the  nX  mn  matrix 
"A-""""^ "
= 
[A-''B,...,A-^B] 
(1.8) 
isofinterestandthesystemiscontrollableifandonlyifranA:(A~^^)  =  rank%  =  n. 
If,  however,  rank  A  <  n,  then  controllability  does  not  imply  reachability  (see 
Section  3.2). 
EXAMPLE 1.2.  The system in Example 1.1 is controllable (-to-the-origin). To see this, 
219 
we let xi  =  0 in (1.5) and write -A^XQ = 
1  1 
1  2 
a 
b 
=  [B,AB] 
a 
P. 
-b 
,  where 
Xo  = 
From  this  we  obtain 
u(0)\ 
u(0) 
la 
L^. 
-11 
-i\ 
—a — b 
at ^  =  2. 
,  the input  that  will  drive  the  state  from 
0 
-I 
"""0^ "
Oj 
EXAMPLE 1.3.  The system x(k  + 1)  =  0 is controllable since any state, say, x(0) = 
, can be transferred  to the zero state in one step. In this system, however, the input 
u(l) 
u(0) 
1  r 
1  0 
a 
0  1 
1  1 
l]\a 
1 
1  2 
at  ^  =  0 to 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
u does not affect  the state at all! This example shows that reachability is a more useful 
concept than controllability for discrete-time systems. 
• 
It should be pointed out that nothing has been said up to now about maintaining 
the desired system state after reaching it [refer to (1.5)]. Zeroing the input for k^  n, 
i.e., letting M(fe)  =  Oforfe>  n, will not typically work, unless Axi  =  xi. In general 
a state starting at xi  will remain at xi  for all fc >  n if and only if there exists an input 
u(k),  k^  n, such that 
xi  =  Axi  +  Bu(k\ 
(1.9) 
that  is,  if  and  only  if  (/  -  A)xi 
condition may not be  satisfied. 
^(B).  Clearly,  there  are  states  for  which  this 
2. Observability  and  constructibility 
In Section 3.3, definitions  for  state observability  and constructibility  are given, 
and appropriate tests for these concepts are derived. It is shown that observability al 
ways implies constructibility, while constructibility implies observability only when 
the state transition matrix O of the system is nonsingular. Whereas this is always true 
for  continuous-time  systems, it is true for discrete-time  systems only when the ma 
trix A  of  the  system  [or  when  A(k)  for  particular  values  of  k]  is  nonsingular.  If  a 
system is state observable, then its present state can be determined from  knowledge 
of the present  and future  outputs  and inputs. Constructibility  refers  to the ability to 
determine the present state from present and past outputs and inputs, and as such, it 
is of greater interest in applications. 
In the time-invariant case a system  [or a pair (A, C)] is observable if and only if 
its observability  matrix  0,  where 
C 
CA 
CA n-l 
^f^pn> 
(1.10) 
has full  column  rank,  i.e.,  rank  €  =  n. The matrices  A  G R^^^  and  C  E RP^ 
given by the system  description 
are 
X — Ax  +  Bu, 
=  Cx  +  Du 
(1.11) 
220 
Linear Systems 
in the continuous-time  case, and by the system  description 
^(^ +  1)  ^  ^^(y^) _p  ^^^^^^ 
^(^)  ^  Cx(yt) +  Du(k\ 
(1.12) 
with fe >  /:o  =  0. in the discrete-time case. 
We shall now briefly  discuss observability  and constructibility  for the discrete-
time time-invariant  case. As in the case of reachability  and controllability,  this dis 
cussion  will  provide  insight  into  the  underlying  concepts  and  clarify  what  these 
imply for a system. 
If the output in (1.12) is expressed in terms of the initial vector x(0),  then 
y(k)  =  CA^x(0)  + ^  CA^-^'^^^Bu(i)  +  Du{k) 
(1.13) 
k-i 
for  A: >  0 (see Section 2.7). This implies  that 
i = 0 
y(k)  =  CA^xo 
(1.14) 
for  /: >  0, where 
y{k)  =  y(k)  -
k-l 
^CA^'^'^^^Bu{i) 
i = 0 
+ Du{k) 
for  ^ >  0, 3;(0)  =  yiO) -  Du{G), and  XQ =  x(0).  In  (1.14),  XQ  is to be  determined 
assuming  that the system parameters  are given and the inputs and outputs are mea 
sured. Note that if u(k)  =  0 for /: ^  0, then the problem is simplified  since y(k)  = 
y(k)  and the output is generated  only by the initial  condition  XQ. It is clear that the 
ability  to determine  XQ  from  output  and input  measurements  depends  only  on the 
matrices  A  and  C  since  the left-hand  side  of  (1.14)  is  a known  quantity.  Now if 
^(0)  =  XQ is known, then all x(k),  ^ >  0, can be determined by means of (1.4). To 
determine  XQ, we apply (1.14) for ^  =  0,..  .,n  -  1. Then 
Yo,n-l  =  ^nXo, 
(1.15) 
where ©^  =  [C^, (CA)^,..., 
(CA^-^)^]^  -  0  [as in (1.10)] and 
hn-i  = 
[fm...,f(n-l)f. 
Now  (1.15)  always  has a solution  XQ, by construction.  A system  is  observable 
if the solution  XQ  is unique, i.e., if it is the only initial condition  that, together  with 
the given input sequence, can generate the observed output sequence. From the the 
ory  of  linear  systems  of  equations,  (1.15)  has a unique  solution  XQ  if  and only  if 
the null  space of 0  consists  of only the zero vector, i.e., null  (0)  =  }((€)  =  {0},  or 
equivalently, if and only if the only x  E  R^ that  satisfies 
€x  =  0 
(1.16) 
is the zero vector. This is true if and only if rank €  =  n. Thus, a system is observable 
if  and only if  rank€  =  n. Any nonzero  state vector  x  G R^ that  satisfies  (1.16) is 
said to be an unobservable  state, and J{{€) is said to be the unobservable  subspace. 
Note  that  any  such  x  satisfies  CA^x  =  0  for fc =  0, 1,..., n  -  1. If  rank€  <  n, 
then  all vectors  XQ  that  sansfy  (1.15)  are given by  XQ =  xop +  XQ/Z, where  xop is a 
particular solution and XQU is any vector in }((€).  Any of these state vectors, together 
with the given inputs, could have generated the measured  outputs. 
.,n 
To  determine  XQ from  (1.15)  it  is  not  necessary  to  use  more  than  n  values  for 
-  I,  ov to  observe  y(k)  for  more  than  n  steps  in  the  future.  This 
y(k),  k  =  0,.. 
is  true  because,  in  view  of  the  Cayley-Hamilton  Theorem,  it  can  be  shown  that 
J{(€n)  =  >r(0^)  for  k^ 
J<(€k))  for  k  <  n.  Therefore,  in  general,  one  has  to  observe  the  output  for  n  steps 
(see  Exercise  3.1). 
n.  Note  also  that  J{(€n) 
is  included  in  Ji(€k) 
(JV'(O^)  C 
221 
CHAPTER3: 
Controllability, 
Observability,' 
and  Special 
Forms 
EXAMPLE  1.4.  Consider  the  system  x(k  +  1)  =  Ax(k),  y(k)  =  Cx(k),  where  A  = 
and  C  =  [0, 1].  Presently, 
0  1 
1  1 
the  system  [or  the  pair  (A, C)]  is  observable.  This  means  that  x(0)  can  uniquely  be 
determined  from  n  =  2 output  measurements  (in  the  present  cases,  the  input  is  zero). 
with  rank  0  =  2.  Therefore, 
0  1 
1  1 
C 
CA 
In  fact,  in  view  of  (1.15), 
"y{\)  -  KO)"" "
yiP) 
J(l) 
0  1 
1  1 
^i(O) 
^2(0).  or 
^i(O) 
^2(0)J 
-1  1 
1  0 
y(0) 
J d ). 
EXAMPLE  1.5.  Consider  the  system  x{k  +  1)  =  Ax{k),  y{k)  =  Cx(k),  where  A  = 
1  0 
1  1 
and  C  =  [1,0].  Presently,  0  = 
with  rank  0 = 1.  Therefore, 
1  0 
1  0 
C 
CA 
the  system  is  not  observable.  Note  that  a  basis  for  }((€)  is 
which  in  view  of 
(1.16)  implies  that  all  state  vectors  of  the  form 
R,  are  unobservable.  Rela 
tion (1.15) implies  that  y(0) 
LKDJ 
1  0 
1  0 
xi(0) 
X2(0)J 
. For a solution  x(0)  to exist, as it must. 
we  have  that  y(0)  =  y(l)  =  a.  Thus, this  system  will  generate  an identical  output  for 
k>  0. Accordingly, all x(0)  that satisfy  (1.15) and can generate this output are given by 
xi(0)l 
.^2(0)J 
where  c  G R. 
"""0"" "
c  = 
a 
0. 
a 
c 
= 
+ 
_ 
In  general,  a  system  (1.12)  [or  a  pair  (A,  C)]  is  constructible  if  the  only  vector 
X that  satisfies  x  =  A^x  with  Cx  =  0  for  every  k  >  0  is  the  zero  vector.  When  A 
is  nonsingular,  this  condition  can  be  stated  more  simply,  namely,  that  the  system 
is  constructible  if  the  only  vector  x  that  satisfies  CA~^x  =  0  for  every  fe  >  0  is 
the  zero  vector.  Compare  this  with  the  condition  CA^x  =  0,  k  >  0,  for  x  to  be  an 
unobservable  state; or with the condition that a system is observable if the only  vector 
X that  satisfies  CA^x  =  0  for  every  /:  >  0  is  the  zero  vector.  In  view  of  (1.14),  the 
above  condition  for  a  system  to be  constructible  is the  condition  for  the  existence  of 
a  unique  solution  XQ when  past  outputs  and  inputs  are  used.  This,  of  course,  makes 
sense since constructibility  refers  to determining  the present  state from  knowledge  of 
past outputs  and inputs. Therefore,  when A is nonsingular  the system is  constructible 
if  and  only  if  the  pnX  n  matrix 
CA-
CA-
(1.17) 
has  full  rank,  since  in  this  case  the  only  x  that  satisfies  CA 
'^x  =  0  for  every 
k  ^  0  is  X  =  0.  Note  that  if  the  system  is  observable,  then  it  is  also  constructible; 
222 
Linear Systems 
however, if it is constructible, then it is also observable only when A is nonsingular 
(see Section 3.3). 
EXAMPLE 1.6.  Consider the (unobservable)  system in Example  1.5. Since A is non-
singular, OA  ^ = 
1  01 
.1  OJ 
r  1  0^ 
[-2 
Ij 
"1  0"" "
.1  0_ 
Since rank OA  ^ =  1 <  2, the system [or 
the pair (A, C)] is not constructible. This can also be seen from the relation CA  ^x = 
0,k>  0, that has nonzero  solutions x, since  C  =  [1,0] =  CA~^ = CA~^ =  •••  = 
CA~^ for /: >  0, which implies that any x = 
, c  '  7? is a solution. 
3. Dual  systems 
Consider the system described by 
X =  Ax  +  Bu, 
y  = Cx^Du, 
(1.18) 
"where A  G 7?""X^ B  G R'''''^",  C G  RP''^ 
is defined  as the system 
and D G 7^^^^. The dual  system  of (1.18) 
XD  =  ADXD  +  BDUD, 
yo  =  CDXD  +  DDUD. 
(1.19) 
where AD  =  A^, BD  =  C^,  CD  =  B^,  and Do  =  D^. 
LEMMA 1.1.  System (1.18), denoted by {A, B, C, D}, is reachable (controllable) if and 
only if its dual {A^, BD,  CD, DO} in (1.19) is observable (constructible), and vice versa. 
Proof. System {A, 5, C, D] is reachable if and only if ^  =  [5, AB,...,  A'^'^B] has full 
rank n, and its dual is observable if and only if 
B^ 
B^A^ 
\B^{A^Y-^\ 
has full rank n. Since 0^  =  %, {A, B, C, D} is reachable if and only if {AD, ^D,  CD, /^D} 
is observable.  Similarly,  {A, 5, C, D} is observable  if and only  if  {AD, ^D> CD, DD}  is 
reachable. Now {A, B, C, D] is controllable if and only if its dual is constructible, and 
vice versa; recall from Sections 3.2 and 3.3, a continuous-time system is controllable if 
and only if it is reachable; and is constructible if and only if it is observable. 
For  the discrete-time  time-invariant  case, the dual  system  is  again  defined  as 
AD  =  A^, BD  =  C^,  CD  =  B^,  and DD =  D^.  That  such  a  system  is  reachable 
if  and only  if  its dual  is  observable  can be  shown  in  exactly  the  same  way as in 
the proof  of Lemma  1.1. That  such  a system  is controllable  if  and only  if its dual 
is  constructible  when  A  is  nonsingular  is  true  because  in  this  case  the  system  is 
reachable if and only if it is controllable;  and the same holds for observability and 
constructibility. The proof for the case when A is singular involves the controllable 
and  unconstructible  subspaces  of  a  system  and its dual. We omit  the details. The 
reader is encouraged to complete this proof  after  studying  Sections 3.2 and 3.3. 
In  the time-varying  case,  the  dual  system  is  defined  in  a  similar  manner  as 
given, taking transposes of matrices, and in addition, reversing time. This will not be 
discussed  further  here.  We  merely  wish  to  point  out  that  the  mappings  from  the 
original  system to the dual  system  are in this  case of the form  {A(a  +  t), B(a  +  t), 
C(a  +  tl  D(a  +  t)} -^  {A^(a  -  t), C^(a  -  t), B^(a  -  t), D^{a  -  0}, where a  is a 
fixed real number. Thus, under this transformation  we mirror the image of the graph 
of each function  about a point a  on the time axis and then take the transpose of each 
matrix.  Note  that  the  mapping  between  the  state transition  matrices  is  of  the form 
^^{a-t,a).  With this definition, it is now possible to establish results 
^{a,  a^-t)^ 
similar  to Lemma  1.1  for  the time-varying  case. The proofs  involve  the  Gramians 
defined  in Sections 3.2 and 3.3. 
Figure  3.3  summarizes  the  relationships  between  reachability  (observability) 
and controllability  (constructibility)  for continuous- and discrete-time  systems. 
223 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
Reachability 
Dual 
Observability 
v 
Controllability 
Dual 
V 
Constructibility 
FIGURE 3.3 
In continuous-time systems reachability (observability) always 
implies and is implied by controllability (constructibility). In 
discrete-time systems reachability (observability) always implies 
but in general is not implied by controllability (constructibility). 
B.  Chapter  Description 
This  chapter  consists  of  an  introduction  and  two  parts.  In  Part  1,  consisting  of 
Sections  3.2  and  3.3,  reachability  and  controllability,  and  observability  and  con 
structibility, are introduced and studied. In Part 2, consisting of Sections 3.4 and 3.5, 
special forms for state-space representations of time-invariant systems are developed 
for controllable/uncontrollable,  observable/unobservable  (continuous- and discrete-
time)  systems.  In  addition,  the  poles  and  zeros  of  a  system  are  introduced  and 
studied. 
In  the  introduction.  Subsection  3.1 A,  the  concepts  of  reachability  (or 
controllability-from-the-origin)  and  observability  are  introduced  using  discrete-
time  time-invariant  systems.  The  inputs  that  accomplish  the  desired  transfers  of  a 
state are easily derived in terms of the controllability  (-from-the-origin)  matrix of a 
system.  Conditions  for  reachability  and  observability  are  derived  directly  in  terms 
of the controllability  and observability  matrices  of the system.  Similarly,  controlla 
bility (or controllability-to-the-origin)  and constructibility  are also introduced.  State 
reachability  and  observability  are  related  by  duality.  Dual  systems  and  the  dual 
notions of reachability (respectively, observability) and controllability  (respectively, 
constructibility)  are also  discussed. 
In  Section  3.2, reachabihty  and  controllability  are discussed  at length  for  both 
continuous- and  discrete-time  systems. In the continuous-time  case, the inputs  that 
224 
Linear Systems 
accomplish the desirable state transfers  are derived using the reachability  (and the 
controllability) Gramian. Since with only minimal additional work one can treat the 
time-varying case as well, this is the approach pursued herein, i.e., both time-varying 
and time-invariant cases are studied. The time-invariant case is discussed separately 
and can be treated independently of the time-varying case. This adds significant  flex 
ibility to the coverage of the material in this chapter. Many criteria for reachability 
(controllability) are developed. It is shown that reachability implies controllability, 
and vice versa in the case of continuous-time systems. In discrete-time systems, al 
though reachability implies controllability, controllability does not necessarily imply 
reachability. This is due to the lack of general time-reversibility in the case of differ 
ence equations, as pointed out in Chapter 2. (Note that a detailed section summary 
is included at the beginning of Section 3.2.) 
Observability  and  constructibility  are  addressed  in  Section  3.3, in  a manner 
analogous to the treatment of the dual concepts of reachability  and controllability 
in  Section  3.2. Both continuous- and  discrete-time  cases  are considered.  Observ 
ability and constructibility  Gramians are used to study these properties in the case 
of both time-varying  and time-invariant  continuous-time  systems. Once more, the 
time-invariant  case is treated  separately  and  can be  studied  independently  of the 
more  general  time-varying  case.  Observability  always  implies  constructibility  in 
both continuous- and discrete-time  systems; however,  constructibility  always im 
plies observability only in the case of continuous-time  systems. This is due to the 
lack of general time-reversibility of difference  equations. (Note that a detailed sec 
tion summary is included at the beginning of Section 3.3.) 
In Section 3.4, similarity transformations are used to reduce the state-space rep 
resentations  of  time-invariant  systems  to  special  forms.  First,  standard  forms  for 
uncontrollable  and unobservable  systems  are developed.  These lead  to  Kalman's 
Decomposition Theorem and to additional tests for  controllability  and observabil 
ity that involve eigenvalues  and eigenvectors  of the system matrix A (in Subsec 
tion  B)  and  to relations  between  state-space  and  transfer  matrix  descriptions  (in 
Subsection C). Controller and observer forms  for controllable and observable sys 
tems are derived next (in Subsection D). These forms  are useful  in state  feedback 
control and in state observer design, discussed in Chapter 4. The Structure Theo 
rem is introduced next. This result, which involves the controller (observer) forms 
and relates the state-space representations to the transfer function matrix of the sys 
tem, is used in Chapter  5, where  state-space reahzations  of transfer  functions  are 
addressed. 
In Section  3.5, the poles of a system and of a transfer  function  matrix are in 
troduced. There, the zeros of the system, the invariant zeros, the input and output 
decoupling  zeros, and the transmission  zeros, which  are the zeros of the  transfer 
function matrix, are also introduced. The Smith and Smith-McMillan forms of poly 
nomial and rational matrices, respectively, are used to define poles and zeros. Utiliz 
ing zeros, one can render certain eigenvalues (system poles) and their corresponding 
modes unobservable from  the output, using state feedback.  This leads to the solu 
tion of several control problems, such as disturbance decoupling, model matching, 
and diagonal decoupling. The discussion of poles and zeros of a system {A, B, C, D} 
and of the corresponding transfer function matrix H(s) also helps to clarify the rela 
tionship between internal (state-space) descriptions and external (transfer  function 
matrix) descriptions. This is studied in greater detail in Chapter 5. 
225 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
C.  Guidelines  for the  Reader 
Reachability,  which  is  controllability-from-the-origin  and  controllability  (-to-the-
origin), together with observability  and construetibility  are introduced in Subsection 
3.1 A using discrete-time time-invariant  systems. Careful  study of this  introductory 
section  leads  to  early  and  significant  insight  into  these  important  system  proper 
ties, without requiring  the mathematical  sophistication  needed  in a careful  study of 
these  properties  in  the  continuous-time  case.  Duality  is  also  discussed  in  Subsec 
tion 3.1 A. 
In Part  1, reachability  and controllability,  and observability  and  constmctibility 
are 
in  Sections  3.2  and  3.3,  respectively,  for  continuous-time 
introduced 
time-varying  and  time-invariant  systems  as  well  as  for  discrete-time  systems.  For 
convenience,  detailed  summaries  of  the  results  with  reference  to  particular  def 
initions  and  theorems  are  included  at  the  beginning  of  these  sections.  At  a  first 
reading, one may concentrate on the time-invariant  continuous-time  case  discussed 
in  Subsections  3.2B  and  3.3B.  (Recall  that  an  introduction  to  the  time-invariant 
discrete-time  case  was  presented  in  Subsection  3.1 A.)  The  time-invariant  case  is 
developed in a self-contained  manner in these sections, providing  flexibility  in cov 
erage  of  the material.  Note  that  in  Corollary  2.12, in  Subsection  3.2B,  it is  shown 
that the system is reachable if and only if the controllability  matrix  C has full  rank. 
Theorem  2.13  provides  an  input  u(t)  that  can  accomplish  the  transfer  of  the  state 
from  a  vector  value  XQ  to  another  vector  value  xi,  provided  that  such  transfer  is 
possible, while Theorem  2.17  gives  additional  tests for reachability.  A  relationship 
between reachability  and controllability  is established  in Theorem 2.16. In an anal 
ogous  manner,  in  Corollary  3.8,  in  Subsection  3.3B,  it  is  shown  that  a  system  is 
observable if and only if the observability  matrix € has full rank. A relationship be 
tween observability  and constmctibility  is given in Theorem  3.9, while in  Theorem 
3.10  additional tests for  observability  are presented. A useful  table of all  Gramians 
used in this chapter is provided in the summary  section  (Section  3.6). 
In Part  2,  special  forms  for  state-space  representations  of continuous-time  and 
discrete-time time-invariant  systems are introduced. The standard forms  for  uncon 
trollable and unobservable representations and the Kalman Decomposition  Theorem 
are presented  in  Subsection  3.4A,  and useful  eigenvalue/eigenvector  tests  for  con 
trollability  and  observability  are developed  in  Subsection  3.4B. The controller  and 
observer  forms  and  the  Structure  Theorem  are  discussed  in  Subsection  3.4D.  At 
a  first  reading,  one  could  study  Subsections  3.4A  and  3.4B  and  cover  Subsection 
3.4D  selectively, concentrating  on deriving and using controller and observer  forms 
rather  than  proofs  and  properties.  Note  that  the  controller  and  observer  forms  are 
used primarily  in realization  algorithms in Chapter 5, in a method to assign  closed-
loop eigenvalues  via  state feedback  in Chapter  4, and in Chapter  7, to gain  insight 
into the relations between  state-space and polynomial matrix representations  of lin 
ear  time-invariant  systems.  Furthermore,  the  Structure  Theorem  discussed  in  this 
section  introduces  polynomial  matrix  fractional  descriptions  of  the  transfer  func 
tion  matrix  H(s).  These  descriptions  are  very  useful  in  control  problems  and  are 
discussed further  in Chapter 7. In Section 3.5, the poles and zeros of a system are in 
troduced using the Smith form of a polynomial matrix and the Smith-McMillan  form 
of a transfer function matrix H(s).  The pole and zero polynomials of H(s)  are defined 
next. This  gives rise to the McMillan  degree of H(s)  and to the order of a minimal 
226 
Linear Systems 
realization, discussed in Subsection 5.2C of Chapter 5. The study of poles and zeros 
offers  significant  insight  into  feedback  control  systems.  At  a first reading,  Section 
3.5 may be omitted without loss of continuity. 
P A R TI 
CONTROLLABILITY  AND  OBSERVABILITY 
3.2 
REACHABILITY  AND  CONTROLLABILITY 
The  objective  here  is  to  study  the  important  properties  of  state  controllability  and 
reachability  when  a  system  is  described  by  a  state-space  representation.  In  Sub 
section  3.1 A, a brief  introduction  to these concepts for  discrete-time  time-invariant 
systems  was  given,  where  it  was  shown  that  a  system  is  completely  reachable  if 
and  only  if  the  controllability  (-from-the-origin)  matrix  ^  in  (1.1)  has  full  rank  n 
{rank%  =  n).  Furthermore,  it was  shown  that  the input  sequence  necessary  to ac 
complish  the  transfer  can  be  determined  directly  from  % by  solving  a  system  of 
linear  algebraic  equations.  In  a  similar  manner,  we  would  like  to  derive  tests  for 
reachability  and  controllability  and  determine  the  necessary  system  inputs  to  ac 
complish  the state transfer  for  the continuous-time  case. This is the main  objective 
of this  section. We note, however, that whereas the test for reachability  in the time-
invariant case {rank ^  =  n) can be derived by a number of methods, the appropriate 
sequence of system inputs to use cannot easily be determined directly from ^,  as was 
the case for discrete-time  systems. For this reason, we use an approach that utilizes 
ranges of maps, in particular, the range of an important nXn  matrix—the reachabil 
ity Gramian. The inputs that accomplish the desired state transfer can be determined 
directly  from  this  matrix.  However,  once  this  is  accomplished,  we  can  develop  all 
the results for the time-varying  case as well, with hardly  any  additional work. This 
is the approach we will employ. The reader can skip the more general material, how 
ever, starting with Definition  2.1, and concentrate on the time-invariant case starting 
with Definition  2.9, if  so desired. The contents  of this  section  are now presented  in 
greater detail. 
Section  description 
In this section, the concepts of reachability and controllability are introduced and 
discussed  in detail for  linear  system  state-space  descriptions. This is  accomplished 
for  continuous- and discrete-time  systems for both time-varying  and  time-invariant 
cases. 
Reachability  for continuous-time  systems is discussed first and the reachability 
Gramian  Wr(to, ^i) is defined  (in Definition  2.7). It is then  shown  (in Corollary  2.3) 
that the system is reachable at t\ if and only if Wr(to, t\) has full rank for some /Q — ^i • 
Reachability  implies that it is possible to transfer  the state from  a value  XQ to some 
value  xi,  and  system inputs that accomplish  this transfer  are given in Theorem  2.4 
and Corollary  2.5. Controllability  is discussed next and the controllability  Gramian 
is  defined  (in  Definition  2.8).  It is  shown  (in  Theorem  2.6)  that  a  continuous-time 
227 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
system  is  reachable  if  and  only  if  it  is  controllable.  Two  additional  results  (Theo 
rems  2.8  and  2.9)  provide  further  criteria  for  reachability  and  controllability.  All 
these results are then applied to the continuous-time time-invariant case. The above 
material is presented in a manner that makes possible the study of time-invariant sys 
tems, independent of the time-varying case. In Lemma 2.10, a relationship  between 
the reachability  Gramian  Wr(0, T)  and the controllability  (-from-the-origin)  matrix 
%  =  [B, AB,...,  A'^'^B]  is  estabHshed.  It  is  then  shown  in  Corollary  2.12  that  a 
system  is reachable  if  and  only  if ^  has  full  rank  n.  A  system  input  sequence  that 
transfers  the state from  XQ to xi  is derived in Theorem 2.13 and in Corollary 2.14. In 
Theorem 2.16 a relationship between reachability  and controllability  is  established, 
and Theorem 2.17 provides additional tests for  reachability. 
For  discrete-time  systems,  in  particular,  discrete-time  time-invariant  systems, 
reachability  and  controllability  are  discussed  next.  Here, the  controllability  matrix 
% plays  a predominant  role.  It  is  shown  that  when  ^  has  full  rank,  the  system  is 
reachable  (Corollary  2.19),  and  input  sequences  that  transfer  the  state  to  desired 
values are derived  (Theorem 2.20 and Corollary 2.21). In Theorem 2.22 it is shown 
that reachability  in the case of discrete-time  systems always implies  controllability. 
In contrast  to the  continuous-time  case, the  converse  to this  statement  is  generally 
not true. This is due to a lack of time reversibility  in difference  equations. When  A 
is nonsingular,  then  controllability  also implies  reachability.  Finally,  in  Definitions 
2.13 and 2.14 the reachability and controllability Gramians for the discrete-time case 
are defined  for  sake of completeness. 
A.  Continuous-Time  Time-Varying  Systems 
We consider the state equation 
X =  A{t)x  +  B{t)u, 
(2.1) 
where A{t)  G  R'''^'',"  B{t)  G R^^^^  and  u(t)  G  R""^ are defined  and  (piecewise)  con "
tinuous on some real open interval  {a, b). The state at time t is given by 
x{t,  to, XQ)  ^  x{t)  =  ^{t,  to)x(to)  + 
0(^,  T)B(T)U(T)  dr, 
(2.2) 
J to 
where ^(t,  r) is the state transition matrix of the system, to, t  G {a, b), and x(fo)  = XQ 
denotes the initial state at initial time. 
In the time-invariant  case. 
"where A  G /^^><""", B  G /^^><'^, (2.2) is still valid  with 
X =  Ax  +  Bu, 
^{t,  T)  =  ^{t  -  T, 0)  -  exp [{t -  T)A\  =  e^^'-^\ 
(2.3) 
(2.4) 
We are interested  in using  the input to transfer  the  state from  XQ  to some  other 
value  x\  at  some  finite  time  ti  >  to, [i.e., x(ti)  =  xi].  Equation  (2.2)  assumes  the 
form 
Xi  =  $(^1, ^o)^0  + 
0(^i,  T)5(T)W(T)JT, 
(2.5) 
228 
Linear Systems 
and clearly, there exists u(t), t  E  [/Q, h ] that satisfies  (2.5) if and only if such  transfer 
^f ^^e state is possible. Rewriting  (2.5) as 
ch 
jci  -  (5(^1, ro)xo  = 
^{ti,  T)B{T)U{T)  dr 
(2.6) 
and letting  xi  ^^ x\  -  ^{h,  to)XQ,  we note that the  u{t) that transfers  the state  from 
XQ  at ^0 to  x\  at time  t\  will  also cause the  state to reach  x\  at ti,  starting  from  the 
origin at to (i.e., x{to)  =  0). 
For system (2.1), we introduce the following  concept. 
DEFINITION  2.1.  A State  xi  is reachable  at time t\  if  for  some finite to < t\  there 
exists an input u{t\  t E  [to, t\\  that transfers the state x{t) from the origin at ^o, to x\  at 
time t\  [i.e., that transfers x(t) from x(tQ)  =  0 to x(t\)  =  xi]. 
Thus, when xi is reachable at ti [with x(to) = 0], then in view of (2.5), there exists 
an input u such that 
xi  =  i'  c^(ti,T)B(T)u(T)dr. 
(2.7) 
• 
We note that the times  ti  and  to are important  individually  in the  time-varying 
case only; in the time-invariant case, as is well known by now, ti -  to is the important 
quantity, and typically ^o is taken to be ro  =  0 with ti  =  T,3. finite positive number. 
The set of all reachable states xi  contains the origin and constitutes a linear sub-
space of the state space (X, R)  =  (R^, R) (verify this). This gives rise to the following. 
DEFINITION 2.2.  The reachable at ti subspace R[^ of (2.1) is 
Rr^ = {set of all states x\  reachable at ^i}. 
• 
When  the context is clear  and there is no ambiguity,  we will write  Rr in  place 
ofR',. 
DEFINITION 2.3.  The system (2.1) is (completely state) reachable at ti if every state 
xi in the state-space is reachable at ti (i.e., Rr =  R'^). In this case, we equivalently make 
• 
reference to reachable pair (A(t), B(t)) atti. 
A reachable  state is  sometimes  also called  controllable-from-the-origin.  Addi 
tionally, there are also states defined  to be controllable-to-the-origin  or simply  con 
trollable.  In particular, we have the following  notion. 
DEFINITION 2.4.  A state XQ is controllable at time to if for some finite t\  > to there 
exists an input u(t\  t E  [to, ti] that transfers the state x(t) from  xo at ^o to the origin at 
time ti  [i.e., from x(to) = xo to x(ti)  =  0]. 
• 
In view of (2.5), there exists an input u such that 
-^(tu 
to)Xo  = 
f  '  ^(h, 
JtQ 
T)B{T)u{T)dT, 
or by premultiplying by ^~^{t\,  to)  =  ^(to,  ti)  (see Section 2.3), 
- xo  =  f  ' 0(^0, T)B{T)u{r)dT, 
(2.8) 
(2.9) 
where the semigroup property ^{to,  t\)^{t\y  r)  =  0(^0, r)  was used. 
Similar to the case of reachable  states, the set of all controllable  states  includes 
the origin, and is a linear subspace  Re of the state-space X  (i.e.. Re  C  X). 
DEFINITION 2.5.  The controllable at to subspace /?J? of (2.1) is 
R^c  = {set of all states XQ controllable at ^o}- 
It is denoted by Re for convenience when there is no  ambiguity. 
229 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
• 
DEFINITION2.6.  The system (2.1) is (completely state) controllable at to if every state 
xo in its state-space is controllable (i.e., if Re = R^). In this case, we equivalently make 
reference to controllable pair (A(t), B(t)) at ^. 
• 
Discussion 
Relation  (2.7) shows that for  x  =  A(t)x  +  B(t)u  given in (2.1) and for given  ti, 
the range of the integral  map 
L  =  L(u,  to, ti)  = 
^{t\, 
T)B{T)U{T) 
dr 
(2.10) 
with  u{t), t  E  [^0, ^i],  and  with  t^  varying  over  all  finite  values  ^Q <  ^i, is  exactly 
the reachability  subspace  Rr,  since  a state  x\  is reachable  if  there exists  a t^ and u 
such  that  xi  E  2/l(L). Notice  that  in  view  of  (2.6), the  input  u which  transfers  the 
state  from  the  origin  at  t^io  x\  at  t\  also  transfers  the  state  from  XQ at  t^io  xi  at 
t\,  where xi  =  x\  — ^{t\,  ^)xo. For fixed  XQ, since {x\}  spans the reachability  sub-
space /^^\ this relation yields all states xi  that can be reached from  XQ in finite time 
t\  -  to-
In  Lemma  2.1, the  range  of  L  is  shown  to  be  equal  to  the  range  of  a  matrix, 
the reachability  Gramian  Wr(to, t\),  which  is rather  easy  to determine. In the time-
invariant case, it is also shown to be equal to the range of the controllability  matrix 
%. Before  proving  these  results,  the  relation  between  reachability  (controllability-
from-the-origin)  and  controllability  (controllability-to-the-origin)  is  discussed;  the 
exact relation is proved in Theorem 2.6. 
In view of (2.7) and (2.8), a vector x is reachable  (controllable-from-the-origin) 
at  t\  if  there  exists  a  finite  ^o and  u(t), t  E  [^o, ^i],  so  that  x  E  9l(L),  where  L  is 
defined  in  (2.10), and it is controllable  (-to-the-origin)  at ^o if 0(^i, to)x  E  Sl(L). It 
is shown later (Theorem 2.6) that the system (2.1), or the pair (A, B), is  (completely 
state) reachable if and only if it is controllable. This is the reason why only one term 
is typically  used  in  the  literature  when  describing  these properties  for  continuous-
time  systems. For discrete-time  systems, however,  the  situation  is different.  In this 
case,  as  will  be  shown  later  in  this  section,  if  the  pair  (A, B)  is  reachable,  then  it 
is also controllable, but not necessarily  vice versa; that is, in the discrete-time  case 
controllability  does  not  necessarily  imply  reachability.  Indeed,  controllability  im 
plies reachability  only when the state transition matrix ^(k,  ko) has full rank, which 
is not  always  true in  discrete-time  systems. As  discussed  in  Chapter  2, this  is  due 
"to  the  lack  of  the  ""time  reversibility""  property.  On  the  other  hand",  in  the  case  of 
continuous-time  systems, ^(t,  r)  is always nonsingular. In such systems, reachabil 
ity  implies  that  any  state  xi  can  be  reached  from  any  other  state  XQ  in  finite  time 
"ti  -  to. This property is sometimes used in the literature to define  ""controllability."" "
An  input  that  achieves  this  transfer  is given  later  in  Corollary  2.5. In the  discrete-
time systems literature," the term that is typically used is ""reachability""; however", for 
simplicity," the term ""controllability"" is sometimes  also used", with  some sacrifice  of 
230 
Linear Systems 
accuracy.  We will  use both  terms,  reachability  and controllability,  with  a warning  to 
the reader  when  use of the term  controllability  (-from-the-origin)  is made,  instead  of 
reachability. 
Now  suppose  there  exists  an  input  u  which  transfers  the  state  of  the  system 
from  x{to)  =  0  to  x{ti)  =  x i,  that  is,  (2.7)  is  true.  The  integral  in  (2.7)  is  a  map 
L  =  L{u,to,ti) 
defined  in  (2.10)  that  maps  an  input  u{t)  ^  R^  defined  over  [^o^^i] 
to  states xi  ^  R^.  We are interested  in the range  of L,  ^ ( L)  since  it contains  all the 
states that can be reached  from  the origin, x{to)  =  0, at time ti,  by varying the input  u. 
Note  that L has infinite-dimensional  domain,  and therefore  it is not easy to  determine 
its  range  directly.  In  the  following  we  show  that  ^ ( L)  is  equal  to  the  range  of  an 
important  matrix,  the reachability  Gramian. 
DEFINITION  2.7.  The reachability  Gramian  of the system x = A(t)x-\-B(t)u 
nxn  matrix 
is the 
Wr{toA)  =  r O ( n , T ) 5 ( T ) 5 ^ ( T ) 0 ^ ( n , T ) J T, 
Jto 
where 0(r, T)  denotes the state transition matrix. 
(2.11) 
• 
Note  that  Wr is  symmetric  and  positive  semidefinite  for  every  ti  >  to;  that  is, 
Wr  =  W^  and  Wr >  0  (show  this).  Now  let  to <  ti  be  given.  Then  the  following 
lemma  can be  shown. 
L E M MA  2.1.  ^{L{u,to,ti)) 
=^{Wr{to,ti)). 
Proof,  We  first  show  that  ^(W^)  C  ^ ( L ).  Let  xi  G ^(W^);  that  is,  there  exists 
7]i  eR^  such  that  WrT]i  =xi.  Choose  UI{T) = B^(T)^^{ti,T)rii. 
Then  L{ui,to,ti)  = 
Jl^ 0{ti,T)B{T)B^ 
{T)0^  {ti,T)dT\rii  =Wrrii  =xi.  Therefore,  xi  G ^ ( L ), and since 
xi  is arbitrary, it follows  that ^{Wr)  C ^ ( L ). 
We  shall  now  show  that  ^ ( L)  C ^(Wr),  which  together  with  ^(Wr)  C ^ ( L) 
proves  that  ^ ( L)  =  ^(W^).  Let xi  G ^ ( L ),  i.e.,  there  exists  an  input  ui  such  that 
L{ui,to,ti)  = xi.  We assume  that  xi  ^  ^(W^) and we  shall  show  that  this  leads  to a 
contradiction.  This implies that the null  space of W^(^0,^1) is nonempty.  Wr is  symmet 
ric,  and so the range of Wr is the orthogonal  complement  of its null  space  (prove this). 
Thus  for any u G ^{Wr)  and v G yK(Wr),  u^v  = 0. Also,  we may write xi  = x^^ +x'/ 
with  x[  G ^(Wr)  and  x'l  G yK{Wr)  (x'l ^  0  since  xx  ^  ^(Wr)).  Then  there  exists 
X2 G yK(Wr)  such  that  X2x'( ^  0,  which  implies  X2X1  7^ 0. Now ^2 Wr(^0,^1 )-^2  =  0  = 
Ho [ 4 ^ ( ^ i ' ^ ) ^ ( ^ )]  [xl^{tuT)B{T)fdT 
=  g'  II x^O(ri,T)5(T)  11^ J T,  which  shows 
that^2 0(^1, T)B{T)  = 0 for every  T G [^0,^1]• This in turn implies that^2xi  = X2L{u\)  = 
= 0,  which  is  a  contradiction  since  ^2X1 7^ 0.  Therefore, 
Jl^[xl^{tuT)B{T)]ui{T)dT 
XI  G ^(Wr),  which implies that ^ ( L)  C ^(Wr). 
• 
Lemma  2.1  shows  that  the  set  of  all  states  that  can be  reached  at  time  ti  from 
the  range  of  the 
the  origin  at  some  finite  time  to <  ti,  is  given  by  ^(Wr{to,ti)), 
reachability  Gramian. 
THEOREM  2.2.  Consider the systemi  = A(^)x + 5(^)w givenin  (2.1). There exists an 
input  u that  transfers  the state to xi  at ti  from  the origin  at some  finite  time  ^0 <  ^1 ^  if 
and only if there exists finite time ^0 < h  so that 
XI 
e^{Wr{to,ti)). 
Furthermore, an appropriate u that will accomplish this transfer  is given by 
231 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
u(t)  =  B^{t)^^{ti, 
t)j]i 
(2.12) 
with 171  a solution of Writ^, ti)ri\  =  xi  and t G [to, ti]. 
Proof,  In view of Lemma  2.1 and the definition  of L(u) in (2.10), the proof  of the first 
part of the theorem is straightforward.  To prove the second part of the theorem, note that 
• 
(2.12) was used in the proof of Lemma 2.2 to accomplish the transfer  to xi. 
COROLLARY  2.3.  The system  x  =  A(t)x  +  B(t)u  is (completely  state)  reachable at 
ti,  or the pair (A(t),  B(t)) is reachable at ti, if and only if there exists finite to < t\  such 
that 
rank  Wr{to, t\)  =  n. 
(2.13) 
Proof.  In  view  of  Theorem  2.2, all  states  xi  can be reached  at  ti  if  and only  if for 
some  to  <  h,"^{Wr(toyt\))  =  ^""",  the  entire  state  space.  This  is  true  if  and  only  if 
• 
rank  Wr{to, ti)  =  n for some finite ^  <  ^1. 
The  following  result  is  useful  in  accomplishing  the transfer  from  a  state  XQ to 
another  state  x\  in some  given  finite  time  t\ 
-to. 
THEOREM  2.4.  There  exists  an  input  u  that  transfers  the  state  of  the  system  x  = 
A(t)x  + B(t)u from  xo at time to to xi  at time ti  >  to if and only if 
Xi  -  ^(ti, 
to)Xo  E  ^(Writo, 
h)). 
Furthermore,  such input is given by 
u(t)  =  B^(t)^'^(ti, 
t)r]i 
with 171  a solution of 
W'^(^o, ^i)'»7i  =  -^1 
-^{ti,to)xo' 
(2.14) 
(2.15) 
(2.16) 
Proof  The proof is straightforward  in view of Theorem 2.2 and the fact that there exists 
an input  which  transfers  the state from  xo at to to xi  at t\  if and only if it transfers the 
• 
state from the origin at to to xi  =  x\  -  0(fi, to)xo at t\  [see (2.6)]. 
EXAMPLE  2.1.  Consider i:  =  A(Ox + 5(0w, where A(0  = 
B{t)  =  0 
The  state  transition  matrix  was calculated  in Example  3.4, Section  2.3 (of Chapter 2), 
to be 
-1 
0 
e^' 
-1 
^{U  T) 
O-it-T) 
7+3x1 
i^z.^ W^' — e 
-a-r) 
Here ^{t, 
T)B(T) 
0 
and the reachability  Gramian of the system is 
WritoJl) 
to  L  0 
dr  =  '(ti  -  to)e-^' 
1  0' 
0_ 
0 
It  is  clear  that  rankWr{toy ti)  <  2  =  /2  for  any  to <  t\  and  therefore  the  system 
is  not reachable  at  t\.  Note  that  since  t\  is  arbitrary,  the  system  is  not reachable  at 
any  finite  time.  However,  the  state  can  be  transfered  from  the  origin  to  a  state 
xi  E  ^{Wr{to,  h)).  In  particular,  in  view  of  Theorem  2.2,  let  xi  = 
\(X 
I,  a  E  R, 
232 
Linear  Systems 
and solve Wr{to, ti)r]i  =  xi  to obtain r/i  = 
-to 
where p  G R arbitrary. Then, 
_e^h 
in  view  of  (2.12),  u(t)  =  [<^(ti,"t)B{t)fr]i  =  [^""^i",0] 
- ^0 
-e^^ will 
to 
drive  the  state  from  the  origin  at  ^o to  xi  at  ti.  To  verify  this,  we  note  that  x(ti)  = 
\;'^{h,T)B{T)u{T)dT 
= 
0 
-e'^ih  -to)  =  ,,_.  Notice  that  for  the  transfer 
t\  —  to 
to  be  accomplished  in  a  short  period  of  time,  t\  -  to  =  e  with  e  small,  the  required 
control magnitude can be quite large since  uit)  =  (a/e)e^^. 
• 
The last observation  in Example  2.1 points to two important  aspects that we  now 
elaborate  on. 
First,  we  note  that  the  faster  the  state  of  the  system  is  required  to  move  (the 
smaller  the  ti  -  to  =  e)  and  the  further  away  the  desired  state  x\  is  (the  larger  the 
a ),  the  larger  the  required  control  magnitude  will  be.  This  makes  intuitive  sense 
since  it  simply  states  that  the  more  sudden  and  drastic  the  change  in  the  state,  the 
larger  the  required  control  force  will  be  (think,  e.g.,  of  a  simple  mechanical  spring 
system). 
Second,  it  is  clear  that  the  property  of  reachability  (controllability)  implies  the 
ability  to  change  the  state  of  the  system  very  fast  indeed,  paying  for  this  of  course 
in  terms  of  increased  control  magnitude  (see  Example  2.1  and  Exercise  3.12).  In 
tuitively,  this  is  not  always  possible  in  the  case  of  physical  processes,  where  only 
limited  control  action  is typically  available.  This  points  to  some  of the  limitations  of 
linear  system  models  that  do  not  include  information  about  input  saturation  limits, 
nonlinear  behavior,  limitations  of  output  sensors,  and  the  like. 
EXAMPLE  2.2.  Consider  the  system  described  by  i  =  A(t)x  +  B(t)u,  where  A(t)  = 
-1 
0 
e^' 
-1 
B(t)  = 
.  The  state  transition  matrix  ^(?, T)  is  given  in  Example 2.1. 
Here 0(?, r)B(T)  = 
the system is reachable at ti  (show this). 
and the reachability Gramian  Wr(to, t\)is  such that 
• 
e~ 
-t+2T-\ 
The following  result demonstrates  the importance  of reachability  in  determining 
an  input  u to  transfer  the  state  from  any  XQ to  any  x\  in  finite  time. 
COROLLARY  2.5.  Let the system  i:  =  A(t)x  +  B(t)u  be (completely  state)  reachable 
at time  t{,  or let the pair  (A(t),  B(t))  be reachable  at  ti.  Then  there  exists  an  input  that 
will transfer  any state xo at some finite time to <  ti,  to any state xi  at time ti.  Such input 
is given by 
u(t)  =  B^(t)^^(ti,t)W;\to,ti)[xi 
-<^(ti,to)xo] 
(2.17) 
fort  E  [^0,^1]. 
Proof,  In view of Corollary  2.3, reachability  implies that, given ti,  rank Wr(to, ti)  =  n 
for  some  ^o <  t\  or that ^{Wr{to,"  t\))  =  /?""", the whole  space, for  some to. This  implies 
that any vector xi  - ^ ( ^ i,  to)xo G ^(W;.(^, ^0), which in view of Theorem 2.2 and (2.12) 
implies that the input in (2.17) is an input which will accomplish  this transfer. 
• 
There  are  many  different  control  inputs  u  that  can  accomplish  the  state  trans 
fer  from  Xo  at  ^  =  to  to  x\  at  t  =  ti.  It  can  be  shown  that  the  input  u  given  by 
(2.17)  accomplishes  this  transfer  while  expending  a  minimum  amount  of  energy. 
In  particular,  among  all  the  control  inputs  u(t)  that  will  transfer  the  state  from  XQ 
at  to  to  xi  at  t\,  u(t)  in  (2.17)  minimizes  the  cost  functional  J/^  ||W(T)|P J r,  where 
\\u(t)\\  =  [w^(Ow(0]^^^theEuchdean  norm  of  u(t). 
We  shall  now  establish  a connection  between  controllability  and  reachabihty  of 
the  continuous-time  system  x  =  A(t)x  +  B(t)u. 
233 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
THEOREM  2.6.  If the  system  x  =  A(t)x  +  B(t)u,  or the pair (A(t),  B(t)),  is  reachable 
at  ti,  then  it  is  controllable  at  some  ^  <  ^i. Also,  if  it  is  controllable  at  ^o, then  it  is 
reachable at some ti  >  to. 
Proof.  It was  shown  in  Corollary  2.3 that  for  reachability  of  (2.1)  at ti,  we must  have 
rank Wr(to, ti)  =  n. A  similar test for controllability can be derived in an identical man 
ner. In particular, in view of (2.9), it is clear that the range of 
L  =  L{u,tQ,ti)  = 
(^(to, T)B(T)U(T) 
dT 
(2.18) 
is  of  (present)  interest  [compare  with  L  in  (2.10)  used  to  prove  reachability].  A  re 
sult similar to Lemma  2.1 can now be established  using  an identical  approach,  namely, 
that ^(L(u, 
to, ti))  =  '3i(Wc(to, ^i)), where  Wdto,  ti)  is the controllability  Gramian,  de 
• 
fined next. 
DEFINITION2.8.  The controllability  Gramian  of the system  x 
nX  n matrix 
A(t)x  + B(t)u  is the 
Wc(to,ti) 
^(to,  T)B{T)B^{T)^^{to, 
T)dT, 
(2.19) 
where ^{t,  r)  denotes the state transition  matrix. 
Continuing  the proof of Theorem 2.6, we note that it can be shown that the input 
uiit)  = 
-B^(t)^^(toJ)vi 
(2.20) 
with 171  such that  Wdto,  ^1)171  =  ^0 satisfies  L(wi, to, ti)  =  -XQ  or relation  (2.9). Thus, 
171(0 drives the state from  xo at time to to the origin at time ti  >  to (compare with Theo 
rem 2.2). As in Corollary 2.3 for the case of reachability, it can be shown in an analogous 
manner that the system is (completely  state) controllable  at to if and only if there  exists 
ti  >  to so that 
Next, we note that in view of the definitions  of  Wr and  Wc, 
rank  Wdto,  ti)  =  n. 
Wr(to,ti)  = 
^(tiJoWc(to,ti)^^(tuto)-
(2.21) 
(2.22) 
Since  0(ri, ^o) is  nonsingular  for  every  to and  t\,  rank  Wr(to, ti)  =  rank Wdto,  ti)  for 
every to and ti.  Therefore,  the system  is reachable  if and  only  if it is controllable. 
• 
EXAMPLE2.3.  Consider the system  x 
lability Gramian is given by 
A{t)x  +  B{t)u  of Example  2.1. The control-
Wc{to,ti) 
[e-'^0]dT  = 
0 
to 
(ti-to)e-^'o 
0 
0 
0 
Compare this with the reachability Gramian of Example 2.1 and note that 4>(ri, to)) 
Wc(to,ti)<^^(ti,to) 
0 
Wr(to, ti),  as expected  [see (2.22)]. 
(ti  -  to)e-^'^+'o)  0 
0 
^ ^ ( ^ 1 , ^ 0) 
= 
to) 
'dti 
0 
234 
Linear Systems 
Before proceeding, we note that a relation similar to (2.17) can be derived using 
^^^ Gramian  Wdto,  ti) and (2.20) in place of Wr(to, ti). In particular, an appropriate 
input that transfers  the state from  XQ at to to xi  at ti is given by 
u(t)  =  -B^(t)^^(to, 
t)W;\to, 
ti)[xo  -  $ (% h)xil 
(2.23) 
We ask the reader to show  that this relation  can also be derived  from  (2.17), using 
(2.22). 
Additional  criteria for reachability and controllability 
First recall from  Chapter 2 the definition  of a set of linearly  independent  func 
tions  of  time  and  consider  in  particular  n  complex-valued  functions  fi(t\  i  = 
1,...,  /i,  where  f^{t)  G  C^.  Recall  that  the  set of  functions  fi,i  =  1,..., n, is 
linearly  dependent  on a time interval  [ti, ^2] over the field of complex numbers  C if 
there exist complex numbers at, i  =  \,..  .,n,  not all zero, such that 
^ i / i (0  +  • • *  +  ^nfn(t)  = 0 
for all t in [ti, ^2]; 
otherwise, the set of functions  is said to be linearly  independent  on [ti, ^2] over the 
field of complex  numbers. 
It  is possible  to test  linear  independence  using  the Gram  matrix  of the  func 
tions  fi. 
"LEMMA 2.7.  Let F(t) G C^""^ be a matrix with fi(t) G C^^"""" in its /th row. Define the "
Gram matrix of fi(t), i  = 1,..., ^, by 
W(tiJ2)  = 
F{t)F\t)dt, 
(2.24) 
where ( • )* denotes the complex conjugate transpose. The set fi{t\  i  = I,..  .,n,is  lin 
early independent on [ti, ^2]  over the field of complex numbers if and only if the Gram 
matrix  W(ti, ^2) is nonsingular,  or equivalently,  if and only if the Gram  determinant 
det W{ti, t2)  7^ 0. 
Proof, {Necessity) Assume the set fi,i  = I,...,  n, is linearly independent but W{t\, ^2) 
"is singular. Then there exists some nonzero a  ^  C^^""^ so that a W^(ri", ti)  = 0, from which 
aW(ti,t2)a*  = l^[\aF(t))(aF(t)ydt  = 0. Since (aF(t))(aF(t)y  >  0 for all r, this im 
plies that aF(t)  = 0 for all t in [^1, ^2], which is a contradiction. Therefore  W(ti, ^2) is 
nonsingular. 
(Sufficiency)  Assume that  W(ti, ^2) is nonsingular but the set fi,i  =  1,..., n, is 
linearly dependent. Then there exists some nonzero a ^  C^^^ so that aF(t) = 0. Then 
aW(ti,  ^2) = J/^ aF(t)F*(t)dt  = 0, which is a contradiction. Therefore the set fi, i = 
1,..., /t, is linearly independent. 
• 
We will use the above result to derive additional tests for reachability  and con 
trollability  in this  section and for observability  and constructibility  in the next  sec 
tion. In the following  two theorems, we repeat some earlier results, for convenience. 
THEOREM 2.8.  The system x  = A(t)x + B(t)u is (completely state) reachable at ti 
(i) if and only if there exists finite ^0 <  ^1, such that 
rankWritoJi)  = n, 
(2.25) 
j /^  <I>(ri, T)5(T)B^(T)^^(ri, T)(iT,  the  reachability  Gramian,  or 
\,l'^(tuT)l 
),^l)  ^ 
where  Wr(to,ti)  - 
equivalently, 
(ii) if and only if there exists finite ^o  < ^i, such that the n rows of 
235 
^{h,  t)B{t) 
(2.26) 
are Hnearly independent on [t^, t\\ over the field of complex numbers. 
Proof. Part (i) was established in Corollary 2.3, while part (ii) is a direct consequence 
of the previous lemma and the definition of the reachability Gramian. 
• 
Similar results can be derived for controllability.  Specifically,  we have the fol 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
lowing  result. 
THEOREM 2.9.  The system x  = A(t)x + B(t)u is (completely state) controllable at to 
(i) if and only if there exist finite ti > to such that 
rank Wdto, ti)  = n, 
(2.27) 
where Wc(^, ti)  =  j^^^ 0(^0, T)5(T)5^(T)0^(^,  T) (ir, the controllability Gramian, 
or equivalently, 
(ii) if and only if there exists finite ti > to such that the n rows of 
are linearly independent on [^o, ^i] over the field of complex numbers. 
Proof, The proof is analogous to the proof for Theorem 2.8. 
0(^, t)B(t) 
(2.28) 
• 
Notice that premultiplication  of $ ( ^,  t)B(t)  by the nonsingular matrix 0(?i, ^o) 
yields $(fi, t)B(t)  [refer to (2.26) in the reachability theorem; compare with (2.22)]. 
This can be used to prove in an alternative way the result of Theorem 2.6, that reach 
ability  (controllability-from-the-origin)  implies  and  is  implied  by  controllability 
(-to-the-origin), in the case of continuous-time  systems (show this). 
B.  Continuous-Time  Time-Invariant  Systems 
We  shall  now apply  the results  developed  above  to  time-invariant  systems  x  = 
Ax  +  Bu  given  in  (2.3). In this  case,  the state  transition  matrix  <tf(t, r)  is explic 
itly  known  and is given  by ^(t,  r)  =  ^^(^~'^) in (2.4). Because  of time  invariance, 
the difference  t\  -  to =  T,  rather than the individual  times  ^Q and ti,  plays  an im 
portant role. Accordingly," for the time-invariant case we can always take ^o ""^ 0 and "
ti  =  T. This practice will be adopted in the following. 
The  definitions  of reachability,  Definitions  2.1 to 2.3, and controllability,  Def 
initions  2.4 to  2.6, are certainly  also  valid  in the time-invariant  case.  We repeat 
them here for convenience, specializing them to the the system x  = Ax-\- Bu given 
in (2.3). 
DEFINITION  2.9.  (i)A State xi is reachable if there exists an input u{t), t E  [0, T], 
that transfers the state x{t) from the origin at r =  0 to ;ci in some finite time T. 
(ii)  The set of all reachable states Rr is the reachable subspace of the system i: = 
Ax  + Bu, or of the pair (A, B). 
(iii)  The system x  = Ax + Bu, or the pair {A, B) is {completely state) reachable if 
every state is reachable, i.e., if Rr = R^. 
• 
DEFINITION 2.10.  (i)A State xo is controllable if there exists an input u(t), t G [0, T], 
that transfers the state x(t) from xo ^tt  = 0 to the origin in some finite time T. 
236 
Linear Systems 
(ii)  The  set  of  all  controllable  states  Re  is  the  controllable  sub space  of  the 
system i  =  Ax + Bu,  or of the pair  (A, 5). 
(iii)  The system i  = Ax+Bu, or the pair (A, 5), is {completely  state)  controllable 
• 
if every  state is controllable, i.e., if Re = R^. 
DEFINITION  2.11.  The  n  X n  reachability  Gramian  of  the  time-invariant  system 
x=  Ax-\-Bu  is 
Wr{0, T)  ^ 
r  e^^-'^^BB^e^^-'^'^'dT. 
Jo 
(2.29) 
g 
Note  that  Wr is  symmetric  and  positive  semidefinite  for  every  T  >  0,  i.e.,  W^  = 
matrix 
(-from-the-origin) 
Wj  and  Wr  >  0  (shovv^ this).  Let  the  n  x  mn  controllability 
(or more  precisely,  the  reachability  matrix)  be 
and  recall  that  ^  vv^as also  defined  in  Section  3.L 
^ = [ 5 , A 5 , . . . , A ^ - ^ 5 ], 
(2.30) 
It  is  now  shovv^n  that  in  the  time-invariant  case  the  range  of  Wr(0, T),  denoted 
by  ^ ( W r ( 0, r ) ),  is  independent  of  T,  i.e.,  it  is  the  same  for  any  finite  T{>  0), 
and  in  particular,  it  is  equal  to  the  range  of  the  controllability  matrix  ^.  Thus,  the 
reachable  subspace  Rr  of  a  system  is  given  by  the  range  of  ^,^(^), 
or the  range  of 
Wr{0,  T),^{Wr{0, 
r ) ),  for  some  finite  (and  therefore  for  any) 
T>0. 
LEMMA  2.10.  ^ ( W , ( 0 , r ))  = ^ ( ^)  for every  T  >  0. 
Proof,  We  first  show  that  ^(Wr)  C  ^ ( ^)  for  some  T  >  0.  Let  xi  e  ^{Wr) 
for 
some  r  >  0.  In  view  of  Lemma  2.1,  xi  G ^ ( L ),  i.e.,  there  exists  ui  such  that 
L(wi,0,r)  =  /Q {Qxp[(T — T)A]}Bui{T)dT  = xi.  Using  the  series  definition  exp[A^]  = 
Er=o(^  /^-M  '  -^1 ^^^  t)e  written  as xi  =  Yk=o'^^ 
f^{iT-Tf/kl)ui{T)dT\ 
or,  in 
view of the Cay ley-Hamilton Theorem, xi  =  2^~Q A^5ay^(r), where  ak{T)  is appropri 
ately defined.  This imphes thatxi  G ^ ( ^ ).  Since xi  is arbitrary, ^{Wr)  C  ^ ( ^ ). 
We shall now show that ^ ( ^)  C^{Wr).LQtxi  G ^ ( ^ ), i.e.," there exists 7] i  eR""""""^ "
such  that  ^ r |i  =  xi.  Assume  that  xi  ^  ^(W^)  for  some  7  >  0.  We  shall  show  that 
this  leads  to  a  contradiction.  This  implies  that  the  null  space  of  Wr  is  nonempty. 
Wr  is  symmetric,  and  so  the  range  of  Wr  is  the  orthogonal  complement  of  its  null 
space  (prove  this).  Thus  for  any  u  e  ^(Wr)  and  v G yK{Wr),u^v  =  0.  Also,  we  may 
write  XI  =  x[  +x'/  with  x[  G ^{Wr)  and  x'l  G ^ ( W ,)  (x'l  ^  0  since  xi  ^ 
^(Wr)). 
Then  there  exists  X2 G yl^{Wr)  such  that  X2x'( ^  0,  which  implies  X2X1 7^ 0.  Next, 
consider  xlWr{0,T)x2  =  0  =  /o^[x^{exp[(r  -  T)A]}5][x^{exp[(r  -  T)A]}B]^dT  = 
JQ  \\xl{Qxp[{T  -  T)A]}B\\ldT,  which  shows  that  x^exp[(r  -  T)A]B  =  0  for  every 
T G [0, r ].  Taking  derivatives  of  both  sides  with  respect  to  T and  evaluating  at  T =  T, 
we  obtain x^B  =  -x^AB  =  ---  =  {-ifx^A^B 
=  0 for  every  ^  >  0.  Thus, x^A^B  =  0 
for  every  ^  >  0,  and  therefore,  ^2X1  =  X2^r\\  =  0,  which  is  a  contradiction  since 
x^xi  y^ 0.  Therefore,  xi  G  ^(W^),  which  implies  that ^ ( ^)  C ^(W^).  This,  together 
with ^(Wr)  C ^ ( ^ ),  shows that ^{Wr)  = ^ ( ^ ). 
• 
Lemma  2.10  shovv^s that  given  the  time-invariant  system  x  =  Ax-\-Bu, 
if x(0)  = 
0,  then  the  set  of  all  states  that  can  be  reached  in  finite  time,  i.e.,  the  reachability 
the range of the controllability  matrix,  or  equivalently, 
subspace Rr is given by ^(^), 
by  ^ ( W r ( 0 , r ) ),  the  range  of  the  reachability  Gramian,  vv^here  T  >  0  is  any 
finite 
time. 
EXAMPLE  2.4.  For the system i:  =  Ax  + Bu  v^iih A  = 
0  1 
0  0 
andB 
, we have 
1 
t 
0  1 
and  e^^B  = 
. The  reachability  Gramian  is  ^^^(0, T)  = 
T 
-T 
1 
[T  -  T,l]dT  = 
(T  -rf 
T  -T 
T  -  7 
1 
dr  = 
.  Since  det  W,(0,7)  = 
237 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
^ r^  7^ 0  for  any  T  >  0,  ra^/:  W,(0, T)  =  ^  and  (A, 5)  is  reachable.  Note  that % 
12 
and that ^(WM 
T))  =  S?l(^)  =  R^,  as expected  (Lemma  2.10). 
[5, AB]  = 
0  1 
1  0 
If  B  --
1 
0 
instead  of 
then  ^  =  [B, AB] 
1  0 
0  0 
and  (A, B)  is  not  reach-
able. In this case e^^B = 
and the reachability matrix is Wr(0, T)  = \^ 
T  1  0 
0  0 
dr  = 
T 
0 
0  0 
Notice again that 
=  ^(Wr(0,  T))  for every  T  >  0. 
THEOREM  2.11.  Consider  the  system  x  =  Ax  -\-  Bu  and  let  x(0)  =  0.  There  exists 
input u that transfers the state to xi in finite time if and only if xi  G S/l(^), or equivalently, 
if and only if 
xi  G ^(Wr(0,  T)) 
for  some  finite  (and  therefore  for  any)  T.  Thus, the reachable  subspace  Rr  =  S/l(^)  = 
^(Wr{0,  T)).  Furthermore, an appropriate  u that will accomplish  this transfer  in time T 
is given by 
u(t)  =  ^ V ^ ^ - ^i 
(2.31) 
with r/i  such that Wr(0, T)r]i  = xi  and t G [0, T]. 
Proof. Apply Theorem 2.2 to the time-invariant case and then use Lemma 2.10. 
• 
Note that in  (2.31)  no restrictions  are imposed  on time  T, other than  that  T  be 
finite.  T can be as small as we wish, i.e., the transfer  can be accomplished  in a very 
short time indeed. 
COROLLARY 2.12.  The system x  = Ax + Bu, or the pair (A, 5), is (completely state) 
reachable, if and only if 
or equivalently, if and only if 
"rank""^ = n", 
rankWr(0,T)  = n 
(2.32) 
(2.33) 
for some finite (and therefore for any) T. 
Proof, Apply Corollary 2.3 to the time-invariant case and use Lemma 2.10. 
• 
THEOREM2.13.  There exists input u that transfers the state of the system x  =  Ax+Bu 
from XQio x\  in some finite time T if and only if 
or equivalently, if and only if 
XX -  e^^XQ  G  m.{%), 
xi  -  e^^XQ G ^{WXO,  T)). 
(2.34) 
(2.35) 
238 
Linear  Systems 
Such input is given by 
u(t)  =  B^e^^^^-'^i]i 
with t E  [0, r ], where r/i is a solution of 
Wrifi, T)7]i  =  xi- 
e^^XQ. 
(2.36) 
(2.37) 
Proof,  Apply Theorem 2.4 to the time-invariant  case and use Lemma 2.10. 
• 
The  above  leads  to the next  result,  which  establishes  the importance  of  reacha 
bility  in determining  an input  u to transfer  the state  from  any  XQ to any xi  in  finite 
time. 
COROLLARY  2.14.  Let the system  i:  ^  Ax +  5M  be (completely  state) reachable, or 
the pair (A, B) be reachable. Then there exists an input that will transfer  any state  XQ to 
any other state x\  in some finite time T. Such input is given by 
u{t)  =  B^e^^^^-'^W;\0,T)[xi 
-  e^^x^-] 
(2.38) 
for re  [0, r ]. 
Proof,  This  result is the time-invariant  version  of Corollary  2.5. In view  of  Corollary 
2.12, reachability implies that  ra^y^W;-(0,r)  =  ^ for some T or that 2?l(W^(0," T))  = /?""", 
the  whole  state  space. This  implies  that  any vector  xi  -  e^-^xo E  '3i(Wr(0, T))  that, in 
view of Theorem 2.13, implies that the input in (2.38) is an input which will  accomplish 
this transfer. 
• 
There  are many  different  control  inputs  u that  can accomplish  the transfer  from 
xo  to  xi  in  time  T.  It  can be  shown  that  the input  u  given  by  (2.38)  accomplishes 
this transfer  while expending  a minimum  amount of energy; in fact,  u minimizes the 
cost  functional  j^  ||W(T)|P J r,  where  \\u(t)\\  =  [u^(t)u(t)y^^ 
denotes  the  Euclidean 
norm  of  u(t). 
EXAMPLE  2.5.  The system x  = Ax  + Bu with A 
0  1 
0  0 
and  5 
is reachable 
(see Example  2.4). A control input  u(t) that will transfer  any state  XQ to any other  state 
Xi in some finite time T is given by (see Corollary 2.14 and Example 2.4) 
u(t)  =  B^e'^'^^^-'^W;\0,  T)[xi 
XQ] 
=  [T-t,  1] 
12 
6 
j2 
J2 
4 
J 
Xi 
Xo 
EXAMPLE 2.6.  For the (scalar) system x  =  -ax  + bu, determine u(t) that will transfer 
the state from  x(0) =  XQ to the origin in T sec; i.e., x{T)  = 0. 
We shall apply Corollary  2.14. The reachability  Gramian is Wr(0, T)  = 
-[1 
[e' 
2a 
~^''^].  Note  [see (2.41) below]  that the controllability  Gramian is Wc(0, T) 
1]. Now in view of (2.38), we have 
^(0  =  be-^^-'^'' 
[-e-^'^x^] 
-2aT 
e'^XQ 
2a 
FT 
e-^'^ 
-laT 
2a 
b  1 
2a 
b  ^2«r _ I 
1 
"^""'Xo. "
239 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
To verify  that  this  u{t) accompHshes  the desired  transfer,  we compute  x{t)  =  ^^^xo + 
''e^^'-^^Bu(T)dT  =  e-
XQ  +  Jo e-'''e''^bu{r)dT  =  e'^\x^  +  JQ e'^'b X 
2a 
1 
dr  = e 
1  -
^2at 
, 
1 
XQ. Note that x{T)  =  0, as desired, and 
also  that  x(0)  =  XQ. The above  expression  shovv^s  also  that  for  t  >  T,  the  state  does 
not remain at the origin. An important point to notice here is that as T ^  0, the control 
magnitude \u\^  oo. Thus, although it is (theoretically) possible to accomplish the desired 
transfer instantaneously, this will require infinite control magnitude. In general, the faster 
• 
the transfer,  the larger the control magnitude required. 
We  shall novs^ establish  the relationship  between  reachability  and  controllability 
for  the continuous-time  time-invariant  systems  (2.3). 
Applying  (2.8) to the time-invariant  case,  XQ is  controllable  v\^hen  there  exists 
u(t),  t  G  [0, Tl  so  that 
-e^^XQ  = 
or when  e^^xo  £  ^(Wr(0,  T)),  or equivalently,  in view  of Lemma  2.1,  when 
for  some  finite  T.  Recall  that  xi  is reachable  when 
e^^XQ  G  2/l(^) 
XX G  3l(^). 
We  require  the following  technical  result. 
(2.39) 
(2.40) 
LEMMA  2.15.  If X E ^{%),  then Ax  G S/l(^); i.e., the reachable subspace Rr  =  ^{%) 
is an A-invariant  subspace. 
Proof,  If  X G S^(^),  this  means  that  there  exists  a  vector  a  such  that  [B,  AB,..., 
A«-i5]a  -  X. Then Ax  =  [AB, A^B,...,"  A""5]a. In view of the Cay ley-Hamilton The "
orem," A"" can be expressed as a linear combination of A""~^ . . .", A, /, which implies that 
Ax  = %fi for some appropriate vector  jS. Therefore, Ax  G S^(^). 
• 
THEOREM  2.16.  Consider the system x  = Ax  + Bu. 
(i)  A state x is reachable if and only if it is controllable, 
(ii)  Re  =  Rr. 
(iii)  The system (2.3), or the pair (A, B), is (completely  state) reachable if and only 
if it is (completely  state)  controllable. 
Proof,  (i)Letxbe reachable; that is, xG2?l(^).Premultiplyxby^^^  =  X1=o(T^/kl)A^ 
and notice that in view  of Lemma  2.15, Ax, A^x,...,  A^x  G 2?l(^). Therefore,  e^^ x G 
2/l(^) for any T, which, in view of (2.39), implies  that x is also controllable. If now x is 
controllable, i.e., e^^x  G ^ ( ^ ), then premultiplying by e~^^, the vector e~^^ [e^^x)  = 
X will  also be in ^(%).  Therefore,  x is also reachable.  Note that the second part of (i), 
that controllabihty implies reachability, is true because the inverse {e^'^Y^  =  e~^^ does 
240 
Linear Systems 
exist. This is in contrast to the discrete-time case where the state transition matrix 4>(/c, 0) 
^^ nonsingular if and only if A is nonsingular  [nonreversibihty of time in discrete-time 
systems (see Section 2.7)]. 
Parts (ii) and (iii) of the theorem follow directly from (i). 
• 
The reachability  Gramian  for the time-invariant  case,  Wr(0, T), was defined  in 
(2.29). Similarly, in view of Definition  2.8, we make the following  definition. 
DEFINITION2.12.  The controllability Gramian in the time-invariant case is the  nXn 
matrix 
Wc(0,T)^\ 
rT 
Jo 
e-^'BB^e-^^'dr. 
(2.41) 
• 
We note that 
which can be verified  directly  [see also (2.22)]. 
As  was  done  in  the  time-varying  case  above,  we  now  introduce  a  number  of 
additional tests for reachability  and controllability  of time-invariant  systems.  Some 
earlier results are also repeated here for  convenience. 
THEOREM 2.17.  The system x  = Ax + Bu'\^ reachable  (controllable-from-the-origin) 
(i)  if and only if 
rank Wr(fi, T)  = n 
for some finite T  > 0, 
rT 
where 
WM  T)  = 
e^^-''^^BB^ e^'^'^^^^ dr, 
(2.42) 
the reachability Gramian, or 
(ii)  if and only if the n rows of 
(2.43) 
are linearly independent on [0, ^)  over the field of complex numbers, or alter 
natively, if and only if the n rows of 
{sI-Ay^B 
are linearly independent over the field of complex numbers, or 
(iii)  if and only if 
rank% = n, 
where % =  [B,A,B,...,"  A""~^B]", the controllability matrix, or 
(iv)  if and only if 
rank [sil -  A,B]  = n 
(2.44) 
(2.45) 
(2.46) 
for all complex numbers st, or alternatively, for si, i  =  \,..  .,n,  the eigenval 
ues of A. 
Proof, Parts (i) and (iii) were proved in Corollary 2.9. 
In part (ii), rank W^(0, T)  = n implies and is implied by the linear independence of 
the n rows of e^^'^^^B on [0, T] over the field of complex numbers, in view of Lemma 2.7, 
or by the linear independence of the n rows of e^^B, where t = T -t,  on [0, T]. Therefore 
the system is reachable if and only if the n rows of e'^^B are linearly independent on [0, oo) 
over the field of complex numbers. Note that the time interval can be taken to be [0, ^) 
since in [0, 7], T can be taken to be any finite positive real number. To prove the second 
part  of  (ii),  recall  that  ^{e^^B)  =  (si  — A)~^B  and  that  the  Laplace  transform  is  a 
one-to-one linear  operator. 
Part (iv) will be proved later in this chapter, in Corollary 4.6. 
• 
Results  for  controllability  that  are  in  the  spirit  of  those  given  in  Theorem  2.17 
can  also be  established.  The  reader  is  asked  to  do  so. This  is  of  course  not  surprising 
since  it  vv^as  shovv^n  (in  Theorem  2.16)  that  reachability  implies  and  is  implied  by 
controllability.  Therefore,  the  criteria  developed  in  the  theorem  for  reachability  are 
typically  used  to test the  controllability  of  a  system. 
241 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
EXAMPLE  2.7.  For the  system x  = Ax-\- Bu,  where  A 
0 
0 
1 
0 
and  5: 
(as in 
Example 2.4), we shall verify  Theorem  2.17. The system is reachable  since 
(i)  the reachability Gramian Wr(0,7): 
for  any 7  >  0, or  since 
\T^ 
\T^-
2^ 
has rankWr{0,T) •• 
(ii)  e^^B  • 
has  rows  that  are  linearly  independent  on  [0,oo)  over  the  field 
of  complex  numbers  (since  ai  -1 -\- a2 -  I  =  0,  where  ai  and  a2 are  complex 
numbers  implies  that  ai  =  a2 =  0).  Similarly,  the  rows  of  {si — A)~^B  = 
lA^l 
^ 
are  linearly  independent  over  the  field  of  complex  numbers.  Also, 
smce 
(iii)  rank ^  — rank  \B^AB\ — rank 
(iv)  rank  [5;7 —A,5]  =  rank 
eigenvalues of A. 
If  5 
in place of 
then 
0 
1 
1 
0 
-1 
Si 
0 
1 
: n, or 
2  =  n  for  Si =  0,i  =  1,2, 
the 
(i)  WriOJ) 
T 
0 
0 
0 
(see Example  2.4) with  rank Wr{0,T)  =  I  <2  = n, and 
(ii)  e^^B  • 
and  {sI-A)-^B 
• 
\/s 
0 
,  neither  of  which  has  rows  that  are 
linearly independent  over the complex numbers. Also, 
(iii)  rank' 
1 
0 
0 
0 
I  <2  = n, and 
(iv)  rank  [sil — A,B\  =  rank 
1 
-1 
Si  OJ 
I  <2  = n for Si  = 0. 
Based on any of the above tests, it is concluded that the system is not reachable. 
C.  Discrete-Time  Systems 
The  response  of  discrete-time  systems  was  studied  in  Section  2.7  of  Chapter  2.  We 
consider  systems  described  by  equations  of the  form 
242 
Linear Systems 
x(k  +  1)  -  A(k)x(k)  +  B(kMkl 
(2.47) 
^j^^j,^  ^^^^  ^  j^nxn^ 5(^)  ^  ^nxm^ ^j^^j ^^^ ^^^^^ ^^^^  ^  ^m ^^^ defined  for  it ^  ko. 
The state x(fe) for  k>  kois  given by 
k  ^  ko, 
y t -l 
4 ^)  =  ^(k  ko)x(ko)  +  ^ 
/ = ^, 
^(k 
i +  l)B{i)u{i), 
(2.48) 
where  the  state  transition  matrix  ^{k,  ko)  is  given  by  ^(k,  ko)  =  A(k  -  1) X 
A(k  -  2)''  'A(ko)  for  k  >  ko, and O(^o. ko)  =  L 
In the time-invariant  case we have 
x{k+\)  =  Ax{k)  +  Bu{k\ 
k  ^  ko, 
(2.49) 
"where A  G /^'^X"" and B  E  /?""><^. The state x(yfc) of (2.49) is given by (2.48)  with "
^{k,  ko)  =  A^-^', 
k  ^  ko. 
(2.50) 
Let the state at time  ko be  XQ. For the state at some time  ki  >  ko to assume the 
value xi,  an input u must exist that  satisfies 
xi  =  3>(A:i, ^o)^o  +  ^ 
^(kh 
i +  l)B(i)u(i), 
(2.51) 
Reachability  and controllability  are defined  for discrete-time systems in a com 
pletely analogous fashion as in the continuous-time case. The mathematical develop 
ment, however, involves  summations  instead of integrals  and is easier to deal with. 
The  time-varying  case  can be  developed  in  a manner  similar  to the  time-invariant 
case.  For  this  reason,  the  discrete-time  time-varying  case  will  not  be  developed 
presently. Instead, we shall concentrate on the time-invariant case. Note that some of 
the results given below for the discrete-time time-invariant  case have already  been 
presented in Section 3.1, Introduction. 
Discrete-time time-invariant  systems 
For the  time-invariant  system  x(k  +  1)  == Ax(k)  +  Bu(k)  given  in  (2.49),  the 
elapsed time  fei-/co  is of central interest, and we therefore take ^0  =  Oandfei  =  K. 
Recalling that ^{k,  0)  =  A^, we rewrite (2.51) as 
when ^  >  0, or 
xi  =  A^xo  + ^A^-^'^^^Bu{i) 
/=o 
XX =  A^XO  +  '^KUK, 
where 
and 
%K =  [B, AB,...,  A^-^B] 
UK  =  [u^{K  -  \),  u^(K  -  2 ) , . . .,  u^(0)f. 
(2.52) 
(2.53) 
(2.54) 
(2.55) 
The definitions of reachable state xi,  reachable sub space Rr, and a system  being 
{completely  state)  reachable,  or the pair  (A, B)  being  reachable,  are the same as in 
the continuous-time case (see Definition  2.9, and use integer K in place of real time 
T).  Similarly, the definitions  of controllable  state  XQ, controllable  subspace  Re, and 
a system  being (completely  state)  controllable,  or the pair  {A, B) being  controllable 
are  similar  to  the  corresponding  concepts  given  in  Definition  2.10  for  the  case  of 
continuous-time  systems. 
To determine the finite input sequence for discrete-time systems that will accom 
plish  a desired  state transfer,  if  such a sequence  exists, one does not have to  define 
matrices comparable to the reachability  Gramian  Wr, as in the case for  continuous-
time systems. In particular, we have the following  result. 
243 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
THEOREM 2.18.  Consider the system x{k + V) = Ax{k) + Bu{k) given in (2.39) and 
let  x(0)  =  0. There  exists  input  u that  transfers  the  state  to  xi  in finite time  if  and 
only if 
xx E  ^{%). 
In this case, xi  is reachable and Rr = S^(^). An appropriate input sequence {u{k)}, k  = 
0,..., w -  1, that accompHshes this transfer in n steps is determined by Un =  [u^(n  -
l),u^(n  -  2),...,  w^(0)]^, a solufion to the equation 
"""^Un  = xi. "
(2.56) 
Henceforth, with an abuse of language, we will refer to Un as a control sequence when, 
in fact, we actually have in mind {u(k)}. 
Proof, In view of (2.52), xi  can be reached from  the origin in K  steps if and only if 
xi  =  ^KUK  has a solution  UK,  or if and only if  x\  E  ^(^K)-  Furthermore, all input 
sequences that accomplish this are solutions to the equation x\  = ^RUK- For x\  to be 
reachable we must have xi  E ^(^K)  for  some finite K. This range, however, cannot 
increase beyond the range of ^„  = %  i.e.,"  ^(""^K)  = S^(^n) for K  >  n. This  follows "
from the Cayley-Hamilton Theorem, which implies that any vector x in ^(^A:), K  >  n, 
can be expressed as a linear combination of B, AB,...,  A^~^B. Therefore,  x  E S?l(^„). 
It  is  of  course  possible  to  have  x\  E  ^{%K)  with  ^  <  n  for  a particular  x\\  how 
ever, in this case xi  E S^(^„) since %K is a subset of ^„. Thus, xi  is reachable if and 
only  if  it  is in  the range  of ^„  =  %. Clearly,  any  t/„  that  accomplishes  the  transfer 
satisfies (2.56). 
• 
As pointed  out in the  above proof,  for  given  x\  we may  have  x\  E  ^(^K) 
for 
some K  <  n.\n  this case the transfer can be accomplished in fewer than n steps, and 
appropriate inputs are obtained by solving the equation ^KUK  =  ^i-
COROLLARY 2.19.  The system x(k  +  1)  =  Ax(k)  + Bu(k) given in (2.49) is (com 
pletely state) reachable, or the pair (A, B) is reachable, if and only if 
(2.51) 
Proof, Apply Theorem 2.18," noting that S/l(^)  = Rr =  /?"" if and only if rank ^  =  n. "
rank'^  = n. 
THEOREM  2.20.  There  exists  an  input  u  that  transfers  the  state  of  the  system 
x(k  +  1)  =  Ax(k)  +  Bu(k)  given  in  (2.49)  from  XQ to  x\  in  some finite number of 
steps K, if and only if 
xi  -  A^xo  E m.C^Kl 
(2.58) 
u^(0)]^ is determined by solving 
Such input sequence UK  =  [u^(K -l),u^(K-2),..., 
the equation 
Proof  The proof follows directly from (2.53). 
"""^KUK  = xi-A^xo. "
(2.59) 
• 
244 
Linear  Systems 
The  above  theorem  leads  to the  following  result  that  establishes  the  importance 
of reachability  in determining  u to transfer  the  state from  any  XQ  to  any  xi  in  a  finite 
number  of  steps. 
COROLLARY2.21.  Let the sy Stem x(^+1)  =  Ax(^) + 5w(^) given in (2.49) be (com 
pletely  state) reachable,  or the pair  (A, B)  be reachable.  Then  there  exists  an input  se 
quence to transfer  the state from  any  XQ to any x\  in a finite number of steps. Such input 
is determined by solving Eq. (2.60). 
Proof,  Consider (2.54). Since (A, B) is reachable, r<2n^^„  =  rank%  =  nandS/l(^)  = 
R^.  Then 
"%Un  =  XX  - A "" xo "
(2.60) 
always  has  a  solution  Un  =  [u^(n  -  1),...,  w^(0)]^ for  any  XQ  and  xi.  This  input  se 
quence transfers  the state from  XQ  to xi  in n steps. 
• 
Note  that,  in  view  of  Theorem  2.20, for  a particular  XQ and  xi,  the  state  transfer 
may  be  accomplished  in  K  <  n  steps, using  (2.59). 
EXAMPLE  2.8.  Consider  the  system  in  Example  1.1,  namely,  x(k  +  1)  =  Ax(k)  + 
5M(^),whereA  = 
0  1 
1  1 
and 5  = 
.SincQ rank^  =  rank[B,AB]  =  rank 
0  1 
1  1 
2  =  n,  the  system  is  reachable,  and  any  state  XQ  can  be  transferred  to  any  other  state 
xi  in  2  steps.  Let  xi  = 
1  1 
1  2 
or 
u(l) 
u(0) 
,Xo  = 
-1  1 
1  0 
.  Then  (2.60)  implies  that 
0  1 
1  1 
u(l) 
u(0) 
0  1 
1  1 
ao 
bo} 
b-l-bo 
a-  ao -  bo 
This  agrees 
with the results obtained in Example  1.1. In view of (2.59), if Xi and XQ are chosen so that 
xi  -  Axo 
0  1 
1  1 
a-  bo 
b-  ao-  bo. 
is in the 2/1(^0  -  ^(B)  =  span 
then  the  state  transfer  can  be  achieved  in  one  step.  For  example,  if  xi  = 
and 
thenBu(0)  = 
Xo 
xi  can be accomplished  in this case in  1 <  2  =  fz steps with  u(0)  =  2. 
u(0)  =  xi  -  Axo  = 
implies that the transfer  from  xo to 
EXAMPLE 2.9.  Consider the system x(k  +  1)  =  Ax(k)  + Bu(k)  with A 
0  1 
0  0 
and 
B  = 
. Since ^  =  [B, AB] 
0  1 
1  0 
has full rank, there exists an input sequence that 
will transfer the state from  any x{0)  =  xo to any x(n)  =  xi  (in n steps), given by (2.60), 
U2  = 
U{1) 
Lw(0)J 
\xi 
-  A^xo)  = 
0  1 
1  0 
(xi  -  Xo). Compare  this with Example 2.5, 
where the continuous-time  system had the same system parameters A and B. 
• 
We  shall now  establish  the relationship  between  reachability  and  controllability 
for  the  discrete-time  time-invariant  systems  x(k  +  1)  =  Ax(k)  +  Bu(k)  given  in 
(2.49). 
Consider  (2.51).  The  state  XQ is  controllable  if  it  can  be  steered  to  the  origin 
xi  =  0 in  a  finite  number  of  steps  K.  That  is,  XQ is  controllable  if  and  only  if 
A^xo  =  %KUK 
(2.61) 
for some K,  or when 
for  some K. Recall that x\  is reachable  when 
(2.62) 
(2.63) 
245 
CHAPTER  3: 
Controllability, 
Observability, 
and Special 
Forms 
THEOREM 2.22.  Consider the system x{k +  1)  =  Ax{k) + Bu{k) given in (2.49). 
(i)  If state X is reachable, then it is controllable, 
(ii)  RrdRc-
(iii)  If the system is (completely  state) reachable, or the pair (A, B) is reachable, 
then the system  is also  (completely  state)  controllable,  or the pair  (A, B) is 
controllable. 
Furthermore, if A is nonsingular, then relations (i) and (iii) become if and only if 
statements, since controllability  also implies reachability, and relation (ii) becomes an 
equality, i.e., Re = Rr. 
Proof, (i) If X is reachable, then  x  G S/l(^).  In view  of Lemma  2.14, S/l(^) is  an A-
"invariant subspace and so A""x G S/l(^)", which in view of (2.61) implies that x is also 
controllable. Since x is an arbitrary  vector in Rr," this implies  (ii). If S^(^)  =  /?""", the 
whole state space, then A^x for any x is in S/l(^) and so any vector x is also controllable. 
Thus, reachability implies controllability. Now, if A is nonsingular," then A~"" exists. If x "
is controllable, i.e., A^x  G 2?l(^), then x  G ^(^), i.e., x is also reachable. This can be 
"seen by noting that A~"" can be written as a power series in terms of A", which in view of 
Lemma 2.15," implies that A~""(A""jc)  =  ;c is also in ^(%). "
• 
Matrix A being nonsingular is the necessary and sufficient  condition for the state 
transition  matrix  0(/:, ^o) to be  nonsingular  (see  Section  2.8),  which  in  turn  is  the 
"condition for  ""time  reversibility'' "
in discrete-time  systems. Recall that reversibility 
in time may not be present in such systems since 0(^,  ^o) may be singular. In contrast 
to this, in continuous-time systems, ^(t,  to) is always nonsingular. This causes  differ 
ences  in behavior  between  continuous-  and  discrete-time  systems  and  implies  that 
in  discrete-time  systems  controllability  may  not  imply  reachability  (see  Theorem 
2.22). Note that, in view  of Theorem  2.16, in the case of continuous-time  systems, 
it is not only reachability  which  always  implies  controllability,  but  also vice  versa, 
controllability  always implies  reachability. 
In  the  following,  we  introduce  the  discrete-time  reachability  and  controllabil 
ity  Gramians  for  system  (2.49).  These  are  defined  in  a  manner  analogous  to  the 
continuous-time  case. 
DEFINITION2.13.  The reachability Gramian is defined by 
K-l 
Wr(0, K)  = ^  A^-^^-'^^BB^(A^f-^'^^\ 
/=o 
(2.64) 
It is not difficult  to verify that W,(0," K)  = Xf~o  A'BB^{A^j  = ""^K^- "
• 
LEMMA 2.23.  ^{%)  = ^(Wr(0,  K)) for every K  ^  n. 
Proof, This result can be established in a way similar to the proof of the corresponding 
result in the continuous-time case (Lemma 2.7). The details are left to the reader. 
• 
When  a  system  is reachable,  the  input  sequence  that  transfers  XQ  aX  k  =  0 to 
x\a.tk  =  K can be determined in terms of the reachability Gramian. In particular, let 
246 
Linear  Systems 
rank  %  = n = rank  Wr{^,  K) for K > n, and  notice  that  the  relation 
UK  =  '^KW;\0,  K)(xi  -  A^xo) 
(2.65) 
satisfies  (2.59)  since  W,(0, K) =  ^ / ^ ^ J. 
DEFINITION2.14.  The controllability  Gramian  is defined  as 
Wc{^, K)  = ^  A'^'^^^BB^(A^y^'^^\ 
(2.66) 
We  note  that  WdO,  K) is  well  defined  only  when A is  nonsingular.  The  reacha 
bility  and  controllability  Gramians  are related  by 
Wr{0,K)  =  A^WMK)(A^f, 
(2.67) 
as  can  easily  be  verified. 
When A  is  nonsingular,  the input  that  will  transfer  the  state from  XQ at  /:  =  0 to 
xi  = Oinn  steps  can  be  determined  using  (2.60).  In  particular,  one  needs  to  solve 
[A-^'^Wn = [A-''B,...,A-^B]Un  = xo 
(2.68) 
for  Un  =  [u^(n-1),..., 
g/l(^),"  or if and  only if XQ G  gi(A~""^)  for A  nonsingular. "
w^(0)]^. Note that  XQ is controllable if and only if  -A^XQ  G 
Clearly,  in  the  case  of  controllability  (and  under  the  assumption  that A is  non-
singular), the matrix  A~^%  is of interest,  instead  of ^  [see  also  (1.18)]. In  particular, 
a  system  is  controllable if and  only if ranfc (A~'^^)  =  rank%  = n. 
EXAMPLE  2.10.  Consider the system x(k  + 1)  = Ax(k)  + Bu(k),  where A = 
1  1 
0  1 
and 5 
. Since ra^^^ =  rank[B,  AB]  = rank 
1  1 
0  0 
=  \ <2  = n, this  system 
is not (completely)  reachable  (controllable-from-the-origin).  All reachable  states  are of 
the form a 
, where a E R  since 
is a basis for the 2?l(^)  =  Rf,  the  reachability 
subspace. The reachability Gramian for i^  = n = 2isWX0, 2)  = BB^  +  (AB)(AB) T  _ 
"1  0"" "
0  0 
^(Wr(0,  2)), which verifies  Lemma 2.23. 
Note  that a basis  for  ^(Wr(0,  2)), is 
'2  0' 
0  0 
1  0 
0  0 
and  S?l(^) = 
+ 
In view of (2.62) and the Cay ley-Hamilton  Theorem,  all controllable  states  XQ  sat 
isfy  A^xo E 9l(^);  i.e.,  all controllable  states  are of the form  <^ L  , where a  G R.  This 
verifies  Theorem 2.22 for the case when A is nonsingular. Note that presently  Rr  =  Re 
EXAMPLE  2.11.  Consider the system  x{k  + 1)  = Ax(k)  + Bu{k),  where A 
0  1 
0  0 
and 5 
SincQ rank ^  = rank[B,AB]  =  rank 
1  0 
0  0 
=  1 < 2 == ^,  the  system 
is not  (completely)  reachable.  All reachable  states  are  of the form a 
where a E: R 
smce 
is a basis for ^(^)  = Ry, the reachability  subspace. 
To determine the controllable subspace R^  consider (2.62) for K  = n/m  view of 
the Cay ley-Hamilton Theorem. Note that A~^%  cannot be used in the present case, since 
A is singular. Since A^XQ  = 
Xo 
G S/l(^), any state XQ will be a controllable 
state, i.e., the system is (completely) controllable and Re = R^. This verifies Theorem 
2.22 and illustrates that controllability does not in general imply reachability. 
Note that (2.60) can be used to determine the control sequence that will drive any 
state xo to the origin (xi  =  0). In particular, 
247 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
^f/„  = 
u(l) 
u(0) 
= 
-A^XQ. 
Therefore,  w(0)  -  a  and w(l)  =  0, where a  E  /? will drive any state to the origin. To 
verify this, we consider x(l) 
Ax(0) + Bu(0) 
x(2)  = Ax(l) + Bu(l)  --
X02  + Oi 
0 
Xoi 
•^02. 
0 
0  < 
0  = 
X02  +  ex 
0 
and 
3.3 
OBSERVABILITY  AND  CONSTRUCTIBILITY 
In applications, the  state of a system is frequently  required  but not accessible.  Un 
der such conditions, the question  arises whether it is possible to determine the state 
by  observing  the  response  of  a  system  to  some  input  over  some  period  of  time.  It 
turns  out that the answer to this question  is affirmative  if the  system is  observable. 
Observability  refers to the ability of determining the present state x(to) from knowl 
edge  of  future  system  outputs,  y(t),  and  system  inputs,  u(t), t  ^  to.  Constructibil-
ity  refers  to  the  ability  of  determining  the  present  state  x(fo)  from  knowledge  of 
past  system outputs, y{t),  and  system inputs,  u{t), t  ^  to. Observability  was  briefly 
addressed  in  Section  3.1. In  this  section  this  concept  is  formally  defined  and  the 
(present)  state is explicitly  determined  from  input  and output measurements. As in 
Section 3.2 (dealing with reachability and controllability), the reader can concentrate 
on the time-invariant  case,  starting  with  Definition  3.9, if  so desired,  and  omit  the 
more  general  material  (dealing  with  time-varying  systems)  that  starts  with  Defini 
tion 3.1. 
Section  description 
In this  section,  observability  and  constructibility  are introduced  and  discussed 
in detail  for  given  linear  system  state-space  descriptions. This  is  accomplished  for 
continuous  and discrete-time  systems  and for both time-varying  and  time-invariant 
cases. 
Observability  in  continuous-time  systems  is  addressed  first  with  introduction 
of the observability  Gramian  Wo(to, ti)  (Definition  3.4). It is shown  (Corollary  3.2) 
that  a  system  is  observable  at  to if  Wo(to, ti)  has  full  rank  for  some  ti  >  to, and 
furthermore,  if the system is observable, how an initial state can be determined. Ob 
servability refers to the ability to determine the current state of a system from  future 
system outputs (and inputs). Constructibility, which refers to the ability of determin 
ing the current state of a system from past system outputs (and inputs), is  addressed 
next with the introduction of the constructibility Gramian (Definition 3.8). It is shown 
248 
Linear Systems 
(Theorem  3.3)  that  a continuous-time  system  is observable  if  and  only  if  it is  con-
structible.  Next,  additional  tests  for  observability  and  constmctibility  are  obtained 
(Theorem 3.4). All these results are then applied in the study of the  continuous-time 
time-invariant  case. The material is arranged in such a manner that the continuous-
time time-invariant  systems can be studied independently  of the time-varying  case. 
The relation between the observability  Gramian  Wo(0, T)  and the observability  ma 
trix  0  =  [C^, {CAf,..., 
"(CA""""^)^]^  is  estabhshed  next  (Lemma  3.6).  It  is  then "
shown  (Corollary  3.8)  that  a system  is  observable  if  and  only  if  0  has  full  rank  n. 
Next, the relation between observability and constmctibility is established  (Theorem 
3.9). Finally, additional tests for observability  are derived  (Theorem  3.10). 
A discussion of observability and constmctibility for discrete-time systems with 
particular  emphasis  on time-invariant  systems  is presented  next.  It is  shown  that  a 
system is observable if the observability matrix 0 has full rank (Corollary 3.12), and 
for this case, an expression for the initial state XQ is given as a function  of future  out 
puts  (and  inputs).  A  similar  result  involving  the  observability  Gramian  Wo{0, K) 
in  place  of  0  is  also  established  (Corollary  3.14).  Next,  it  is  shown  that  observ 
ability  in  discrete-time  systems  always  implies  constmctibility.  In  contrast  to  the 
continuous-time case, the converse of the above statement is generally not true. This 
is due to the lack of time reversibility in difference  equations. When A is nonsingular, 
then constmctibility  also implies observability. Finally, the constmctibility  Gramian 
Wcnd^y K)  is also introduced  (Definition  3.16). 
A.  Continuous-Time  Time-Varying  Systems 
We consider  systems described by equations of the  form 
X =  A(t)x  +  B(t)u, 
(3.1) 
where  A{t)  G  iR^^^ B{t)  G  R''''^,  C{t)  E  7?^><^ D{t)  G  /?^><^, and  u{t)  G  R^  are 
defined  and  (piecewise)  continuous  on some real open interval  {a, b). It was  shown 
in Chapter 2 that the output y{t)  is given by 
y  =  C{t)x  -H  D{t)u, 
y{t)  =  C(t)^(t,  to)x(to)  + 
C(t)<i^(t,  T)B{T)U(T)  dr  +  D(t)u(t) 
(3.2) 
t 
Jto 
for  to, t  G {a, h), where ^{t,  r)  denotes the state transition matrix. This can be writ 
ten as 
y{t)  -  C{tmu 
to)xo, 
(3.3) 
where j (0  =  y(t) 
^  C(t)<i>(t, r)B(r)u(T)dT  +  D{t)u(t) andxo  =  x(ro)-Wewill 
find it convenient to first give the definition  of an unobservable  state. 
DEFINITIONS.1.  A State X is unobservable at time to if the zero-input response of the 
system is zero for every t >  to, i.e., if 
C(t)(^(t, to)x = 0 
for every t >  to. 
DEFINITION 3.2.  The unobservable at to subspace R^^  of (3.1) is 
R^^ = { set of all unobservable at ^o states x}. 
(3.4) 
• 
• 
When  the context  is clear  and there is no ambiguity,  we will write  Ro in place 
ofR'l 
249 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
DEFINITION  3.3.  The  system  (3.1)  is  {completely  state)  observable  at ^,  or the  pair 
(A(0,  C{t))  is observable  at ^,"  if the only  state  x  G  /?"" that  is unobservable  at fo is the "
• 
zero state, jc  =  0, i.e., if  R^^  =  {0}. 
We  will  show  later  that  observability  depends  only  on  the  pair  (A(t),  C(t)).  Ac 
cording  to  Definition  3.1,  a  nonzero  unobservable  state  x  cannot  be  distinguished 
from  the  zero  state  if  only  the  (future)  outputs  are  known;  that  is,  an  unobservable 
state  cannot  be  determined  uniquely  from  knowledge  of  the  inputs  and  outputs  of 
the  system.  This  can  be  seen  from  (3.3),  where  for  the  unobservable  states  x  at 
^0. y(t)  =  0  for  r  ^ 
to.  This  implies  that  the  states  x,  which  together  with  the  in 
put  u(t)  produce  the  output  y(t),  cannot  be  distinguished  from  the  zero  state,  since 
they  both  produce  the  same  output. 
In  a  manner  analogous  to  the  development  of  reachability  in  Section  3.2,  we 
make  the  following  definition. 
DEFINITION  3.4.  The observability  Gramian  of the system (3.1) is the n X ri matrix 
Wo{to,tx)= 
<D^(T,^)C^(T)C(T)CD(T,^O)^T. 
(3.5) 
Note that  Wo is symmetric and positive semidefinite  for every ti  >  to, i.e., Wo  = 
Wj  and  Wo^ 
0  (show  this). 
THEOREM  3.1.  A State X is unobservable  at to if and only if 
xGX(Wo(to.ti)) 
(3.6) 
for every  t\  >  ^o, where J{(-) denotes the null space of a map. 
Proof.  If  X is  unobservable,  then  (3.4)  is  satisfied.  Postmultiply  (3.5)  by  x  to  obtain 
Wo(to, ti)x  =  0 for  every  ti  >  to, i.e.,  x  G }((Wo(to,  ti))  for  every  ^i  >  to. Conversely, 
let X be in the null space of  Wo. Then  x'^Wo(to, ti)x  =  |^^^ ||C(T)^(T,  ro)x|p dr  =  0  for 
every ti  >  to. This implies that (3.4) is true, or that the state x is unobservable. 
• 
EXAMPLE  3.1.  Consider the system i:  =  A(t)x,  y  =  C(0^, where A(0  = 
-1  e^^ 
0 
-1 
and  C(t)  =  [0, e~^].  The  state transition  matrix  in this  case is  (see Example  2.1 in  this 
and  C(0 
chapter) 
0(r, r)  = 
^-(t-r) 
0 
i^^t+T  _  ^-r+Sr-) 
e 
Then  C(T)^(T, 
to)  =  [0, e  ^^+^0] and the observability  Gramian is given by 
WoitoJi)  = 
^2^0 
0 
, - 2T 
[0,e~^']dT 
0 
0 
0  ^-4^ 
dr 
to 
0 
0 
0 
^-4/1  _ 
^-4to 
It is clear that this system is not observable, since rank Woito, ti)  =  I  <2  =  n.ln  view 
of Theorem 3.1, all unobservable  states are given by 
, where a  E  R. 
0 
Notice  that  };(0  =  C(t)^(t,to)xo  =  [0, e-^^^'o]xo  =  0 for  JCQ  = 
, that  is, none 
of the (unobservable)  states 
can be distinguished  from  the zero state. 
250 
Linear Systems 
Clearly,  x  is  observable  at  t^  if  and  only  if  there  exists  a  fi  >  ^o  such  that 
^ovo,"  ti)X  ¥""  0. "
COROLLARY 3.2.  The system (3.1) is {completely state) observable at to, or the pair 
(A(t), C(t)) is observable at to, if and only if there exists a finite ti  > to such that 
If the system is observable, the state xo at to is given by 
rankWoitoJi)  =  n. 
Xo =  W^\to,ti) 
fh 
^0 
C D ^ ( T , ^ O ) C ^ ( T ) K T ) ^T 
(3.7) 
(3.8) 
Proof, The system is observable if and only if the only vector x that satisfies (3.6) is the 
zero vector. This is true if and only if there exists (at least one) finite time ti for which the 
null space of Wo(to, ti) contains only the zero vector, or if and only if (3.7) is satisfied. To 
determine the state XQ  at to, given the output and input values over [^o. ^i], premultiply 
(3.3) by (^^(t, to)C'^(t) and integrate over [to, ti]. Then, in view of (3.5), 
Woito, h)xo  =  r  CD^(T, fo)C^(T)KT) Jr. 
When the system is observable, (3.9) has the unique solution (3.8). 
(3.9) 
• 
It  is  clear  that  if  the  state  at  some  time  to  is  found,  then  the  state  x(t)  for 
r ^  ^0 is  easily  determined,  given  u(t), t  >  to, via  the  variation  of constants  form 
ula (2.2). 
We mention  here  that  alternative  methods  to  (3.8)  to  determine  the  state  of  a 
system  when the system is observable  are given in the next chapter  (in Section  4.3 
on state estimation). 
EXAMPLE  3.2  For  the  scalar  system  x  =  a{t)x,y  =  c{t)x,  where  a{t)  =  -1  and 
c{t) =  e\  we have <b{t," r)  =  ^""(^~^> and C{T)^(J","  to) =  e^e'^'""'^^^  =  e^^.  The observ "
ability  Gramian  in this case is  Woito, ^i)  =  //^ e'^^^ dr  =  e'^^^it\  -  to), which implies 
that  the  system  is  observable  at  ^o since  rankWoito, t\)  =  1  =  w for  any  t\  y^  to. 
Suppose  now  that  the  observed  output  is  y(t)  =  y(t)  =  ae^^  fort  >  to. Then  xo 
can  be  determined  using  (3.8),  Xo =  [e-^'^/(ti  -  to)][\,l'e\ae')dT]  =  a.  Indeed, 
y(t)  = c(t)^(t,  to)a = ae^o, as observed. 
• 
Observability  utilizes  future  output  measurements  to  determine  the  present 
state. In contructibility, past output measurements  are used to accomplish this. Con-
structibility  is defined  below  and its relation to observability  is  established. 
DEFINITION 3.5.  A State X is unconstructible at time t\ if for every finite time t ^  t\, 
the zero-input response of the system is zero for all t, i.e., 
C{t)^{t, ti)x  =  0 
for every t <  ^i. 
(3.10) 
DEFINITION3.6.  The unconstructible at t\ sub space S^^ of (3.1) is 
(3^^ = {set of all states x unconstructible at ^i}. 
• 
It is denoted  in the following  by  R^,  for  convenience,  when  there is no ambi 
guity. 
251 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
DEFINITION3.7.  The system (3.1) is {completely  state)  constructible  at t\,  or the pair 
(A(0, C{t))  is constructible  at ti,"  if the only  state  x  G  R""  that is unconstructible  at to is "
• 
X =  0,i.e.,if/?^  =  {0}. 
THEOREM  3.3.  If the system  (3.1), or the pair  (A(0, C(0), is observable  at ^,  then  it 
is constructible  at some ti  >  ^;  if it is constructible  at ti,  then it is observable  at  some 
to^ 
ti. 
It  was  shown  in  Corollary  3.2  that  the  system  is  observable  at  ^o if  and  only  if 
rank  Wo(to, t\)  =  n for some ti  >  to. Similar results can be established for constructibil-
ity. We will require the following  concept. 
DEFINITION  3.8.  The constructibUity  Gramian  of (3.1) is the n X n matrix 
Wcn{to,tl) 
^^(r,  ti)C^{T)C{T)^{T, 
tOdr. 
(3.11) 
Proof  of  Theorem  3.3.  A similar result as Theorem 3.1, but for unconstructible  state  x, 
can be derived. Next, using a proof similar to the proof of Corollary 3.2, it can be shown 
that the system is constructible  at ti  if and only if there exists finite to <  ti  such that 
Note that 
rank  Wcn(to> ti)  =  n. 
WoitoJl) 
= 
^\tiJoWcn(to>tO<^(thtol 
(3.12) 
(3.13) 
which  implies  that  rank  Wo(to, ti)  =  rank  Wcn(to, h)  for  every  to  and  ^i.  Note  that 
• 
^(ti,  to) is nonsingular for every to and ti. 
EXAMPLE  3.3.  (i)  Consider  the  system  x  =  A{t)x,  y 
constructibility  Gramian is 
C{t)x  of  Example  3.1. The 
Wcnito, h)  = 
0 
0 
0 
[0,e  -2T + t] ]dT 
4 
Compare this with the observabiUty  Gramian of Example  3.1 and note that 
^HhJoWcn(to,h)^ituto) 
= 
-\e^'' 
0 
Wo(to,til 
as expected  [see (3.13)]. Presently, 
C{t)^{t,ti)x  =  [0,e -2t+t^i 
0 
for every t  ^  ti  implies, in view of Definition  3.5, that all unreconstructible  states (at ^i) 
are of the form 
Example  3.1). 
, a  G /?. Note that they  are identical  to the unobservable  states  (see 
(ii)  For  the  scalar  system  x  =  -x,y  =  e^ of  Example  3.2,  the  constructibility 
Gramian is Wcn(to, h)  =  e^^^iti -  to) and ^^(^i, to)Wcn(to, ^1)^(^1, to)  =  ^-(^1-^0)^2^1  >< 
(ti  -  ro)e~(^i~^o)  =  e^^^iti -  ^o)  =  Wo(to, ti),  as expected in view  of (3.13). 
• 
We shall now use Lemma 2.7 in Section 3.2 to develop additional tests for ob 
servability and constructibility. These are analogous to corresponding results that we 
established for reachability and controllability (Theorems 2.8 and 2.9). 
252 
Lh^^Systems 
THEOREM 3.4.  The system i  =  A(t)x+B(t)u, y  = C(0-^+/)(Ow is (completely state) 
observable at ^o 
(i)  if and only if there exists a finite ti > to such that 
rankWo(to,ti)  = n, 
(3.14) 
where  Wo{tQ,t\) =  \^^^^ <^^(T,to)C'^(T)C(T)^(TJo)dT  is  the  observability 
Gramian, or equivalently, 
(ii)  if and only if there exists finite ti > to such that the n columns of 
C(t)^(tJo) 
(3.15) 
are linearly independent on [to, ti] over the field of complex numbers. 
Proof. Part (i) was shown in Corollary 3.2 and part (ii) is a consequence of Lemma 2.7 
(compare with the corresponding Theorem 2.8 for reachability). 
• 
Similar  results  can be derived  for  constructibility.  In particular,  we have the 
following  result. 
THEOREM  3.5.  The system  x  = A(t)x + B(t)u, y  = C(t)x + D(t)u is (completely 
state) constructible at ti 
(i)  if and only if there exists finite to  < t\ such that 
rankWcn{to,t\) = n, 
(3.16) 
where  WcnitoJi)  =  ^^^^ ^^(rJi)C'^(r)C(r)^(T,ti)dT, 
Gramian, or equivalently, 
the  constructibility 
(ii)  if and only if there exists finite to  < ti, such that the n columns of 
are linearly independent on [to, ti] over the field of complex numbers. 
Proof, The proof is analogous to the proof of the corresponding results on observability. 
C(tmt,ti) 
(3.17) 
• 
Note that postmultiplication  of C(0^(^, ^i) by the nonsingular  matrix  ^(ti,  to) 
yields  C(t)^(t,  to) in (ii) of Theorem  3.4 [compare  with  (3.13)]. This  shows  again 
the  result  given  in Theorem  3.3 that  observability  implies  and is implied  by con 
structibility, in the case of continuous-time  systems. 
B.  Continuous-Time  Time-Invariant  Systems 
We shall now study observability and constructibility for time-invariant systems de 
scribed by equations of the  form 
x  =  Ax-^Bu, 
y  =  Cx  + Du, 
(3.18) 
where A  G /^^^^^ B  E  T^^^^, C G /?^><^ D  G 7^^><^," and u(t) G R""^ is  (piecewise) "
continuous. As was shown in Chapter 2, the output of this system is given by 
y(t)  =  Ce'^'xiO) +  Ce^^'-'^Bu{7)dT  + Du{t). 
rt 
0 
(3.19) 
We  recall  once  more  that  in  the  present  case  <I>(r, r)  =  ^(t  -  r, 0)  = 
exp [A{t -  T)]  and that initial  time can always be taken to be to  =  0. We will find 
253 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
it convenient  to rewrite  (3.19)  as 
m 
: C / %, 
(3.20) 
whcvcy{t)  =  y{t)- 
\J^Ce^^'-^^Bu{T)dT^Du{t) 
andxo  =x(0). 
DEFINITION  3.9.  A state  x is unobservable  if the zero-input response  of the  system 
(3.18) is zero for every ^ >  0, i.e., if 
-- 0 
for every ^ >  0. 
(3.21) 
The  set  of  all  unobservable  states,  x,R^,  is  called  the  unobservable  subspace  of 
(3.18).  System  (3.18) is  (completely  state)  observable,  or the pair  (A,C)  is  observable, 
if the only  state x  e  R^  that is unobservable is x =  0, i.e., if R^  = {0}. 
Definition  3.9  states  that  a  state  is unobservable  precisely  when  it  cannot  be  dis 
tinguished  as  an initial  condition  at time  0 from  the  initial  condition x(0)  =  0.  This  is 
because in this case the output is the same as if the initial condition were the zero vector. 
DEFINITION  3.10.  The observability  Gramian  of  system (3.18) is \hQnxn  matrix 
Wo(0, T)^ 
Vo{()J)= 
"[  e""""^ ^C  Ce^^dT. "
I 
e^^'C^Ce^'dT. 
Jo 
(3.22) 
We  note  that  Wo  is  symmetric  and  positive  semidefinite  for  every  T  >  0,  i.e., 
^o  =  ^J  and  Wo>0 
(show  this). Recall  that  the pnxn 
observability  matrix 
^: 
C 
CA 
CA n-\ 
(3.23) 
was  defined  in  Section  3.1. 
We  now  show  that  the  null  space  of  ^ ^ ( 0 , 7 ),  denoted  by  ^ ( ^ ^ ( 0 , 7 ) ), 
is 
independent  of  T,  i.e.,  it  is  the  same  for  any  T  >  0,  and  in  particular,  it  is  equal 
to  the  null  space  of  the  observability  matrix  0'.  Thus,  the  unobservable  subspace  RQ 
of  the  system  is  given  by  the  null  space  of  ^,  ^ ( ^ ),  or  the  null  space  of  Wo(0, T), 
^ ( W o ( 0,  r ))  for  some  finite  (and  therefore  for  all)  T  >  0. 
LEMMA3.6.  J/{0)  = ^(Wo(0,T)) 
for every  7  >  0. 
Proof,  If  X  G ^ ( ^ ),  then  ^x  =  0.  Thus,  CA^x  =  0  for  all  0  <  ^  <  n -  1,  which  is 
also true for  every ^ >  n —  1, in view  of the Cay ley-Hamilton  Theorem.  Then Ce^^x  = 
C[E^=o(^^/^-Mi-^ =  0 for every finite t. Therefore,  in view of  (3.22) ^^^(0, T)x  = 0  for 
every 7  >  0, i.e., x G yK{Wo{0, T))  for every 7  >  0. Now letx  G yK{Wo{0, T))  for  some 
r  >  0,  so that x^ W{0,  T)x  = f^ ^0  II Ce^^x  f  dT  =  0,  or Ce^'x  =  0 for  every  t  G [0, T]. 
Taking  derivatives  of  the  last  equation  with  respect  to  t  and  evaluating  at  ^ =  0,  we 
obtain  Cx  =  CAx  =  • • • =  CA^x  =  0  for  every  ^  >  0.  Therefore,  CA^x  =  0  for  every 
^ > 0,  i.e.,  ^x  =  O o r x G ^ ( ^ ). 
• 
THEOREM  3.7.  A State X is unobservable if and only if 
or equivalently, if and only if 
X G ^ ( ^ ), 
xe^(Wo{0,T)) 
(3.24) 
(3.25) 
254 
L h ^ S y s t e ms 
for  some  finite  (and therefore  for  all) T  > 0.  Thus,  the unobservable  subspace  Ro = 
^ ( ^)  = ^ ( ^ o ( 0, T))  for some T  >0. 
Proof,  If X is unobservable,  (3.21) is satisfied.  Taking  derivatives  with respect to t and 
evaluating  at ^ =  0, we obtain  Cx = CAx =  ••• = CA^x =  0 for ^ >  0 or CA^x = 0 for 
every  ^ >  0. Therefore,  ^x  = 0 and (3.24) is satisfied.  Assume  now that  ^x  = 0, i.e., 
CA^x =  O f o r O < ^ < n — 1,  which is also true for every ^ > n — 1, in view of the Cay ley-
Hamilton  Theorem.  Then Ce^^x = C[Y^^Q{t^/k\)A']x  = 0 for every  finite t, i.e., (3.21) 
is  satisfied  and x is unobservable.  Therefore,  x is unobservable  if and only  if  (3.24) is 
satisfied.  In view of Lemma 3.6, (3.25) follows. 
• 
Clearly, x is observable  if and only  if  ^x  7^ 0 or ^ ^ ( 0, T)x  ^  0 for  some  T  >  0. 
COROLLARY  3.8.  The  system  (3.19)  is  (completely  state)  observable,  or the  pair 
(A, C) is observable, if and only if 
or equivalently, if and only if 
rank  ^  = n, 
rankWo{0,T)=n 
(3.26) 
(3.27) 
for  some  finite (and therefore  for all) 7  >  0. If the system is observable, the state XQ  at 
^ =  0 is given by 
xo =  W-\OJ) 
Jo 
(3.28) 
Proof,  The system  is observable  if  and only  if the only  vector  that  satisfies  (3.20) or 
(3.21) is the zero  vector.  This is true if and only  if the null  space is empty,  i.e., if and 
only if (3.26) or (3.27) are true. To determine the state XQ at ^ =  0, given the output and 
input  values  over  some  interval  [0,7],  we premultiply  (3.20) by e^  ^C^  and integrate 
over  [0, T] to obtain 
Wo{0,T)xo= 
/''C^y{T)dT, 
[ 
Jo 
(3.29) 
in view of (3.22). When the system is observable, (3.29) has the unique solution (3.28). 
• 
Note  that  T  >  0, the time  span  over  which  the input  and output  are observed,  is 
arbitrary.  Intuitively,  one would  expect  in  practice  to  have  difficulties  in  evaluating 
XQ accurately  when  T  is small,  using  any numerical  method.  Note  that for very  small 
r,  |Wo(0,r)|  can be  very  small,  which  can  lead  to  numerical  difficulties  in  solving 
(3.29).  Compare  this  with  the  analogous  case  for  reachability,  where  small  T  leads 
in  general  to large  values  in control  action. 
It is clear  that if the state  at some  time t^ is determined,  then  the state x{t)  at any 
subsequent  time is easily  determined,  given  w(f), f >  fo, via the variation  of  constants 
formula  (3.2), where  0(f,  T)  =  exp[A(f  -  T)]. 
Alternative  methods  to  (3.29)  to  determine  the  state  of  the  system  when  the 
system  is observable  are provided  in the next  chapter,  in Section 4.3. 
EXAMPLE  3.4.  (i)  Consider  the  system  x  = Ax,y  =  Cx,  where  A 
0 
0 
1 
0 
and 
C = [ 1 , 0 ].  Here  e^' 
1 
0 
t 
1 
and  Ce^^ =  [l,t].  The  observability  Gramian  is  then 
255 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
Wo(0,T)  =  \n 
\[lT]dT  =  \^ 
1  T 
T 
T 
dr 
\rp2 
3^ 
NoticQih2itdetWo(0,T) 
j^r^  7^ 0  for  any  T  >  0,  i.e.,  ra^^  W^(0, T)  =  2  =  fz  for  any  T  >  0,  and  there 
fore  (Corollary  3.8),  the  system  is  observable.  Alternatively,  note  that  the  observabil 
ity  matrix  0  = 
M(Wo(0,  T))  = 
C 
CA 
0 
0 
1  0 
0  1 
and  rank€  =  2  =  n.  Clearly,  in  this  case  J{(€) 
, which verifies  Lemma  3.6. 
(ii)If  A  = 
0  1 
0  0 
, as before, but  C  =  [0, 1], in place of  [1,  0], then  Ce^^  =  [0, 1] 
and  the  observability  Gramian  is  WoiO, T)  = 
[0,1] JT 
-
0  0 
0  T 
We  have 
rank  Wo(0,T)  =  I  <  2  =  n  and  the  system  is  not  completely  observable.  In  view 
of Theorem  3.7, all unobservable  states  x  E  XiWoiO,  T))  and are therefore  of the  form 
,a  E^  R.  Alternatively,  the  observability  matrix  0  = 
c 
CA 
0  1 
0  0 
Note  that 
jvr(O) = >r(Wo(o,  T)) 
span 
Observability  utilizes future  output measurements  to determine the present  state. 
In (re)constructibility,  past output measurements  are used. Constructibility  is  defined 
in  the  following,  and  its  relation  to  observability  is  determined. 
DEFlNITlON3.il.  A State x is unconstructible  if the zero-input response of the system 
(3.18) is zero for  all t  <  0, i.e., 
Ce^'x  =  0 
for every  ^ <  0. 
(3.30) 
The  set  of  all  unconstructible  states  x, R^, 
is  called  the  unconstructible  subspace  of 
(3.18).  The  system  (3.18)  is  (completely  state)  {re)constructible,  or  the  pair  (A, C) 
is  (re)constructible, 
"if  the  only  state  x  E  /?""  that  is  unconstructible  is  ;c  =  0",  i.e., 
Ren  = {0}. 
We shall now establish a relationship between observability and constructibility  for 
the continuous-time  time-invariant  systems  (3.18). Recall that x  is unobservable  if  and 
only if 
Ce'^'x  =  0 
for every t  >  0. 
(3.31) 
THEOREM  3.9.  Consider the system x  =  Ax  + Bu, y  =  Cx  + Du  given in (3.18). 
(i)  A state x is unobservable if and only if it is unconstructible. 
(ii)  Ro  =  R^. 
(iii)  The  system,  or the pair  (A, C), is  (completely  state)  observable  if  and only if 
it is (completely  state)  (re)constructible. 
Proof,  (i)  If  X  is  unobservable,  then  Ce^^x  =  0  for  every  t  >  0.  Taking  deriva 
tives  with  respect  to  t  and  evaluating  ai  t  =  0,"  we  obtain  Cx  =  CAx  =  ""•  = "
CA^x  =  0  for  A:  >  0  or  CA^'x  =  0  for  every  /:  >  0.  This,  in  view  of  Ce^^x  = 
implies  thai Ce^^x  =  0 for every r<  0, i.e., x is unconstructible. The 
"^""l=Q(t^/k\)CA^x", 
converse is proved in a similar manner. Parts (ii) and (iii) of the theorem follow  directly 
from  (i). 
• 
The  observability  Gramian  for  the time-invariant  case,  Wo(0,  T),  was  defined  in 
(3.22).  In  view  of  (3.11), we  make  the  following  definition. 
256 
Linear  Systems 
DEFINITION  3.12.  The constructibUity  Gramian  of system (3.18) is ih^nXn  matrix 
W,,(0,  T) 
,AHr~T)^T^^A(r-T)^^^ 
(3.32) 
Note  that 
Wo(0,T)  = 
"e^""^Wcn{0",T)e AT 
(3.33) 
as  can  be  verified  directly  [see  also  (3.13)]. 
As  in  the  time-varying  case  above,  we  now  introduce  a  number  of  additional 
criteria  for  observability. 
THEOREM  3.10.  The system x  =  Ax  + Bu, y  =  Cx  + Dui^  observable 
(i)  if and only if 
rank  W^(0, T)  =  n 
(3.34) 
for  some  finite  T  >  0, where  Wo(0, T)  =  \Q  e^^'^C^Ce^'  dr,  the  observabil 
ity Gramian, or 
(ii)  if and only if the n columns of 
are linearly independent on  [0, oo) over the field of complex numbers, or alter 
natively, if and only if the n columns of 
"Ce""^' "
(3.35) 
are linearly independent  over the field of complex numbers, or 
(iii)  if and only if 
C(sl  -  A)-^ 
where 0  -
C 
CA 
CA n -l 
(iv)  if and only if 
rank  €  =  n, 
the observability  matrix, or 
rank 
Sil  -  A 
C 
(3.36) 
(3.37) 
(3.38) 
for all complex numbers 5/, or alternatively, for all eigenvalues  of A. 
Proof.  The proof of this theorem is completely  analogous to the (dual) results on reach 
ability  (Theorem 2.17)  and is omitted. 
• 
Similar  results  as  those  given  in  Theorem  3.10  can  be  derived  for  constructibil-
ity,  and  the  reader  is  encouraged  to  state  and  prove  these  for  the  cases  (i)  and  (ii). 
This  is  of  course  not  surprising,  since  it  was  shown  (in  Theorem  3.9)  that  observ 
ability  implies  and  is  implied  by  constructibility.  Accordingly,  the  tests  developed 
in  the  theorem  for  observability  are  typically  also  used  to  test  for  constructibility. 
EXAMPLE  3.5.  Consider  the  system  x  =  Ax,  y  =  Cx,  where  A  = 
andC 
0  0 
[1, 0], as in Example  3.4(i). We shall verify  (i) to (iv) of Theorem  3.10 for this case. 
(i)  For the observability Gramian, Wo (0, r)  = 
2^  we have rank Wo(0, T) 
i T2 
2^ 
=  2  = nfor  any T >  0. 
(ii)  The columns of Ce^^ =  [l,t]  are linearly independent on [0, oo) over the  field 
of complex numbers, since ai  • I + a2-1  = 0 implies that the complex num 
bers ai  and a2  must both be zero. Similarly, the columns of C{sl —  A)~^  = 
[1/5, \ls^] are linearly independent over the field of complex numbers. 
257 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
= rank 
=  2  = n. 
"""1  0' "
.0  1. 
"- 1"" "
(iii)  rank€ 
}  =  rank r c' 
[cA_ 
(iv) rank 
Sil  -  A] 
C  J 
= rank 
values of A. 
Consider again A = 
0  1 
0  0 
'Si 
0 
.1 
=  2  =  n for Si =  0,  /  =  1, 2, the eigen-
= 
Si 
0. 
butC  =  [0, 1] [in place of [1,0], as in Example 3.4(ii)]. 
The system is not observable for the reasons given below. 
(i)  Wo(0, T)  = 
with rank Wo{0, T)  =  l<  2  = n. 
(ii)  Ce^^ =  [0,1]  and  its  columns  are  not  linearly  independent.  Similarly,  the 
columns of C(sl  — A)~^  =  [0, l/s] are not linearly independent. 
(iii)  rank€  = rank 
C 
CA 
= rank 
(iv) rank 
Sil  -  A 
C 
= rank 
of A. 
C.  Discrete-Time  Systems 
0  1 
0  0 
-1 
1<2  = n. 
=  I  < 2  =  n  for Si =  0,  an  eigenvalue 
We consider  systems described by equations of the  form 
x(k  +  1)  =  A(k)x(k)  +  B(k)u(k\ 
y(k)  =  C(k)x(k)  +  D(k)u(k\ 
(3.39) 
"where  A(k)  G  /('""^^ B(k)  G  /^""^""^"," C(k)  G  i?^><^ D(k)  G  RP""""""^",  and  the  input 
"u(k)  G  R""^ are  defined  for  k  ^  ko  (see  Section  2.7).  The  output  y(k)  for  ^  > ^Q "
is given by 
y(k)  =  C(k)^(k 
ko)x(ko)  +  ^  C(k)^(k, 
i +  l)B(i)u(i)  +  D(k)u(kl 
(3.40) 
k-\ 
i = ko 
where the state transition matrix ^(k,  ko) is given by ^(k,  ko)  =  A(k  —  l)A(k  —  2) 
... A(ko)  for  k  >  ko, and <P(ko,  ko)  =  I. 
In the time-invariant  case, (3.39) assumes the  form 
x{k  +1)  =  Ax(k)  +  Bu(kl 
y(k)  =  Cx(k)  +  Du(k), 
k  ^  ko, 
(3.41) 
"where A G iR""><^ C  G jR^^^"," C  G /^^x^ D  G  RP""""""^", and (3.40) is still valid with the 
state transition matrix 0(fc, ko) given in this case by 
^(k,  ko)  =  A^-^o, 
k  ^  ko. 
(3.42) 
258 
Linear Systems 
Observability  and  (re)constmctibility  for  discrete-time  systems  are  defined  as 
^^ the  continuous-time  case.  Observability  refers  to  the  ability  to  uniquely  deter 
mine the state from  knowledge of current and future  outputs and inputs, while con-
structibility  refers  to  the  ability  to  determine  the  state  from  knowledge  of  current 
and past outputs and inputs. In discrete-time  systems, the time-varying  case can be 
developed in a manner analogous to the time-invariant case and will therefore not be 
developed  here. Instead,  we  shall concentrate  on the time-invariant  case. Note that 
some of the following  results have already been presented in Section 3.1. 
Discrete-time time-invariant  systems 
Consider the time-invariant system (3.41) and the expression for its output  y(k), 
given in (3.40). Without loss of generality, we take  ^o  =  0. Then 
y(k)  =  CA^x{0)  + ^  CA^-^'^^'^Buii)  +  Du{k) 
(3.43) 
k-i 
for  yfe  >  0 and j(0)  =  CJC(O) +  Dw(0). Rewrite (3.43) as 
/=o 
y{k)  =  CA^xo 
(3.44) 
for  ^  >  0,  where  y{k)  =  y(k) 
XfZo  CA^-^'+^^Bu(i)  -h  Du(k)  for fc >  0  and 
y(0)  =  y(0)  -  Du(Ol  and  XQ =  x(0). 
DEFINITION  3.13.  A State  x  is  unobservable  if  the  zero-input  response  of  system 
(3.41) is zero for all ^ >  0, i.e., if 
CA^x  = 0 
for every y^ >  0. 
(3.45) 
The set of all unobservable states x, Ro, is called the unobservable subspace of (3.41). 
The system (3.41) is {completely state) obse^able,  or the pair (A, C) is observable, if the 
"only state x E  /?"" that is unobservable is x  =  0", i.e., if Ro = {0}. 
• 
The pnX  n observability  matrix  0  was defined  in  (3.23). Let J{(G) denote  the 
null space of  0. 
THEOREM3.il.  A State X is unobservable if and only if 
X E K(€X 
(3.46) 
i.e., the unobservable subspace Ro = M(€). 
Proof. If X  E Jvr(O), then Ox  =  0 or CA^x  =  O f o r O < ^ < n - l.  This statement is 
also true fork>n- 
1, in view of the Cay ley-Hamilton Theorem. Therefore, (3.45) is 
satisfied and x is unobservable. Conversely, if x is unobservable, then (3.45) is satisfied 
and €x  = 0. 
• 
Clearly," x is observable if and only if €x  ¥""  0. "
COROLLARY  3.12.  The  system  (3.41)  is  (completely  state)  observable,  or the pair 
(A, C) is observable, if and only if 
rank€  = n. 
(3.47) 
259 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
If the system is observable, the state XQ at ^ = 0 can be determined as the unique  solution 
of 
(3.48) 
where 
l'0.«-l  =  b ^ ( 0 ) , / ( l ) , . . . , / ( « - l ) ] ^ 6 / ? ' ' «, 
t/o.«-i  =  [M^(0),M^(l),...,"«^(n-l)]^  €/?""•""", 
and Mfi is the pn x mn matrix given by 
D 
CB 
0 
D 
0 
0 
"0"" "
0 
Mn--
CA^'-^B 
CA^'-^B 
D 
••  CB 
D 
Proof,  The system is observable if and only if the only vector that satisfies  (3.45) is the 
zero  vector.  This is true if and only if ^ ( ^)  =  {0}, or if (3.47) is true. To determine 
the  state XQ, apply  (3.43) for ^ =  0 , 1 , . . ., n — 1, and rearrange in a form  of a system of 
linear equations to obtain  (3.48). 
• 
The  matrix M^  defined  above has the special  structure  of a ToepUtz  matrix.  Note 
that  a matrix  T  is Toeplitz  if its  (/, 7)th entry  depends  on the value  i —  j',  that  is, T is 
"""constant  along  the diagonals."" "
Similarly  to the continuous-time  case, we now define  the observability  Gramian. 
DEFINITION  3.14.  The observability  Gramian  of the system (3.41) is iho nxn  matrix 
^ -1 
i=o 
If  ^k  =  [C^, ( C A ) ^ , . . ., (CA^-i)^]^  (with  ^n  =  ^ ), then 
Wo{0,K)  =  ^^^K- 
The  following  result is  apparent. 
LEMMA 3.13.  ^ ( ^)  =  ^(Wo(0,K)) 
for every  K>n. 
(3.49) 
(3.50) 
Proof,  The proof is left  as an exercise for the reader. 
• 
COROLLARY  3.14.  The system  (3.41)  is  (completely  state)  observable,  or the pair 
(A, C) is observable, if and only if 
rankWo{0,K)=n 
(3.51) 
for  some  (and consequently  for all) K  > n. If the system  is observable,  the state XQ  at 
^ =  0 is given by 
xo = W-\0,K)^^[Yo,K-i 
-MkUo,K-i]. 
(3.52) 
where K  >n. 
Proof  Statement  (3.51) is a direct consequence of Corollary  3.12 and Lemma 3.13. To 
obtain (3.52), rewrite  (3.48) in terms of K, premultiply by ^ ^, and use relation  (3.50). 
260 
Linear  Systems 
EXAMPLE  3.6.  Consider  the  system  in  Example  1.4,  x{k  +  1)  =  Ax{k),y{k)  = 
Cx(k),  where  A  = 
' 
1  1 
and  C  =  [0,1].  The  observability  Gramian  Wo{0,K) 
foYK  =  n  =  2is  given  by  (3.49),  Wo(0,2)  = 
Xi^o(A^yC^CA^ 
[0, 1]  + 
ro^ 
[i. 10,  IJ ro  r 
ro  11 
iJ 
.1 
of full  rank. Therefore,  the system is observable. Note that 0  = 
.1.  [0,1] + ni 
.1  1.  — ro^ 
0  0 
0  1  + 
i_ [1,1] 
1  1 
ll  1 
1  1 
1  2 
, which is 
is of full  rank as 
ro  1 
Ll  1 
well  (see Example  1.4).  Notice also that rank  Wo(0, K)  =  2 for  every  K  >  2 and  that 
[refer  to (3.50)]  W^(0, 2) 
"""1  1 "
1  2  = 
"""0  1 "
1  1 
T  r 0  1 
1  1 
0^0.  The unique vector  x(0) 
can be determined  from  y(0) and yil)  using (3.52) to obtain 
xi(0) 
^2(0)J 
=  w; Ho, 2)0^ 3^(0) 
3^(1) 
3^(1) -  3^(0) 
This is the same as the result obtained in Example  1.4,  using an alternative  approach. 
Constructibility  refers  to  the  ability  to  determine  uniquely  the  state  x{0)  from 
knowledge  of current  and past outputs  and inputs. This is in contrast to  observability, 
which  utilizes  future  outputs  and inputs. The  easiest  way  to define  constructibility  is 
by the use of (3.44), where  x(0)  =  XQ is to be determined  from  past data y{k),  A:  <  0. 
Note, however,  that for fc <  0, A^ may  not exist; in fact,  it exists only when A is  non-
singular.  To  avoid  making  restrictive  assumptions,  we  shall  define  unconstructible 
states in a slightly  different  way than anticipated.  Unfortunately,  this definition  is not 
very  transparent.  It  turns  out  that  by  using  this  definition,  an  unconstructible  state 
can  be  related  to  an  unobservable  state  in  a  manner  analogous  to  the  way  a  control 
lable  state  was  related  to  a reachable  state  in  Section  3.2  (see  also  the  discussion  of 
duality  in  Section  3.1). 
DEFINITION  3.15.  A State X is unconstructible  if for every  ^  >  0 there exists x i 
such that 
/?« 
=  Ak A'x, 
Cx  =  0. 
(3.53) 
The  set  of  all  unconstructible  states,  R^,  is  called  the  unconstructible  subspace.  The 
system  (3.41)  is  (completely  state)  constructible,  or the  pair  (A, C)  is  constructible,  if 
• 
"the only state x  E  /?"" that is unconstructible  is x  =  0", i.e., if R^  =  {0}. 
Note that if A is nonsingular,  then  (3.53)  simply  states that x is unconstructible  if 
CA~^x  =  0  for  every  k>  0  (compare  this  with  Definition  3.13  of  an  unobservable 
state). 
The  results  that  can  be  derived  for  constructibility  are  simply  dual  to the  results 
on  controllability.  They  are presented  briefly  below, but  first,  a technical  result  must 
be  established. 
LEMMA  3.15.  If  X E  M'(€) then  Ax 
J{(€)  is an A-invariant  subspace. 
>r(0),  i.e.,  the  unobservable  subspace  Ro  = 
Proof,  Let  x  E  >r(0), so that Ox  =  0. Then  CA^x  =  O f o r O < / : < n - l.  This  state 
ment  is  also  true for  k>  n  — 1, in  view  of  the  Cayley-Hamilton  Theorem.  Therefore, 
OAx  =  0, i.e.. Ax  E  M{p). 
• 
THEOREM 3.16.  Consider the  systemx(^+1): 
given in (3.41). 
--Ax{k)+Bu{k),y{k)=Cx{k)+Du{k) 
261 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
(i)  If a state x is unconstructible, then it is unobservable. 
(ii)  RcnCRo. 
(iii)  If the system is (completely  state) observable, or the pair  (A, C) is observable, 
then  the  system  is  also  (completely  state)  constructible,  or  the  pair  {A,C)  is 
constructible. 
If A is nonsingular,  then relations  (i) and  (iii)  are if  and only  if  statements. In  this 
case, constructibility  also implies observability. Furthermore, in this case, (ii) becomes 
an equality, i.e., Rcw = Ro-
Proof,  This  theorem  is dual  to Theorem  2.22,  which  relates  reachability  and  control 
lability  in  the  discrete-time  case.  To  verify  (i),  assume  that  x  satisfies  (3.53)  and 
premultiply  by  C  to  obtain  Cx  =  CA^x  for  every  ^  >  0.  Note  that  Cx  =  0  since  for 
k = 0^  x = x,  and  Cx  =  0.  Therefore,  CA^x  =  0  for  every  ^  >  0,  i.e.,  x  G ^ ( ^ ).  In 
view of Lemma 3.15, x = A^x  G ./K(^), and thus, x is unobservable. Since x is arbitrary, 
we  have  also  verified  (ii).  When  the  system  is  observable,  Ro =  {0},  which  in  view 
of  (ii),  implies  that  Ren =  {0}  or  that  the  system  is  constructible.  This  proves  (iii). 
Alternatively,  one  could  also prove this  directly:  assume  that the  system  is  observable 
but  not  constructible.  Then  there  exist  x,x  7^ 0,  which  satisfy  (3.53).  As  above,  this 
implies that x G ./K(^), which is a contradiction  since the system is observable. 
Consider  now  the  case  when  A  is  nonsingular  and  let  x  be  unobservable.  Then, 
in  view  of  Lemma  3.15, x  = A~^x  is  also  in  ^ ( ^ ),  i.e.,  Cx  =  0.  Therefore,  x  =  A^x 
is  unconstructible,  in  view  of  Definition  3.15.  This  implies  also  that  R^  C  Ren,  and 
therefore,  Ro =  RCE, which proves that in the present  case constructibility  also  implies 
observability. 
• 
EXAMPLE  3.7.  Consider the  system in Example  1.5, x{k+l)= 
Ax{k),y{k)  =  Cx{k), 
where A 
and C =  [1,0]. As shown in Example  1.5,  rank^  =  rank 
[Ol 
a 
1  <2  =  n,  i.e.,  the  system  is  not  observable.  All  unobservable  states  are  of  the  form 
where  a  ^  R  since m is  a  basis  for  yK{^)  =  Ro,  the  unobservable  sub-
is  {[:]}  and 
.  Note  that  a  basis  for  yK(Wo(0,2)) 
space.  The  observability  Gramian  foYK  =  n  =  2is  Wo(0,2)  =  C^C  +  (CA)^(CA) 
2  0 
0  0 
0 
0  + 
1 
0 
1 
0 
0 
0 
^ ( ^)  =  J^{Wo{0,2)).  This verifies  Lemma 3.13. 
In Example  1.6  it was  shown that  all the  states x  that  satisfy  CA~^x  = 0 for  every 
^  >  0,  i.e.,  all  the  unconstructible  states,  are  given  by  a 
,a  e  R.  This  verifies 
Theorem  3.16  (i) and (ii) for the case when A is  nonsingular. 
EXAMPLE  3.8.  Consider  the  system  x(k+  1)  =  Ax(k),y(k)  =  Cx{k),  where  A 
0 
1 
0 
0 
and C =  [1,0]. The observability  matrix 
1 
0 
0 
0 
is of rank  1, and there-
fore,  the system is not observable. In fact,  all states of the form  a 
I are  unobservable 
states  since 
< 
>  is a basis for 
J^{^). 
To  check  constructibility,  the  defining  relations  (3.53)  must  be  used  since  A  is 
5ck  consti 
singular.  Cx  =  [l,0]x  =  0  implies  x 
Substituting  into  x  =  A^x,  we  obtain 
262 
Linear  Systems 
for  k  =  0,x  = X,  and x =  0  for fc >  1.  Therefore,  the  only  unconstructible  state  is 
X =  0,  which  imphes  that  the  system  is  constructible  (although  it  is  unobservable). 
This  means  that  the initial  state x(0) can be uniquely  determined  from  past  measure-
rxi(o)i  _ 
X2(0)J 
ments. In fact,  from  x{k +  1) = Ax{k)  and y{k)  = Cx{k),  we obtain x(0) 
x i ( - l) 
X2(-l). 
Therefore, x(0) 
0 
xi(-iy 
0 
y ( - l) 
and  y ( - l)  =  C x ( - l)  =  [1,0] 
XI ( - 1) 
X2(-l). 
= x i ( - l ). 
DEFINITION  3.16.  The constructibility  Gramian  is defined as 
(3.54) 
We  note  that  Wc^(0,^)  is well  defined  only  when A  is nonsingular.  The  observ 
ability  and constructibility  Gramians  are related  by 
Wo(0,K)  = 
{A^)^Wcn{0,K)A^, 
(3.55) 
as can easily  be  verified. 
When A  is nonsingular,  the state XQ at ^ =  0 can be determined  from  past  outputs 
and  inputs  in the following  manner.  We consider  (3.44)  and note  that in this  case 
is  valid  for ^ <  0 as well.  This  implies  that 
y{k)  =  CA^jco 
"'CA-""""' "
-l,-n 
"""Xo "
Xo 
(3.56) 
CA-' 
with  Y-i^-n  = 
[j^(—n),.. .,j^(—1)]^.  Equation  (3.56)  must  be  solved  for XQ. 
Clearly,  in  the  case  of  constructibility  (and  under  the  assumption  that  A  is  non-
singular),  the  matrix  ^A~^ 
[compare  this  with  the 
dual  results  in  (2.66)].  In  particular,  the  system  is  constructible  if  and  only  if 
rank  {^A~'^)  =  rank  ^  =  n. 
is  of  interest  instead  of  ^ 
EXAMPLE  3.9.  Consider  the  system  in  Examples  1.4  and 3.6,  namely,  x ( ^+ 1)  = 
Ax{k),y{k)  =  Cx{k),  where  A 
[0 
1 
ll 
1 
check constructibility  we consider  ^A 
and  C =  [0,1].  Since  A  is  nonsingular,  to 
CA-^ 
CA-' 
, which has full  rank. 
Therefore, the system is constructible (as expected), since it is observable. To determine 
x(0), in view of (3.56), we note  that 
which 
XI (0) 
X2(0), 
namely,  (A^)^Wc„(0,2)A 
}'(-2) 
1 
1 
XI (0) 
X2(0) 
,  from 
ffA-^x{Q) 
}'(-2) 
} ' ( - 2) 
K-l)+K-2)  . It is also easy to verify  (3.55), 
• 
= W,(0,2). 
263 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
PART  2 
SPECIAL  FORMS  FOR  TIME-INVARIANT  SYSTEMS 
3.4 
SPECIAL  FORMS 
In  this  section,  important  special  forms  for  the  state-space  description  of  time-
invariant  systems  are  presented.  These  forms  are  obtained  by  means  of  similarity 
transformations  and  are  designed  to  reveal  those  features  of  a  system  that  are  re 
lated to the properties  of controllability  and observability.  In Subsection  A,  special 
state-space  forms  that  display  the  controllable  (observable)  part  of  a  system  and 
that  separate  this  part  from  the  uncontrollable  (unobservable)  part  are  presented. 
These forms, referred  to as the standard  forms  for uncontrollable  and  unobservable 
systems,  are  very  useful  in  establishing  a  number  of  results.  In  particular,  these 
forms  are used in Subsection B to derive alternative tests for controllability  and ob 
servability,  and in Subsection  C to relate  state-space  and input-output  descriptions. 
(Additionally,  these  forms  are further  used  in  Chapters  4  and  5.)  In  Subsection  D, 
the controller and observer state-space forms  are introduced. These are useful  in the 
study  of  state feedback  and  state estimators  (to be  addressed  in  Chapter  4), and  in 
state-space realizations  (to be addressed in Chapter 5). 
A.  Standard  Forms  for  Uncontrollable  and Unobservable  Systems 
We consider time-invariant  systems described by equations of the  form 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
(4.1) 
"where A  £  R""""^"""," B  G T?""^™","  C  £  RP^""","  and D  £  RP^"""".  It was shown earlier in this "
chapter that this system is state reachable or controllable-from-the-origin  if and only 
if the n X mn  controllability  matrix 
%  = 
[B,AB,...,A''-^B] 
(4.2) 
has  full  row  rank  n,  i.e.,  rank  %  =  n.  Recall  that  9l(^)  =  Rr  is  the  reachable 
subspace,  which  contains  all  the  state  vectors  that  can  be  reached  from  the  zero 
vector  in  finite  time  by  applying  an  appropriate  input.  If  the  system  is  reachable 
(or controllable-from-the-origin),  then it is also controllable  (or  controllable-to-the-
origin), and vice versa (see Section  3.2). 
It was also shown earlier in this chapter that  system  (4.1) is state observable if 
and only if the pnX  n observability  matrix 
C 
CA 
CA n-\ 
(4.3) 
has full  column rank, i.e.,  rank  €  =  n. Recall that J{(€)  =  RQ  is the  unobservable 
subspace that contains all the states that cannot be determined uniquely  from  input 
264 
Linear Systems 
and  output  measurements  in  finite  time. If  the  system  is observable,  then  it is  also 
constructible, and vice versa (see Section  3.3). 
Similar  results  were  also  derived  for  discrete-time  time-invariant  systems  de 
scribed by equations of the  form 
x(k  +1)  =  Ax(k)  +  Bu(kl 
y(k)  =  Cx(k)  +  Du(k) 
(4.4) 
in Sections 3.1, 3.2, and 3.3. Again, rank  %  =  n and rank  0  =  n are the necessary 
and sufficient  conditions for state reachability and observability, respectively. Reach 
ability always implies controllability and observability always implies constructibil-
ity, as in the continuous-time case. However, in the discrete-time case, controllability 
does not necessarily  imply  reachability  and constructibility  does not imply  observ 
ability, unless A  is  nonsingular. 
Next,  we  will  address  standard  forms  for  unreachable  and  unobservable  sys 
tems both for the continuous-time  and the discrete-time time-invariant cases. These 
forms  will be referred  to as  standard  forms  for  uncontrollable  systems,  rather  than 
unreachable  systems,  and  standard  forms  for  unobservable  systems,  respectively. 
This is to conform  with the established terminology in the literature, where the term 
"""controllable""  is used  instead  of  ""reachable","""  perhaps  because  of  emphasis  on  the "
continuous-time  case. It  should be noted, however,  that by  the term  controllable  in 
this section we mean controllable-from-the-origin,  i.e., reachable. 
1. Standard form for uncontrollable  systems 
If  the  system  (4.1)  [or  (4.4)]  is not  completely  controllable  (-from-the-origin), 
"then  it is possible  to  ""separate"" the controllable  part  of the  system  by means  of  an "
appropriate similarity transformation. This amounts to changing the basis of the state 
space  (see Section  2.2)  so that  all the vectors  in the controllable  (-from-the-origin) 
or reachable subspace Rr have certain structure. In particular, let rank  ^  =  nr <  n, 
i.e.,  the pair  (A, B)  is  not  controllable.  This  implies  that  the  subspace  Rr  =  2/l(^) 
has  dimension  n^. Let  {vi, V2,..., v„J  be  a basis  for  Rr.  These  n^ vectors  can  be, 
for example, any nr linearly independent  columns of ^.  Define  the  nX  n  similarity 
transformation  matrix 
Q=  [Vl,V2,...,Vn,,Qn-n^ 
(4.5) 
where  the  nX  (n  -  nr) matrix  Qn-nr contains  n  -  nr linearly  independent  vectors 
chosen  so  that  Q  is  nonsingular.  There  are  many  such  choices.  We  are  now  in  a 
position to prove the following  result. 
LEMMA 4.1.  For (A, B) uncontrollable, there is a nonsingular matrix Q such that 
A = Q-'AQ  =  Ai  An 
0  A2 
and 
B  =  Q'^B  = 
(4.6) 
where Ai  E R'^rXnr^ ^i  G R'^rX'^^ and the pair (Ai, Bi) is controllable. The pair (A, B) is 
in the standard form for uncontrollable systems. 
Proof  We need to show that 
AQ  =  A[Vi,  . . .,  Vn,,  Qn-nr]  = 
l^h  • • •,  V„,,  Qn-nr] 
=  QA. 
0  A2. 
Since the subspace Rr is A-invariant (see Lemma 2.15 in this chapter), Av/ G Rr, 
which can be written as a linear combination of only the nr vectors in a basis of Rr. Thus, 
Ai in A is an rir X rir matrix, and the (n — rir) X rir matrix below it in A is a zero matrix. 
Similarly, we also need to show that 
265 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
B  =  [vi,...,v„,, Q„-„J  0 
-QB. 
But this is true for similar reasons: the columns of 5  are in the range of'^  or in Rr. 
The n X nm  controllability  matrix '^ of (A, B) is 
^  =  [B,AB,...,"A""-'B] "
=  0 
0 
Ar'Bi 
0 
(4.7) 
which clearly has ranfcC  = 
that 
rank[Bi,AiBi,... 
"A""{''^Bi",...,"A""^-^Bi] "
=  n,.Note 
(4.8) 
The range of ^  is the controllable  (-from-the-origin)  subspace of (A, B).  It contains 
vectorsonlyoftheform[a^,  0]^," wherea  G JR""^ Since dim  S/l(^)  =  rank%  =  rir", 
every  vector  of  the  form  [a^,  0]^  is  a  controllable  (state)  vector.  In  other  words, 
"the  similarity  transformation  has changed  the basis  of  /?"" in  such a manner  that  all "
controllable  (-from-the-origin)  vectors,  expressed  in  terms  of  this  new  basis,  have 
this very particular  structure of zeros in the last n —  rir entries. 
Given  system (4.1)  [or (4.4)], if a new  state x(t)  is taken to be x(t)  =  Q~^x(t), 
then 
k  =  Ax  + Bu, 
y  =  Cx  + bu, 
(4.9) 
where  A  =  Q~^AQ,B  =  Q~^B,C  =  CQ,  and  D  =  D  constitutes  an  equivalent 
representation  (see Chapter 2). For Q as in Lemma 4.1, we obtain 
Xi 
X2 
An 
Ai. 
0 
u,y  =  [Ci, C2] 
+  Du, 
(4.10) 
where  x  =  {x[,  X2]  with  xi  G R^'  and where  (Ai, ^i)  is controllable. The matrix 
C  =  [Ci, C2] does not have any particular  structure. This representation  is called a 
standard form  for  the  uncontrollable  system.  The  state  equation  can  now  be  writ 
ten as 
X\  ^  A i ^i  +  BiW  +  A12X2, X2  =  A2X2, 
(4.11) 
which  shows  that  the  input  u does  not  affect  the trajectory  component  X2(t) at  all, 
and therefore,  X2{t) is determined  only by the value of its initial vector. The input u 
certainly affects  xi (t). Note also that the trajectory component xi (t) is also influenced 
by X2(t). In  fact. 
xi(t)  =  ^^i^Jci(O)  + 
e'^'^'~^^Biu(T)dT  + 
oMit-T. -^Ane^^'dr  X2(0). 
(4.12) 
The  nr eigenvalues  of Ai  and the corresponding  modes  are called  controllable 
eigenvalues  and controllable  modes  of the pair (A, B) or of system (4.1) [or of (4.4)]. 
The n-  nr eigenvalues of A2 and the corresponding modes are called the  uncontrol 
lable  eigenvalues  and uncontrollable  modes,  respectively. 
It  is  interesting  to  observe  that  in  the  zero-state  response  of  the  system  (zero 
initial  conditions)  the  uncontrollable  modes  are  completely  absent.  In  particular. 
266 
Linear Systems 
in  the  solution  x(t)  =  e^^x(0)  +  \Q e^^^ ^'^Bu{T)dr  of  x  =  Ax  + Bu,  given  x(0), 
notice that 
eMt-r)^  ^  [Qe^(^-^^Q-'][QB]  =  Q 
0 
(show this), where Ai  [from (4.6)] contains only the controllable eigenvalues. There 
fore,  the input  u(t)  cannot  directly  influence  the uncontrollable  modes. Note, how 
ever, that the uncontrollable modes do appear in the zero-input response e^^x(0).  The 
same observations  can be made for  discrete-time  systems  (4.4), where the  quantity 
A^B  is of interest (show this). 
EXAMPLE 4.1.  Given A  =1 
ro 
-1 
-2 
LO 
1 
11 
1 
- ij 
and 5  = 
"""1  0"" "
1  1 
.1  2. 
tern (4.1) to the standard form (4.6). Here 
we wish to reduce sys-
% =  [B, AB, A^B] 
1 
1 
1 
0 
1 
2 
: 
: 
: 
1 
0 
-1 
:  0 
:  0 
:  0 
-1 
0 
1 
and rank % = nr'=2<3  = n. Thus, the subspace Ry = S?l(^) has dimension rir  = 2, 
and a basis {vi, V2} can be found by taking two linearly independent columns of ^, say, 
the first two, to obtain 
[Vl,V2, Gl]  = 
1  0 
1  1 
1  2 
0 
0 
1 
The third  column of  Q was  selected  so that  Q is nonsingular.  Note that the first two 
columns of Q could have been the first and third columns of ^  instead, or any other two 
linearly independent vectors obtained as a linear combination of the columns in %. For 
the above choice for Q we have. 
A =  Q-'AQ  = 
1 
-1 
1 
0 
1 
-2 
0 
1 
-2 
-1 
-1 
4 
1] 
1 
"ri  0  0"" "
1 10 
[1  2  1. 
1  -ij 
01 
0 
ij 
11 
0 
2] 
-1 
To 
1 -2 
[0 
ri  0  01 
1 10 
[1  2 
i_ 
0 
0 
0 
1 
-1 
: 
: 
1 
0 
Ai 
:  An 
: 
-2_ 
.0 
:  M_ 
B=  Q-^B  = 
1 
-1 
1 
0 
1 
-2 
n 
1 
1 
01 
0 
ij 
0] 
1 
2^ 
= 
"""  1 "
0 
0  ' 
1 
0 
0 J 
[B11 
= 
0 
where (Ai, Bi) is controllable [verify this and show that ^  = Q  ^^,  i.e., verify  (4.8)]. 
267 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
The  matrix  A  has  three  eigenvalues  at  0 , - 1 , - 2.  It  is  clear  from  (A, B)  that 
the  eigenvalues  0,-1  are controllable  (in  Ai), while  -2  is  an uncontrollable  eigen 
• 
value (in A2). 
2.  Standard form for unobservable  systems 
The standard form  for  an unobservable  system can be derived  in a similar  way 
as the  standard  form  of uncontrollable  systems. If the  system  (4.1)  [or (4.4)] is not 
completely  state observable," then  it is possible to ""separate"" the unobservable  part "
of the system by means of a similarity transformation.  This amounts to changing the 
basis of the state space so that all the vectors in the unobservable  subspace Ro have 
a certain  structure. 
As  in the preceding  discussion  concerning  systems  or pairs  (A, B)  that  are  not 
completely  controllable,  we  shall  presently  select  a  similarity  transformation  Q to 
reduce a pair  (A, C), which is not completely  observable, to a particular  form.  This 
can be accomplished  in two ways. The  simplest  way  is to invoke duality  and  work 
with the pair (AD  =  A^,Bo  =  C^), which is not controllable (refer to the discussion 
of dual systems in Section 3.1). If Lemma 4.1 is applied, then 
AD  =  Q'DADQD 
= 
AD\ 
0 
ADU 
AD2 
BD  -  QD  BD 
- BDI 
0 
where (Aoi,  Boi)  is controllable. 
Taking the dual again, we obtain the pair  (A, C), which has the desired  proper 
ties. In particular, 
' A^ 
A = A'^ = QhAUQor'  = QoMGhr' = 
A^ 
^D12 
c  = Bi = BUQlr'  =  c(Qir 1  _  [B: IvOl 
0 
A^ 
^D2 
(4.13) 
where (A^p Bj^^) is completely  observable by duality  (see Theorem  1.1). 
EXAMPLE  4.2.  Given  A  = 
0 
-1 
1 
1 
-2 
1 
0] 
1  andC = 
- ij 
we wish to reduce 
system (4.1) to the standard form (4.13). To accomplish this, let AD  = A^ and BD  =  C^ • 
Notice that the pair (Ao, Bo) is precisely the pair (A, B) of Example 4.1. 
• 
A  pair  (A, C)  can  of  course  also  be  reduced  directly  to  the  standard  form  for 
unobservable  systems. This is accomplished  in the  following. 
Consider the system (4.1)  [or (4.4)] and the observability  matrix 0  in (4.3). Let 
rank  €  =  rio <  n, i.e., the pair (A,  C) is not completely observable. This implies that 
the unobservable subspace Ro  =  J^(€)  has dimension n -  HQ. Let {vi,..., v„-„J  be 
a basis for 7?^  and define  an n X n similarity transformation  matrix  Q as 
Q  = 
[Qno,Vi,...,Vn-nol 
(4.14) 
where the n^irio  matrix  Qn^  contains UQ linearly independent vectors chosen so that 
Q is nonsingular. Clearly, there are many  such choices. 
LEMMA 4.2.  For (A,  C) unobservable, there is a nonsingular matrix Q such that 
A = Q-'AQ  = 
\Ai 
0 
U21  A2 
and 
C  =  CQ  =  [Ci, 0], 
(4.15) 
268 
Linear Systems 
where Ai  G /?«^^««, Ci  E T^^^^^ and the pair (Ai, d)  is observable. The pair (A, C) is 
in the standard form for  unobservahle systems. 
Proof  We need to show that 
Since the unobservahle subspace Ro is A-invariant (see Lemma 3.15), Av/ E T^^, which 
can be written as a linear combination of only the n-  rio vectors in a basis of Ro. Thus, 
A2 in A is an (n ~ rio) X (n -  Ho) matrix, and the rio X (n -  rio) matrix above it in A is a 
zero matrix. Similarly, we also need to show that 
0 
A2.  = eA. 
A21 
CQ  =  C[Q,„vi,...,v,_„J  =  [Ci,0]  =  C. 
This is true since Cvi  = 0. 
The pnX  n observability  matrix 0  of (A, C) is 
which clearly  has 
C 
CA 
Ci 
CiAi 
CA n-\ 
C,A\-' 
Ci 
CiAi 
rank€  =  rank 
CiA 
«o-i 
=  ^« 
Note that 
ciAr 
=  €Q, 
• 
(4.16) 
(4.17) 
The null space of © is the unobservable  subspace of (A, C). It contains vectors only 
of the form  [0, a'^f,"  where a  G  /^""""""o.  Since dim >f(d)  =  n- "
rank  €  =  n  -  no, 
every  vector  of the form  [0, a ^ ]^  is an unobservable  (state)  vector. In other words, 
the  similarity  transformation  has changed  the basis  of  R'^ in  such  a manner  that  all 
unobservable  vectors expressed in terms of this new basis have this very  particular 
structure—zeros  in the first no entries. 
For Q chosen as in Lemma 4.2 and (4.9), it assumes the  form 
Ai 
A21 
0 
A2 
Bi 
Bi 
u,y  =  [Ci, 0] 
+  Du, 
(4.18) 
where  x  =  [x[,"  x^Y  with  xi  G  7?""^ and  where  {A\",  C\)  is observable. The  matrix 
B  =  [BJ, B^]^  does  not  have  any  particular  form.  This  representation  is  called  a 
standard form  for  the unobservable  system. 
The  no eigenvalues  of Ai  and  the  corresponding  modes  are  called  observable 
eigenvalues  and  observable  modes  of  the  pair  (A, C)  or  of  the  system  (4.1)  [or of 
(4.4)]. The n -  no eigenvalues of A2 and the corresponding modes are called  unob 
servable  eigenvalues  and unobservable  modes,  respectively. 
Notice  that  the  trajectory  component  x(t),  which  is  observed  via  the  output 3;, 
is not influenced  at all by X2, the trajectory  of which is determined primarily by the 
eigenvalues  of A2. 
The unobservable  modes  of the  system  are completely  absent  from  the  output. 
In particular, given x  =  Ax  -\-  Bu, y  =  Cx  with initial state x(0), we have 
269 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
y{t) 
Jo 
"and  Ce""^'  =  [CQ-^][Qe^'Q-^]  =  [Cie'^^'",0]Q-^ 
(show  this),  where  Ai  [from 
(4.15)] contains only the observable eigenvalues. Therefore, the unobservable modes 
cannot  be  seen  by  observing  the  output.  The  same  observations  can  be  made  for 
discrete-time  systems where the quantity  CA^  is of interest (show this). 
EXAMPLE  4.3.  Given  A  =  \  ^ 
2 
^ | and C  =  [1, 1], we  wish  to  reduce  system 
-3J 
(4.1)  to  the  standard  form  (4.15).  To  accomplish  this,  we  compute  0  = 
, which has rank €  =  rio  =  1 < 2  =  n. Therefore,  the  unobservj 
space Ro = M(€) has dimension n -  Uo  =  1. In view of (4.14), 
Q  =  [Qhvi]  = 
: 
0 
1 
1  :  -ij 
where vi  =  [1, -1]^ is a basis for Ro, and Qi was chosen so that Q is nonsingular. Then 
A  =  Q-'AQ 
1  1 
1  0 
"""0 "
1 
1 
-1 
Ai 
A21 
0 
A2, 
C=  CQ=  [1,1] 
[1,0]  =  [Ci,0], 
where (Ai, Ci) is observable [show this and verify that 6  =  €Q, i.e., verify (4.17)]. 
The matrix A has two eigenvalues at  - 1,  - 2. It is clear from (A, C) that the eigen 
• 
value -2  is observable (in Ai), while -1  is an unobservable eigenvalue (in A2). 
3. Kalman's Decomposition  Theorem 
Lemmas 4.1 and 4.2 can be combined to obtain an equivalent representation of 
(4.1)  where the reachable  and  observable parts  of this  system  can readily  be  iden 
tified.  To this end, we consider  system  (4.9) again  and proceed, in the following,  to 
construct the  nX  n required  similarity transformation  matrix  Q. 
As before, we let rir denote the dimension of the controllable  (-from-the-origin) 
subspace 7?r i-e., ^r  =  dim Rr  =  dim9l(^)  =  ran^^.  The dimension of the unob 
servable subspace/?^  =  >r(0)isgivenby  n^  =  n-rankG  =  n-n^.Let/i^^bethe 
dimension of the subspace Rro  =  Rr(^  Ro that contains all the state vectors x  E  R^ 
that are controllable but unobservable. We choose 
Q  =  [Vl,  . . .,  Vn,-nro  + h  . • .,  Vnr^  QN,  Vi,  . . .,  V ^ , - « , J, 
(4.19) 
270 
Linear  Systems 
where  the  rir  vectors  in  { v i , . . . , v ^ ^}  form  a  basis  for  Rr.  The  last  riro  vectors 
"{^nr-nro+ii""'i^nr} "
ii^  the  basis  for  Rr  dire chosen  so  that  they  form  a  basis  for 
Rro =  Rr^Ro'  The Ho — Uro  =  {n — HQ — Uro)  vcctors  { v i ,. . .,  Vn^-Tiro)  ^^^  Selected  so 
that  when  taken  together  with  the  rird vectors  {v^^_^^-+i,..., V^^} they  form  a  basis 
for  Ro,  the  unobservable  subspace.  The  remaining  N  =  n—  {fir + rio — Uro) columns 
in  Q^  are  simply  selected  so that  Q is  nonsingular. 
The  following  theorem  is  called  the  Canonical  Structure  Theorem  or  Kalman's 
Decomposition 
Theorem. 
THEOREM  4.3.  For  (A,5)  uncontrollable  and  {A,C)  unobservable, 
nonsingular matrix  Q such that 
0 
there  is  a 
A = Or^AQ = 
B =  Q-'B  = 
1 
(4.20) 
Al3 
"0  "" "
All 
A21  A22  A23  A24 
0 
A33 
A43  A44_ 
0 
0 
0 
0 
'B{ 
B2 
0 
0 
C =  Ce=[Ci,0,C3,0], 
where 
(i) 
(A„5,)with 
Ac^ 
"""All "
"0  "" "
A21  A22_ 
and 
Be  = 
B{ 
is controllable  (-from-the-origin),  where A^ G R^'^^',Bc  G  R^^^^, 
{Ao,Co)  with 
(ii) 
\An  Ai31 
A33 
0 
and 
Co = [Ci,C3] 
is observable,  where Ag  G R^o><no  ^^^  Q  ^  j^pxno  ^j^^^ where the  dimensions 
of the matrices Aij.Bi,  and Cj  are 
A ll  :  {nr  -  Uro)  X  {rir  -  Uro), 
A33 : {n-{nr  + no-nro))  x  {n -  {ur + no -  firo)),  A44 : {fio-firo)  x 
B\ 
B2  '.  Uro  X m, 
Ci  :  px(nr-nro), 
C3  : p  x  (n-(rir  +  no-nro)), 
: {fir — firo) X m, 
A22  :  Uro  X  Uro, 
{fio-firo), 
(iii) 
the triple  (Ai 1, 5 i, Ci)  is such that  (Ai 1,5i)  is controllable  (from-the-origin) 
and  (Aii,Ci)  is observable. 
Proof,  For  details  of  the proof,  refer  to  [8]  and  to  R.  E.  Kalman,"  ""On  the  Computa "
tion of the Reachable/Observable  Canonical Form,""" SI AM J. Control  and  Optimization", 
Vol. 20, No. 2, pp. 258-260,  1982, where  further  classifications  to  [8] and  an  updated 
method of  selecting  Q are given. 
• 
The  similarity  transformation  (4.19)  has  altered  the  basis  of  the  state  space  in 
such  a  manner  that  the  vectors  in  the  controllable  (-from-the-origin)  subspace  Rr, 
the  vectors  in  the  unobservable  subspace  RQ,  and  the  vectors  in  the  subspace 
Rro^Ro 
all  have  specific  forms.  To  see  this,  we  construct  the  controllability  matrix 
C  =  [ 5 , . ..  ,A^~^5]  whose  range  is  the  controllable  (-from-the-origin  or  reachable) 
subspace  and  the  observability  matrix  S  =  [ C ^ , . . ., (CA^~^)^]^, whose  null  space  is 
the unobservable  subspace. Then,  all controllable  states are of the form  [^^,^2  ,0,0]^, 
all  the  unobservable  ones  have  the  structure  [0,^2 ,0,^4]^,  while  states  of  the  form 
[0,^2 ,0,0]^  characterize  Rro,  i.e., they  are  controllable  but  unobservable. 
Similarly  to  the  previous  two  lemmas,  the  eigenvalues  of  A,  or  of A,  are  the 
eigenvalues of An, A22, A33, and A44, i.e., 
|A/  -  A\  =  |A/ -  A\  =  \XI -  AiillA/  -  A22IIA/ -  A33IIA/ -  A44I. 
(4.21) 
If in particular we consider the representation {A, B, C, D} given in (4.9), where 
Q was selected  as in the canonical structure theorem given above, then 
271 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
0 
Ai3 
An 
A21  A22  A23 
0 
0  A33 
0  A43 
[  0 
0  1 
A24 
0 
A44J 
pi 
U2 
p3 
[x4 
+ 
r^ii 
B2 
0 
0 
-1 
y  =  [Ci.0,C3,0] 
Xl 
X2 
+  Dw. 
(4.22) 
This shows that the trajectory components corresponding to X3 and X4 are not  affected 
by the input u. The modes associated with the eigenvalues of A33 and A44 determine 
the trajectory components for X3 and f 4 (compare this with the results in Lemma 4.1). 
Similarly to Lemma 4.2, the trajectory  components for X2 and X4 cannot be observed 
from y, and are determined by the eigenvalues of A22 and A44. The following  is now 
apparent  (see also Fig. 3.4): 
The eigenvalues of 
All  are controllable and observable, 
A22 are controllable and unobservable, 
A33 are uncontrollable  and observable, 
A44 are uncontrollable  and unobservable. 
CO 
I 
FIGURE 3.4 
Canonical decomposition (c and c 
denote controllable and uncontrollable, 
respectively). The connections of the 
c/c and 0/0 parts of the system to the 
input and output are emphasized. 
Note that the impulse response 
(transfer function) of the system, 
which is an input-output description 
only, represents the part of the 
system that is both controllable 
and observable (see Section 3.4C). 
272 
Linear Systems 
EXAMPLE  4.4.  Given 
1 
1 
-1 
ro 
A  -  1 
[o 
-1 
-2 
1 
,5  = 
"""1  0"" "
1  1 
.1  2_ 
,  and  C  =  [0,1, 0],  we wish to reduce  system 
(4.1) to the canonical structure (or Kalman decomposition) form (4.20). The appropriate 
transformation matrix Q is given by (4.19). The matrix ^  was found in Example 4.1 and 
C 
CA 
0 
1 
2 
1 
-2 
4 
0 
1 
-2 
A basis for R^  = >r(0) is {(1, 0, -1)^}. Note that rir  = Zrio  =  1, and riro  =  1- There 
fore, 
Q  =  [Vl, V2,  QN] 
1 
1 
1 
1 
0 
-1 
0 
0 
1 
is an appropriate similarity matrix (check that det Q ¥- 0). We compute 
0 
0 
1 
A =  Q-'AQ 
1 
-1 
-2 
11 
1 
-ij 
01 
0 
ij 
1 
0 
-1 
1 
1 
1 
0 
1 
1 
1 
2 
1 
ro 
1 
[o 
-1 
0 
Ai3 
All 
A21  A22  A23 
0 
A33 
0 
^  n-^n  = 
B  =  Q-'B 
0 
1 
1 
1 
-1 
-2 
01 
0 
ij 
ri  0' 
1 
1 
Ll 
2. 
= 
"""  1 "
1  ' 
Bi' 
B2 
. 0. 
0 
0 
-1 
= 
0 
and 
C  = CQ  =  [0, 1, 0] 
1 
1 
1 
1  0 
0  0 
-1  1 
[1,0,0]  = [Ci,0,C3]. 
The eigenvalue 0 (in An) is controllable and observable, the eigenvalue -1  (in A22) 
is controllable and unobservable, and the eigenvalue  -2  (in A33) is uncontrollable and 
observable. There are no eigenvalues that are both uncontrollable and unobservable.  • 
B.  Eigenvalue/Eigenvector  Tests for  Controllability  and  Observability 
There  are  tests  for  controllability  (-from-the-origin)  and  observability  for  both 
continuous-  and  discrete-time  time  invariant  systems  that  involve  the  eigenvalues 
and eigenvectors  of A. Some of these criteria  are called PBH tests, after  the initials 
of the codiscoverers  (Popov-Belevitch-Hautus)  of these tests. These tests are  useful 
in  theoretical  analysis,  and  in  addition,  they  are  also  attractive  as  computational 
tools. 
THEOREM  4.4.  (i) The pair (A, B) is uncontrollable if and only if there exists a 1 X ^ 
(in general) complex vector vt #  0 such that 
v / [ A / / - A , 5]  =  0, 
(4.23) 
where A/ is some complex  scalar. 
(ii) The pair (A, C) is unobservable if and only if there exists annX 
I (in general) 
complex vector v/  T^ 0 such that 
273 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
[A// -  A] 
C 
0, 
(4.24) 
where A/ is some complex  scalar. 
Proof,  Only part (i) will be considered since (ii) can be proved using a similar argument, 
or directly, by duality  arguments. 
(Sufficiency)  Assume  that  (4.23)  is satisfied.  In view  of v/A  =  A/V/ and ViB  = 0, 
ViAB  =  XiViB  =  0, and vtA^B  =  0,  ^  =  0, 1, 2 , . . ..  Therefore,  Vi% =  Vi[B,  AB,..., 
A^~^B]  =  0, which shows that (A, B) is not completely  controllable. 
(Necessity)  Let (A, B) be uncontrollable  and assume without loss of generality the 
standard form for A and B given in Lemma 4.1. We will show that there exist A/ and v/ so 
that (4.23) holds. Let Aj be an uncontrollable eigenvalue and let v/  =  [0, a]," a^  G  C""~""% "
where  a(XiI  -  A2)  =  0, i.e., a  is a left  eigenvector  of A2 corresponding  to A/. Then 
• 
v/[A,/  -A,B]  =  [0, a(\il  -  A2), 0]  =  0, i.e., (4.23) is satisfied. 
COROLLARY  4.5.  (i) The pair  (A, B) is controllable if and only if no left  eigenvector 
of A is orthogonal to all the columns of B. 
(ii) The pair (A, C) is observable if and only if no right eigenvector of A is orthogonal 
to all the rows of C. 
Proof,  The proof  follows  directly from  Theorem 4.4. 
• 
COROLLARY  4.6.  (i) A/ is an uncontrollable  eigenvalue of (A, B) if and only if there 
exists a 1 X /I (in general) complex vector v/ 7^  0 that satisfies  (4.23). 
(ii) A/ is an unobservable  eigenvalue  of (A, C) if and only if there exists  an /i X 1 
(in general) complex vector v,  7^ 0 that satisfies  (4.24). 
Proof  Only  part  (i) will  be considered,  since  part  (ii) can be proved  using  a  similar 
argument or directly, by duality  arguments. 
(Sufficiency)  Assume  that  (4.23)  is satisfied.  Now v/[A//  -  A, B]  =  0, in view of 
the  sufficiency  proof  of Theorem  4.4, implies  that  v/^  =  v/[5, AB,...,  A^'^B]  =  0. 
Therefore,  (A, B) is not controllable.  Without  loss  of generality,  assume  that  (A, B) is 
in the standard  form  of Lemma  4.1. In this case the controllability  matrix has the form 
(4.7)  with  its top nr rows  linearly  independent  and its lower  n -  nr rows  being  zero. 
Therefore,  in view  of Vj^  =  0, v/ has the form  v/  =  [0," a\  for some  a  E  C""~""^  Now "
v/(A//  -  A)  =  0 implies that a (A// -  A2) =  0, which shows that A/ is an eigenvalue of 
A2, i.e., it is an uncontrollable  eigenvalue. 
(Necessity)  Let A/ be an uncontrollable eigenvalue of (A, B). Assume without loss of 
generality that the pair (A, B) is in the standard form of Lemma 4.1. Then v/  =  [0, a ], where 
a i s s u c h t h a t a ( A / /-  A2) =  0 (see the proof of Theorem 4.4), satisfies v/(A//-  A)  =  0. 
Also, ViB  =  [0, a] 
0  =  0. So (4.23) is  satisfied. 
EXAMPLE  4.5.  Given  are A  = 
"""1  0' "
1  1 
.1  2. 
Example 4.4. The matrix A has three eigenvalues, Ai  =  0, A2 
-1 
-2 
1 
1 
1 
-1 
0 
1 
0 
,B  = 
, and C  =  [0,1, 0],  as in 
^ - 1,  and A3 =  - 2, with 
274 
Linear  Systems 
corresponding right eigenvectors vi  =  [1,1,1]^, V2 =  [1,0, - 1 ] ^, V3 =  [1,1, - 1 ]^ and 
with  left  eigenvectors  vi  =  [^,0,  ^],V2  =  [1, ~ 1,  0],  and  V3  =  [-^,  1, - 5 ],  respec 
tively. 
In view of Corollary 4.6, viB  =  [1,1]  7^ 0 implies that Ai  =  0 is controllable. This 
is  because  vi  is  the  only  nonzero  vector  (within  a multiplication  by  a nonzero  scalar) 
that satisfies  vi(Ai/  -  A)  =  0, and so Vi5  7^ 0 impUes that the only  1 x3  vector a  that 
satisfies a[\il 
-  A, B]  =  0 is the zero vector, which in turn imphes that Ai is controllable 
in  view  of  (i) of Lemma  4.6. For  similar reasons  Cvi  =  1 7^ 0 imphes  that  Ai  =  0  is 
observable; see (ii) of Lemma 4.6. Similarly, V2B =  [0, - 1]  7^ 0 implies that A2  =  -1 
is controllable, and  Cv2  =  0 implies that A2 =  -1  is unobservable.  Also, v^^B  =  [0, 0] 
implies  that  A3  =  -2  is  uncontrollable,  and  CV3  =  1 7^ 0  implies  that  A3  =  -2  is 
observable. 
These results agree with the results derived in Example 4.4. 
• 
COROLLARY  4.7. (RANK  TESTS),  (ia) The pair (A, B) is controllable if and only if 
rank  [A/  -  A, 5]  =  n 
for all complex numbers  A, or for all n eigenvalues  A/ of A. 
(ib) Xi is an uncontrollable eigenvalue of A if and only if 
(iia) The pair (A, C) is observable if and only if 
rank  [A//  -  A, 5]  <  n. 
rank 
XI  -  A 
C 
for all complex numbers  A, or for all n eigenvalues A/. 
(iib) Xi is an unobservable eigenvalue of A if and only if 
rank 
\XiI  -  A] 
C 
<  n. 
(4.25) 
(4.26) 
(4.27) 
(4.28) 
Proof.  The  proofs  follow  in  a  straightforward  manner  from  Theorem  4.4.  Notice  that 
the only values of A that can possibly reduce the rank of [XI -  A, B] are the  eigenvalues 
ofA. 
• 
EXAMPLE  4.6.  If  in  Example  4.5  the  eigenvalues  Ai, A2, A3 of A are known,  but  the 
corresponding  eigenvectors  are not, consider the system  matrix 
P(s)  = 
si  -  A  B 
0 
-C 
s 
-1 
0 
1 
s  + 2 
-1 
-1 
-1 
-1 
s+\ 
1 
1 
1 
0 
1 
2 
0 
0 
0 
and determine  rank  [XJ  -  A, B] and  rank 
Xil  -  A 
C 
. Notice that 
rank 
si  -  A 
C 
5 =  ^2 
=  rank 
and 
rank  [si  —  A, B]s=x^ =  rank 
-1 
-1 
0 
0 
-2 
-1 
0 
1 
1 
-1 
1 
2 
0 
-1 
-1 
-1 
-1 
=  2<3  =  n 
=  2<3  =  n. 
In view of Corollary 4.7, A2 =  -1  is unobservable and A3 =  -2  is uncontrollable. 
Verify  that these are the only uncontrollable  and unobservable eigenvalues by apply 
ing the rank tests of Corollary 4.7. Compare these results with the results in Example 4.5. 
E X A M P LE  4.7.  Let  A 
and B 
with  A 
1  the  eigenvalues 
of A. We would like to determine  which  of the eigenvalues  are uncontrollable. Note 
that (A, B) is in the standard form for uncontrollable  systems of Lemma 4.1, namely. 
Ai 
0 
An 
Ai, 
. We know by inspection that the eigenvalue A2 =  1  of A2, is uncon 
275 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
U z -l 
[0 
-1 
11 
A, -  1  oj 
and for V2 =  [0, 1], V2[A2/ 
trollable. Presently, [A// -  A, B] 
A, B] =  [0, 0], which in view of Theorem 4.4 and Corollary 4.6, imphes that A2 =  1  is 
an uncontrollable eigenvalue and that V2 =  [0, 1] is the corresponding left  eigenvector. 
Note that V2  is of the form  [0, a], as discussed in the proof of Theorem 4.4. The other 
eigenvalue, Ai  =  1, is controllable. It is the eigenvalue of Ai  =  1, where (Ai, Bi)  is 
controllable. Note that the corresponding  eigenvector to the controllable eigenvalue is 
vi  =  [0,1], the same as V2- Therefore, when using the eigenvalue/eigenvector tests, one 
can detect in the present example only that at least one of the multiple eigenvalues is 
uncontrollable; this test is unable to detect that the other eigenvalue is controllable. This 
situation arises when there are multiple eigenvalues, in which case care should be taken 
when using the eigenvalue/eigenvector  tests. When the eigenvalues  are distinct, then 
each of them can specifically be identified as being controllable or uncontrollable by the 
eigenvalue/eigenvector test. For another example," try A =  1  0"" "
0  1. 
and 5  = 
1' 
0. 
C.  Relating  State-Space  and Input-Output  Descriptions 
The system x  =  Ax-^  Bu, y  =  Cx-^  Du  given in (4.1) has pX  m transfer  function 
matrix 
H(s)  =  C(sl  -  A)-^B  + D  =  C(sl  -  Ay^B  +  A 
(4.29) 
where {A, B, C, D} is the equivalent representation  given in (4.9) (see also  Sections 
2.5 and 2.6). Consider now the Kalman  Decomposition  Theorem  and the  represen 
tation (4.22). We wish to investigate which of the submatrices A/y, Bi, Cj  determine 
H(s)  and which do not. The inverse of si  -  A  can be determined by repeated  appli 
cation of the  formulas 
and 
-1 
0  8 
-1 
"la  0"" "
[y  8 
a 
0 
§ -1 
a 
ya  -1 
0 
(4.30) 
where  a,  (5, 7, 8  are  matrices,  with  a  and  8  square  and  nonsingular.  It  turns  out 
(verify)  that 
"H{s)  =  Ci(sl  -  Aii)""iJ5i  +  A "
(4.31) 
that  is,  the  only  part  of  the  system  that  determines  the  external  description  is 
{All, Bi, Ci, D},  the  subsystem  that  is  both  controllable  and  observable  [see  The 
orem  4.3(iii)]. Analogous  results  exist  in  the  time  domain.  Specifically,  taking  the 
276 
Linear  Systems 
inverse Laplace transform  of both  sides in  (4.29), the impulse response  of the  system 
for  r  >  0  is  derived  as  (see  Chapter  2) 
H{t,  0)  =  de^'^'Bi 
+  D8{t), 
(4.32) 
which  depends  only  on  the  controllable  and  observable  parts  of  the  system,  as  ex 
pected. 
Similar  results  exist  for  discrete-time  systems  described  by  (4.4). For  such  sys 
tems,  the  transfer  function  matrix  H{z)  and  the  pulse  response  H{k,  0)  (see  Chap 
ter  2)  are  given  by 
H{z) 
Cx{zI-Axi)-^Bi+D 
and 
H{k,  0) 
D, 
k>0, 
k  =  0, 
(4.33) 
(4.34) 
These  depend  only on the part  of the  system that is both controllable  and  observable, 
as  in  the  continuous-time  case. 
EXAMPLE  4.8.  For the system x  =  Ax  + Bu, y  =  Cx, where A, B, C are as in Exam 
ples 4.4 and 4.5, we have i/(5)  =  C{sI-A)-^B 
=  (1)(1/^)[1,1]  = 
[l/s,  l/s].  Notice  that  only  the  controllable  and  observable  eigenvalue  of  A, Ai  =  0 
(in  All),  appears  in  the  transfer  function  as  a  pole.  All  other  eigenvalues  (A2  =  - 1, 
A3 =  - 2)  cancel out. 
• 
=  Ci(sI-An)~^Bi 
EXAMPLE  4.9.  The  circuit  depicted  in Fig.  3.5  is  described  by  the  state-space  equa 
tions 
1 
(RiC) 
0 
0 
L 
Xi(t) 
X2(t) 
1 
(RiC) 
1 
v(0 
i(t)  = 
1 
Ri 
1 
Xi(t) 
MO 
where the voltage v(t)  and current  i(t)  are the input  and output variables  of the  system, 
xi(t)  is the voltage across the capacitor, and X2(t) is the current through the inductor. We 
have  i(s)  =  H(s)v(s)  with the transfer  function  given by 
His)  =  C(sl  -  AT^B  +  D  =  (^'.C-L)s^(R,-R2) 
^ ^ 
^ 
^ 
(Ls  + R2){R\Cs  + Ri) 
^  1 
Ri 
The  eigenvalues  of  A  are  Ai  =  -l/(RiC) 
and  A2 
-R2IL.  Note  that  in  general 
rank  [A//  —A,B]  =  rank 
[A//  -  A 
C 
=  2  =  n,  i.e.,  the  system  is  controllable  and 
/•(O 
^2(0 
v{t) 
^i(0 
FIGURE  3.5 
observable, unless the relation  R1R2C  =  Lis  satisfied.  In this case Ai 
and the system matrix  P(s)  assumes the  form 
P(s)  = 
si  -  A  B 
D 
-C 
= 
'^T 
0 
^ 
.+  ^ 
In the following,  assume that R1R2C  =  Lis  satisfied. 
-k 
-
(i) Let Ri  7^  R2 and take 
Ri-
L 
1 
1 
1 
A2 
-Ri/L 
277 
CHAPTERS: 
Controllability, 
Observability, 
and  Special 
Forms 
L^h V2I  — 
R2  Ri 
.1 
1  . ' 
-  rvi 
I M 1 ~^  — 
i<2 -
~Ri 
1 
1 
-R, 
R2. 
to  be  the  linearly  independent  right  and  left  eigenvectors  corresponding  to  the  eigen 
values Ai  =  A2  =  -R2IL.  The eigenvectors could have been any two linearly  indepen 
dent  vectors  since  XJ  -  A  =  0.  They  were  chosen  as  above  because  they  also  have 
the  property  that  V2^  =  0  and  Cv2  =  0,  which  in  view  of  Theorem  4.4,  implies  that 
A2  =  -R2IL  is both  uncontrollable  and unobservable.  The  eigenvalue  Ai  =  -R2IL  is 
D  1 
r D 
both controllable and observable since it can be seen using 2  =  K 
^\x.o  reduce the 
representation to the canonical structure form (Kalman Decomposition Theorem)  (verify 
this). The transfer  function  is in this case given by 
{s +  RxlL){s  +  R2IL) 
Ri(s  +  R2/L)(s  +  R2/L) 
Ri(s  +  R2/Ly 
s  +  RilL 
His) 
that  is,  only  the  controllable  and  observable  eigenvalue  appears  as  a  pole  in  H(s),  as 
expected. 
(ii) Let Ri  =  R2  =  R and take 
Lvi, V2J 
[Vl,V2]  ^  = 
In  this  case  viB  =  0  and  Cv2  =  0.  Thus,  one  of  the  eigenvalues,  Ai  =  -RIL, 
is  un 
controllable (but can be shown to be observable) and the other eigenvalue, A2  = 
-RIL, 
is unobservable  (but can be  shown  to be  controllable). In the present  case, none  of  the 
eigenvalues  appear in the transfer  function.  In  fact. 
His) =  1. 
as can readily be verified. Thus, in this case the network behaves as a constant resistance 
network. 
At this point it should be made  clear that the modes  that are uncontrollable  and/or 
unobservable  from  certain  inputs  and  outputs  do  not  actually  disappear;  they  are  sim 
ply  invisible  from  certain  vantage  points  under  certain  conditions.  (The  voltages  and 
currents  of this  network  in the  case  of constant  resistance  [H{s)  =  l/R]  are  studied  in 
Exercise 3.26.) 
• 
EXAMPLE 4.10.  Consider the system i  =  Ax+Bu,y  =  Cx where A 
1 
0 -2 
0 
0 
0 
0 
0 -1 
B  = 
and  C  =  [1, 1,0].  Using  the  eigenvalue/eigenvector  test  it  can  be  shown 
278 
Linear Systems 
(verify this) that the three eigenvalues of A (resp., the three modes of A) are Ai  =  1 (resp., 
e^), which is controllable and observable, A2 =  -2  (resp., e'^^), which is uncontrollable 
and observable, and A3 =  -1  (resp., e^^), which is controllable and unobservable. 
The response due to the initial condition x(0) and the input u(t) is 
x(t)  = e'''xiO)+  \ e''^'-^^Bu(T)dT 
"0 "" "
0 
,-t 
ft 
x(0)  + 
-  e«-T)  -
0 
U{T)  dr 
Jo 
_e-('--\ 
and 
KO  =  C^^'x(O)  +  Ce^^'~^^Bu(T)dr 
=  [e\e~^\Q]x{0)+\ 
e^'''h(T)dT. 
Notice that only controllable modes appear in e^^B [resp., only controllable eigenvalues 
appear in (si  -  A)~^5], only observable modes appear in Ce^^ [resp., only observable 
eigenvalues appear in C(5/ - A) ~ ^ ], and only modes that are both controllable and observ 
able appear in Ce^^B [resp., only eigenvalues which are both controllable and observable 
appear in C{sl -  A)~^B  = H{s)]. 
For the discrete-time case, refer to Exercise 3.17d. 
• 
D.  Controller  and  Observer  Forms 
It has been seen several times in this book that equivalent representations of systems 
given by the  equations 
=  Ax  +  Bu, 
y  =  Cx  +  Du, 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
(4.35) 
(4.36) 
where  x  =  Px,A  =  PAP-\  B  =  PB,C  =  CP-\  and D  =  D, may offer  advan 
tages  over the original representation  when P  (or Q  =  P~^)  is chosen in an appro 
priate manner. This is the case when P (or Q) is such that the new basis of the  state 
space  (see  Section  2.2)  provides  a natural  setting  for  the properties  of interest.  As 
a  specific  case,  refer  for  example  to  Subsection  3.4A,  where  Q  (and  the  new  ba 
sis) was chosen  so that the controllable and uncontrollable parts of the system  were 
separated. The same results of course apply to discrete-time systems (4.4). This sub 
section  shows how to select  Q when  (A, B)  is controllable  [or (A, C) is  observable] 
to  obtain  the  controller  and  observer  forms.  These  special  forms  are  very  useful, 
especially  when  studying  state-feedback  control  (and  state observers)  discussed  in 
Chapter  4  and  in realizations  discussed  in  Chapter  5. These  special  forms  are  also 
very useful  in establishing  a quick way to shift  between  state-space  representations 
and another very useful  class of equivalent internal representations, the polynomial 
matrix representations  studied in Chapter 7. 
Controller forms  are considered first. Observer forms  can of course be obtained 
directly  in  a  similar  manner  as  the  controller  forms,  or  they  may  be  obtained  by 
duality. This is addressed in the latter part of this  section. 
279 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
1. Controller  forms 
The  controller  form  is  a particular  system  representation  where  both  matrices 
(A, B) have certain  special  structure.  Since in this case A  is in the companion  form 
(see  Section  2.2  in  Chapter  2)  the  controller  form  is  sometimes  also  referred  to  as 
the controllable  companion form.  Consider the  system 
X =  Ax-\-  Bu, 
y  =  Cx-\-  Du, 
(4.37) 
where  A  G  /?^x^ B  G  R'''''^,"  C  G  7?^>'^ and  D  G  RP""""""^  and  let  (A", B)  be  control 
lable (-from-the-origin).  Then ran ^^  =  n, where 
Assume that 
%  = 
[B,AB,...,A''~^Bl 
rank  B  =  m  ^  n. 
(4.38) 
(4.39) 
Under these assumptions, r a n ^^  =  n and rank  B  =  m. We will show how to obtain 
an equivalent  pair  (A, B)  in controller  form,  first  for  the  single-input  case  (m  =  1) 
and then for  the multi-input  case  (m  >  1). Before  this is accomplished,  we  discuss 
two  special  cases  that  do not  satisfy  the  above  assumptions  that  rank  B  =  m  and 
that (A, B) is controllable. 
1.  If the m columns of 5  are not linearly independent  (rankB  =  r  <  m), then there 
exists an m X m nonsingular matrix K  (or equivently, there exist elementary col 
umn operations) so that BK  =  [Br, 0], where the r columns of Br are linearly in 
dependent (ran ^ 5^  =  r). Note that i  =  Ax  + Bu  =  Ax  + {BK){K~^u)  =  Ax^-
[Br, 0]  Ur 
same input action to the system can be accomplished by only r inputs, instead of 
m inputs, and there is a redundancy  of inputs, which in control problems  clearly 
implies  that  a reconsideration  of  the  input  choices  is  in  order.  The pair  (A, Br), 
which is controllable when (A, B) is controllable (show this), can now be reduced 
to controller form,  using the method developed  below. 
=  Ax  + BrUr, which clearly shows that when rankB  =  r  <  m the 
Uyyi—y 
2.  When  (A, B)  is  not  completely  controllable,  then  a  two-step  approach  can  be 
taken. First, the controllable part is isolated (see Subsection 3.4A) and then is re 
duced to the controller form, using the methods of this section. In particular, con 
"sider the system x  =  Ax  + Bu  with A G  R""^^"""""," B  G i^^X'""", and rankB  =  m. Let 
rank  [B, AB,...,  A^~^B]  =  nr <  n. Then there exists  a transformation  Pi  such 
that  PiAP-
Ai 
0 
Al2 
A2 
and  PiB  = 
where  Ai  G  P^^^^^^ Bi  G P'^^^'^, 
and  (Ai,Bi) 
is  controllable  (Subsection  3.4A).  Since  (Ai,  Bi)  is  controllable, 
there  exists  a  transformation  P2  such  that  P2A1P2 ^  =  Mc,  and  P2B1  =  Bic, 
where Aic, Bic  is in controller form,  defined  below. Combining, we obtain 
and 
PiAn 
A2  _ 
-1  ^ 
PAp-'  = 
"""B  = "
Ale 
0 
Bic 
0 
(4.40) 
280 
Linear Systems 
[where Axc ^  R'^'^'^'.Bic  G R'^rxm^  ^^^  (Aic,Bic)  is  controllable],  which  is  in 
controller form. Note that 
P2  0 
0 
/  Pi-
(4.41) 
Single-input  case  (m  =  1).  The  representation  {Ac^Bc^Cc^Dc}  in  controller 
form is given by Ac 
A = PAP-^  and Bc=  B = PB with 
0 
-oco 
0 
-ai 
1 
-OCn-l 
Br 
(4.42) 
where the coefficients  ai dire the coefficients  of the characteristic polynomial  a{s)  of 
A, that is, 
"a{s)=  det  {si -  A)  = s"""" ^  an-is""""'^  ^ "
h^i^ +  ao- 
(4.43) 
Note  that  Q  =  C =  CP~^  and  Dc =  D  do  not  have  any  particular  structure.  The 
structure  of  (Ac,Be)  is  very  useful  (in  control  problems)  and  the  representation 
{Ac^Bc^Cc^Dc} shall  be  referred  to  as  the  controller form  of  the  system.  The  sim 
ilarity  transformation  matrix  P  is  obtained  as  follows.  The  controllability  matrix 
^  =  [B^AB,...  ,A^  ^5] is in this case minxn  nonsingular matrix and  ^ 
where q is the nth row of ^ 
"and  x  indicates the remaining entries of ""^ "
. Then 
qA 
qA n-\ 
(4.44) 
To show  that PAP~^  = Ac  and PB  = Be given  in  (4.42), note first that  qA'~^B  =  0, 
/ =  1,... , n-  1, and qA^'-^B =  1. This can be verified  from the definition  of q, which 
implies that q^  =  [0,0,..., 1] (verify  this). Now 
P^  =  P[5,A5,...,"A^""^5] "
"""0 "
0 
1 
0 
0 
1 
X 
•• 
•• 
r X 
1 
X 
X 
•  ^ c-
(4.45) 
which  imphes  that  | P ^|  =  | P | | ^|  7^ 0  or  that  |P|  ^  0.  Therefore,  P  quaUfies  as 
a  similarity  transformation  matrix.  In  view  of  (4.45),  PB  =  [0,0,...,!]^  =  Be. 
Furthermore, 
AcP 
qA 
n-l 
qA 
qA^ 
PA. 
(4.46) 
where in the last row  of  A^P," the relation  -  X/^=o ^/^^  ^  ^""  was used  [which  is "
the Cay ley-Hamilton  Theorem, namely, a(A)  =  0]. 
EXAMPLE4.il.  Let A  = 
1 
0 
0 
0 
1 
0 
"0"" "
0 
- 2. 
and  B  = 
"""  1"" "
-1 
1. 
Since n  = 3 and 
l^-/ -  A|  =  (^ +  1)(5' -  l)(s + 2)  =  s^ +2s^ -  s -2,  {Ac, Be} in controller form is given 
281 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
by 
A,  = 
0 
0 
2 
1 
0 
1 
0 
1 
-2 
and 
Br  = 
The transformadon  matrix P that reduces  (A, B) to (Ac  =  PAP  ^,Bc  =  PB) is now 
derived. We have 
=  [B, AB, A^B] = 
, 1 -1 
n 
-1 
1 
-1 
-2 
and 
-1  _ 
1  -I 
2 
2 
The third (the nth) row of^  ^  is q  =  [-  ^, -  ^, ^], and therefore, 
P^ 
qA 
qA^ 
1 
2 
i 
2 
L 
i 
3 
2 
3 
4 
3  J 
It can now easily be verified that Ac  = PAP  ^ or 
AcP 
=  PA, 
and that  Be  =  P5.  [Verify  that  P^  = %c  is given by  (4.45)  and also compare with 
• 
Exercise 3.23, which explicitly derives ^cJ 
An alternative form  to (4.42) is 
-Oin-\ 
1 
Aci  = 
-ax 
0 
- ao 
0 
0 
••• 
1 
0 
^cl 
-
(4.47) 
which is obtained if the similarity transformation  matrix is taken to be 
"r^A^-i"" "
A 
P^  = 
qA 
(4.48) 
i.e., by reversing  the order of the rows of P in (4.44). The reader  should verify  this 
(see Exercise  3.25). 
282 
Linear Systems 
In the above, Ac is a companion matrix of the  form  0 
X 
"x"" "
0  and Br 
has  the  form  [0  0 . ..  1]^ or  [1  0 . ..  0]^,  respectively.  These  representations  are 
very  useful  when  studying  pole  assignment  via  state feedback  control  law  and  are 
used in the next  chapter. 
/ 
X  or 
'x 
/ 
"A companion  matrix  could  also be of the  form  ""0 "
/ 
x' 
X 
or  'x 
X 
"0"" "
/ 
(see  Section 
2.2) with the coefficients  -[ao,..., 
c^n-iV  in the last or the first column. It is shown 
here, for  completeness, how to determine  controller  forms  where Ac  are such  com 
panion matrices. In particular, if 
G2  =  Pi^  = 
[B,AB,... ,"A""-^5]  = "
"""0  ••• "
1 
••• 
0 
0 
- ao 
0 
••• 
1 
then 
Ac2 
=  Qi'^Qi 
= 
Also, if 
Bc2 
=  Q2'B  = 
Q3  =  P3' 
= 
"[ A "" ~ ' B", 
• 
.,Bl 
- a „ -i 
1 
"...  0"" "
then 
Ac3 
-  Q^'AQ^ 
= 
0 
0 
...  1 
...  0 
- ao 
Bc3 
=  Q^'B  = 
(4.49) 
(4.50) 
(4.51) 
(4.52) 
'1 
0 
0 
"""0 "
0 
1 
(Ac, Be)  in  (4.50)  and  (4.52)  are  also  in  controller  canonical  or  controllable  com 
panion  form.  (The reader  is encouraged  to verify  these expressions.  See also  Exer 
cise  3.25.)  We also  note that  if  the  structures  of Ac  and  Be  are  specified,  then P  is 
uniquely determined  (see Exercise 3.24). That is, given (A^ Be) in any of the above 
four  controllable  companion  forms,  P  is readily  uniquely  determined  in  each  case 
"by  P  =  ^ ^ ""^  assuming  that P  also  satisfies  PA^B  ^  A^Bc  (in view  of  Exercise "
3.24), which it does in the above four cases. If different  Be are desirable, then an ap 
propriate P can be found by the same formula. Note that ^  denotes the controllability 
matrix of (Ac, Be). 
EXAMPLE  4.12.  Let  A  = 
r -1 
0 
0 
0 
1 
0 
0 
0 
-2 
and 5  = 
, as in Example 4.11. AI-
temative controller forms can be derived for different P. In particular, if 
\qA^ 
(i)P  = P,  =  \ qA 
L q  J 
in Example 4.11), then 
1 
2 
1 
2 
1 
2 
1 
6 
1 
6 
1 
6 
4-1 
3 
2 
3 
1 
3-1 
as in (4.48) {%^ 
', and q were found 
"-2  1  2"" "
, 
1  0  0 
0  1  0_ 
Be 
- 
] 
1 
2 
1 
-2 
1 
6 
1 
6 
1 
6 
8 
3 
4 
3 
2 
3 
PiA, 
283 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
as  in  (4.47).  Note  that  in  the  present 
case  AciPi  = 
, as in 
(4.49). Then 
Bel  =  PiB. 
(ii) 22  =  ^  = 
""" 1 -1 "
-1 
-1 
. 1 -2 
"""0 "
1 
.0 
Ac2  = 
r 
-1 
4. 
0 
0 
1  -
"2"" "
1 
-2. 
> 
as in (4.50). 
(iii)e3  =  [A^B,AB,B]  = 
"""  1 "
-1 
4 
Ac3  = 
"""-2 "
1 
2 
-1 
-1 
-2 
1 
0 
0 
as in (4.52). Note that gsA^s  = 
-1 
-1 
. -8 
1 
-1 
4 
Bc2  =  Q2'B  = 
ri] 
0 
LOJ 
1] 
-1 
, as in (4.51). Then 
1. 
"0"" "
1 
0. 
"- 1"" "
-1 
- 2_ 
Bc3 
-
roi 
, 
0 
[ij 
=  AGs,  Q3Bc3  = 
"r  1"" "
-1 
L  1. 
= 
Multi-input  case  (m  >  I).  In  this  case  the  n  X mn  matrix  % given  in  (4.38) 
is not  square, and there  are typically  many  sets of n columns  of % that are  linearly 
independent  (rank%  =  n).  Depending  on which  columns  are  chosen  and  in  what 
order,  different  controller  forms  (controllable  companion  forms)  are  derived.  Note 
that  in  the  case  when  m  =  1,  four  different  controller  forms  were  derived,  even 
though there was only one set of n linearly independent columns. In the present case 
there  are  many  more  such  choices.  The  form  that  will  be  used  most  often  in  the 
following is a generalization of (A^ Be) given in (4.42), and this is the form that will 
be derived first. Other forms  will be discussed  as well. 
Let A  =  PAP~^  and B  =  PB,  where P is constructed  as follows:  consider 
=  [bu  ,,.,bm,  Ah,, 
. . ., Abn,,  . . ., A^-'b,, 
. . .,  A^-'bml 
(4.53) 
where the bi,.. 
.,bm  are the m columns of 5. Select, starting from the left and moving 
to the right,  the first n independent  columns  {rank  %  =  n). Reorder these  columns 
by  taking first Z?i, Ab\,  A^bi,  etc., until  all columns  involving  bi  have been  taken; 
then take Z?2, Ab2, etc., and lastly, take bm, Abm, etc., to obtain 
%  =  [bi,Abi,...,Af''-^bi,...,bm,-.^,Af^^-^bml 
(4.54) 
an n  X ^ matrix. The integer  ixi denotes the number of columns involving  bi in the 
set of the first n linearly independent columns found  in % when moving from  left  to 
right. 
DEFINITION  4.1.  The m integers  /Xj, /  =  1,..., m, are the controllability indices of 
the system,  and ^x = max fxt is called the controllability index of the system. Note that 
284 
Linear Systems 
E M/ 
and 
mil  >  n. 
(4.55) 
To illustrate the significance  of ^i, note that an alternative but equivalent  defini 
tion for  IX  is that  /x is the minimum integer k such that 
rank[B,AB,...,A''''B] 
= n. 
(4.56) 
Taking  this  view,  one  keeps  adding  blocks  B,  AB,  A^B,  etc.,  until  n  independent 
columns appear (from left to right) for the first time. It is then not difficult  to see that 
/x  =  max  fjLi. Alternatively,  jm  can be defined  as the least integer  such that 
rank  [B, AB,...,  A^'^B]  =  rank  [B, AB,..., 
A^B]. 
(4.57) 
Notice  that  in  (4.54)  all  columns  of B  are  always  present  since  rank  B  =  m. 
This  implies  also  that  /uLi  >  1 for  all  /. Notice  further  that  if  A^bi  is present,  then 
A^~^bi  must  also be present  in  (4.54). For  if  it were not, i.e.,  if  it were  dependent 
on the previous  columns in % and had been  eliminated,  then A^bt  would  also  have 
been dependent (write A^'^bi  as a linear combination of previous columns in ^  and 
premultiply by A to show this). Column A^^'bi is of course dependent on the previous 
ones. This relation can be expressed  explicitly  as 
m  mmiixuixj) 
A^'bt  =X 
y -i 
X 
k=i 
i-\ 
^iJkA'-'bj  +  X 
7 =1 
^ij^^'bj 
(4.58) 
Note  that  the  first  sum in  (4.58)  indicates  the dependence  of A^'bi  on the  linearly 
independent  columns  in  B, AB,.. 
.,A^''^B,  while  the  second  sum  shows  the  de 
pendence on the independent  columns in Af^'B  to the left  of A^'bi  (aijk  and pij  are 
appropriate reals). 
Now  define 
k 
a^  = XfJiu 
k  =  l,...,m, 
/ =  i 
(4.59) 
i.e., cTi  == fjLi, cr2  =  ^ll  +  fJi2y...,"  o""^  =  /xi  +  • • • +  ^tm  — ^'  Also", consider %~^ 
and let q^, where q^  G R^, k  =  1,...,  m, denote its akth  row, i.e., 
^ -1  =  [X, 
x,qY:-- :X,  X, qlV. 
(4.60) 
Next,  define 
qiA 
p^ 
(4.61) 
qmA 
[qmAf^' i -i 
285 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
It can now be shown that PAP  ^  =  Ac and  PB  =  B^ with 
Ac  =  [Aijl 
i,j  =  1,...,  m, 
0 
0 
X 
0 
0 
X 
Bi 
B2 
AH  = 
Aij 
and 
Be  = 
I 
f J L i -l 
Rf^iXf^i^  i  =  j^ 
X 
X 
R^^^'^J, i  #  j, 
X 
0  0 
Bi  = 
0 
0  1  X 
X 
J^^.,xm^  (4.62) 
where  the  1 in  the  last  row  of  Bi  occurs  at  the  /th  column  location,  /  =  1,...,  m, 
and  X denotes nonfixed  entries. Note that  Q  =  CP~^  does not have any particular 
structure. The expression (4.62) is a very useful  form (in control problems) and shall 
be referred  to  as the  controller form  of  the  system.  The  derivation  of  this  result  is 
discussed below. First, examples  are given to illustrate the procedure involved,  and 
then  some alternative expressions  and properties  are also  discussed. 
"EXAMPLE 4.13.  Given are A G R'''^'' and B E  R""""^""^ with (A", B) controllable and with 
rank B  = m. Let n  = 4 and m  = 2. Then there must be two controllability indices  ii\ 
and 1X2 such that n  = 4  =  Sf= i i^/  =  Mi + M2- Under these conditions, there are three 
possibilities: 
(i)  fii  =  2,  /X2  =  2, 
Ar  = 
All 
An 
A21  A22. 
(ii)  /xi  =  1,  /X2  =  3, 
0 
X 
0 
X 
1 
X 
0 
X 
: 
0 
:  X 
: 
0 
:  X 
0 
X 
1 
X 
Br  = 
Bi] 
Bi. 
0 
1 
0 
0 
0 
X 
0 
1 
X 
X
XX 
Ac  = 
0 
0 
1 
0 
0 
1 
X
XX 
"""  1 "
X  ' 
Br  = 
0 
0 
0 
0 
0 
1 
286 
Linear  Systems 
(iii)  ixx  =  3, /X.2 =  1, 
1 
0 
X 
0 
1 
X 
Ac 
X 
X 
Br  = 
"""0 "
0 
1 
"0"" "
0 
X 
0 
1 
It  is possible  to  write  Ac,  Be  in  a  systematic  and  perhaps  more  transparent  way. 
In  particular,  notice  that  Ac,  Be  in  (4.62)  can  be  expressed  as 
Ac  — Ac  +  t>cAyi 
B,  — 
Jjctjfyi, 
(4.63) 
where  Ac  ^  blockdiag 
[An,  A22,....  Amm\  with 
[o 
An  = 
//..-I 
0 
0  0-
•0 
Be  =  block  diag 
R^^^'K 
i  = 
\,..,,m 
and Am  G  R^^^  and  Bm  G  R^^^  are  some  appropriate  matrices  with  ^ ^^  ^ /x/  =  n. 
Note  that  the matrices  Ac,  Be  are  completely  determined  by  the m  controllability  in 
dices  iJLi,  i  =  1 , . . .,  m  (they  are  in  fact  in the  so-called  Brunovski  canonical  form— 
see  the  discussion  following  Lemma  4.8).  The  matrices  Am  and  Bm  consist  of  the 
(Tith, (T2th,...,  cr^th rows  of A^  (entries  denoted  by  X)  and  the  same rows  ofBc,  re 
spectively.  Note that Am  and  Bm  is that part  of the controllable  system  x  =  Ax  +  Bu 
that  can  be  altered  by  linear  state  feedback  u  =  Fx  +  Gv,  a  fact  that  will  be  used 
extensively  in  the  next  chapter. 
EXAMPLE  4.14.  Let  A  = 
troller form  (4.62), consider 
= 
[B,AB,A^B] 
1 
0 
2 
0 
1 
-1 
and  B  = 
"""0  r "
1  1 
.0  0. 
.  To  determine  the  con-
=  [bx,h2, Abu  Ab2, A^bx, A^b2\  = 
1 
0 
2 
where rank^  =  3  =  n, i.e., (A, B) is controllable. Searching from  left to right, the first 
three columns of ^  are selected  since they are linearly independent.  Then 
^  =  [bi, Abi,  Z72] - 
"ro  1  1"" "
1  0  1 
lo  2  OJ 
and the controllability  indices  are ^ci 
jjii  + iJi2  =  3  =  n, and 
2 and  ^2  =  1- Also, ai  =  /JLI  =  2 and (T2 
""" -1 "
0 
1 
1 
0 
0 
1 
2 
1 
2 
1 
2 
Notice that q\  =  [0, 0, \]  and q2  =  [1, 0, - 1 ], the second and third rows of ^ 
\  respec-
287 
tively. In view  of  (4.61),  P  = 
PAP~ 
q\A 
L  qi 
0 
2 
1 
ro 
0 
1  -
2 
1 
2 
1 
2-J 
,P~'  = 
"1  0  1"" "
1  1  0 
.2  0  0. 
and Ar  = 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
*c =  PB  = 
B{ 
B2\ 
— 
0 
1 
0 
0  ' 
1 
1 
One can also verify  (4.63) quite easily. We have 
Ar  +  BrAvy 
: 
: 
0 
0 
+ 
o] 
0 
1J 
0 
1 
0 
-1 
0 
and 
0 
1 
0 
"o"" "
1 
1 
0 
BcBtr 
0 
: 
"""o "
1 
0 
ol 
0 
0 
1J 
"ri  1"" "
[o  1. 
It is interesting to note that in this example, the given pair (A, B) could have already 
been  in  controller  form  if B  were  different,  but A  the  same. For  example,  consider  the 
following  three cases: 
'  1 
X 
0 
0 
0 
1 
0 
0 
1 
o' 
X 
1 
^x  = 
\,  1X2  =  2, 
/xi  =  2, ^1  =  1, 
1.  A  = 
B  = 
0 
0 
1 
0 
0 
1 
2.  A 
0 
2 
-1 
0 
0 
0 
1 
0 
0 
1 
2 -1 
3.  A  = 
B  = 
/^i 
Note that case 3 is the single-input  case (4.42). 
• 
Several results  involving  the controllability  indices  of  (A, B)  are now  presented. 
First,  it  is  shown  that  the  controllability  indices  /x/  of  a  system,  defined  in  Defini 
tion  4.1, do  not  change  under  similarity  transformations  [for  if  they  were  changing, 
then  (Ac,  Be)  might  have  different  controllability  indices  from  the  original  (A,  B)]. 
288 
Linear Systems 
In particular, let x  =  Ax  -\-  Buhe  given, where  (A, B)  is controllable, and  consider 
x  =  Ax  -i-  Bu,  where A  =  PAP~^,  B  =  PB,  x  =  Px,  and P is  nonsingular. 
LEMMA 4.8.  The controllability  indices  of  (A, B) are identical  to the  controllability 
indices of A =  PAP-\  B  =  PB. 
Proof. We have ^  =  [B, AB,...,  A^-^B]  =  p-^[B,  AB,...,  A^'^B]  =  p-^^. To de 
termine the controllability indices  /JLI of (A, B), the first n linearly independent columns 
of ^  are taken, working from left to right. It is clear that the corresponding n columns of 
^  will also be linearly independent, since they are the n columns of ^,  each premulti-
plied by P. Furthermore, as one checks linear dependence of columns in ^, from left to 
right, if a column is dependent on the previous ones, then the corresponding column in 
^  will also be dependent on the previous ones in ^  (show this). Therefore, the linearly 
independent columns generated by this left to right search are exactly the same in ^  and 
^,  and therefore, the controllability indices are identical. 
• 
Note  that  the  controllability  indices  of  (A, BG),  where  G  is  nonsingular,  are 
equal to the controllability indices /x/ of (A, B) within reordering (see Exercise 3.20). 
Note also that when  linear  state feedback  u  =  Fx  -\-  Gv  with  |G|  T^ 0 is applied  to 
X =  Ax  -^ Bu  (see Exercise 3.21), then the controllability  indices of (A +  BF,  BG) 
are equal  to the controllability  indices  of  (A, B),  i.e., the controllability  indices  are 
invariant under linear state feedback.  These results can be summarized  as  follows. 
Given  (A, B)  controllable,  then  (P(A  +  BGF)p-\  PBG)  will  have  the  same 
controllability  indices, within  reordering,  for  any P,  F,  and  G (\P\  T^ 0, \G\ T^  0) of 
appropriate dimensions. In other words, the controllability  indices  are invariant  un 
der similarity  and input transformations  P and G, and state feedback  F [or similarity 
transformation  P  and  state feedback  (F, G)]. Furthermore,  it can  be  shown  that  if 
two pairs (A/, Bt),  i  =  \, 2, have the same indices, then there must exist P, G, and F 
"such that Ai  =  P(A2+ ^2GF)P""^  and 5i  =  PB2G. This in fdidhXh^  completeness "
property,  which together  with the invariance property  implies  that the  controllabil 
ity  indices  {/x/}  constitute  a set  of  complete  invariants  for  (A, B)  under  operations 
P,  G, and F, Using  (4.63), it is not difficult  to see that given any  (A2, B2) with con 
trollability  indices {/x/}, there exist_P, G, F  such that Ai  =  P(A2  +  B2GF)P~^  and 
Bi  =  PB2G  are  exactly  equal  to  Ac  =  Ai, Be  =  B\.  The  pair  {Ac, Be)  is  unique, 
and  since  any  controllable  pair  (A, B)  with  controllability  indices  {^t/}  can  be  re 
duced  to  (Ac, Be)  by  these  operations,  {Ac, Be)  is  a  canonical  form  of  such  (A, B) 
under these operations. The pair {Ac, Be) is called the Brunovsky  canonical form.  It 
should  also be  mentioned  here  that  the {jUi}  are the right  Kronecker  indices  of  the 
pencil  [si  -  Ac, Be].  (Recall  that  [si  -  Ac, Be]  =  s[I, 0]  -  [Ac, -Be]  =  sE  -  A, 
a  matrix  form  called  a linear  matrix  pencil.)  The  derivation  of  A^, Be  in  (4.62)  is 
discussed  next. 
The exact  structure  of Ac  and  Be depends  on the  selection  of the n linearly  in 
dependent columns in % and on the choice of the equivalence transformation  matrix 
P.  The n linearly  independent  columns  in ^  were  selected by  a search from  left  to 
right; if a column  was found  dependent  on previous  ones, then it was dropped.  The 
dependence  relation  is  given  in  (4.58). This  relation,  together  with  the  expression 
for P  given in (4.61), are central in the derivation of A^, Be. 
In view of ^ - ^^  =  /, 
qt^  -  qi[bi,Ab,,...,Af'^-'bu-.-.A^^~'bi,...,bm.....A^--'b^] 
^^^^^ 
-  [0,...,  0, 1, 0 , . . .,  0], 
i  = 
l,...,m, 
289 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
where  the 1 occurs  at the cr^th column.  These  relations  can be written  as 
qtA^'^bi  =  0 
^  =  1 , . . .,  /x/ -  1, 
and 
qiA^^-'bi 
- 
I, 
(4.65) 
where /  =  1 , . . .,  m, and j  =  1 , . . .,  m. In view of (4.64), (4.65), and the dependence 
relations  (4.58), it can be shown that P^  is nonsingular,  which in view of the fact  that 
1^1 7^ 0  implies  that  \P\ T^ 0  as well,  i.e., P  qualifies  as a  similarity  transformation. 
We  note  that  the proof  of  this  result  is  rather  involved  (see Section  3.7, Notes,  for 
appropriate references). In view of the relationship  PA  =  AcP,  it is now not  difficult 
to  see  that  n  -  m  rows  of  Ac  will  contain  fixed  zeros  and  ones,  as  in  (4.62).  The 
(m)  (Tith,  cr2th,...,  cr^th  rows  of Ac  that  are denoted  by Am in (4.63)  are given by 
qiA^' 
^rn  — 
P-\ 
qmAf^^ 
(4.66) 
where  Ac  =  Ac  + Be Am.  Similarly,  in view  of the equality  Be  =  PB  and (4.63), it 
is  not difficult  to see that  n  -  m  rows  of Be  must  be zero. The (m) remaining  crith, 
0-2th,...,  amth  rows  of Be  that  are denoted  by Bm in (4.63)  are given  by 
qiA^'-^ 
Bm — 
B, 
qmA^^ 
(4.67) 
where  Be  =  BcB  The  matrix  Bm in  (4.67)  is, in  fact,  an  upper  triangular  matrix 
with  ones  on the diagonal.  This  result  follows  from  the special  form  of P^  that was 
used  above  to show  that P is  nonsingular. 
At  this  point  it may perhaps  be beneficial  to examine  a  special  case  that  is not 
only interesting but will  also provide  some indication  of the type of proof  required to 
establish  these  results.  In particular,  it will  be  shown  that  when  jui  <  ^l2 —  * *'  — 
fjLm, the upper  triangular  matrix  Bm in (4.67)  is in fact  diagonal. 
LEMMA  4.9.  If/Xi  <  ^l2 
diagonal, i.e., Bm  =  Im-
fjLm, then Bm in (4.67) is diagonal with ones on the 
Proof,  The matrix  Bm in  (4.67)  is  upper  triangular.  When,  in  addition,  /xi  <  )Li2  ^ 
•••  <  fjLm. then  qiAf^^-^B  -  ^iA^i-i[Z?i, Z?2, • •-, W  =  [1, 0 , . . .,  0], in viewof  (4.65); 
in particular,  qiA^^~^bi  =  1 and q\Af^^~^b2  =  0 since q\A^~^b2  =  0, k  =  1,..., JLXI, 
and  /xi  <  ^l2. Similar  statements  hold  for  the columns  bs, b^, ...ybm-  The proof  for 
^2^^2-15^..., qmA^^'^'^B is completely  analogous. 
• 
Note  that  if  different  relations  among  the controllability  indices  /x^ exist,  then 
different  entries  of Bm (above  the diagonal)  will be zero. 
EXAMPLE 4.15.  We wish to reduce A  = 
0 
0 
0 
1 
0 
2 
"0"" "
1 
- 1_ 
andB  = 
1  r 
0  1 
_0  0. 
to controller 
form.  Note  that A  and B are almost  the same  as in Example  4.14; however,  presently, 
1  <  2  =  /X2, as  will  be  seen.  We  have  %  =  [B, AB, A^B]  =  [bu bi, Abu 
Ml 
290 
Linear  Systems 
Abo 
1 
1 10 
0 
0  10 
0  0  0  2 
. Searching from  left  to right, the first three linearly in 
dependent columns are bi,  b2, Ab2 and ^  =  [bi, b2, Ab2]  = 
, from which we 
"1  1  1"" "
0  1  0 
0  0  2. 
[1  -1 
1 
0 
.0 
0 
-^1 
0 
|. 
conclude that jLii  =  1, fjL2  =  2,ai  =  1, and 0-2  =  3. We compute 
pute^^i  -
Note that  qi  =  [1, - 1, -  ^]  and  ^2  =  [0, 0,  ^],  the first and third  rows of ^ ~\  respec 
tively. Then 
p  = 
qi  ' 
qi 
qiA. 
-
"""1 "
0 
.0 
-1 
0 
1 
"""1 "
0 
.0 
2  r 
1  1 
2  0. 
Ac  =  PAP-^ 
A21 
^22 
Bi] 
= 
52J 
"""  1 "
"0 "" "
0 
0 
0 
1 
c  =  PB = 
and 
•1 
0 
0 
2 
qi 
qiA 
Presently,  (4.67)  yields  5^ 
B  and equals I2, as expected  in view  of the  above 
lemma  (JJLI <  1^2)- In general, Bm is an upper triangular  matrix. 
For the present example, we ask the reader to also verify  relations (4.65), determine 
• 
Am by (4.66), and compare these with the above results. 
In  the  case  of  single-input  systems,  m  =  1,  ^tl  =  n,  and  P  in  (4.61)  is  exactly 
the transformation  matrix given in (4.44)  (verify  this). In the case m  =  1, if the  order 
of rows in P is reversed  and  Pi  in (4.48) is used instead, then an alternative  controller 
form  is  obtained,  shown  in  (4.47).  Similar  results  apply  when  m>  1: if  the  order  of 
the  rows  of P  in  (4.61)  is reversed  within  the  fit  X  n  blocks,  then 
qi 
Pi 
(4.68) 
in  which  case  Ad  =  P\AP^  ^,Bc^  =  P\,  and  B  are  given  by 
Aci  =  [Aijl 
ij 
-  1 , . . .,  m, 
X 
0 
/?M,XM,^ j  =  j^ 
X 
0 
R^^iX^^j^  i  ^ 
j^ 
291 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
Aii  = 
X 
X 
V,-i 
Aij  = 
X 
0 
0 
"""fii "
and 
Bel  = 
Bi  = 
0 
0 
0 
•••  0  1  X 
•••  0  0  0 
•••  X 
••• 
0 
0  0  0 
0 
J^t^i 
(4.69) 
where  the  1 on  the  first  row  of  Hi occurs  at the  iih  (i  =  1,...,  m) location  and  X 
denotes nonfixed  entries. These formulas  are similar to (4.62) and can be derived in 
a completely  analogous  fashion. 
As  in  the  case  m  =  I  [see  (4.49)  to  (4.52)], the  columns  of  P~^  can  also  be 
selected to be n linearly independent columns of ^,  in which case A  =  PAP~^  and 
B  =  PB  will be in  alternative  controller  forms.  There  are many  ways  of  selecting 
these  n  linearly  independent  columns  of  the  n  X  nm  matrix  ^,  as  was  discussed 
before. For example, one may search ^  from left to right as above, or one may check 
for  linear  independence.  The  controller  forms  resulting  in 
bi, Abi,.. 
this way are generahzations of (4.50) and (4.52). These forms  are not as useful  to us 
and are omitted here. 
.,b2,  Ab2,... 
Structure  theorem—controllable  version.  The  transfer  function  matrix  H{s) 
of the system x  =  Ax  + Bu,  y  =  Cx  + Duis  given by H(s)  =  C(sl  -  Ay^B  +  D. 
If  (A, B)  is  in  controller form  (4.62), then  H{s)  can  alternatively  be  characterized 
by the  Structure  Theorem  stated  in Theorem  4.10. This result  is very  useful  in  the 
realization of systems, addressed in Chapter  5 and in the study of state feedback  in 
the next  chapter. 
Let  A  =  Ac  =  Ac  + Be Am and  B  =  Be  =  BcBm, as in  (4.63), with  | 5 ^| T^ 0 
and let C  =  Q  and D  =  Dc.  Define 
vf^l 
e ^2 
A W^ 
S(s)  =  block  diag 
1 
s 
/  — 1,..., m 
Note  that  S{s)  is  an  n  X  m  polynomial  matrix  (n  =  Xf^i  i^O. i-^.,  a matrix  with 
polynomials as entries. Now define the m X m polynomial matrix D(s)  and the /? X m 
polynomial matrix N(s)  by 
D(s)  ^  B-'[A(s) 
-  AmS(s)l 
N(s)  ^  CcS(s)  +  DeD(s). 
(4.71) 
The following  is the controllable version of the Structure  Theorem. 
(4.70) 
292 
Linear  Systems 
THEOREM  4.10.  H(s)  =  N(s)D~\s),  where N(s)  and D(s)  are defined  in (4.71). 
Proof,  First, note that 
(si  -  Ac)S(s)  =  BcD{s). 
(4.72) 
To see this, we  write  BcD{s)  =  BcBmB;;^^[A(s)  -  AmS(s)]  =  BcA(s)  -  BcAmS(s)  and 
(si  -  Ac)S(s)  =  sS(s)  -  (Ac  + BcAm)S(s)  =  (si  -  Ac)S(s)  -  BcAmS(s)  =  BcA(s) 
BcAmS(sXwhichpro\ts 
Dc  =  [CcS(s)  +  DcD(s)]D-\s)  =  N(s)D-\s). 
-
(4.72). NowH(s)  =  Cc(sl-  AcT^Bc  + Dc  =  CcS(s)D-\s)  + 
• 
EXAMPLE  4.16.  Let  Ar  = 
0 
2 -1 
1 
1 
0 
0 
0 
0. 
and  Be  = 
,  as  in  Example  4.14. 
"0"" "
0. y  Bm  —  \ 
r^^  0 
.ThenA(5)  =  r^ 
0 
s 
ro  01 
1  1 
[o  1. 
1  11 
0 
i j' 
Here  /JLI  =  2, iui2  =  I  and A^  = 
ri  01 
S(s)  =  \s 
0  , and 
ij 
LO 
D(s)  =  B-'[A(s)-A,nS(s)] 
2 
1 
-1 
0 
= 
1 
.0 
"""1.0 "
IJL 
-1 
Now  Cc  =  [0,1,1],  and Dc  =  [0, 0], 
N(s)  =  CcS(s)  +  DcD(s)  =  [s,  1], 
-s + 2  0 
0 
1 
I J [ LO 
S^ 
's^  + s -  I 
-1 
—s 
s 
and  H(s)  =  [s,l] 
5 ^ + 5 -1 
-1 
-1 
-
-s 
S 
=  [s,  1] 
s 
[I 
=  - j^ 
- [ 5^  +  1,2^^  +  5 - 1] 
s(s^  +  5 - 2) 
s 
1 
s^ + s  -  l\  s(s^  +  5 - 2) 
2 
EXAMPLE  4.17.  Let  Ac  = 
=  Cc(sl  -  AcY^Bc  +  Dc. 
"""0 "
0 
2 
1 
0 
1 
0 
1 
-2 
Be  = 
Cc  = 
[0,1,0], 
and Dc  =  0 (see Example 4.11). In the present case we have A^  =  [2,1, - 2 ], B^  =  1, 
A(5)  =  s\S(s)  =  [l,5,52]^,and 
D(s)  =  1 . [5^ -  [2,1, -2][1,  5, s^f]  =  5^ +  2 5 ^ - 5 - 2, 
N(s)  = 5. 
Then 
H(s)  = 
N(s)D-\s) 
+  2 5 ^ - 5 -2 
=  Cc(sl  -  AcT^Bc  +  Dc. 
2.  Observer  forms 
Consider  the  system  x  =  Ax  +  Bu,  y  =  Cx  -\-  Du  given  in  (4.1)  and  assume 
that  (A,  C)  is  observable,  i.e.,  rankG  =  n,  where 
C 
CA 
CA' n-\ 
(4.73) 
293 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
Also, assume that the p  X n matrix  C has a full  row rank p,  i.e., 
rankC  =  p  ^  n. 
(4.74) 
Presently,  it  is  of  interest  to  determine  a  transformation  matrix  P  so  that  the 
equivalent  system representation  {A^, Bo, Co, Do} with 
Ao 
PAP~\ 
Bo  =  PB, 
Co  =  CP~\ 
Do  =  D 
(4.75) 
will  have  {Ao, Co)  in  an  observer  form  (defined  below).  As  will  become  clear 
in  the  following,  these  forms  are  dual  to  the  controller  forms  previously  dis 
cussed  and  can  be  derived  by  taking  advantage  of  this  fact.  In  particular,  let 
A  ^  A^  ,B  =  C^  [(A, B)  is controllable]  and  determine  a nonsingular  transforma 
tion  P  so that Ac  =  PAP~^,  Be  =  PB  are in controller form  given in (4.62). Then 
Ao  =  A^  and  Co  =  B^  is in observer form.  In fact the equivalent representation  in 
this case is given by (4.75), where  P  =  (P^)~^  (show this). 
It will be demonstrated  in the following  how to obtain observer  forms  directly, 
in a way that parallels the approach described  for  controller forms.  This is done  for 
the  sake  of  completeness  and  to define  the  observability  indices.  Our  presentation 
will  be  rather  brief.  The  approach  of  using  duality just  given  can  be  used  in  each 
case to verify  the results. 
We first note that if  rank C  =  r  <  /?, an approach  analogous  to the case  when 
rank B  <  m can be followed,  as above. The fact  that the rows  of  C are not  linearly 
independent means that the same information  can be extracted from  only  r outputs, 
and  therefore,  the  choice  for  the  outputs  should  perhaps  be  reconsidered.  Now  if 
(A, C) is unobservable, one may use two steps to first isolate the observable part and 
then reduce it to the observer form,  in an analogous  way to the uncontrollable  case 
previously  given. 
Single-output  case  (p  =  I).  Let 
p -i  =  (2  A 
[q^Aq,...,A''-^q], 
(4.76) 
where q is the ^th column in 0~^  Then 
An  = 
0 
0 
1 
-ao 
-ai 
-OCn-\ 
Co  =  [0,...,0,1L 
(4.77) 
where  the  at  denote  the  coefficients  of  the  characteristic  polynomial  a(s)  = 
"=  ^^ + a:„-i^'^""i + ---+ai^ + ao.HereA^  =  PAP'^  =  Q~^AQXo  = "
det(sI-A) 
CP'  ^  =  CQ,  and the desired result can be established by using a proof that is com 
pletely  analogous  to  the  proof  in  determining  the  (dual)  controller  form  presented 
earlier  in  this  section.  Note  that  Bo  =  PB  does  not  have  any  particular  structure. 
The representation  {Ao, Bo, Co, Do} will  be referred  to  as the  observer form  of  the 
system. 
Reversing the order of columns in P~ ^ given in (4.76) or selecting P to be exactly 
0, or to be equal to the matrix obtained after  the order of the columns in 0 has been 
reversed, leads to alternative observer forms  in a manner analogous to the controller 
form case. We leave it to the reader to investigate these possibilities  further. 
294 
Linear Systems 
EXAMPLE  4.18.  Let  A 
-1 
0 
0 
0 
0 
1 
0 
0 -2 
and  C  =  [1, -1,1].  To derive  the ob 
server form (4.77), we could use duality, by defining  A  = A^,  B  =  C^, and deriving 
the controller form of A, B, i.e., by following the procedure outlined above. This is left to 
the reader as an exercise. We note that the A, B are exactly the matrices given in Exam 
ples 4.11 and 4.12. In the following the observer form is derived directly. In particular, 
we have 
c 
CA 
CA\ 
= 
""" 1 -1 "
-1 
-1 
. 1 -1 
"1"" "
-2 
4. 
, 
0-1  = 
1 
1 
3 
.-1 
- 1 
2 
1 
2 
0 
1 
2 
1 
6 
1 
3 
and in view of (4.76), 
.76), 
Q  =  p -i  =  [q^Aq^A^q]  = 
r 
L 
1 
2 
1 
6 
1 
3 
1 
2 
1 
6 
2 
3 
1  1 
2 
1 
6 
4 
3  J 
Note that q = 
I  I 
6'  3 
," the last column of 0""^. Then "
Ao  =  Q-'AQ  = 
0 
0 
1 
2 
1 
-2 
and 
Co =  CQ  =  [0, 0,1], 
where l^-/ -  A|  = s^ + 2s -  s -  2  = s^ -{- a2S^  + ais  + ao. Hence, 
GA.  = 
ii 
2 
i 
6  =  AQ. 
Multi-output  case  (p  >  1).  Consider 
C 
CA 
CA « -i 
ci 
ciA 
CpA 
ciA « -i 
LCpA'^-
(4.78) 
where  c\,.. 
.,Cp  denote thep  rows of  C, and  select the first n linearly  independent 
rows in 0,  moving  from  the top to bottom  (rank €  =  n). Next, reorder the  selected 
rows by first taking all rows involving  ci, then  C2, etc., to obtain 
c\A 
ciA  v^-l 
295 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
(4.79) 
Sin  n  X  n matrix. The integer  Vi denotes  the number  of rows involving  c/ in the  set 
of the first n Unearly independent rows found in 0 when moving from top to bottom. 
DEFINITION 4.2.  The/? integers vt, i  =  1,..., p, are the observability indices of the 
system, and v  = max Vi is called the observability index of the system. Note that 
Y^Vi  = n 
and 
pv  ^  n. 
(4.80) 
When  rankC  =  p,  then  ^/  >  1. Now  define 
k 
d-k =^Pi 
/ -I 
k  =  I, 
A 
(4.81) 
i.e., (Ti  =  1^1," (T2  =  v\  -}- V2y' ""y^p  =  v\  +  '""  -\- Vp  =  n.  Consider  0  ^ and  let "
qk  E  R^,  k  =  1,..., /?, represent its or^th column, i.e., 
g-i  =  [X---  X^il  X •••  Xg2|**-| X •••  X qpl 
(4.82) 
Define 
P-'  =  Q=  [qi,...,A-^-'q,,...,qp,.,,,A^p-'qpl 
(4.83) 
ThenA^  =  PAP'^  =  Q-^AQmdCo 
=  CP~^  =  CQ are given by 
Ao  =  [Aijl  i,j=\,..., 
p, 
0 
•••  0  X 
An  = 
/^^^•^^/  =  7,  Aij  = 
X 
0 
X 
0 
X 
/^^'•><^^/#y, 
and 
Co  -  [Cl, C2,...,  Cp], Ci — 
ro  •• 
0 
0 
0 
0 
0 
1 
0  X 
0  X 
J^p-XVi 
(4.84) 
where  the  1 on the  last  column  of  C/  occurs  at the  /th-row  location  (/  =  \,..., 
p) 
and  X denotes  nonfixed  entries. Note  that  the  matrix  BQ  =  PB  =  Q~^B  does  not 
296 
Linear Systems 
have any particular  structure. Equation  (4.84) is a very useful  form  (in the observer 
problem)  and shall be referred  to as the observer form  of the  system. 
Analogous to (4.63), we express  AQ  and  Co as 
/\.o 
^o 
'  ^p^O) 
^o 
^p^oy 
(4.85) 
where  Ao  =  blockdiag  [A\, A2,...,  Ap\  with  A/  = 
RVi^^Vi^  C^  = 
0 
•• 
0 
e  7?^s/ 
=  1,..., ;?)," and Ap  G T?""^^", and Cp G  RP'^P  are 
block  diag {[0,...,0,lY 
appropriate matrices (Xf= 1  ^/  =  ^). Note that AQ,  CO are completely determined by 
the/? observability indices  ^'/, /  =  I,...,  p,  and A^ and Cp contain this  information 
in the o-ith,...,  or^th columns  of Ao  and  in the  same  columns  of  Co, respectively. 
Note also that Ap is that part of the observable system i  =  Ax + Bu,  y  =  Cx^-  Du 
that  can  be  altered  by  the  gain  of  a  state  observer.  This  is  discussed  further  in  the 
next  chapter. 
Results  that  are  in  the  spirit  of  Lemmas  4.8  and  4.9  also  exist  and  can  be  es 
tablished directly in a completely  analogous  way or by duality. The same is true  for 
proving that Q in (4.83) is nonsingular  and that Ao  and  Co in (4.84) have their par 
ticular structure. Furthermore, by reversing the order of the columns of P~^ in (4.83) 
or by selecting the columns of P directly from 0, one can derive alternative observer 
forms.  These are dual to the controller forms  discussed  before. 
EXAMPLE  4.19.  Given  A  =1 
0 
ro 
0 
01 
LO 
1 
andC  = 
2 
- ij 
"""0  1  0"" "
1  1  0_ 
we wish to reduce 
these to observer form. This can be accomplished using duality, i.e., by first reducing 
A =  A^, 5  =  C^ to controller form. Note that A, B are the matrices used in Example 
4.14, and therefore, the desired answer is easily obtained. Presently, we shall follow the 
direct algorithm described above. We have 
C 
CA 
CA^ 
0 
1 
1 
1 
0 
0 
1 
1 
0 
0 
2 
2 
0 
0 
2 
2 
-2 
-2 
Searching from top to bottom, the first three linearly independent rows are ci, C2, c\A, 
and 
'  ci  ' 
c\A 
.  C2 
. 
= 
"""0  1  0"" "
1  0  2 
.1  1  0. 
Note that the observability indices are z^i =  2, z^2 =  lando-i  ==  2,0-2  =  3. We compute 
Then,  Q  =  [qi,  Aqi,  ^2] 
a n d g -i  = 
r 
0 
1 
2  J 
"""X  0 "
X  0 
= 
"1"" "
0 
L^ 
2 
2^ 
T 
"1  2"" "
0  1  0 
.1  0  0. 
. Therefore, 
2 
-1 
0 
1 
0 
1 :0 
1 :1 
297 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
+ 
0 
0 
0 
"""  2  11 "
-1  0 
0  Oj 
ro  1  0' 
[o  0  1. 
Ao  = Q-'AQ  = 
All 
All, 
0 
0 
0 
1 
0 
0 
Co = CQ  =  [Ci 
:  Ci\  = 
We can also verify  (4.85), namely, 
0 
1 
2 
-1 
0 
0 
0  1 
0  1 
: 
: 
Ao 
and 
Co  = 
—  Ao + ApC^o 
0 
0 
^  p^o 
1  0 
1  1 
0  1  0 
0  0  1 
Structure  Theorem—observable  version.  The transfer function  matrix H{s)  of 
systemi  =  Ax + Bu,y  =  Cx + Duisgiytnhy  H{s)  = 
C(sI-A)~^B-^D,lf(A,C) 
is in the observer form,  given in (4.84), then H(s)  can alternatively be characterized 
by the Structure Theorem  stated in Theorem 4.11. This result will be very useful  in 
the realization of systems, addressed in Chapter 5 and also in the study of observers 
in the next  chapter. 
Let A  =  Ao  =  Ao + ApCo  and C  =  Co  =  CpCo as in (4.85) v^ith \Cp\ #  0, let 
B  =  Bo and D  =  Do, and  define 
A(^)  =  diag  [^^S s''^  . . .,  s^'p],  S(s)  =  block  diag  ([1, ^,...,"  s""""^'^]", /  =  1,..., p). 
(4.86) 
Note that S{s)  is  a p  X  n polynomial  matrix,  where  n  =  ^f^^vi.  Now  define  the 
pX  p  polynomial matrix D(s)  and the p  X  m polynomial matrix N(s)  as 
D(s)  ^  [Ms)  -  S(s)Ap]Cp 
N(s)  =  S(s)Bo  +  D(s)Do. 
(4.87) 
The  following  result  is  the  observable  version  of  the  Structure  Theorem.  It  is  the 
dual  of  Theorem  4.10  and  can  therefore  be  proved  using  duality  arguments.  The 
proof given is direct. 
THEOREM4.il.  H{s)  = D~H^)^('y), where 7V(5), 6(5) are defined in (4.87). 
Proof, First we note that 
b{s)Co  = S(s){sl -  Aol 
(4.88) 
To see this, write D(5)Co  =  [A(s)-S(s)Ap]C-^CpCo  = A(5)C^-5^(>y)A^Co, and also, 
S(s)(sl  -  Ao)  = S(s)s -  S(s)(Ao + ApCo) = S(s)(sl  -  Ao) -  S(s)ApCo =  A(^)C.  -
S(s)ApCo, which  proves  (4.88). We now  obtain  H{s)  =  Co{sI -  Ao)~'^Bo  + Do = 
D-\s)S(s)Bo  + Do = D~\s)[S(s)Bo  + D(s)Do] = D-\s)N(s), 
• 
298 
Linear  Systems 
EXAMPLE  4.20.  Consider A^  = 
0 
1 
0 
2 
-1 
0 
and  Co  = 
0  1  0 
0  1  1 
of Example 
4.19. Here  z^i  =  2,  1^2  =  I,  Ms)  = 
s^  0 
0 
s 
, and S{s)  = 
[A(s)  -  S(s)Ap]C-' 
0 
s 
1  5  0 
0  0  1 
-s  + 2 
0 
i 
0 
1  0 
-1  1 
"s""-  +  s-"
- 2 -1 
0 
2  1 
-1  0 
0  0. 
1  0 
1 
-1 
1 
s  0 
0  0  1 
1-1 
1  0 
1  1 
. Then D{s)  = 
's^  01 
0 
s 
's'^  +  s -\ 
-1 
Now if  Bo  =  [0, 1, 1]^, Do  =  0, and A^(^)  =  S(s)Bo  +  D(s)Do  =  [s, if, 
D-\s)N(s)  =  {l/[s(s^  + s-  2)]}[s^ +  h2s^  + s- 
If  =  Co(sI  -  AoT^Bo  +  Do. 
then H(s)  = 
• 
3.5 
P O L ES  A ND  Z E R OS 
In  this  section  the  poles  and  zeros  of  a  time-invariant  system  are  defined  and  dis 
cussed.  The  primary  reason  for  considering  poles  and  zeros  of  a  system  at  this  time 
is  that  poles  and  zeros  are  related  to  the  (controllable  and  observable,  resp.,  uncon 
trollable  and  unobservable)  eigenvalues  of A.  These  relationships  shed  light  on  the 
eigenvalue  cancellation  mechanisms  encountered  when  input-output  relations,  such 
as  transfer  functions,  are  formed.  These  relationships  also  provide  greater  insight 
into the realization theory  addressed  later in this book. Furthermore, the  relationships 
between  uncontrollable  or unobservable  eigenvalues,  decoupling  zeros,  and  cancel 
lations in the transfer  function  matrix to be discussed  below, provide  also insight  into 
how  state feedback  can  alter  system behavior.  State feedback  will be  studied  later  in 
Chapter  4. 
In the following  development,  the fmio^ poles  of  a  transfer  function  matrix  H(s) 
[or  H(z)]  are  defined  first  (for  the  definition  of  poles  at  infinity,  refer  to  Exercise 
3.36). It should be noted here that the eigenvalues  of A are  sometimes  called  poles  of 
the  system  {A,  B,  C, D}.  To  avoid  confusion,  we  shall  use  the  complete  itrxn. poles  of 
H(s),  when  necessary.  The  zeros  of  a  system  are  defined  using  internal  descriptions 
(state-space  representations). 
Smith  and  Smith-McMillan  forms 
To define  the  poles  of H(s),  we  shall  first  introduce  the  Smith  form  of  a  polyno 
mial  matrix  P(s)  and  the  Smith-McMillan  form  of  a rational  matrix  H(s). 
The  Smith  form  Sp(s)  of  a p  X  m  polynomial  matrix  P(s)  (in  which  the  entries 
are  polynomials  in  s)  is  defined  as  (see  also  Subsection  7.2C  of  Chapter  7) 
Sp(s)  = 
'A(s) 
0 
(5.1) 
er(s)],  where  r  =  rank  P(s).  The  unique  monic  poly 
with  A(^)  =  diag  [ei(s),..., 
nomials  €i(s)  (polynomials  with  leading  coefficient  equal  to  one)  are  the 
invariant 
factors  of  P(s).  It can be  shown  that ei(s)  divides  e/+i(5'),  /  =  1 , . . .,  r  -  1. Note  that 
299 
CHAPTERS: 
Controllability, 
Observability, 
and Special 
Forms 
€i(s) can be determined  by 
ei(s)  = 
Di(s) 
i  =  1,  ...,r, 
where Di(s) is the monic greatest common divisor of all the nonzero /th-order minors 
"of P(s)  with Do(s)  =  1. The Di(s)  are the determinantal  divisors  of ^(5""). A matrix "
P{s)  can be reduced  to Smith  form  by  elementary  row  and  column  operations  (see 
Subsections  7.2B  and  C  in  Chapter  7). This  ensures  that  the properties  of  interest 
are preserved  when P{s) is reduced to its (unique) Smith form. In particular, we are 
interested here in the invariant factors  ei{s)  of P{s)  that can be determined  directly 
from the determinantal divisors Di{s) without having to reduce P{s) to its Smith form 
via elementary  operations. 
Consider now a /? X m rational matrix H{s).  Let d{s) be the monic least common 
denominator of all nonzero entries and write 
1 
Ks) N{s), 
H{s) 
(5.2) 
where N{s)  is a polynomial matrix. Let SN{S)  =  diag  [ni(s\  . . .,  nr(s), Op-r,m-r] be 
the  Smith  form  of  N(s),  where  r  =  rank  N(s)  =  rank  H(s).  Divide  each  nds)  of 
SN(S)  by d(s),  cancelling  all common factors  to obtain the Smith-McMillan  form of 
H(s), 
SMH(S) 
= 
'A(s)  0 
0 
0 
(5.3) 
with  A(s)  =  diag  [e\(s)/ilji(s),.. 
ei(s)  divides  ei+i(s),  i  =  \,2,.. 
r-  1. 
.,er(s)/il/r(s)],  where  r  =  rank  H(s).  Note  that 
.,r  ~  I,  and  if/i+iis)  divides  iptis),  i  = 
\,2,..., 
Poles 
Given a. pX  m rational matrix H(s),  its characteristic  polynomial  or pole  poly 
nomial,  PH(S),  is defined  as 
PH(S)  = 
"il/i(sy""il/r(s\ "
(5.4) 
where  the  i///,  /  =  1,...,  r,  are  the  denominators  of  the  Smith-McMillan  form  of 
H(s).  It  can  be  shown  that  PH(S) is  the  monic  least  common  denominator  of  all 
nonzero minors of  H(s). 
DEFINITION 5.1.  The poles ofH(s)  are the roots of the pole polynomial PH(S). 
• 
Note that the monic least common denominator of all nonzero first-order minors 
(entries) of H(s)  is called the minimal polynomial  of H(s)  and is denoted by  mnis). 
The  mH(s)  divides  PH(S) and  when  the roots  of  PH(S)  [poles  of H(s)]  are  distinct, 
J^H(S)  =  PH(S),  since the additional roots in  PH(S)  are repeated roots of  mnis). 
It is important to note that when the minors of H(s)  [of order 1,2,  . . ., min (p, m)] 
are formed by taking the determinants of all square submatrices of dimension  1 x 1, 
2 x 2,  etc., all cancellations of common factors between numerator and denominator 
polynomials  should be carried  out. 
In the  scalar case, p  =  m  =  1, Definition  5.1  reduces  to the well-known  def 
inition  of  poles  of  a  transfer  function  H(s),  since  in  this  case  there  is  only  one 
300 
Linear Systems 
minor (of order 1), H(s),  and the poles are the roots of the denominator polynomial of 
H{s).  Notice that in the present case it is assumed that all the possible  cancellations 
have taken place in the transfer  function  of a system. Here PH(S)  =  mnis),  that is, 
the pole or characteristic polynomial equals the minimal polynomial  of H(s).  Thus, 
PH(S)  =  ^H(S)  are equal to the (monic) denominator of 77(5'). 
EXAMPLE  5.1.  Let  H(s) 
[l/[^(^ +  1)]  1/^ 
^ 
' 
0 
^ 
0 
1  1  ^, 
^ / 9 • The nonzero minors of order 
l/s^j 
^ 
. 
, 
1  are the nonzero entries. The least  common  denominator  is 5'^(^ +  1)  =  mnis),  the 
minimal polynomial of H(s). The nonzero minors of order 2 are l/[s^(s +1)]  and 1/^-^ 
(taking columns 1  and 3, and 2 and 3, respectively). The least common denominator of 
all minors (of order 1 and 2) is s^(s + 1)  =  PH(S),  the characteristic polynomial of H(s). 
The poles are {0, 0, 0, -1}. Note that mnis) is a factor of PH(S) and the additional root at 
5 =  0 in PH(S) is a repeated pole. 
To obtain the Smith-McMillan form of H(s), write 
H(s) 
1 
sHs + 1) 
s(s + 1) 
0 
s\s  + 1) 
(s + 1) 
1 
d(i) 
N(sl 
where d(s)  = s^(s +  1)  =  fnnis) [see (5.2)]. The Smith form of N(s) is 
SN(S)  = 
0 
1 
0 
0  s{s +  1)  0 
since Do  =  I, Di  ==  I, D2 = s{s -\-  I)  [the determinantal divisors of A^(5)], and ni  = 
DJDQ  =  l,n2  = D2/D1  = s(s + 1), the invariant factors of N(s). Dividing by d(s), we 
obtain the Smith-McMillan form of H(s), 
SMH(S)  = 
el 
h 
0 
0 
51 
i//2 
1 
sHs + 1) 
0 
0 
1 
0 
0 
Note that 1/^2 divides ij/i  and ei  divides €2. Now the characteristic or pole polynomial of 
H{s) is PH(S)  = il^iil^i  = s^(s -\-  1) and the poles are {0, 0, 0,-1}, as expected. 
• 
1 
s + 2 
EXAMPLE  5.2.  Let  H(s)  = 
If a  7^  1, then the second-order minor is 
1^(^)1 =  (1 -  a)/(s + 2)^. The least common denominator of this nonzero second-order 
minor \H(s)\  and of all the entries of H(s) (the first-order  minors) is (s + 2)^  =  PH(S), 
i.e., the poles are at {-2,  -2}. Also, mnis)  = s + 2. 
Now  if  a  =  1, then  there  are  only first-order nonzero  minors  (\H(s)\ =  0). In 
this case PH(S)  = mnis)  = S + 2, which is quite different  from the case when a  7^ 1. 
Presently, there is only one pole at - 2. The reader should verify these results, using the 
Smith-McMillan form of H(s). 
m 
In  view  of  Subsection  3.4.C,  it  is  clear  that  all  the  poles  of  H(s)  are  roots  of 
l^/ -  All |, that is, they are some or all of the controllable and observable  eigenvalues 
of the  system. In fact,  as will be  shown in Chapter  5, the poles of H(s)  are  exactly 
the controllable and observable eigenvalues of the system (in An)  and no factors of 
l^-/ -  All I  in H(s)  cancel. 
In general, for the set of poles of H(s)  and the eigenvalues of A, we have 
{poles of H(s)}  C  {eigenvalues of A} 
(5.5) 
with equality holding when all the eigenvalues of A are controllable and  observable 
eigenvalues of the system. Similar results hold for discrete-time  systems and  H(z). 
EXAMPLE 5.3.  Consider A 
ro 
1 
[o 
-1 
-2 
11 
1 
1  -ij 
,B  = 
"1  0"" "
1  1 
.1  2. 
and C  =  [0, 1, 0]  (refer 
to Example 4.6 in Section 3.5). Then the transfer  function  H(s)  =  [l/s, l/s]. H(s) has 
only one pole, ^i  =  0(PH(S)  = s), and Ai  =  0, is the only controllable and observable 
eigenvalue. The other two eigenvalues of A, A2 =  - 1,  A3 =  - 2, that are not both con 
• 
trollable and observable, do not appear as poles of H(s). 
301 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
EXAMPLE 5.4.  Recall the circuit in Example 4.9 in Section 3.4. If R1R2C ¥^  L, then 
{poles of//(5')}  =  {eigenvalues of A at Ai  =  -\I{R\C)  and A2 =  -R^II^.  In this case, 
both eigenvalues  are controllable  and observable. Now if  R1R2C = L with Ri 7^  R2, 
then H(s) has only one pole, ^i  =  -R2IL,  since in this case only one eigenvalue Ai  = 
-R2/L  is  controllable  and  observable.  The  other  eigenvalue  A2 at the  same location 
-R2IL  is uncontrollable  and unobservable. Now if  R\R2C  =  L with  Ri  =  R2 =  R, 
then one of the eigenvalues becomes uncontrollable  and the other (also at  -RIL)  be 
comes unobservable. In this case H{s) has no finite poles {H{s) =  \IR). 
• 
Zeros 
In  a  scalar  transfer  function  H{s)  the roots  of  the  denominator  polynomial  are 
the poles,  and  the roots  of  its numerator  polynomial  are the  zeros  of H{s).  As  was 
discussed, iht  poles  ofH{s)  are some or all of the eigenvalues of A (the eigenvalues 
of A are sometimes also cdlXtd poles  of the system  {A, B, C, D}). In particular, it v^as 
shown in Subsection  3.4.C  that the uncontrollable  and/or unobservable  eigenvalues 
of A can never be poles of H(s).  In Chapter 5 it is shown that only those eigenvalues 
of A that are both controllable and observable appear as poles of the transfer  function 
H(s).  Along similar lines, the zeros ofH(s)  (to be defined later) are some or all of the 
characteristic values of another matrix, the system matrix P(s).  These  characteristic 
values are called the zeros  of the system  {A, B, C, D]. 
The  zeros  of  a  system  for  both  the  continuous-  and  discrete-time  case  are  de 
fined and discussed next. We consider now only finite zeros. For the case of zeros at 
infinity,  refer  to the exercises. 
Let  the system  matrix  (also  called Rosenbrock's  system  matrix)  of {A, B, C, D] 
be 
P{s)^ 
si  -  A 
-C 
B 
D 
(5.6) 
Note that in view of the system equations  x 
Ax  +  Bu,  y 
Cx  +  Du,  we have 
P(s)  -x(s) 
U(s) 
0 
where x(s)  denotes the Laplace transform  of  x(t). 
Let r  =  rank P(s)  [note that n  ^  r  ^  min (p-\-n,m-\-  n)] and consider all those 
rth-order  nonzero  minors  of  P(s)  that  are  formed  by  taking  the  first  n rows  and  n 
columns  of  P(s),  i.e., all rows and columns  of 5'/ -  A, and then  adding  appropriate 
r  -  n rows  (of  [-C,  D])  and  columns  (of  [B^, D^Y).  The  zero polynomial  of  the 
system  {A, B, C, Z)},  zp{s),  is  defined  as  the  monic  greatest  common  divisor  of  all 
these minors. 
DEFINITION5.2.  The zeros of the system {A, B, C, D} or the system zeros are the roots 
of the zero polynomial of the system, zp(s). 
• 
302 
Linear Systems 
In  addition,  we  define  tlie  invariant  zeros  of  the  system  as  tlie  roots  of  tlie 
invariant polynomials of  P{s). 
In particular, consider the  (p + n)  x  (m + n)  system matrix P{s)  and let 
Sp{s) 
"'A{s)  0"" "
0 
0 
A(^) =  diag[ei (^),..., e^(^)], 
(5.7) 
be its Smith form. The invariant zero polynomial  of the system  {A,  5, C, D}  is defined 
as 
(5.8) 
and  its  roots  are  the  invariant  zeros  of  the  system.  It  can  be  shown  that  the  monic 
greatest common divisor of all the highest order nonzero minors of P(^) equals Zp{s). 
Z^p{s) =  ei{s)e2{s)---er{s) 
In general, 
{zeros of the system} D {invariant zeros of the system}. 
When  p  =  m  with  det  P{s)  ^  0,  then  the  zeros  of  the  system  coincide  with  the 
invariant zeros. 
Now  consider  the  nx  {m-\-n)  matrix  [si — A,B]  and  determine  its  n  invariant 
factors  e/(^)  and its Smith form.  The product of its invariant factors  is a polynomial, 
the  roots  of  which  are  the  input-decoupling  zeros  of  the  system  {A,5,C,D}.  Note 
that  this  polynomial  equals  the  monic  greatest  common  divisor  of  all  the  highest 
order nonzero minors  (of  order n) of  [si — A,B].  Similarly,  consider  the  {p-\-n)  xn 
\sl  —  A\ 
matrix 
decoupling  zeros of the system  {A,5,C,D}. 
^ 
and its invariant polynomials, the roots  of which define  the  output-
Using  the  above definitions  it is not difficult  to  show that the  input-decoupling 
zeros  of  the  system  are  eigenvalues  of  A  and  also  zeros  of  the  system  {A,5,C,D} 
(show  this).  In  addition  note  that  if  A/  is  such  an  input-decoupling  zero,  then 
rank  [A// —A,5]  <  n,  and  therefore,  there  exists  a  1 x  n  vector  v/  ^  0  such  that 
v/[A// —A,5]  =  0. This, however, implies that A/  is an uncontrollable eigenvalue of A 
(and Vi is the corresponding left eigenvector), in view of Subsection 3.4B. Conversely, 
it can be shown that an uncontrollable eigenvalue is an input-decoupling  zero. There 
fore,  the  input-decoupling  zeros  of  the  system  {A,5,C,D}  are  the  uncontrollable 
eigenvalues  of A.  Similarly,  it can be  shown that the output-decoupling  zeros  of the 
system  {A,5,C,D} are the unobservable  eigenvalues of A.  They are also zeros of the 
system, as can easily be seen from  the  definitions. 
There are eigenvalues of A that are both uncontrollable and unobservable. These 
can be  determined  using  the left  and right  corresponding  eigenvector  test  or by  the 
Canonical  Structure  Theorem  (Kalman  Decomposition  Theorem)  (see  Subsections 
3.4A and B).  These uncontrollable and unobservable eigenvalues of A are zeros of the 
system that are both input-  and output-decoupling  zeros  and are called  input-output 
decoupling  zeros.  These input-output  decoupling  zeros  can  also be defined  directly 
from P{s)  given in (5.6); however, care should be taken in the case of repeated zeros. 
If  the  zeros  of  a  system  are  determined  and  the  zeros  that  are  input-  and/or 
output-decoupling  zeros  are  removed,  then  the  zeros  that  remain  are  the  zeros  of 
H{s)  and can be found  directly  from  the transfer  function  II{s).  In particular,  if  the 
Smith-McMillan  form  of H{s)  is given by (5.3), then 
"ZH{S)  =ei{s)e2{s)""'er{s) "
(5.9) 
is  the  zero polynomial  of  H(s)  and  its  roots  are  the  zeros  of  H(s).  These  are  also 
called the transmission  zeros  of the  system. 
DEFINITION  5.3.  The zeros of H(s) or the transmission zeros of the system are the 
roots of the zero polynomial of H(s), ZH(S)' 
• 
The relationship between the zeros of the system and the zeros of H(s)  can easily 
be determined using the identity 
303 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
P(s)  = 
si 
-A 
B 
-C  D 
si 
-A 
-C 
(si  -  A)-
H(s) 
'B 
for  the  case  when  P(s)  is  square  and  nonsingular.  Note  that  in  the  present  case 
|P(^)|  =  1^/ -  A||//(5')|. It is also possible to obtain this result using the special struc 
ture of the matrices in the special form of Subsection 3.4A. In this case, the invariant 
"zeros of the system  [the roots of IPC^"")]]", which are equal here to the zeros of the sys 
tem,  are the  zeros  of H(s)  [the roots  of  |//(^)|]  and  those  eigenvalues  of A that  are 
not both controllable and observable  [the ones that do not cancel in \sl  -  A\\H(s)\], 
Note that the zero polynomial of H(s),  ZH(S),  equals the monic greatest common 
divisor  of  the  numerators  of  all  the  highest  order  nonzero  minors  in  H(s)  after  all 
their  denominators  have  been  set  equal  to  PH(S), 
the  characteristic  polynomial  of 
H{s).  In the scalar case (p  =  m  =  I)  our definition  of the zeros of H{s)  reduces to 
the  well-known  definition  of  zeros, namely,  the roots  of the numerator  polynomial 
of  H(s). 
EXAMPLE  5.5.  Consider  H(s)  of  Example  5.1. From  the  Smith-McMillan  form of 
H(s), we obtain the zero polynomial ZH(S)  =  1, and H(s) has no (finite) zeros. Alterna 
tively, the highest order nonzero minors are l/[s^(s +  1)] and l/s^  = (s + l)/[s^(s +1)] 
and the greatest common divisor of the numerators is ZH(S)  = 1. 
EXAMPLE  5.6.  We  wish  to  determine  the  zeros  of  H(s)  = 
s 
r 
s+  1 
1 
0 
s+  1 
s+  1 
1 
s +  1 
s + I'  s + I' 
Then  PH(S)  =  s^(s +  1), 
s^ 
and 
The first-order minors  are  the  entries  of  H(s),  namely, 
1 
s' 
there  is  only  one  second-order  minor 
s+  1 
s + I 
s^ 
the least common denominator, is the characteristic polynomial. Next, write the highest 
(second-)  order  minor  as  -
and  note  that  s(s +  1)  is  the 
s 
s(s +  1)  _  s(s + 1) 
"sKs +  1)  "" "
PH(S) 
zero polynomial of H(s), ZH(S), and the zeros of H(s) are {0, -1}. It is worth noting that 
the poles and zeros of H(s) are at the same locations. This may happen only when H(s) 
is a matrix. 
If  the  Smith-McMillan  form  of  H(s)  is  to  be  used,  write  H(s) 
0 
's' 
U' 
(s + If 
Do 
= 
l,Di 
--
1 and ^2  = D2/D\ 
—--N(s).  The  Smith  form  of  N(s)  is  now 
d(s) 
l,D2  = ^-^(^+1)2 with invariant factors of A/^(5') given by ^1  =  DI/DQ  = 
s^(s+lf.  Therefore, the Smith-McMillan form (5.3) of H{s) is 
sHs + 1) 
0 
S\S  +  1)2  since 
SMH(S)  = 
1 
s\s  + 1) 
0 
0 
s(s + 1) 
i  J 
r ^l 
^l 
0 
0 1 
^2 
IA2-I 
304 
Linear Systems 
The zero polynomial is then ZH(S)  = e\e2  = s(s + 1) and the zeros of H(s) are {0,  -1}, 
as expected. Also, the pole polynomial is PH(S)  = i//ii/^2  =  s^{s + 1) and the poles are 
• 
{0,0,-1}. 
s+  1 
1 
s+  1 
0 
0 
5+  1 
1 
s 
The 
EXAMPLE  5.7.  We  wish  to  determine  the  zeros  of  H(s) 
1 
1 
s'  s + I'  s(s + I) 
1 
second-order minors are 
s^(s +  1). Rewriting the highest (second-) order minors as s(s +  \)IPH{S),  s^lpnis), and 
SIPH{S),  the greatest common divisor of the numerators is s, i.e., the zero polynomial of 
H{s) is ZH{.S)  = s. Thus, there is only one zero of H(s) located at 0. Alternatively, note 
that the Smith-McMillan form is 
and the characteristic polynomial is PH(S) 
SMH(S) 
1 
sHs + 1) 
0 
0 
Relations between poles, zeros, and eigenvalues of A 
Consider  the  system  x  =  Ax  -\-  Bu,  y  =  Cx  -\-  Du  and  its  transfer  function 
matrix H(s)  =  C(sl  -A)~^B-\-D.  Summarizing the above discussion, the following 
relations can be shown to be true. 
1.  We have the set relationship 
{zeros of the system}  =  {zeros of  H{s)} 
U {input-decoupling  zeros} U {output-decoupling  zeros} 
(5.10) 
-  {input-output decoupling  zeros}. 
Note that the invariant zeros of the system contain all the zeros of H(s)  (trans 
mission zeros), but not all the decoupling  zeros (see Example 5.8). When  P(s)  is 
square  and  nonsingular,  the  zeros  of  the  system  are  exactly  the  invariant  zeros 
of the system. Also, in the case when {A, B, C, D} is controllable and observable, 
the zeros of the system, the invariant  zeros, and the transmission  zeros  [zeros of 
H(s)]  all coincide. 
2.  We have the set relationship 
{eigenvalues of A (or poles of the system)}  =  {poles of  H(s)} 
U {uncontrollable eigenvalues  of A} U {unobservable eigenvalues of A} 
-  {both uncontrollable  and unobservable eigenvalues  of A}. 
(5.11) 
3.  We have the set relationships 
{input-decoupling  zeros}  =  {uncontrollable eigenvalues  of A}, 
{output-decoupling  zeros}  =  {unobservable eigenvalue of A}, 
{input-output decoupling  zeros}  =  {eigenvalues of A that are both 
and 
uncontrollable and unobservable}. 
(5.12) 
4.  When  the  system  {A, B,  C, D}  is  controllable  and  observable,  then 
{zeros  of  the  system}  =  {zeros  of  H(s)} 
{eigenvalues  of A  (or poles  of  the  system)}  =  {poles  of  H(s)}. 
(5.13) 
and 
Note  that  the  eigenvalues  of  A  (the  poles  of  the  system)  can  be  defined  as  the  roots 
of  the  invariant  factors  of  ^/  -  A  in  P(s)  given  in  (5.6). 
EXAMPLE  5.8.  Consider the system {A, B, C} of Example 5.3. Let 
305 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
P(s)  = 
si  -  A  B 
D 
-C 
s 
-1 
1 
^ +  2 
-1 
-1 
0 
-1 
s+  1 
1 
1 
1 
0 
1 
2 
0 
-1 
0 
0 
0 
There  are two fourth-order  minors  that include  all columns  of ^/  -  A obtained  by 
taking  columns  1, 2,  3, 4  and  columns  1, 2,  3, 5  of  P{s)\  they  are  {s +  \){s  +  2)  and 
{s +  \){s  + 2) (verify  this). The zero polynomial of the system is zp  =  {s+  l){s  + 2) and 
the zeros of the system are {-1,  - 2 }. To determine the input-decoupling  zeros, consider 
all the third-order minors of [si -  A, 5]. The greatest common divisor is 5* + 2 (verify this), 
which implies that the input-decoupling zeros are {-2}. Similarly, consider 
\sl  —  Al 
and 
show that 5 -t- 1 is the greatest common divisor of all the third-order minors and that the 
output-decoupling  zeros  are {-1}.  The transfer  function  for  this  example  was  found  in 
Example5.3 tobe//(>y)  =  [I/5, 1/^]. The zero polynomial of//(i-)  is z//(^)  =  land  there 
are no  zeros  of H{s).  Notice  that  there  are  no input-output  decoupling  zeros. It  is  now 
clear that relation  (5.10) holds. 
The  controllable  (resp.,  uncontrollable)  and  the  observable  (resp.,  unobservable) 
eigenvalues  of A  (poles  of  the  system)  have  been  found  in  Examples  4.4  and  4.5  in 
Section  3.4. Compare these results to show that  (5.12) holds. The poles of H(s)  are {0}. 
Verify  that (5.11) holds. 
One  could  work  with  the  Smith  form  of  the  matrices  of  interest  and  the  Smith-
McMillan  form  of  H(s).  In  particular,  it  can  be  shown  (do  so)  that  the  Smith  form  of 
P(s)  is 
"""1  0  « "
0  1 
0  0 
0  0 
'^ 
0 
0 
s + 2 
0^ 
^1  0 
I, of  [si  -  A, B]  is  ' 
0 
0 
s  + 2 
0  01 
of 
si 
-A 
-C 
0 
0 
"""1  0 "
0  1 
0  0 
0  0 
the Smith-McMillan  form  of H(s)  is 
, and of  [si  -
no 
-A]  is  0  1 
s + 1 
0 
0 
0 
0  0  ^r^ -1-1){ 
. Also, it can be  shown  that 
SMH(S)  = 
-,o 
It is straightforward  to verify the above results. Note that in the present case the invariant 
zero polynomial is Zp(s)  =  s  + 2 and there is only one invariant zero at  - 2. 
• 
EXAMPLES.9.  Consider the circuit of Example 5.4 and of Example 4.9 in this chapter 
and the system matrix  P(s)  for the case when  R1R2C  =  L given by 
306 
Linear Systems 
P(s) = 
si  -A  B 
-C  D 
s + R2 
L 
0 
0 
s + R2 
R2 
L 
1 
Ri 
^ 
'  Ri 
(i)  First, let Ri ¥^  R2. To determine the zeros of the system,  consider  \P{s)\ = 
{\IR\){s + R\IL){s + R2IL), which  impHes that the zeros of the  system  are  {—R\IL, 
-R2IL}.  Consider now all second-order (nonzero) minors of [si -  A,B], namely, {s + 
R2/Lf. (l/LXs  + R2/L), and -(R2/L)(s  + R2/LX from which we see that {~R2/L} is the 
input-decoupling zero. Similarly, we also see that {-7^2/^} is the output-decoupling zero. 
Therefore, {-R2/L} is the input-output decoupling zero. Compare this with the results in 
Example 5.4 to verify (5.13). 
(ii) When Ri  = R2 = R, then  \P(s)\ = (l/R)(s  + RILf,  which impHes that the 
zeros of the system are at {-R/L,  -R/L}.  Proceeding as in (i), it can readily be shown 
that {—R/L} is the input-decoupling zero and {—R/L} is the output-decoupling zero. To 
determine which are the input-output decoupling zeros, one needs additional information 
to the zero location. This information can be provided by the left and right eigenvectors 
of the two zeros at -R/L  to determine that there is no input-output decoupling zero in 
this case (see Example 4.9). 
In both cases (i) and (ii), H(s) has been derived in Example 4.9 of Section 3.4. 
• 
Verify relation (5.10). 
Zero directions and pole-zero  cancellations 
There are characteristic vectors or zero directions, associated with each invariant 
and decoupling zero of the system {A, B, C, Z)}, just as there are characteristic vectors 
or eigenvectors, associated with each eigenvalue of A (pole of the system). 
Consider  the system  matrix  P(A) given  in (5.6) at 5* =  A. If A is an invariant 
zero of the system, then there exist nonzero vectors v^ and v^ associated with A such 
that 
P(A)v,  =  0, 
v,P(A)  =  0. 
(5.14) 
This  is  so  because  if  A is  an  invariant  zero  of  the  system,  then  ranii  P(X) < 
rank  P(s) <  min(^ -\-  p,n  -\-  m), and therefore  the columns  (resp.,  the rows) are 
linearly  dependent.  Here  rank  P(s)  denotes  the number  of  linearly  independent 
columns or rows over the field of rational functions  in s [it is called normal  rank of 
P(s)];  rank  P(A) is the rank of P(A) over the field of complex numbers. 
The  vector  v^ is called  an invariant  zero  direction  or a zero  direction  corre 
, that is. 
sponding to A. A physical interpretation of this is as follows. Let v^ = 
-u 
let 
XI  -  A  B 
D 
-C 
(5.15) 
and assume that the system is at rest at ^ =  0. If an input of the form w(0  =  ue 
0, is applied, and if A is not a pole of the system, then it will produce a state of the 
form  x{t)  =  xe^^ and an output 
r..,^t 
yit)  -  0, 
r >  0. 
This is sometimes referred to in the literature as the output-zeroing  or blocking prop- 
erty of zeros. This property is a generahzation of the blocking property  of zeros orig- 
inally expressed in terms of the transfer  function  and its zeros for  a SISO system. 
For decoupling  zeros, it is quite  easy  to  see what  the corresponding  directions 
will be. In particular,  if  A  is  an input-decoupling  zero, then  there  exists  a nonzero 
vector V such that v[A/  -  A, B]  =  0, which implies that 
307 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
v,PW  =  [v,0] 
\XI 
- A B] 
-c  D\ 
[0,0]. 
(5.16) 
It is clear that the vector v is the left eigenvector of A corresponding to A, which 
is also an eigenvalue of A. This, in fact,  determines  the exact relationship  (location 
and  corresponding  directions)  between  input-decoupling  zeros  and  uncontrollable 
eigenvalues. 
Similar results can be derived for the output-decoupling  zeros. In fact if A is an 
[A/ — AI 
v - 0, 
-C 
output-decoupling  zero, then there exists a nonzero vector v so that 
which implies that 
^(A)v,  = 
XI 
-A 
-C 
(5.17) 
It is clear that the vector v is the right eigenvector of A corresponding to A, which is 
also an eigenvalue of A. This provides the exact relation between  output-decoupling 
zeros and unobservable  eigenvalues. 
Consider now an input-decoupling zero A and the corresponding direction [v, 0]. 
As  was  shown  above  A, v are an  (uncontrollable)  eigenvalue  and its  corresponding 
left  eigenvector,  respectively.  Let  v be the  corresponding  right  eigenvector  to  A. If 
\I  — A] 
_ ^  V =  0, then A is also an unobservable eigenvalue and an output-decoupling 
zero. In particular,  A is an input-output  decoupling  zero and also an eigenvalue  that 
is both uncontrollable  and unobservable.  The vectors  [v, 0]  and  [v^, 0]^ are the di 
rections associated with such zero. 
In general the directions v^ and v^ in (5.14) associated with the invariant zeros do 
not have any particular form [v^  =  [v, 0] in (5.16) for the case of an input-decoupling 
zero]. When the rank of P(s)  is full,  that is, 
rank  P(s)  =  n -{-  min (p,  m), 
(5.18) 
the direction that corresponds to the invariant zero at A can be taken to be v^ [where 
P{X)Vz =  0] when min (;?, m)  =  m, andv^ [where V2P(A)  =  0], when min (/?, m)  = 
p.  Note  that  when  min  (p, m)  =  p  <  m,  there  are  nonzero  vectors  satisfying 
P{K)Vz =  0 with A not necessarily  being an invariant  zero of the system.  This situa 
tion becomes accentuated, i.e., (5.14) is satisfied for values of A that are not necessar 
ily zeros of the system, when rank P(s)  <  n-\-mm  {p, m). This phenomenon is unique 
to 
MIMO 
systems. 
In the MIMO case it is possible for a /? X m transfer  function  H{s)  to have poles 
and  zeros  at the same location  (see Example  5.10). This is impossible  in the  scalar 
case, where H{s) is a 1X1 matrix, since in this case common factors in the numerator 
and denominator will cancel in the process of forming H{s).  In state-space terms, this 
result can be expressed  as  follows. 
308 
Linear Svstems 
LEMMA 5.1.  In the SISO case, if A is both a zero of the system and an eigenvalue of 
"""^ ^^^ P^^^ ^^ ^^^ system)", then A must be an input- and/or output-decoupling zero (un 
controllable and/or unobservable eigenvalue). This is not necessarily true in the MIMO 
case. 
Proof, Assume that A is not an input- and/or output-decoupling  zero, or equivalently, 
that all eigenvalues of A are controllable and observable. Then all eigenvalues of A will 
be poles of H{s) and all zeros of the system will be zeros of H{s). This is not possible, 
however, since by definition the numerator and denominator of H{s) cannot have a com 
mon factor [presently, {s -  A)]. Therefore, A must be an input- and/or output-decoupling 
zero. 
• 
EXAMPLE  5.10.  For  H{s) 
s 
I s 
s+  1 
1 
0 
^ +1 
s^ 
-s + I 
the poles  and zeros were  determined 
in Example 5.6 to be {poles of H{s)} = {0, 0, -1} and {zeros of H(s)} = {0, -1}.  Note 
that in this case the poles and zeros are at the same locations, 0 and  - 1. 
• 
We conclude by noting that, as will be shown in Section 4.2 of Chapter 4, one can 
arbitrarily  assign values to the controllable eigenvalues, and to a certain extent,  one 
can alter their corresponding  eigenvectors, using linear state feedback.  In the scalar 
case,  assigning  a  closed-loop  eigenvalue  at  an  open-loop  zero  location  guarantees 
that  the eigenvalue  will become  unobservable  (linear  state feedback  does not  alter 
controllability) and will not appear in the transfer function  (refer to Exercises 4.6 and 
4.7 in Chapter 4). In the MIMO case, the eigenvectors of the closed-loop eigenvalues 
must also be assigned appropriately for the eigenvalues to become unobservable and 
cancel  out  when  forming  the  transfer  function  matrix  (see Exercise  4.19  in  Chap 
ter 4). 
3.6 
SUMMARY 
In  this  chapter  the  system  properties  of  reachability  (or  controllability-from-the-
origin)  and  controllability  (-to-the-origin),  together  with  the  dual  properties  of ob 
servability  and constructibility,  respectively,  were developed.  These concepts  were 
introduced  using  discrete-time  time-invariant  systems  (Subsection  3.1 A)  and  were 
further  developed in Part  1 of the chapter  (Sections  3.2 and  3.3). 
In Section  3.2, the reachability  Gramian  of a continuous-time  system was used 
to derive inputs that transfer  the state of the system from  one desirable vector value 
to another. This was accomplished for both time-varying and time-invariant systems. 
The time-invariant case was developed in Subsection 3.2B, so that it may be studied 
independently.  It was  shown that for  continuous-time  systems, reachability  implies 
controllability, and vice-versa; however, for discrete-time systems, although reacha 
bility always implies controllability,  controllability  may not imply reachability  (un 
less A  has  full  rank).  Analogous  results  were  developed  in  Section  3.3  regarding 
observability  and  constructibility. 
In  Part  2,  Section  3.4,  useful  special  forms  for  (continuous-time  and  discrete-
time)  state-space  descriptions  of  time-invariant  systems  were  developed.  The 
standard  forms  for  uncontrollable  (resp.,  unobservable)  systems  lead  to better  un 
derstanding  of the relationships  between  state-space  and  transfer  function  descrip 
tions  of  systems.  The  controller  and  observer  forms  provide  important  structural 
information  about a system that is useful  in state-space realizations of transfer  func- 
tion matrices  and in feedback  control. Polynomial  matrix  fractional  descriptions  of 
transfer  matrices  were also introduced, by the structure theorem. Finally, poles and 
zeros  of  systems  were  addressed,  in  Section  3.5.  They  were  introduced  using  the 
Smith form  of polynomial matrices  and the Smith-McMillan  form  of transfer  func- 
tion matrices. 
The reachability  (controllability)  and observability  (constructibility)  Gramians 
played an important role in this chapter. These are now summarized, for convenience. 
309 
CHAPTER 3: 
Controllability, 
Observability, 
and Special 
Forms 
Summary  of Gramians  Introduced  in This  Chapter 
Reachability  Gramians 
A.  Wr(to,tl)= 
rh 
J to 
^{ti,T)B{T)B^{T)^{ti,T)dT. 
(2.11) 
(2.29) 
B.  WM  T)  =  f  e^^-'^^BB^e^^~'^^' 
dr. 
Jo 
K-l 
C.  Wr{0,K)  =  ^A^-^'^^^BB^(A^f-^'+^^ 
K-\ 
= 
^A'BB^(A^y. 
(2.64) 
1 = 0 
ControUabihty  Gramians 
A.  Wc(toJl)= 
^{tQ,T)B{T)B^{T)^^{tQ,T)dT. 
B.  WMT)=^ 
Jto 
rT 
Jo 
K-l 
e-'^^BB^e-'^^^dr. 
C.  WM  K)  =  ^  A-~^'^^^BB^{A^)-^'^^\ 
/=o 
Observabihty  Gramians 
\A\ T^ 0. 
A.  W,(ro, h)=  V  ^\T,  ro)C^(T)C(T)c&(T, ro) d7. 
Jto 
B.  Wo(0,T)=l 
e^^'C^Ce^'dr. 
Jo 
K-\ 
C.  Wo{0,K)  = 
^(A^yC^CA\ 
i = 0 
Constructibility  Gramians 
A.  Wcnito, tl)= 
\'  0^(T,  ^ I ) C ^ ( T ) C ( T ) 0 ( T,  ti)dT. 
Jto 
B.  Wcn(0,T)= 
l' 
Jo 
e^'^'-^^C^Ce^^'-^Ur. 
C.  Wcn(0," K)  =  ^(A^)""^^'+^^C^CA-^^+^\ "
\A\ 7^ 0. 
i=o 
(2.19) 
(2.41) 
(2.66) 
(3.5) 
(3.22) 
(3.49) 
(3.11) 
(3.32) 
(3.54) 
310 
Linear Systems 
where the Gramians in A, B, and C in each case are the Gramians of the  systems 
i:  =  A(t)x  +  B(t)u,  y  =  Cx(t)  +  D(t)u. 
A. 
B.  X  =  Ax  -\-  Bu, y  =  Cx  -\-  Du. 
C.  x(k  +  I)  =  Ax(k)  +  Bu(k\  y(k)  =  Cx(k)  +  Du(k),  respectively. 
In B and C the controllability  and observability  matrices  are, respectively, 
^  -  [B,AB,.,.,A''-^Bl 
€  =  [C^,(CA/,  ...,(CA^~i)^]^. 
Note that reachability  is the dual concept to observability  and controllability  is 
dual to  (re)constructibility. 
3.7 
NOTES 
The concept of controllability  was first encountered  as a technical  condition in cer 
tain  optimal  control  problems  and  also  in  the  so-called  finite-settling-time  design 
problem for  discrete-time  systems  (see Kalman  [6]). In the latter,  an input must be 
found  that  returns  the  state  XQ  to  the  origin  as  quickly  as  possible.  Manipulating 
the  input  to  assign  particular  values  to the initial  state in  (analog-computer)  simu 
lations  was  not  an  issue  since  the  individual  capacitors  could  initially  be  charged 
independently. Also, observability  was not an issue in simulations due to the partic 
ular  system  structures  that  were used  (corresponding,  e.g.,  to observer forms).  The 
current definitions for controllability and observability and the recognition of the du 
ality between  them were worked out by Kalman in  1959-1960  (see Kalman  [9] for 
historical comments) and were presented by Kalman in [7]. The significance  of real 
izations that were both controllable  and observable  (see Chapter 5) was  established 
later in Gilbert  [3], Kalman  [8], and Popov  [12]. For further  information  regarding 
these historical issues, consult Kailath  [5] and the original sources. Note that [5] has 
extensive  references  up  to  the  late  seventies  with  emphasis  on  the  time-invariant 
case and a rather complete set of original references  together with historical remarks 
for the period where the foundations  of the state-space system theory were set, in the 
late fifties and sixties. 
Special  state-space  forms  for  controllable  and  observable  systems  obtained  by 
similarity  transformations  are  discussed  at  length  in  Kailath  [5]  (refer  also  to  the 
discussion  on various canonical forms). Wolovich  [19] discusses the algorithms  for 
controller and observer forms and introduces the Structure Theorems. The controller 
form is based on results by Luenberger  [11] (see also Popov [13]). A detailed deriva 
tion of the controller form  can also be found  in Rugh [16]. 
Original  sources  for  the Canonical  Structure Theorem  include  Kalman  [8] and 
Gilbert [3]. 
The  eigenvector  and  rank  tests  for  controllability  and  observability  are  called 
PBH  tests  in  Kailath  [5]. Original  sources  for  these  include  Popov  [14],  Belevich 
[1], and Hautus  [4]. Consult  also Rosenbrock  [15], and for  the case when A  can be 
diagonalized  via a similarity  transformation,  see Gilbert  [3]. Note that in the eigen 
value/eigenvector  tests  presented  herein  the  uncontrollable  (unobservable)  eigen 
values  are  also  explicitly  identified,  which  represents  a modification  of  the  above 
original results. 
The  Brunovsky  canonical  form  is  developed  in  Brunovsky  [2]. 
The  fact  that  the  controllability  indices  appear  in  the  work  of  Kronecker  was 
recognized  by  Rosenbrock  [15]  and  Kalman  [10]. 
For  an  extensive  introductory  discussion  and  a  formal  definition  of  canonical 
forms,  see Kailath  [5]. Note that certain  special forms  exist for time-varying  systems 
as  well,  but  they  are  not  considered  here. 
Multivariable  zeros  have  an  interesting  history.  For  a review,  see  Schrader  and 
Sain  [17]  and  the  references  therein.  Refer  also  to  Vardulakis  [18]. 
311 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
3.8 
R E F E R E N C ES 
1.  V. Belevich,  Classical  Network  Theory, Holden-Day,  San Francisco,  1968. 
2.  P. Brunovsky,"  ""A  Classification  of  Linear  Controllable  Systems",""" Kybernetika",  Vol. 3, 
pp.  173-187,  1970. 
3.  E. Gilbert,"  ""Controllability  and Observability  in Multivariable  Control Systems",""" SIAM "
J.  Control  Vol.  1, pp.  128-151,  1963. 
4.  M.  L.  J.  Hautus,"  ""Controllability  and  Observability  Conditions  of  Linear  Automonous "
Systems,""" Proc.  Koninklijke  Akademie  van  Wetenschappen",  Serie  A,  Vol. 72, pp. 443-
448,  1969. 
5.  T. Kailath, Linear  Systems,  Prentice-Hall, Englewood  Cliffs,  NJ,  1980. 
6.  R. E. Kalman,"  ""Optimal  Nonlinear  Control  of Saturating  Systems  by  Intermittent  Con "
trol,""" IRE WESCON  Rec",  Sec. IV, pp.  130-135,  1957. 
7.  R. E. Kalman," ""On the General Theory of Control Systems",""" in Proc.  of the First  Intern. "
Congress  on Automatic  Control,  pp. 481-493, Butterworth, London,  1960. 
8.  R. E. Kalman," ""Mathematical Descriptions of Linear Systems",""" SIAM J. Control", Vol. 1, 
pp.  152-192,  1963. 
9.  R. E. Kalman, Lectures  on Controllability  and  Observability,  C.I.M.E., Bologna,  1968. 
10.  R. E. Kalman," ""Kronecker Invariants and Feedback",""" in Ordinary Differential  Equations", 
L. Weiss, ed., pp. 459-471,  Academic  Press, New York,  1972. 
11.  D. G. Luenberger," ""Canonical Forms for Linear Multivariable Systems",""" IEEE  Transac "
tions  on Automatic  Control,  Vol.  12, pp. 290-293, 1967. 
12.  V. M.  Popov,"  ""On  a  New  Problem  of  StabiUty  for  Control  Systems",""" Autom.  Remote "
Control,  pp.  1-23,  Vol. 24, No.  1, 1963. 
13.  V. M.  Popov,"  ""Invariant  Description  of  Linear",  Time-Invariant  Controllable  Systems,""" "
SIAM  Journal  of Control  and  Optimization,  Vol.  10, No. 2, pp. 252-264,  1972. 
14.  V  M. Popov, Hyperstability  of Control  Systems,  Springer-Verlag, Berlin,  1973. 
15.  H. H. Rosenbrock, State-Space  and Multivariable  Theory, Wiley, New York,  1970. 
16.  W. J. Rugh, Linear  System  Theory, Prentice-Hall, Englewood  Chffs,  NJ, 1993. 
17.  C. B. Schrader  and M.  K.  Sain,"  ""Research  on System Zeros: a Survey",""" Int.  Journal  of "
Control,  Vol. 50, No. 4, pp.  1407-1433, 1989. 
18.  A.  I.  G.  Vardulakis,  Linear  Multivariable  Control.  Algebraic  Analysis  and  Synthesis 
Methods,  Wiley  New York, 1991. 
19.  W. A. Wolovich, Linear  Multivariable  Systems,  Springer-Verlag, New York,  1974. 
3.9 
EXERCISES 
3.1.  (a)  Let %k =  [B, AB,...,  A^'^B],  where 
A^R 
"""><«","igG/?""^'"".Showthat "
^ ( ^ ^)  =  ^{%n)  for  k>n, 
and 
k) C  ^{%n)  for 
k<n. 
312 
Linear  Systems 
(b)  Let 0^  =  [C^, (CAf,..., 
A  srT 
(CA'^-^ff,  where A  E  R^''^  C E  /?^^^ Show that 
M{^k)  =  >r(0„) for k>  n, 
and 
J{(€k)  D M'(€n) for  k<n. 
3.2.  Consider the state equation  x  = Ax  + Bu, where 
A 
0 
3w2 
0 
0 
10 
0 
0 
—2w 
0 
0 
0 
0 
2w 
1 
0 
B  = 
0 
1 
0 
0 
o' 
0 
0 
1 
which was obtained by linearizing the nonlinear equations of motion of an orbiting satel 
lite about a steady-state  solution. In the state x  =  [xi, X2,  ^3, ^4]^, xi  is the  differential 
radius,  while  X3 is the differential  angle.  In the input  vector  u  =  [i/i, U2V,  u\  is the 
radial thrust and 1/2 is the tangential  thrust. 
(a)  Is this  system  controllable  from  ullf  y  =  yi 
is  the system  observable 
from  yl 
(b)  Can the  system  be  controlled  if  the radial  thruster  fails?  What  if  the  tangential 
thruster  fails? 
(c)  Is the system observable from  yi  only? From y2 only? 
3.3.  Consider the state equation 
i 
0 
0 
-1 
(a)  lfx(0)  = 
derive an input that will drive the state to 
in T sec. 
(b)  For x{0) 
5 
-5 
, plot  u(t), xi(t),  X2(t) for T  =  1, 2, and 5 sec. Comment  on the 
magnitude of the input in your results. 
3.4.  Consider the state equation x(/:+l)  = 
"""1  1  0"" "
0  1  0 
.0  0  1_ 
x{k) + 
0' 
1 
. 1. 
u(k),y(k)  = 
1  1  0 
0  1  0 
x{k). 
(a)  Is  x^ 
reachable?  If yes,  what  is the minimum  number  of steps  required to 
transfer  the state from  the zero state to x^ ? What inputs do you need? 
(b)  Determine all states that are reachable. 
(c)  Determine all states that are unobservable. 
(d)  If i:  =  Ax  + Bu is given with A, B as in (a), what is the minimum time required to 
transfer  the state from  the zero state to x^l  What is an appropriate u(t)? 
3.5.  Output reachability  (controllability)  can be defined in a manner analogous to state reach 
ability  (controllability). In particular,  a system  will be called  output  reachable if there 
exists an input that transfers  the output from  some yo to any ^^i in finite time. 
Consider  now a discrete-time  time-invariant  system  x{k  +  1)  =  Ax(k)  +  Bu(k), 
"y(k)  =  Cx(k)  + Du(k)  with A  E  /?"">'^ B E  /?""^^","  C E  7?^^""", and D E  RP'''^.  Recall 
that 
y(k)  =  CA^x(O) + ^  CA^-^'-'^^Buii)  +  Du(k). 
k-i 
(a)  Show that the system {A, B, C, D} is output reachable if and only if 
rank  [D, CB, CAB,...,  CA'^'^B]  =  p. 
Note that this rank condition is also the condition for output reachabihty  for 
continuous-time  time-invariant  systems x=Ax  + Bu,y  = Cx +  Du. 
It should be noted that, in general, state reachabihty is neither necessary  nor 
sufficient  for  output reachabihty.  Notice for  example that if  rank D  = p  then the 
system is output reachable, 
(b)  Let  D  =  0.  Show  that  if  (A,5)  is  (state)  reachable,  then  {A,B,C,D} 
is  output 
313 
CHAPTER  3: 
Controllability, 
Observability, 
and  Special 
Forms 
reachable if and only if rank C =  p. 
11 
n 
(c)  L e t A=  0 
[o 
Is the system output reachable? Is it state reachable? 
0] 
0 , 5 =0 
C=  [1,1,0], and D =  0. 
0  -ij 
0 
-2 
[i^ 
(i) 
(ii)  Let  x(0)  =  0.  Determine  an  appropriate  input  sequence  to  transfer  the 
output to yi  =  3 in minimum time. Repeat for x(0)  =  [1,-1,2] 
. 
3.6.  (a)  Given  x  = Ax-^Bu,y  = Cx^Du, 
show  that  this  system  is  output  reachable  if 
and  only  if  the  rows  of  the  /? x m  transfer  matrix  H{s)  are  linearly  indepen 
dent  over  the  field  of  complex  numbers.  In  view  of  this  result,  is  the  system 
His) 
1  1 
5 +  2 
s 
output  reachable? 
(b)  Similarly,  for  discrete-time  systems,  the  system  is  output  reachable  if  and  only 
if  the  rows  of  the  transfer  function  matrix  H{z)  are  hnearly  independent  over 
the  field  of  complex  numbers.  Consider  now  the  system  of  Exercise  3.5  and 
determine if it is output reachable. 
3.7.  Show  that  the  circuit  depicted  in  Fig.  3.6  with  input  u  and  output  y  is  neither  state 
reachable nor observable but is output reachable. 
"""O "
T 
y 1 FIGURE 3.6 
Circuit for Exercise  3.7 
3.8. 
A  system  x  = Ax-^Bu,y  =  Cx + Du  is  called  output function  controllable  if  there 
exists  an input  u{t),t  G [0,oo), that  will  cause the  output y{t)  to  follow  a  prescribed 
trajectory  for  0 <  ^ <  ^o, assuming  that the  system is  at rest  at ^ =  0.  It is easiest  to 
derive a test for output function  controUabihty in terms of the /? x m transfer  function 
matrix H{s),  and this is the  approach  taken in the following.  We say that the m x /? 
rational matrix HR(S) is a right  inverse ofH{s)  if 
H{s)HR{s)=Ip. 
the sufficiency  proof,  select///?  =  H^{HH^)-\ 
(a)  Show  that  the right  inverse HR{S) exists  if  and  only  if  rank  H{s)  =  p.  Hint:  In 
the (right) pseudoinverse  of//. 
(b)  Show  that  the  system  is  output  function  controllable  if  and  only  if  H{s)  has  a 
right inverse  HR{S).  Hint:  Consider y  = Hu.  In the necessity proof,  show that if 
rank H  <p  then the system may not be output function  controllable. 
Input  function  observability  is  the  dual  to  output  function  controUabihty. 
Here, the left inverse  ofH(s),HL{s), 
is of interest and is defined  by 
HL{s)H(s)=Im.. 
314 
Linear  Systems 
(c)  Show that the left inverse Hi{s)  of H{s)  exists if and only if rankH(s)  =  m.  Hint: 
This is the dual result to part (a). 
(d)  Let H(s)  = 
\s  +  I 
ll 
s 
s _ 
(at rest at r  =  0) to exactly follow  a step, _y(^) 
1/^. 
and characterize  all inputs  u(t)  that will cause the  system 
Part  (d) points to a variety  of questions  that may  arise when  inverses  are  consid 
ered, including: Is HR(S) proper? Is it unique? Is it stable? What is the minimum degree 
possible? 
3.9.  Consider the system x  =  Ax-\-  Bu,  y  =  Cx.  Show that output function  controllability 
implies output controllability  (-from-the-origin,  or reachability). 
1  1 
0  1 
3.10.  Given 4 ^ + 1)  = 
x(k)  + 
u(k),  y(k)  ~ 
x(k),  and assume zero initial 
conditions. 
(a)  Is there a sequence of inputs {w(0), u(l),...} 
that transfers  the output from  ^(0) 
0' 
to  0' w in finite time? If the answer is yes, determine  such a sequence. 
W 
(b)  Characterize  all outputs  that can be reached  from  the zero output  iy{0)  = 
m 
one step. 
3.11.  Consider the state equation  x(t)  = 
0  0 
0  1 
x(t)  + 
1 
u(t). 
(a)  Show that it is controllable at any ^o E  (-00,00). 
(b)  Suppose we are interested only in X2(t) \x(t)  = 
xiit) 
Consider,  therefore. 
xiit)  =  X2{t) + e~^u{t). 
Is it possible to determine u{t) so that the state X2it) is transferred from X20 at ^ =  ^ 
[•^2(^0)  =  -^20] to the zero state at some t  =  t\  [^2(^1)  =  0] and then stay there? If 
the answer is yes, find such a  u{t). 
(c)  In (b), let ^  =  0 and study the effects  of the sizes of t\  and  XQ on the magnitude of 
u{t). 
(d)  For the  system in  (b), determine, if possible,  a u{t)  so that the  state is  transferred 
from  xo at ^ =  ^0 to x^ at ^ =  t\  and then  stay there. 
"3.12.  Let F{t)  E  C""^'^ be a matrix with fi{t)  in its /th row. Let f^  G  C{R", ^ ^ ).  It was shown 
that the set fi{t),  i  =  1,...,  n, is linearly  independent  on  [ti, ^2] over the field of com 
plex numbers if and only if the Gram matrix  W(ti,  ^2) is nonsingular (see Lemma 2.7). 
If  the  fi(t),  i  =  1,...,  n, have  continuous  derivatives  up to order  (n  -  1), then  it  can 
be shown that they are linearly independent if for  some ^0 ^  [h, h]^ 
rank[F(to),F^'\to),...,F^''-'\to)] 
=  n. 
If  fi(t),  i  =  \,  ...,n, 
only if for any fixed to E  [^1, ^2], 
are analytic  on  [t\, ^2], then they  are linearly  independent  if  and 
rank  [Fit^),  F^'\tol..., 
F^^'-'Xtol...]  =  n. 
(a)  The above results can be used to derive alternative tests for controllability. In par 
ticular, consider the state equation 
X =  A(t)x  +  B(t)u, 
"where  A(t)  E  /?""^""  and  B(t)  E  /?""^'^  have  continuous  derivatives  up  to  order "
(n  -  1). Then  it  can  be  shown  that  (A(t),  B{t))  is  controllable  at  time  ^  if  there 
exists finite ^i  >  ^  such that 
rank[Mo{t\),M\{ti), 
...,Mn-\{t\)] 
=  n, 
"where the Mk{t)  G /?""^"" are defined  by "
M,+i(0  = 
-A{t)Mk{t)+j^Mk{t), 
0, 1, . . ., /2  -  1, 
315 
CHAPTERS: 
Controllability, 
Observability, 
and  Special 
Forms 
with Mo(0  =  B{t). 
(i)  Prove this result. 
(ii)  Show that the system i:  =  A{t)x  + B{i)uW\i\\A{t)  = 
is controllable  at any tQ. 
"1  0"" "
't 
0 
t 
0 
0  0  ^2 
.B{t)  = 
"""0"" "
1 
.1. 
(b)  The results for linear independence of vectors fi(t),i  =  1,...,  n, can also be used 
to  derive  conditions  for  certain  specialized  types  of  controllability.  In  particular, 
given  X  =  A(t)x  +  B(t)u  as  in  (a),  a  system  is  called  differentially  controllable 
at  to, when  the  transfer  from  any  x(to)  =  xo  to  xi  can  be  accomplished  in  an 
arbitrarily  small  interval  of  time.  Note  that  this  may  lead  to  large  input  magni 
tudes.  It  can  be  shown  that  when  A(0, B{t)  are  analytic  on  (-oo, ^),  the  system 
is  differentially  controllable  at  every  t  E  (-00,00),  if  and  only  if  for  any  fixed 
^0  G  ( - 0 0,  00), 
rank  [Mo(to), Mi(to),...,  Mn-i(to),  ...]  =  «. 
The system is instantaneously  controllable,  if and only if for  allt  G (-00, 00), 
rank  [Mo(t),...,  M„_i(0]  =  n. 
In this  case the transfer  of the  states can be  achieved  instantaneously  at any  time 
by using inputs that include 6-functions  and their derivatives up to order of n -  1. 
Note that in general instantaneous  controllability  implies  differential  controllabil 
ity, which  in turn, implies  controllability.  In the case when A(t),  Bit)  are  analytic 
on (-00, 00), as above, then if  {A{t), B(t))  is controllable  at some point, it is  differ 
entially controllable at every t  G (-00, 00). 
Show  that in the  time-invariant  case  x  =  Ax  + Bu,  controllability  of  (A, B) 
always  implies  both  differential  and  instantaneous  controllability;  i.e.,  if  a  state 
transfer  is  possible  at  all,  it  can  be  achieved  in  an  arbitrarily  small  time  inter 
val  or  even  instantaneously  if  the  5-function  and  its  derivatives  are  used.  For 
the  latter  case,  see  T.  Kailath,  Linear  Systems,  Prentice-Hall,  1980,  for  further 
details. 
Remark:  In controllability, the transfer of the state occurs in finite time, but the 
time  interval  may  be  very  large. In  differential  controllability,  the transfer  of  the 
state is possible in arbitrarily small intervals of time; however, this may lead to very 
large  input  magnitudes  (see Example  2.1). When  the  system  x  =  A{t)x  +  B(t)u 
is uniformly  controllable,  the transfer  of the states can be achieved  in some  finite 
time interval using an input with magnitude not arbitrarily large. Note that  uniform 
controllability  implies  controllability.  Uniform  controllability  is useful  in  optimal 
control theory. For  additional  discussion  on differential  and uniform  controllabil 
ity, see C. T. Chen, Linear  System  Theory and Design,  Holt, Rinehart and Winston, 
1984, and the references  cited therein. Note that dual results  also exist for  differ 
ential, instantaneous, and uniform  observability. 
316 
Linear Systems 
3.13.  Suppose  that for  the system  x{k  + 1) 
1  1  0 
0  1  0 
0  0  1 
x{k\  y(k) 
x(k)  it is 
known  that  y{^)  =  y{l)  =  y{2) = 
. Based  on  this  information,  what  can  be  said 
about the initial condition  x(0)? 
3.14.  (a)  Consider the system x  =  Ax  + Bu,  y  =  Cx  + Du,  where (A, C) is assumed to be 
observable. Express x(t)  as a function  of y(tX  u(t) and their derivatives. Hint:  Write 
y(tX  y^^\tl..., 
"u^^-^\t)  (x(t)  G /?""). "
(b)  Given the system x  =  Ax  + Bu,  y  =  Cx  + Du  with (A, C) observable. Determine 
x(0)  in  terms  of  y(t),  u{t)  and  their  derivatives  up  to  order  n  -  \.  Note  that  in 
general this is not a practical way of determining  x(0), since this method  requires 
differentiation  of signals, which is very  susceptible to measurement  noise. 
/^-i>(0  in terms of x(t)  and u(t), u^^\t),..., 
(c)  Consider  the  system  x{k  +  1)  =  Ax{k)  +  Bu(k),  y(k)  =  Cx(k)  +  Du(k),  where 
y(k  + n -  1) 
y(k  + n-  1) in terms of 
"[x(k)  G  i?""]. Note the relation to expression "
(A,  C) is observable. Express x(k)  as a function  of y(k),  y(k  + I),..., 
and u{k), u(k+  1),...,  y(k  + n-  1). Hint: Express y(k),..., 
x(k)  and u(k),  u(k-\-1),...,  u(k+n-1) 
(3.48) in Section 3.3. 
3.15.  Write software  programs to implement the algorithms of Section  3.4. In  particular: 
(a)  Given the pair (A, B)," where A G /?""><"""," B  G 7?""^'"" with "
rank  [B, AB,...,"  A""""^5]  =  nr <  n", 
reduce this pair to the standard uncontrollable  form 
A  =  PAP-^  = 
An 
Ai 
0 
B  =  PB 
where (Ai, Bi)  is controllable and Ai  G /?«'^x«^ Bi  G  R^rXm^ 
(b)  Given the controllable pair (A, B),"  where A G /?""><""", 5  G i?^^'^ with ran^ 5  =  m, 
reduce this pair to the controller form  Ac  =  PAP'^,  Be  =  PB. 
3.16.  Determine the uncontrollable modes of each pair (A, B)  given below  by 
(a)  reducing  (A, 5), using a similarity  transformation, 
(b)  using eigenvalue/eigenvector  criteria. 
A  = 
1 
0 
0 
"0  0"" "
-1  0 
0  2. 
,B  = 
"""1  0"" "
0  1 
.0  0_ 
and 
A  = 
0  0  1 
0  0  1 
0  0  0 
0  0  0 
"o"" "
0 
0 
-1 
,B  = 
0  r 
0  0 
1  0 
0  0 
3.17.  Consider the system x  =  Ax  + Bu,  y  =  Cx  +  Du. 
(a)  Show that only controllable  modes  appear in  e^^B,  and therefore  in the  zero-state 
response of the state. 
(b)  Show that only observable modes  appear in  Ce^\  and therefore,  in the  zero-input 
response of the  system. 
(c)  Show that only modes that are both controllable  and observable  appear in  Ce^^B, 
and therefore,  in the impulse response and the transfer  function  matrix of the sys 
tem. 
Consider next the system  x{k  +  1)  =  Ax{k)  +  Bu(k),  y(k)  -  Cx(k)  +  Du(k). 
(d)  Show that only controllable modes appear in A^B,  only observable modes in  CA^, 
and only modes thrt  are both controllable and observable appear in CA^B  [that is, 
inHiz)]. 
317 
CHAPTER 3: 
Controllability, 
Observability, 
and  Special 
Forms 
(e)  Let  A  = 
,  B  = 
C  -  [1, 1, 0], and  D  -  0.  Verify  the  results 
0 
2 
0 
"0"" "
0 
- 1. 
"1"" "
0 
.1. 
obtained in (d). Compare these with Example 4.10. 
3.18.  Reduce the pair 
A  = 
0 
3 
1 
1 
0 
0 
1 
0 
1 
-3 
4 
-1 
0 
1 
-1 
0 
B  = 
0 
1 
0 
0 
0 
0 
1 
0 
into  controller  form  Ac  =  PAP 
matrix in this case? What are the controllability  indices? 
\  Be  =  PB.  What  is  the  similarity  transformation 
3.19.  Let A  =  Ac + BcAmmdB  =  5^5^," where the A ^ ^c  are as in (4.63) with A^  G T?'""^^""", 
Bm G  /?^x^,  and  \Bm\ ^  0.  Show  that  (A, B)  is reachable  with  controllabihty  indices 
juii. Hint:  Use the eigenvalue test to show that (A, B) is reachable. Use state feedback to 
simplify  (A, B) (see Exercise 3.21) and show that the /Xi are the controllability indices. 
3.20. 
Show that the controllability indices of the state equation x  =  Ax-\-BGv,  where |G|  T^ 0 
and  (A, B)  is reachable,"  with  A  G  /?«x""", B  G  R^^^^^ are  the  same  as  the  controllabil 
ity  indices  of  x  =  Ax  + Bu,  within  reordering.  Hint:  Write  %k  =  [BG,  ABC,..., 
A^-^BG]  =  [5, A 5 , . . .,  A^~^B]  • [block diag  G]=%k' 
[block diag  G] and show that 
the number  of linearly  dependent  columns  in A^5G  that  occur  while  searching  from 
left  to right in %n  is the same as the corresponding  number in %n-
3.21. 
Consider  the  state  equation  x  =  Ax  + Bu,"  where  A  G  /?"">^"""," B  G  R""^""^ with  (A", B) 
reachable. Let the linear state-feedback  control law be w =  F^  +  Gv, F  G /^'^x^, G G 
f^mxm ^'^^^ 1^1 ^  Q 3how  that 
(a)  (A +  BF,  BG)  is reachable. 
(b)  The controllability  indices of (A +  BF,  B)  are identical to those of (A,  B). 
(c)  The controllability indices of (A +  BF,  BG)  are equal to the controllability  indices 
of (A, B) within reordering. Hint:  Use the eigenvalue test to show (a). To show (b), 
use the controller forms  in Section  3.4. 
3.22.  Show that if (A, B) is controllable (-from-the-origin),"  where A G  /?""^^ and B  G  i?""^^", 
and rank  B  =  m, then rank  A >  n — m. 
3.23.  Consider 
Show that 
0 
0 
1 
-OLn~l} 
0  0 
0  0 
0 
0 
Br  = 
0 
1 
1 
c\ 
[ 5 „ A , 5 „ . . . , A r ' 5 c] 
0 
0 
1 
0 
1 
Ci 
1 
Ci 
C2 
••• 
••• 
••• 
c„-3 
Cn-2 
Cn-l 
318 
Linear  Systems 
where Q  =  -Zf=oQ;„-,-
-1 
^ 
Oil 
OL3 
O^n-l 
1 
1 
0 
, 7 1 - 1,  with Co =  1. Also, show that 
••  an-i 
1 
1 
01 
3.24.  Given  A  G  Z^^^^," and  B  G  /e^^^'""",  let ra/zy^ %  =  n,  where  ^  =  [5, AB,...,  A^^i^]. 
Consider i  G /?^>'^ B  G i?'^^^^ with rank %  =  n, where ^  =  [B,AB,...,  A'^'^B],  and 
"assume that P  G Z?""^'' with det  P 7^  0 exists  such that "
Show that ^  =  P5  and A  =  PAP'K  Hint:  Show that (PA  -  AP)^  =  0. 
3.25.  Show that the matrices Ac  == PAP~\  Be  =  P5  are 
(a)  given by (4.47) if P is given by (4.48), 
(b)  given by (4.50) if 2 (=  P'^)  is given by (4.49), 
(c)  given by (4.52) if e (=  p-^)  is given by (4.51). 
3.26.  In the  circuit  of Example  4.9, let  R1R2C  =  L  and  Ri  =  R2  =  R.  Determine  x(t)  = 
[xi{t),  X2(t)Y  and  i{t)  for  unit  step  input  voltage,  v(0,  and  initial  conditions  x(0)  = 
[a, b]^.  Comment on your results. 
3.27.  Consider  the  pair  (A, b),"  where  A  G  T?""^'^", b  G  R'\  Show  that  if  more  than  one  lin 
early  independent  eigenvector  can be associated  with  a single eigenvalue, then  (A, b) 
is uncontrollable. Hint:  Use the eigenvector test. Let vi, V2 be linearly independent  left 
eigenvectors  associated  with  eigenvalue  Ai  =  A2  =  A. Notice  that  if  vib  =  ai  and 
vib  =  0L2, then {a7^v\  -  a^^V2)b  =  0. 
ro 
-1 
1 
3.28.  (a)  Consider the state equation  x  =  Ax  + Bu,  x(0)  =  XQ, where A  = 
andB  = 
ri 
1 
.1 
01 
1 
2. 
. Determine  x{t)  as a function  of  u(t)  and  XQ, and verify  that  the 
uncontrollable modes do not appear in the zero-state response, but do appear in the 
zero-input response  (see Example 4.1). 
(b)  Consider  the  state  equation  x(k  +  1)  =  Ax(k)  +  Bu(k)  and  ^(0)  =  XQ,  where 
A  and  B  are  as  in  (a).  Demonstrate  for  this  case  results  corresponding  to  (a). 
In (a) and (b), determine x(t)  and x(k)  for unit step inputs and x(0)  =  [1,1,  1]^. 
3.29.  (a)  Consider the system i  =  Ax+Bu,y  =  Cxwithx(O)  =  xo, where A 
•2 
-3J 
B  = 
and  C  =  [1, 1]. Determine  y(t)  as a function  of  u(t)  and  XQ, and  verify 
that the unobservable modes do not appear in the output (see Example 4.3). 
(b)  Consider  the  system  x(k  +  1)  =  Ax(k)  + Bu(k),  y(k)  =  Cx(k)  with  x(0)  = XQ, 
where A, B, and C are as in (a). Demonstrate for this case results which  correspond 
to (a). 
In (a) and (b), determine and plot y(t)  and y(k)  for unit step inputs and x(0)  =  0. 
3.30.  Consider the system  x(k  +  1)  == Ax(k)  + Bu(k),  y(k)  =  Cx(k),  where 
A  = 
1 
0 
0 
0 
1 
2 
0 
0 
0 
_  1 
1 
B 
C  =  [1,1,0]. 
Determine  the  eigenvalues  that  are  uncontrollable  and/or  unobservable.  Determine 
x(k),  y(k)  for  /: >  0,  given  x(0)  and  u(k),  k  >  0,  and  show  that  only  controllable 
eigenvalues  (resp.,  modes)  appear  in  A^B,  only  observable  ones  appear  in  CA^,  and 
only  eigenvalues  (resp.,  modes)  that  are  both  controllable  and  observable  appear  in 
CA^B[mH{z)l 
3.31.  For the system  x  =  Ax  + Bu,  y  =  Cx,  consider the corresponding  sampled-data  sys 
tem x(k  +  1)  =  Ax(k)  +  Bu(k),  y(k)  =  Cx(k),  where 
319 
CHAPTERS: 
Controllability, 
Observability, 
and  Special 
Forms 
A  =  e^ 
B  = 
'dr  B, 
and 
c = a 
(a)  Let the continuous-time  system {A, B, C] be controllable  (observable)  and  assume 
it is a SISO  system. Show that {A, B, C} is controllable  (observable)  if and only if 
the sampling period  T is such that 
Im  (Xi -  Xj)  7^ ~^^'  where  /:  =  ±1, ± 2 , . ..  whenever 7?^ (A/ -  Xj) 
2'Trk 
0, 
where {AJ are the eigenvalues of A. Hint:  Use the PBH test. Also, consult  Appen 
dix D of C. T. Chen, Linear  System  Theory  and Design.  Holt, Rinehart,  and Win 
ston,  1984. 
(b)  Apply  the  results  of  (a)  to  the  double  integrator—Example  7.6  in  Chapter  2— 
0 
U\ 
C  =  [1, 0]. Determine the values of T that preserve controllability  (observability). 
C  =  [1,0],  and  also  to  A 
I 
[-1  oj 
0  1 
0  0 
where  A 
,  B  = 
,  B  = 
0 
3.32.  Given is the system  x 
1 
0 
0 
0 
-1 
0 
x  + 
"""1  0~ "
0  1 
LO  OJ 
^,  y  = 
ri  1  0] 
1  0  0 
(a)  Determine the uncontrollable  and the unobservable eigenvalues  (if any). 
(b)  What is the impulse response of this system? What is its transfer  function  matrix? 
(c)  Is the system asymptotically  stable? 
3.33.  Consider  the  system  x(k  +  1)  = 
x(k)  + 
u(k),  y(k)  =  [I, 3]x(k).  Suppose 
that it is known  that for  zero input,  y(0) 
If yes, find x(0)  and verify  your  answer. 
1 and  _y(l)  =  1. Can  x(0)  be  determined? 
3.34.  Given is the transfer  function  matrix  H(s) 
0 
s + 1 
s + 2 
0 
(a)  Determine the Smith-McMillan  form  of H(s)  and its characteristic  (pole) polyno 
mial and minimal polynomial. What are the poles of  H(s)7 
(b)  Determine the zero polynomial  of H(s).  What are the zeros of  H(s)l 
3.35.  Let H(s)  = 
c2 
1 
s^ 
s+  1 
(a)  Determine the Smith-McMillan  form  of H(s)  and its characteristic  (pole) polyno 
mial and minimal polynomial. What are the poles of  H(s)7 
(b)  Determine the zero polynomial of H(s).  What are the zeros of  H(s)l 
3.36.  A rational  function  matrix  R(s)  may  have, in  addition  to finite poles  and  zeros,  poles 
and  zeros  at  infinity  (s  =  oo). To  study  the  poles  and  zeros  at  infinity,  the  bilinear 
320 
Linear  Systems 
transformation 
s  = 
biw  + 
aiw  +  ao 
with ai  7^ 0, biao  -  h^ax  y^ 0 may be used, where b\lai  is not a finite pole or zero of 
R{s).  This transformation  maps the point s  =  b\la\  iow  =  ^  and the point of interest, 
5- =  00, to w  =  -aja\.  The rational matrix  R{\v) is now obtained  as 
R{w)  =  R 
1\W  • 
aiw  -\-  ao 
and  the  finite  poles  and  zeros  of  R(w)  are  determined.  The  poles  and  zeros  at  w  = 
-ao/a\  are the poles and zeros of R(s)  at 5* =  oo. Note that frequently  a good choice for 
the bilinear transformation  is ^  =  1/w,  that is, bi  =  0, bo  =  1 and ai  =  I,  ao  =  0. 
(a)  Determine the poles and zeros at infinity  of 
Ri(s)  = 
1 
s+  r 
Riis) 
Rsis)  = 
1 
s+  1 
Note that a rational matrix may have both poles and zeros at  infinity, 
"(b)  Show that if R(s)  has a pole at 5"" =  oo", then it is not proper (lim^^oo R(s) • 
-). 
3.37.  Determine the poles and zeros at infinity  of the transfer functions  in Examples  5.1,5.2, 
5.6, and  5.7. 
3.38.  (Spring mass system)  Consider the spring mass given in Exercise 2.69 in Chapter 2. 
(a)  Is the system controllable from  [/i,  /i]^?  If yes, reduce (A, B) to controller  form. 
(b)  Is the system controllable from  input  fi  only? Is it controllable from  /2 only? Dis 
cuss your answers. 
(c)  Let  y  =  Cx  with  C  = 
ri  0  0  01 
0  10 
reduce (A, C) to observer  form. 
0 
Is  the  system  observable  from  j?  If  yes. 
3.39.  (Aircraft  dynamics)  Consider  the  state-space  description  of  the  lateral  motion  of  an 
aircraft  in Exercise 2.76 in Chapter 2. 
(a)  Is the system controllable from  [8A,  8R]^7 If yes, reduce (A, B) to controller  form. 
(b)  Is the system controllable using only the ailerons? Is the system controllable using 
only the rudder? Discuss your answers. 
ro  1  0  01 
[o  0  1  oj 
(c)  Let  y  =  Cx  with  C  = 
reduce (A, C) to observer  form. 
Is  the  system  observable  from  yl  If  yes. 
CHAPTER  4 
State Feedback and State Observers 
"=1 ^lir?:S-«^|t; • > #l  ^ i  -^ *< - >V«ct<-<<;^'^-'^""^-;;¥ "
Feedback is a fundamental mechanism arising in nature and is present in many nat 
ural processes. Feedback is also common in manufactured  systems and is essential 
in automatic control of dynamic processes with uncertainties in their model descrip 
tions and their interactions with the environment. When feedback is used, the actual 
values  of  system  variables  are  sensed,  fed  back,  and used  to control  the  system. 
Hence, a control law  decision process  is based  not only  on predictions  about the 
system behavior derived from  a process model (as in open-loop control), but also 
on information about the actual behavior (closed-loop feedback control). A common 
example of an automatic feedback control system is the cruise control system in an 
automobile, which maintains the speed of the automobile at a certain desired value 
within acceptable tolerances. 
In this chapter feedback  is introduced, and the problem of pole or eigenvalue 
assignment by means of state feedback  is discussed  at length in Section 4.2. It is 
possible to arbitrarily assign all closed-loop eigenvalues by linear static state feed 
back if and only if the system is completely controllable. This relation to controlla 
bility is, in fact, the motivation for introducing state feedback at this point. Feedback 
control is considered again in Chapter 7, where polynomial matrix descriptions are 
introduced. 
In the study of state feedback  it is assumed that it is possible to measure the 
values of the states using appropriate sensors. Frequently, however, it may be either 
impossible or impractical to obtain measurements for all states. It is therefore desir 
able to be able to estimate the states from measurements of input and output variables 
that are typically available. In addition to feedback control problems, there are many 
other problems where knowledge of the state vector is desirable since such knowl 
edge contains useful  information  about the system. This is the case, for example, 
in navigation systems. State observers that asymptotically estimate the states from 
input and output measurements over time are also studied in this chapter. 
State estimation is related to observability in an analogous way that state feed 
back  control  is related  to  controllability.  The  duality  between  controllability  and 
321 
322 
Linear Systems 
observability  makes  it  possible  to  easily  solve  the  estimation  problem  once  the 
control  problem  has  been  solved,  and  vice  versa.  In  this  chapter,  full-order  and 
reduced-order asymptotic estimators, also called observers, are discussed at length in 
Section 4.3. Finally, state feedback  static controllers and state dynamic observers are 
combined to form dynamic output feedback  controllers. Such controllers are studied 
in Section 4.4, using both state-space and transfer  function  matrix  descriptions. 
4.1 
INTRODUCTION 
A.  A Brief  Introduction  to State Feedback  Controllers 
and State  Observers 
In  the  following  discussion,  state feedback  and  state  estimation  are  introduced  for 
continuous- and discrete-time time-varying  and time-invariant  systems. 
We consider  systems described by equations of the  form 
i:  =  A{t)x  +  B{t)u, 
y  =  C(t)x  +  D(t)u, 
(1.1) 
where  t  G  (a, b),  some real  open  interval,  and  A(t)  G  R''^'',  B{t)  G W'^'^^  C(t)  G 
"j^pxn^  £)(r)  G  RP^^^  and  u(t)  G  R""^ are  (piecewise)  continuous  in  t  on  (a", b)  (see 
Chapter 2). 
Let  the input  u be determined  by  a time-varying  linear, state feedback  control 
law of the  form 
u  =  F{t)x  +  r, 
(1.2) 
where  F{t)  G  R^^^  is  (piecewise)  continuous  in  f  G  {a, b),  the  elements  of  F(t) 
represent  time-dependent  gains,  and  r(t)  G  R^  is  an  external  input  (see  Fig. 4.1). 
Substituting  into  (1.1),  the  state-space  description  of  the  compensated  or  closed-
loop system  is given by is given by 
X =  [A(0  +  B(t)F(t)]x  +  B(t)r 
y  -  [C(0  +  D(t)F(t)]x  +  D(t)r 
(1.3) 
We seek to select F(t)  so that the closed-loop  system has certain  desirable  qualita 
tive properties. For example, we may wish the closed-loop system to be stable. (For 
definitions  of stability in the time-varying  case, refer  to Chapter 6.) Stability can be 
achieved  under  appropriate  assumptions  involving  certain  types  of  controllability. 
One way of determining  such stabilizing F(t)  is to use results from the optimal Lin 
ear Quadratic Regulator  (LQR) theory," which in fact yields the ""best"" F(t)  in  some "
System 
+T 
FIGURE 4.1 
sense. Stabilization,  or the achievement  of other control  objectives,  for  linear  time- 
varying  systems  via LQR  or other methods  will not be  studied  in this chapter.  The 
stabilization  of linear time-invariant  systems, however,  is discussed  at great length 
in Section 4.2. 
In  the  time-invariant  case  we  consider  systems  described  by  equations  of  the 
323 
CHAPTER 4: 
state Feedback 
and State 
Observers 
form 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
"where A  E  /?^x^ B  G /^^X""^"," C  G J?^><^ and D  G  RP""""""^.  Let "
u  =  Fx  + r 
(1.4) 
(1.5) 
represent the linear time-invariant  or static state feedback  control law. The  compen 
sated  or closed-loop  system  is then given by the  equations 
i  -  (A +  BF)x  + Br, 
y  =  (C  -\-  DF)x  +  Dr 
(1.6) 
In control design, the gain matrix F is selected  so that the closed-loop  system  (1.6) 
has desired behavior. In this chapter we are particularly  interested  in selecting F to 
stabilize  the  system,  and  we  will  concentrate  on  the  eigenvalue  assignment  prob 
lem.  In particular,  it is  shown  in  the  next  section  that  the  controllable  eigenvalues 
of  the  system  [i.e.,  of  the  pair  (A  +  BF,  B)]  can  be  assigned  (or  shifted)  to  arbi 
trary  locations,  and  therefore,  can  be  assigned  to  locations  that  guarantee  stable 
behavior. 
In view of the results developed in the previous chapter, the central role played 
by controllability  in feedback  stabilization  is most easily  seen in the  time-invariant 
case.  Recall  that  controllability  reflects  the  ability  of  an  input  to transfer  the  state 
of  a  system  to  any  desirable  (state)  value.  It  was  shown  in  Section  3.4  that  given 
a  time-invariant  system  {A, B, C, D}, there  exists  a transformation  so that  the  con 
trollable part  of the  state  space  can  easily  be recognized.  In  other  words, there  ex 
ists  a  basis  for  the  state  space,  so  that  all  controllable  states  have  representations 
of  the  form  [x[, 0^]^  and  the  uncontrollable  state  representations  are  of  the  form 
[x[, X2V,  where X2 =  A2X2, i.e., X2 is independent of u (see Subsection 3.4A). The 
eigenvalues  of A2 are in this case the uncontrollable  eigenvalues that correspond to 
the uncontrollable modes of the system. Since u has no effect  on X2, it is reasonable 
to conjecture that the state feedback  control law (which in fact, is a particular choice 
for u) will not at all affect  the eigenvalues of A2, for if it did, it would also affect X2. 
This conjecture  turns out to be true and will formally  be  shown in the next  section. 
The controllable states can now arbitrarily be shifted, using u. This in turn means that 
the controllable eigenvalues can be arbitrarily  shifted,  using w, or more correctly, by 
appropriately  selecting  u in xi  =  AiXi  -\-  Biu  -^ A12X2,  xi  may be made to behave 
as if the eigenvalues of Ai  were arbitrarily shifted.  This is true because if there were 
restrictions  on  the  location  of  the  eigenvalues,  then  the  state  would  not  be  able  to 
be shifted  arbitrarily, which is a contradiction. It turns out that linear state  feedback 
control provides  such  u, and therefore,  it can  arbitrarily  shift  all the eigenvalues  of 
a  system.  This  will formally  be  shown  in  Section  4.2. A  stabilizing  state  feedback 
matrix F may  also be determined  as the solution to an optimal control problem,  the 
Linear  Quadratic  Regulator  (LQR) problem. This is briefly  addressed  at the end of 
Section 4.2. 
324 
Linear Systems 
We will  also  consider  time-varying  discrete-time  systems,  described  by  equa 
tions of the  form 
x{k  +  1)  =  A{k)x{k)  + B{k)u{k), 
y(k)  =  C(k)x(k)  +  D{k)u{k) 
(1.7) 
with linear, discrete-time,  time-varying  state-feedback  control  law given by 
u{k)  =  F(k)x(k)  +  r(k), 
(1.8) 
In this case, the closed-loop system is given by 
x(k  +  1)  =  [A(k)  -h B(k)F(k)]x(k)  +  B(k)r(k) 
y(k)  =  [C(k)  +  D(k)F(k)]x(k)  +  Dik)r(k). 
(1.9) 
Also, we will consider time-invariant  discrete-time  systems described  by 
x(k  +  1)  =  Ax(k)  +  Bu(k), 
y(k)  =  Cx(k)  +  Du(k) 
(1.10) 
with linear, discrete-time,  time-invariant  state-feedback  control law (time-invariant) 
given by 
u{k)  =  Fx(k)  +  r(k\ 
(1.11) 
In this case the closed-loop system assumes the  form 
x(k  +  1)  -  [A +  BF]x(k)  +  Br(k) 
y(k)  =  [C +  DF]x(k)  +  Dr(k). 
(1.12) 
As in the continuous-time  case, stabilization is emphasized  in this chapter, and cor 
responding results are developed. 
In (continuous-time)  state-space system representations, if the value of the state 
at time  to, x(to),  is known, then the input  u(t), t  >  ^,  uniquely  determines  x(t)  and 
y(t)  for t  ^  to. Since knowledge of the initial value of the state is of such importance, 
methods of determining (estimating) x(to) from input and output measurements have 
been devised  (see Fig. 4.2). 
Methods  of  estimating  the  initial  value  of  the  state,  x(0),  in  time-invariant 
systems  are  addressed  in  Section  4.3. In  particular,  full-  and  reduced-order  state 
observers  are  designed  that  asymptotically  estimate  the  state.  Since  controllability 
(-from-the-origin,  or reachability)  was  the  key  property  in  state  feedback  control, 
the dual property of observabihty,  studied in Section 3.3, is the key attribute in state 
estimation.  Recall  that  observability  refers  to  the  ability  of  determining  the  state 
from  measurements  of  the  output  and  input  over  a  finite  time  interval.  (See,  for 
instance. Corollary  3.8 in Chapter  3, where the initial  state is determined  using  the 
observability Gramian of the system.) Furthermore, since the solution to the optimal 
u 
Sysiern 
y 
State  observer 
\ ,* 
FIGURE 4.2 
LQR  control problem  leads to optimal  state-feedback  control  law  matrices  [F(t)  or 
F], a dual optimal estimation problem can be defined, the solution of which provides 
optimal state-observer gain matrices [K(t) or K]. Corresponding discrete-time results 
on  state  estimation  are  also  discussed.  In  addition,  in  Section  4.4,  state  feedback 
control laws and  state estimation  are combined  to derive a dynamic-observer  based 
controller that receives feedback information, not from the state, but from the outputs 
of the system to be controlled. These are typically more accessible. 
325 
CHAPTER 4: 
state Feedback 
and State 
Observers 
B.  Chapter  Description 
In this chapter state feedback  controllers and asymptotic state estimators, also called 
state  observers,  are  introduced  and  studied.  The  contents  of  the  chapter  were  out 
lined and briefly  discussed in the previous subsection  (Subsection 4.1 A). A detailed 
summary  follows. 
A  brief  introduction  to  state  feedback  controllers  and  state  observers  for 
continuous-time  and discrete-time  systems is given in Subsection 4.1 A. 
In  Section  4.2,  state  feedback  control  is  studied.  Our  development  focuses  on 
time-invariant  systems.  First,  the  need  for  feedback  is  demonstrated  by  a  discus 
sion of open- and closed-loop control laws, and their differences  when  uncertainties 
are  present  in  the  system  model  and  its  environment.  The  stabilization  of  sys 
tems  is  emphasized.  This  leads,  in  the  time-invariant  case,  to  the  eigenvalue  (or 
pole)  assignment  problem,  which  is  studied  next  at  length.  The  flexibility  offered 
in  the  multi-input  case  in  the  choice  of  the  state  feedback  gains  to  accomplish 
control  goals,  in  addition  to  pole  assignment,  is  stressed.  A  number  of  pole  as 
signment methods are introduced, including the eigenvalue/eigenvector  assignment 
method;  an  additional,  historically  important  method  is presented  in  Exercise  4.2. 
It  is  pointed  out  that  stabilization  can  also  be  achieved  by  an  optimal  control  for 
mulation,  such  as  the  Linear  Quadratic  Regulator  (LQR),  which  leads  to  a  stabi 
lizing  state  feedback  control  law  while  attaining  additional  control  goals  as  well. 
The  LQR  problem  is  briefly  discussed  for  both  the  continuous-  and  discrete-time 
cases. 
In  Section 4.3, full-order,  full-state,  and partial-state  observers  for  continuous-
and  discrete-time  systems  are  studied.  Also, reduced-order  and  optimal  observers 
are addressed. In the discrete-time case, current state estimators are also introduced. 
Optimal  Linear  Quadratic  Gaussian  (LQG)  estimators  are  briefly  discussed.  The 
duality  of  the  state  feedback  and  the  state  observer  problems  is  emphasized.  It  is 
pointed out that the main factor that limits the magnitude of the gains in observers is 
noise. This is in contrast to the limiting factor  in the magnitude of the control gains, 
which is limitations of the control actuators and of the linear model used to describe 
the  system. 
In  Section  4.4,  dynamic  state  observers  are  used,  together  with  static  state 
feedback  controllers,  to  derive  dynamic  output  controllers.' The  Separation  Prin 
ciple  is  discussed  and  the  degradation  of  performance  in  state  feedback  control 
when  an  observer  is  used  to  estimate  the  state  is  explained.  The  analysis  is  ac 
complished  in  both  state-space  and  transfer  function  frameworks.  Furthermore, 
additional  output  controller  configurations  are  also  derived  in  terms  of  state-space 
representations. 
326 
Linear Systems 
C.  Guidelines  for  the  Reader 
In this chapter, Unear state feedback  controllers  and linear state observers for  linear 
time-invariant  systems  are  studied.  Subsection  4,IB  describes  the  contents  of  the 
chapter. 
At a first reading, one can cover selected topics from the material on state  feed 
back and state observers in Sections 4.2 and 4.3, respectively. Regarding Section 4.2 
on  state  feedback,  after  studying  the  issues  associated  with  open-  and  closed-loop 
control  in  Subsection  4.2A,  one could  concentrate  on eigenvalue  assignment  using 
linear state feedback. In particular, one could study Theorem 2.1 in Subsection 4.2B, 
which  shows  that  only  the  controllable  eigenvalues  can be  arbitrarily  assigned  via 
state feedback;  then  one could  study the methodologies  to assign  desired  eigenval 
ues (and in part, the corresponding  eigenvectors  as well). Regarding  Section 4.3 on 
state observers, at a first reading  one could concentrate  only on full-order  full-state 
observers  for  continuous-time  systems  in  Subsection  4.3A.  Then  one  could  study 
dynamic output feedback  controllers that are based on state observers in Section 4.4. 
The degradation  of performance  when  an observer is used to estimate the state in a 
state feedback  controller is also discussed in that  section. 
4.2 
LINEAR  STATE  FEEDBACK 
A.  Continuous-Time  Systems 
We consider linear, time-invariant, continuous-time  systems described by  equations 
of the  form 
x  =  Ax  + Bu, 
y  =  Cx  + Du, 
(2.1) 
"where A  G /?""><^ B  G /e'^x^", C  G /^^x^ and D  G /?^><^. 
DEFINITION  2.1.  The linear,  time-invariant, state feedback control law is defined by 
where F  G R^^^  is a gain matrix and r{t) G R^ is an extemal input vector. 
u  = Fx  + r, 
(2.2) 
• 
Note  that  r{t)  is  an  external  input,  also  called  a  command  or  reference  input 
(see Fig. 4.1). It is used to provide an input to the compensated  closed-loop  system 
and  is  omitted  when  such  input  is  not  necessary  in  a given  discussion  [r{t)  =  0]. 
This  is  the  case,  e.g.,  when  the  Lyapunov  stability  of  a  system  is  studied.  Note 
that  the  vector  r(t)  in  (2.2)  has  the  same  dimension  as  u(t).  If  a  different  number 
of  inputs  is  desired,  then  an  input  transformation  map  may  be  used  to  accomplish 
this. 
The compensated  closed-loop  system  of Fig. 4.1 is described by the  equations 
i  =  (A +  BF)x  +  Br 
y  =  {C + DF)x  +  Dr, 
(2.3) 
which  were determined  by  substituting  u  =  Fx  ^- r into the description  of the un 
compensated  open-loop  system  (2.1). 
327 
CHAPTER 4: 
State Feedback 
and State 
Observers 
The state feedback  gain  matrix  F affects  the closed-loop system behavior.  This 
is accomplished by altering the dynamic effects  of the matrices A  and  C of (2.1). In 
fact, the main influence of Fis exercised through the matrix A, resulting in the matrix 
A + BF  of the closed-loop system. The matrix F affects  the eigenvalues of A +  BF, 
and  therefore,  the  modes  of  the  closed-loop  system.  The  effects  of  F  can  also  be 
thought of as restricting the choices for w (=  Fx  for r  =  0) so that for appropriate F, 
certain properties, such as asymptotic Lyapunov  stability, of the equilibrium  x  =  0 
are obtained. 
Open- and closed-loop  control 
The  linear  state  feedback  control  law  (2.2)  can  be  expressed  in  terms  of  the 
initial  state  x(0)  =  XQ. In  particular,  working  with  Laplace  transforms,  we  obtain 
u  =  Fx-^f  =  F[(^/-A)~^xo  + (^/-A)~^Bw]-t-f, inviewof  ^-x-xo  =  Ax  +  Bu, 
derived  from  x  =  Ax  + Bu.  Collecting  terms,  we  have  [/  -  F{sl  -  A)~^B^u  = 
F(sl  -  A)~^xo  +  r. This yields 
u  =  F[sl  -  (A +  BF)r^xo  +  [/  -  F(sl  -  Ay^BV^r, 
(2.4) 
where the matrix identities  [/  -  F(sl  -  A)-^Br^F(sI 
BF(sI  -  A)-i]-i  ^  F[sl  -  (A +  BF)]-^  have been  used. 
"-  A)""^  =  F(sl  -  Ay^[I "
-
Expression  (2.4)  is  an  open-loop  (feedforward)  control  law,  expressed  in  the 
Laplace transform  domain. It is phrased in terms of the initial conditions x(0)  =  XQ, 
and if it is applied to the open-loop system (2.1), it generates exactly the same control 
action  u(t)  for  r >  0  as  the  state  feedback  u  =  Fx  -\-  r  in  (2.2). It  can  readily  be 
verified  that the descriptions  of the compensated  system are exactly the same when 
either control expressions, (2.2) or (2.4), are used (verify  this). In practice, however, 
these two control laws hardly behave the same, as explained in the  following. 
First, notice that in the open-loop  scheme  (2.4) the initial conditions  XQ  are as 
sumed to be known exactly. It is also assumed that the plant parameters in A and B 
are known  exactly.  If  there  are  uncertainties  in  the  data,  this  control  law  may  fail 
miserably, even when the differences  are small, since it is based on incorrect  infor 
mation  without  any way  of knowing  that these data are not valid. In contrast to the 
above,  the  feedback  law  (2.2)  does  not  require  knowledge  of  XQ. Moreover,  it  re 
ceives feedback  information  from  x(t)  and adjusts  u(t)  to reflect  the current  system 
parameters, and consequently, is more robust to parameter variations. Of course the 
feedback  control law (2.2) will also fail when the parameter variations are too large. 
In  fact,  the  area  of  robust  control  relates  feedback  control  law  designs  to  bounds 
on  the  uncertainties  (due  to  possible  changes)  and  aims  to  derive  the  best  design 
possible under the circumstances. 
The  point  we  wish  to  emphasize  here  is  that  although  open-  and  closed-loop 
control laws may appear to produce identical effects,  typically  they do not, the rea 
son being  that  the mathematical  system  models  used  are  not  sufficiently  accurate, 
by  necessity  or  design.  Feedback  control  and  closed-loop  control  are  preferred  to 
accommodate ever-present modeling uncertainties in the plant and the environment. 
The purpose of controlling a system is to achieve certain control goals. Examples 
include tracking a given trajectory,  regulating the state so that it returns to the origin 
if it is disturbed,  and stabilizing a system. Stabilization is discussed at length in this 
chapter.  Regulation  and  tracking,  together  with  other  control  problems,  are  briefly 
discussed  in  Chapter  7,  where  output  feedback  compensation,  in  addition  to  state 
feedback  compensation, is used. 
328 
Linear Systems 
At this point, a few observations are in order. First, we note that feeding back the 
^^ate in synthesizing a control law is a very powerful  mechanism, since the state con 
tains all the information  about the past history of a system that is needed to uniquely 
determine the future system behavior, given the input. We observe that the state feed 
back control law considered presently is linear, resulting in a closed-loop system that 
is also linear. Nonlinear  state feedback  control laws are of course also possible. No 
tice that when a time-invariant  system is considered,  the state feedback  is typically 
static,  unless  there  is  no  choice  (as  in  certain  optimal  control  problems),  resulting 
in a closed-loop  system that is also time-invariant. These comments justify  to a cer 
tain extent the choice of linear, time-invariant,  state feedback  control to compensate 
linear time-invariant  systems. 
The problem of stabilizing  a system by using state feedback  is considered  next. 
Stabilization 
The problem  we wish  to consider now  is to determine  a state feedback  control 
law  (2.2)  having  the  property  that  the  resulting  compensated  closed-loop  system 
has  an  equilibrium  x  =  0 that  is  asymptotically  stable  (in  the  sense  of  Lyapunov) 
when  r  =  0. (For a discussion of asymptotic  stability, refer  to Chapters 2 and 6.) In 
particular, we wish to determine a matrix F  G R^^^  so that the  system 
i:  =  (A +  BF)x, 
(2.5) 
where A G R^^^midB  E  7?'^^'^, has equilibrium x  =  0 that is asymptotically stable. 
Note that (2.5) was obtained from  (2.3) by letting  r  =  0. 
One method of deriving  such  stabilizing F is by formulating  the problem  as an 
optimal  control  problem,  e.g.,  as  the  Linear  Quadratic  Regulator  (LQR)  problem. 
This  is discussed  at the end  of this  section. We point  out that  an LQR  formulation 
can also be used to derive stabilizing gains F(t)  in the time-varying  case so that the 
equilibrium  x  =  0  of  the  system  x  =  [A(t)  +  B(t)F(t)]x  is  asymptotically  stable. 
However, this will not be pursued here. 
Alternatively,  in view  of Chapter  2 (and  Chapter  6), the equilibrium  x  =  0 of 
(2.5)  is  asymptotically  stable  if  and  only  if  the  eigenvalues  A/ of  A +  BF  satisfy 
Re  A/ <  0, /  =  1,...,  n. Therefore,  the stabilization  problem  for  the  time-invariant 
case reduces to the problem of selecting F in such a manner that the eigenvalues of 
A +  BF  are shifted  into desired locations. This will be studied in the following  sub 
section. Note that stabilization is only one of the control objectives, although a most 
important  one, that can be achieved  by  shifting  eigenvalues.  Since the  eigenvalues 
of  a linear  system  determine  its  qualitative  dynamic  behavior  (refer  to the  discus 
sion  of  modes  in  Chapter  2),  one  can  attain  a number  of  control  goals  by  shifting 
of eigenvalues, in addition to stability. Control  system design  via eigenvalue  (pole) 
assignment is a topic that is addressed in detail in a number of control books. 
B.  Eigenvalue  Assignment 
Consider again the closed-loop system i  =  (A + BF)x  given in (2.5). We shall show 
that if (A, B) is fully  controllable (-from-the-origin,  or reachable), all eigenvalues of 
A + BF  can be arbitrarily assigned by appropriately  selecting F. In other words," ""the "
"eigenvalues of the original system can arbitrarily be changed in this case."" This last "
statement,  commonly  used  in  the  literature,  is  rather  confusing:  The  eigenvalues 
of  a  given  system  x  =  Ax  +  Bu,  are  not  physically  changed  by  the  use  of  feed 
back.  They  are  the  same  as  they  used  to  be  before  the  introduction  of  feedback. 
Instead,  the  feedback  law  u  =  Fx  ~\-  r,  r  =  0,  generates  an  input  u(t)  that,  when 
fed  back  to  the  system,  makes  it behave  as  if the  eigenvalues  of  the  system  were  at 
different  locations  [i.e.,  the  input  u(t)  makes  it  behave  as  a  different  system,  the 
behavior  of  which  is,  we  hope,  more  desirable  than  the  behavior  of  the  original 
system]. 
329 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
"THEOREM2.1.  GivenA  G /?""><"" a n d5  G Z?""^'"""," there exists F  G /?""""><"" such that then "
eigenvalues of A + BF  can be assigned to arbitrary, real or complex conjugate,  locations 
if and only if (A, B) is controllable  (-from-the-origin,  or reachable). 
Proof.  (Necessity)  Suppose  that  the  eigenvalues  of  A +  BF  have  been  arbitrarily  as 
signed  and  assume that  (A, B)  in (2.1) is not fully  controllable. We shall  show that  this 
leads  to a contradiction.  Since  (A, B)  is not fully  controllable,  in view  of the results  in 
Section  3.4  in  Chapter  3, there  exists  a similarity  transformation  that  will  separate  the 
controllable  part from  the uncontrollable  part in  (2.5). In particular,  there  exists  a non-
singular matrix  Q such that 
Q-\A 
+  BF)Q  =  Q-'AQ 
+  (Q-'B)(FQ) 
= 
Ai 
0 
An 
Ai. 
{F,,F2\ 
Ai  +  BiFi 
Ai2 + BxF2 
0 
A2 
(2.6) 
where  [Fi, F2]  =  FQ  and  {A\,Bi) 
is controllable.  The  eigenvalues  of A +  BF  are  the 
same  as  the  eigenvalues  of  Q~^{A  +  BF)Q,  which  implies  that  A  +  BF  has  certain 
fixed  eigenvalues,  the  eigenvalues  of  A2, that  cannot  be  shifted  via  F.  These  are  the 
uncontrollable  eigenvalues  of  the  system.  Therefore,  the  eigenvalues  of  A +  BF  have 
not  been  arbitrarily  assigned,  which  is  a  contradiction.  Thus,  (A, B)  is  fully  control 
lable. 
(Sufficiency)  Let  (A, B)  be fully  controllable. Then by using  any of the  eigenvalue 
assignment algorithms presented later in this section, all the eigenvalues of A +  BF  can 
be arbitrarily  assigned. 
• 
LEMMA 2.2.  The uncontrollable eigenvalues of (A, B) cannot be shifted  via state  feed 
back. 
Proof  See the necessity part of the proof  of Theorem  2.1. Note that the  uncontrollable 
eigenvalues  are the eigenvalues of A2. 
• 
EXAMPLE  2.1.  Consider  the  uncontrollable  pair  (A, 5),  where  A  = 
0 
-2 
1  -3 
,  B  = 
. This pair can be transformed  to a standard form for uncontrollable systems, namely, 
A  = 
-2 
0 
1 
-1 
B  = 
, from which it can easily be seen that -1  is the uncontrollable 
eigenvalue, while  -2  is the controllable eigenvalue (see also Example 4.3 in Chapter 3). 
NowifF  =  [f,f2lihendet(sI-(A 
+ BF))  =  det\ 
\~  ^\ 
]_~^^\ 
L -1  -  Jl  S + 3- 
f2_ 
-f2  + 3) + (-f-f2 
s(-f\ 
eigenvalue  -1  cannot be shifted  via state feedback.  The controllable eigenvalue  -2  can 
• 
be shifted  arbitrarily  to (f  +  /s  -  2) by F  =  [/i,  /2]. 
+ 2)  =  (s+  l)(s  + ( - /i  -  /2 + 2)). Clearly, the uncontrollable 
330 
Linear Systems 
It is now quite clear that a given system (2.1) can be made asymptotically  stable 
via the state feedback  control law (2.2) only when all the uncontrollable  eigenvalues 
of  (A, B)  are  already  in  the  open  left  part  of  the  s-plane.  This  is  so because  state 
feedback  can alter only the controllable  eigenvalues. 
DEFINITION 2.2.  The pair (A, B) is called stabilizable if all its uncontrollable eigen 
values are stable. 
• 
Before presenting methods to select F for eigenvalue assignment, it is of interest 
to examine  how  the linear  feedback  control  law  u  =  Fx  + r given  in  (2.2)  affects 
controllability  and observability. We write 
si  -{A  +  BF)  B 
D 
-{C  +  DF) 
si-A 
-c 
B\ 
D\ 
\  ^  ^ 
[-F 
I 
(2.7) 
and note that 
rank [A/ -  (A +  BF),  B]  =  rank [XI -  A, B] 
for  all complex  A (show this). Thus, if (A, B) is controllable, then  so is (A +  BF,  B) 
for  any F. Further, notice that in view of 
%F =  [B, (A  +  BF)B,  (A +  BFfB,..., 
(A +  BF^'^  ^ 
'B] 
I  FB  F(A  +  BF)B 
0 
/ 
FB 
I 
= 
[B,AB,A^B,...,A''~'B] 
(2.8) 
gi(^/r)  =  ^([B,  AB,...,  A^-i^])  =  S/l(^) (why?). This shows that F does not alter 
the controllability  subspace of the system  (see Section 3.2.). This in turn proves the 
following  lemma. 
LE M M A 2.3.  The controllability subspaces of x 
are the same for any F. 
Ax + Bu and i: =  (A + BF)x + Br 
Although the controllability  of the system is not altered by linear state  feedback 
u  == Fx  + r, this is not true for the observability property. Note that the observability 
of the closed-loop system (2.3) depends on the matrices (A + BF)  and (C + DF),  and 
it is possible to select F to make certain eigenvalues unobservable from the output. In 
fact this mechanism is quite common and is used in several control design methods. 
It is  also possible  to make  observable  certain  eigenvalues  of  the  open-loop  system 
that were unobservable; for an example  see Example 2.8 below. 
Several methods are now presented to select F so to arbitrarily assign the closed-
loop eigenvalues. 
Methods for eigenvalue assignment by state  feedback 
In view of Theorem  2.1, the eigenvalue  assignment  problem  can now be  stated 
as follows. Given a controllable pair (A, B), determine F to assign the n eigenvalues 
of A + BF  to arbitrary real and/or complex conjugate locations. This problem is also 
known  as the pole  assignment  problem,"  where by the term  ""pole"" is meant  a ""pole "
"of the system"" (or an eigenvalue of the ""A"" matrix). This is to be distinguished  from "
"the ""poles of the transfer  function""  (see Section 3.5 for the appropriate  definitions). "
Note that all matrices A, B, and F are real, so the coefficients  of the polynomial 
det [si  -  (A + BF)}  are also real. This imposes the restriction that the complex roots 
of  this  polynomial  must  appear  in  conjugate  pairs.  Also,  note  that  if  (A, B)  is  not 
fully  controllable, then (2.6) can be used together with the methods described a little 
later, to assign all the controllable eigenvalues; the uncontrollable  ones will remain 
fixed (see Theorem 2.1 and Lemma  2.2). 
It is assumed in the following  that B has full  column rank, i.e.. 
331 
CHAPTER 4: 
state Feedback 
and State 
Observers 
rank  B  =  m. 
(2.9) 
This means  that the  system  x  =  Ax  + Bu  has m independent  inputs. If  rank  B  = 
r  <  m, this would imply that one could achieve the same result by manipulating only 
r inputs  (instead  of m >  r). To assign eigenvalues  in this case, one can proceed  by 
writing 
A +  J5F  -  A +  (BM)(M-^F)  =  A  + [5i, 0] 
A +  5iFi, 
(2.10) 
where M  is chosen  so that  BM  =  [Bi," 0]  with  Bi  G  T?""^'* and  rank  Bi  =  r.  Then "
Fi  G R^^^  can be determined to assign the eigenvalues of A +  BiFi,  using any one 
of the methods  presented  next.  Note that  (A, B)  is controllable  implies  that  (A,  Bi) 
is controllable (why?). The state feedback  matrix F is given in this case by 
F  =  M 
(2.11) 
where F2 G R(^-^)^n  is  arbitrary. 
/.  Direct  method.  Let F  =  [fij],  i  =  1,...,  m, j  =  \,.. 
.,n,  and  express  the 
coefficients  of the characteristic polynomial of A +  BF  in terms of fij,  i.e., 
det {si  -  (A +  BF))  =  s-  + gn-iifiX'' 
+  • • • +  goifijl 
Now if the roots of the polynomial 
"(^d(s) =  ^"" +  dn-lS""""  ^ +  • • • +  Ji^  +  Jo "
are the n desired  eigenvalues, then the  fij,  i  =  \,.. 
termined  so that 
.,m,  j  =  1, 
, n, must be de-
gk(fij)  =  dk, 
A: =  0, 1, . . . , n-  1. 
(2.12) 
In  general,  (2.12)  constitutes  a nonlinear  system  of  algebraic  equations;  how 
ever, it is linear in the single-input  case, m  =  \.  The main difficulty  in this method 
is not so much in deriving a numerical solution for the nonlinear system of equations, 
but in carrying out the symbolic manipulations needed to determine the  coefficients 
g]^  in  terms  of  the  ftj  in  (2.12). This  difficulty  usually  restricts  this  method  to  the 
simplest cases, with n  =  2 or 3 and m  =  1 or 2 being typical. 
EXAMPLE  2.2.  For  A 
[B 
we have det (si  -  A)  = s(s -  5/2), and 
therefore, the eigenvalues of A are 0 and  |.  We wish to determine F so that the eigen 
values of A + BF are at -1  ± 7. 
332 
Linear Systems 
IfF  =  [fu f2lihQndet(sI-(A  + BF))  = det 
-1 
s-2 
-1 
[fl,f2]]  = 
det 
s-\-fi 
- l - /i 
- 1 - /2 
s-2-f2_ 
=  s^ + s{-l  -  fi  -  f2) + f\  -  Ifi.  The desired eigen-
values are the roots of the polynomial 
aM  =  (^ -  (-1  + Ms  -  (-1  -  j))  ^  s^ + 2s + 2. 
Equating  coefficients,  one obtains  -\  —  fi  -  fi  = 2, fi  -  \f2  =  2, a. linear  system 
of equations. Note that it is linear because m  =  1. In general one must solve a set of 
nonlinear algebraic equations. We have 
as the appropriate state feedback matrix. 
• 
F = [fuf2]  = 
[-l-'i] 
2.  The use of controller forms.  Given that the pair (A, B) is controllable, there 
exists an equivalence transformation  matrix P  so that the pair (Ac  =  PAP~^,Bc  = 
PB)  is  in  controller  form  (see  Section  3.4).  The  matrices  A  +  BF  and  P(A  + 
BF)P~^  =  PAP~^  +  PBFP-^  =  Ac  -^ BcFc have  the  same eigenvalues,  and  the 
problem is to determine Fc so that Ac + BcFc has desired eigenvalues. This problem 
is  easier  to  solve than  the  original  one because  of  the  special  structures  of  Ac  and 
Be. Once Fc has been determined, then the original feedback  matrix F is given by 
FrP 
(2.13) 
We shall now^ assume that (A, B)  has already been reduced  to (A^, Be) and  describe 
methods of deriving Fc for eigenvalue  assignment. 
Consider first the single-input case (m  =  1). We let 
"Fc  -  [fo>  ""  -y  fn-l]' "
(2.14) 
In view^ of Section 3.4, since A^  Be are in controller form,  v^e have 
AcF  =  Ac +  BcFc 
1 
0 
0 
-ao 
0 
-ax 
0 
0 
0 
0 
1 
Oin-\ 
"""o"" "
[/O. •••> 
fn-\\ 
+ 
0 
1 
(2.15) 
-(<^o  -  /o) 
- ( «i  -  /i) 
-{pin-\  - 
fn-\) 
where  a/,  /  =  0 , . . .,  n  -  1, are the coefficients  of the  characteristic  polynomial  of 
Ac, i.e., 
"det{sl  -  Ac)  =  s""""  + an-is""""'^  +  • • • 4- a:i^  +  ao- "
(2.16) 
Notice that  ACF  is also in companion  form  and its characteristic  polynomial  can be 
written directly  as 
"det{sl  -  ACF)  =  S-  + {dn-i  ~  fn-Ds""""-'  +  ' ''  +  (CQ  ""  /Q). "
(2.17) 
If  the  desired  eigenvalues  are  the  roots  of  the  polynomial 
"aais)  =  s"""" +  dn-is""""-^  +  • • • +  ^o", 
(2.18) 
then  by  equating  coefficients,  fi,i  =  0,  1 , . . .,  n  -  1, must  satisfy  the relations  dt  = 
at  -  fiJ  =  0,1,.. 
-  1, from  which  we  obtain 
.,n 
333 
CHAPTER 4: 
State Feedback 
and  State 
Observers 
fi 
«/  -  di. 
0,...,n-h 
(2.19) 
Alternatively,  note  that  there  exists  a matrix  A^  in  companion  form,  the  charac 
teristic  polynomial  of  which  is  (2.18).  An  alternative  way  of  deriving  (2.19)  is  then 
to  set  AcF  =  Ac  +  BcFc  =  A^,  from  which  we  obtain 
Fc  = 
B-'[A.-Aml 
(2.20) 
where  Bm  =  1, Aj^  =  [-do,..., 
- a „ - i ].  Therefore, 
Bm,  Aj^,  and  A^  are  the  nth  rows  of  B^  A^,  and  A^, respectively  (see  Section  3.4). 
Relationship  (2.20), which  is an  alternative  formula  to (2.19), has  the  advantage  that 
it is  in  a form  that  can  be  generalized  to  the  multi-input  case. 
and  Am  =  [-OCQ,  ..., 
-d^-i] 
EXAMPLE2.3.  Consider the matrices  A 
B  = 
of Example 2.2. Deter 
mine F  so that the eigenvalues  of A +  BF  are  -1  ± 
the polynomial ad(s)  =  s^ + 2s  +  2. 
To reduce (A, B)  into the controller form,  let 
j,  i.e., so that they  are the roots of 
^  -  [B, AB]  = 
1 
3 
1  3 
and^ 
-1  _ 
3 
-1 
from which P 
qA 
and 
-2 
[see (4.44) in Chapter 3]. Then P'^  = 
-1 
i 
2 
Ar  =  PAP-^  = 
Br  = 
Thus, Am  =  [0, f ] and B^  =  I.  Now Aj  = 
1 
-2 
and Ad^  =  [ - 2 , - 2]  since the 
characteristic polynomial of A^ is ^^ +  2^ +  2  =  ad(s).  Applying  (2.20), we obtain that 
Fc  =  B-'[Ad^-Am] 
=  [ - 2 , - |] 
and  F  =  FcP  = 
[-2, 
r  2 
3 
1 
3 
- 
2J 
21 
3 
2 
3-
[-
- y]  assigns  the  eigenvalues  of  the 
closed-loop  system  at  -1  ±  j. This is the  same result  as the one obtained  by the  direct 
method given in Example 2.2, If  ad(s)  =  s^ + dis  +  do, then Aj^^  =  [-do,  -d\\  Fc  = 
B-J{Ad^  -  Am]  =  [-^0,  -dx  -  5/2], and 
F  =  FcP  = 
\[2do-di 
-2do  -  2di  -  5]. 
In general the larger the difference between the coefficients  of ad{s) and Q:(5'), (A^^  -Am), 
the larger the gains in F. This is as expected, since larger changes require in general larger 
• 
control action. 
Note  that  (2.20)  can  also be  derived  using  (4.63)  of  Section  3.4  in  Chapter  3. To 
see  this,  write 
AcF  =  Ac  +  BcFc  =  (Ac  +  BcAm)  +  {BcBm)Fc  =  A,  +  5 , ( A^  +  BmFd 
334 
Linear Systems 
where A^  Be are defined in (4.63). Selecting Aj  =  A^ + BcAd^ and requiring ACF  = 
Aj  implies 
Bc[Am +  BfnFc] =  BcAd^, 
from  which A^  +  5m^c  =  ^dm^ which in turn implies (2.20). 
After Fc has been found, to determine F so that A + BF  has desired eigenvalues, 
one  should  use F  =  FcP  given  in  (2.13). Note that P,  which  reduces  (A, B)  to the 
controller form, has a specific form in this case [see (4.44) of Section 3.4]. Combining 
these results, it is possible to derive a formula for the eigenvalue assigning F in terms 
of  the  original  pair  (A, B)  and  the  coefficients  of  the  desired  polynomial  a^is).  In 
particular, the  1 X n matrix F that assigns the n eigenvalues  of A +  BF  at the roots 
of a^is)  is given by 
F  =  -el%-^aM\ 
(2.21) 
where  Cn =  [0,...,  0," 1]^ G  R""""  and ^  =  [5", A 5 , . . .,  A^'-^B]  is the  controllability 
matrix.  Relation  (2.21)  is  known  as Ackermann's  formula  and  its  validity  will  be 
verified  shortly. 
Notice that the F that assigns the n eigenvalues of A + BF  is unique when m  = 
1.  This  is  not  difficult  to  see  from  the  preceding.  In  particular,  notice  that  Fc  = 
"[foy' ""y  fn-\\  is uniquely determined by (2.19) and that the transformation  matrix P "
is also unique in this case (m  =  1) and is in fact  given by (4.44) in Section  3.4. 
Verification  of Ackermann's  Formula 
Given  (A^, Be) in controller form,  it was shown that the matrix 
Fc  =  [o^Q  -  do,.  ..,an-\ 
-  dn-\\  =  5^^[Aj^  -  Ajn] 
assigns the eigenvalues of Ac + BcFc to the desired locations, the roots of a^is)  given 
in (2.18). The matrix Fc is related to Fby F  =  FcP, where Ac  =  PAP-\  Be  =  PB, 
and  P  =  ^c^~^  and  where ^  and %c are the controllability  matrices  of  (A, B)  and 
(Ac, Be), respectively. These relations will now be combined to derive  Ackermann's 
formula. 
First,  note that if  (2.21)  were used  for  a given  pair  (Ac, Be) in controller  form, 
then 
Fc  =  -el%-^aMc\ 
(2.22) 
We now show that this Fc assigns the n eigenvalues at the desired locations. In doing 
so,"  we  note  that  aj(Ac)  =  A^  +  ^„_iA""~^  +  • • • +  d\Ac  +  d(^l", which  in  view  of 
the Cayley-Hamilton Theorem  [namely," a{Ae)  =  A^ + a„_iA^""^  H "
V aol  =  0] 
assumes the  form 
n-l 
otd(Ac)  =  ^(di 
i = 0 
-  ai)A[, 
since  A^  =  -ZfJo^/AJ,.  Also  note  that  ef^c  =  e^  or  that  ^J^^~^  =  e\.  Now 
~el%-^ad{Ac)  =  -el{{do 
[ao-do,..., 
oin-\  -  dn-i]  =  Fe  of  (2.20),  that  is,  (2.22)  is  verified.  Note  that  the  last  relation 
was derived using the fact  that 
-  ao)I  +  •••  +  (d^-i  -  a^-M^^) 
= 
ejAc  =  el,  {e\ Ac) Ac  =  el Ac  =  4 , . . .,  ^f A^^'^  =  e^. 
from  which  -e^^do  -  ao)I  H  + {dn-i  -  an-i)A^  ^] =  (o^o -  <io)^f  + {oci -
di)el  H 
h {an-i  -  dn-i)el  = [ao -  dQ,,ai -  Ji,...,a^_i  -  dn-i].  In view of 
(2.22), we now have 
F =  FcP=-el^-'aMc)P 
335 
CHAPTER 4: 
State Feedback 
and State 
Observers 
which is Ackermann's  formula,  (2.21). 
EX AMPLE 2.4. To the system of Example 2.3 we apply (2.21) and obtain 
-el^t 
'ad{A) 
-[0,1] 
2 
2 
L  3 
-1] 
2 
3J 
/ 
( 
2 
il 
W 
2 
1  2 
+ 2 
•1 
2 
1 
"1"" "
2  + 2 
"""1 "
0 
"0"" "
1 
2  2 
I] 
3J 
""" 3' 3 "
"""17 "
4 
9 
2 
9 
2 
11 
[1 
-
~  L  6' 
13] 
3 J' 
which is identical to the F found in Example 2.3. 
• 
• 
Now  consider  the  multi-input  case  (m >  1).  We proceed  in a way  completely 
analogous to the single-input case. 
Assume  that Ac  and Be are in the controller  form,  (4.62), given  in  Section  3.4. 
Notice  that  ACF = A^ + BcFc is also in (controller)  companion  form  with  identical 
block structure as A(^ for any FQ. In fact, the pair  {AQF^BQ) has the same controllability 
indices  /i/,/ =  1,... ,m, as {Ac^Bc). This was  shown in Section  3.4 of Chapter  3 and 
can also be seen directly, using (4.63), since 
Ac  +  BcFc  —  {Ac  + BcAm)  +  {BcBm)Fc  — Ac + Bc{Am  +  BmFc), 
(2.23) 
where Ac  and Be are defined  in  (4.63). We can now  select  an n x n matrix Aj  with 
desired characteristic  polynomial 
det{sI  — Ad) = OJj(^)  =^^ + J^_i^^ 
-Jo, 
(2.24) 
and in companion  form,  having the  same block  structure  as ACF  or A^,  that is, Aj = 
Ac+BcAd^.  Now if AcF = Aj, then in view of (2.23), Bc{Am+BmFc)  = BcA^^.  From 
this it follows  that 
(2.25) 
where Bm^A^^, and A^  are the m Gjth rows of 5c,Aj,  and A^, respectively, and Gj = 
E/=i l^iij  = ^i---i^'  Note  that this  is a generalization of (2.20)  of  the  single-input 
case. 
F,=B-'[A^„-A^], 
We shall now show how to select an n x n matrix A j  in multivariable  companion 
form to have the desired characteristic  polynomial. 
One choice is 
"""0 "
1 
••• 
0 
Ad 
0 
-Jo 
0 
-di 
1 
-dn-l 
336 
Linear  Systems 
the  characteristic  polynomial  of  which  is  a^{s).  In  this  case  the  m  x  n  matrix A^^  is 
given  by 
'  0 
••• 
0 
1 
••• 
0 
••• 
^d^ 
0 
-do 
0 
0 
0 
0 
-dn-1 
where  the  ith  row,  / = l , . . . , m — l , is  zero  everywhere  except  at  the  (7/ +  1  column 
location,  where  it is  one. 
Another  choice  is  to  select  Aj  =  [Aij],iJ  =  1 , . .. ,m,  with  Aij  =  0  for  /  ^  7, 
i.e., 
[All 
0 
0 
A22 
••• 
••• 
0 
0 
Ad-
0 
0 
"noting  that  det  {si  — A^)  =  det  {si  — An)""- "
det  {sI — Amm).  Then 
"""0 "
1 
••• 
"0"" "
A, 
where the last row is selected  so that det  {si—An)  has desired roots. The  disadvantage 
of  this  selection  is that  it may  impose  unnecessary  restrictions  on  the  number  of  real 
eigenvalues  assigned.  For  example,  if  n  =  4,m  =  2  and  the  dimensions  of  An  and 
A22, which  are equal  to the controllability  indices,  are di=3 
and  d2 =  l,  then  two  of 
the  eigenvalues  must  be  real  (why?). 
There  are of course  other  selections  for A j,  and the reader is encouraged  to  come 
up  with  additional  choices.  A  point  that  should  be  quite  clear  by  now  is  that  Fc  (or 
F)  is  not  unique  in  the  present  case,  since  different  Fc  can  be  derived  for  differ 
ent  A j ^,  all  assigning  the  eigenvalues  at  the  same  desired  locations.  In  the  single-
input  case,  Fc  is  unique,  as  was  shown.  Therefore,  the  following  result  has  been 
shown. 
LEMMA  2.4.  Let  (A,5)  be  controllable  and  suppose  that  n desired  real  and  complex 
conjugate  eigenvalues for A + BF  have been  selected. The state feedback  matrix F  that 
assigns  all eigenvalues  of A +  BF  to  desired  locations  is not unique  in the  multi-input 
case  (m >  1). It is unique in the single-input  case m=  I. 
• 
EXAMPLE  2.5.  Consider the controllable pair  (A, 5),  where 
0 
0 
0 
1 
0 
2 
and 
"""0 "
1 
0 
r 
1 
0 
It was shown in Example 4.14 of Chapter 3, that this pair can be reduced to its controller 
form 
PAP-
0 
2 
1 
1 
-1 
0 
"""0 "
P  = 
0 
.1 
0' 
0 
0. 
0 
1 
0 
Be 
=  PB  = 
"'0  0"" "
1  1 
.0  1. 
11 
2 
1 
2 
1 
2 J 
where 
Suppose  we desire to assign  the eigenvalues  of A +  BF  to the  locations  {-2,  -1  ±  j}, 
i.e., at the roots of the polynomial ad(s)  =  (s + 2)(s'^ + 2s + 2)  =  s^ + As^ +  65' + 4. A 
choice for Ad is 
337 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
Adi  = 
1 
0 
0 
0 
-4 
-
and  F, ci 
B-^Ad 
0 
1 
- 4. 
A  J 
1 
.0 
-
-11 
ij 
r-2 
L-5 
1 
-6 
leading to A^^.  = 
0 
. -4 
0 
-6 
1  1 
0  1 
r 
-4 
1 
-4 
0 
-6 
7 
-6 
ively, 
Ad2  = 
"""  0 "
-2 
( 3 
-
1 
-2 
0 
0 
0 
-2 
and 
5 ; ^ [ A . , - AJ 
,  from  which Ad ^ 
= 
' -2 
0 
-2 
0 
0' 
-2_ 
'1 
0 
- 11 
Ij 
r-4 
[-1 
-1 
0 
"0"" "
-2 
-1 
0 
2 
-2 
5 
1  -
-4 
-6 
Both  Fi  =  FciP  = 
and  F2  =  FciP  = 
2 
-2 
assign  the 
eigenvalues  of A +  5F  to the locations { 
2 , - l ± j }. 
The reader  should plot the  states  of the equation  x  =  {A  + BF)x  for  F  =  Fi  and 
F  =  F2 when  x(0)  =  [1,  1,  1]^, and  should  comment  on the  differences  between  the 
trajectories. 
• 
Relation  (2.25)  gives  all feedback  matrices,  Fc  (or F  =  FcP),  that  assign  the  n 
eigenvalues  of A^ +  BcFc  (or A +  BF)  to desired  locations. The  freedom  in  selecting 
such  Fc  is expressed  in terms  of the  different  A j,  all in companion  form,  with  A^  = 
[Aij]  and A/y of dimensions  fit  X fij,  which have the same characteristic  polynomial. 
Deciding  which  one  of  all  the  possible  matrices  A^  to  select,  so  that  in  addition 
to  eigenvalue  assignment  other  objectives  can  be  achieved,  is  not  apparent.  This 
flexibility 
in  selecting  F  can  also  be  expressed  in  terms  of  other  parameters,  where 
both  eigenvalue  and  eigenvector  assignment  are  discussed,  as  will  now  be  shown. 
3.  Assigning  eigenvalues  and  eigenvectors. 
Suppose  now  that F  was  selected 
so that A +  BF  has  a desired  eigenvalue  Sj  with  corresponding  eigenvector  v^.  Then 
338 
Linear  Systems 
[sjl  — (A +  BF)]Vj  =  0, which  can be written  as 
[Sjl-A,B] 
-Fvj_ 
0. 
(2.26) 
To  determine  an F  that  assigns  Sj  as a closed-loop  eigenvalue,  one could  first  deter 
mine  a basis  for the right  kernel  (null  space)  of  [sjI — A^B], i.e., one could  determine 
a  basis 
Mj 
-Di 
such  that 
[Sjl-A,B] 
Mj 
0. 
(2.27) 
Note  that  the dimension  of this basis is (n + m)-rank 
[sjl —A,B]  =  {n + m)—n  =  m, 
where  rank  [sjl —A,B]  =  n  since  the pair  {A^B)  is  controllable.  Since  it is  a  basis, 
there  exists  a nonzero  m x  1 vector  Uj so that 
Mj-
aj  = 
_-Fvj_ 
Combining  the relations  —DjUj 
—FVj  and Mjaj --
Vj,  one obtains 
FMjaj  = DjUj. 
(2.28) 
(2.29) 
This  is  the  relation  that  F  must  satisfy  for  Sj  to  be  a  closed-loop  eigenvalue.  The 
nonzero  m x  1 vector  aj  can be chosen  arbitrarily.  Note  that Mjaj  =  Vj is the eigen 
vector  corresponding  to  Sj.  Note  also  that  aj  represents  the  flexibility  one  has  in 
selecting  the corresponding  eigenvector,  in addition  to assigning  an eigenvalue.  The 
nxl 
eigenvector  Vj cannot be arbitrarily  assigned;  rather,  the m x  1 vector aj  can be 
(almost)  arbitrarily  selected.  These mild conditions on aj  are stated next as a theorem. 
THEOREM  2.5.  The pair  (sj, Vj) is an (eigenvalue, eigenvector)-pair  of A + BF if and 
only if F  satisfies  (2.29) for some nonzero  vector Uj such that  Vj = MjUj  with 
Mj 
a basis of the null space of [sjl —A,B\  as in (2.27). 
Proof,  Necessity has been shown. To prove sufficiency,  postmultiply Sjl — ( A + 5 F)  by 
Mjaj  and use (2.29) to obtain  (sjI — A)Mjaj  —BDjaj  =  0 in view of (2.27). Thus, 
[sjI-{A  + BF)]Mjaj  = 0. 
which  implies  that Sj is an eigenvalue  of A + BF  and MjUj  = Vj is the  corresponding 
• 
eigenvector. 
If relation  (2.29) is written for n desired  eigenvalues Sj, where the aj  are  selected 
so  that  the  corresponding  eigenvectors  Vj =  Mjaj  are  linearly  independent, 
then 
FV  =  W, 
(2.30) 
where  V  =  [ M i ^ i , . .. ,M^a^]  and  W  =  [ D i ^ i , .. .^Dnan]  uniquely  specify  F  as  the 
solution  to these  n linearly  independent  equations.  When  Sj  are distinct,  it is  always 
possible  to select  aj  so that  V  has full  rank;  in fact  almost  any set of nonzero  aj  suf 
fices.  When  Sj have  repeated  values  it may still be possible  under  certain  conditions 
to  select  aj  so that  Mjaj  are linearly  independent;  however  in  general,  for  multiple 
eigenvalues,  (2.30)  needs  to be modified,  and the details  for this  can be found  in the 
literature  (e.g.,  [16]). 
339 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
It can be shown that for distinct eigenvalues Sj,  the n vectors Mjaj, 
.,n, 
are  Hnearly  independent  for  almost  any  nonzero  aj.  For  further  discussion  on  this, 
see  the  remarks  following  Example  2.6  and  Subsection  A.4,  on  Interpolation,  in 
the  Appendix.  Also  note  that  if  Sj+i  =  s*,  the  complex  conjugate  of  Sj,  then  the 
corresponding  eigenvector  V/+1  =  v*  = 
j  =  1,.. 
^)^)' 
Relation  (2.30)  clearly  shows  that  the  F  that  assigns  all  n  closed-loop  eigenval 
ues  is  not  unique  (see  also  Lemma  2.4).  All  such  F  are  parameterized  by  the  vec 
tors aj  that in turn  characterize  the corresponding  eigenvectors. If the  corresponding 
eigenvectors  have  been  decided  upon—of  course  within  the  set  of  possible  eigen 
vectors  Vj  =  MjUj—then  F is uniquely  specified.  Note that in the  single-input  case, 
(2.29)  becomes  FMj  =  Dj,  where  Vj  =  Mj.  In  this  case,  F  is  unique. 
EXAMPLE  2.6.  Consider the controllable pair (A, B) of Example 2.5 given by 
0 
0 
0 
1 
0 
2 
0 
1 
-1 
ro 
1 
.0 
11 
1 
0. 
Again, it is desired to assign the eigenvalues of A + BF  at - 2,  -1  ±  j.  Let ^-i  =  -2,S2  = 
-I  + j  and S3 =  -I 
-  j. Then, in view of (2.27), 
Ml] 
= 
1 
-1 
2 
r 0 
0 
' 
-1 
1 
-2 
2_ 
J 
2 
M2 
-D2. 
= 
1 
0 
0 
2 +  J 
1 
-1 +  7 
1 -J 
and 
M3 
-D3 
Ml 
, the complex conjugate,  since S3 
Each  eigenvector  v^  =  Miai,  i  =  1, 2, 3, is  a linear combination  of the columns of 
Mi.  Note that V3 =  V2. If we select the eigenvectors  to be 
r 
'1 
y  =  [vi, V2, V3]  =  0 
1 
j 
0  2 
I.e., ai  = 
a2 
, and a3 
then  (2.30) implies  that 
1  1 
0 
j 
0  2 
-
-2-j 
-1 
-2  +  j 
-1 
from  which we have 
'^rj 
-2-j 
-1 
-2  +  J 
-1 
4y 
0 
0 
0 
2 
-2 
- 2/ 
j 
j  . 
2 
-2 
-1 
0 
-2 
^ 
This matrix F is such that A +  BF  has the desired eigenvalues  and eigenvectors  (verify 
this). 
• 
340 
Remarks 
Linear Systems 
At this point, several comments  are in order. 
1.  In Example 2.6, if the eigenvectors were chosen to be the eigenvectors of A + BFi 
(instead of A + BF2) of Example 2.5, then from FV  =  W it follows that F would 
have been Fi  (instead of F2). 
2.  When  st  =  ^*^j,  then  the  corresponding  eigenvectors  are  also  complex  conju 
gates, i.e., Vi =  v*^j. In this case we obtain from  (2.30) that 
FV  =  Fl.., 
ViR +  pii,  ViR - 
jvii,...] 
=  [...,  WiR +  jwii,  WiR -  jwii, 
...]  =  W. 
Although  these  calculations  could  be  performed  over  the  complex  numbers  (as 
was  done  in  the  example),  this  is  not  necessary,  since  postmultiplication  of 
FV  =  Why 
-J', 
+ 7 
shows that the above equation FV  =  W  is equivalent to 
Fl.., 
ViR, Vii,...] 
=  [...,  WiR,  Wii,...], 
which involves only reals. 
3.  The bases 
-Dj\' 
U j  =  1, • • •, n, in (2.27) can be determined in an alternative way 
and the calculations  can be  simplified  if the controller  form  of the pair  (A, B)  is 
ons can be  simplified  if  tl 
known. In particular, note that  [si  -  A,B]\ 
=  0, where the n X m ma 
D{s) 
trix S(s)  is given by S(s)  =  block  diag  [1, >y,...," 5^'""^] and the ^c^", /  =  1,...,  m, 
are the controllability  indices of (A, B).  Also, the m X m matrix D{s) is given by 
D{s)  =  B^^ [diag [s^^\ ...,"  s^""'] -  AmS{s)l  Note that S{s) and D{s) were  defined "
in the Structure Theorem  (controllable version) in Chapter  3 (Subsection  3.4D). 
It was shown there that {si  -  Ac)S{s)  =  BcD(s),  from which it follows that (si  -
A)P~^S(s)  =  BD(s),  where P  is a similarity  transformation  matrix that  reduces 
(A, B) to the controller form  (Ac  =  PAP-\  Be  =  PB).  Since P~^S(s)  and  D(s) 
are right  coprime  polynomial  matrices  (see  Section  7.2  of  Chapter  7), we  have 
rank 
D(sj) 
=  m for any Sj, and  therefore, 
P-'S{Sj) 
D(sj) 
qualifies  as a basis 
for  the null  space of the matrix  [sjl  -  A, B](P  =  I  when  A, B  are in  controller 
form,  i.e., A  =  Ac  and B  =  Be.) We note that this approach is discussed  further 
in Subsection A.4 of the Appendix. 
Returning to Example 2.6, the controller form of (A, B) was found  in Exam 
ple 2.5 using 
341 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
p-' 
— 
"""1  0 "
r 
1  1  0 
2  0  0 
Here 
S(s) 
"'\  0"" "
s  0 
0  1 
D{s) = 
^2 
'-
+  s-  1 
-1 
M{s) 
-Dis) 
and 
Then 
Ml] 
-Di\ 
'  Mi-2) 
-Di-2)_ 
M2 
-£>2 
Mi-l  +  j) 
-D(-l  +  j) 
-s 
s 
1 
0 
0 
s 
-s 
1 
s + 1 
2 
-(-$2 +  5 - 1) 
1 
-1 
2 
r 0 
0 
-1 
1 
-2 
2_ 
1 
0 
0 
J 
2 
2 +  j 
1 
1 +  ; 
1 -7 
Ms 
and 
which are precisely the bases used in the example. 
4.  If in Example 2.6 the only requirement were that (^'i, vi)  =  (-2,  (1, 0, 0)^), then 
F(h  0, Of  =  (2, - 2 f, 
i.e.,  any F  =  \l  {'^  ^}' 
will  assign the desired  values 
to an eigenvalue of A +  BF  and its corresponding  eigenvector. 
L^/22 723. 
5.  All possible eigenvectors  vi  and V2(v3  =  v^) in Example 2.6 are given by 
v\  =  M\a\  = 
1  1] 
-1  0 
2  Oj 
-, 
|- 
an 
[ai2_ 
and V2 = M2a2 
/I 
ail  +  JC131 
[a22 +  JC132 
where  the  atj  are  such  that  the  set  {vi, V2, V3} is  linearly  independent  (i.e., 
y  =  [vi, V2, V3] is nonsingular) but otherwise arbitrary. Note that in this case  (sj 
342 
Linear Systems 
distinct),  almost  any  arbitrary  choice  for  atj  will  satisfy  the  above  requirement 
(see Appendix,  Subsection A.4). 
C.  The Linear  Quadratic  Regulator  (LQR): Continuous-Time  Case 
A linear state feedback  control law that is optimal in some sense can be  determined 
as a solution to the so-called  Linear  Quadratic  Regulator  (LQR) problem  (more re 
cently,  also  called  the  H2  optimal  control  problem).  The  LQR  problem  has  been 
studied extensively, and the interested reader should consult the extensive  literature 
on  optimal  control  for  additional  information  on  the  subject.  In  the  following,  we 
give a brief  outline of certain  central results  of this topic to emphasize the fact  that 
the  state  feedback  gain  F  can  be  determined  to  satisfy,  in  an  optimal  fashion,  re 
quirements  other than  eigenvalue  assignment,  discussed  above. The LQR  problem 
has  been  studied  for  the  time-varying  and  time-invariant  cases. Presently,  we  will 
concentrate on the time-invariant  optimal regulator  problem. 
Consider the time-invariant  linear system given by 
X =  Ax-\-  Bu, 
z  =  Mx, 
(2.31) 
where the vector z(t)  represents the variables to be regulated—to  be driven to zero. 
We wish to determine  u{t), t  ^  0, which minimizes the quadratic  cost 
J(u)  = 
Jo 
[z' (t)Qz(t)  +  u'  (t)Ru(t)]  dt 
(2.32) 
for any initial state x{0).  The weighting matrices  Q, R are real, symmetric, and pos 
itive definite,  i.e.,  Q  =  Q^, R  =  R^,  and  Q>  0, R  >  0. This  is the most  common 
version  of the LQR  problem.  The term  z^Qz  =  x^ {M^ QM)x  is nonnegative,  and 
minimizing  its integral forces  z{t)  to approach  zero as t goes to infinity.  The  matrix 
M^QM 
is  in  general  positive  semidefinite,  which  allows  some  of  the  states  to  be 
"treated  as  ""do  not  care""  states.  The  term  u^Ru  with  R  >  0  is  always  positive  for "
w 7^ 0,"  and  minimizing  its integral  forces  u(t)  to remain  small. The relative  ""size"" "
of Q and R enforces  tradeoffs  between the size of the control action and the speed of 
response. 
Assume that  (A, B, Q^'^^M) is controllable  (-from-the-origin)  and observable. It 
turns out that the solution  w*(0 to this optimal control problem can be expressed  in 
state feedback  form, which is independent of the initial condition x(0). In particular, 
the optimal control  w*  is given by 
u{t)  -  F*x(0  =  -R~^B^Plx{t\ 
(2.33) 
where  P* denotes the  symmetric  positive-definite  solution  of the algebraic  Riccati 
equation 
A^Pc  +  PcA  -  PcBR'^B^Pc  +  M^QM  =  0. 
(2.34) 
This equation may have more than one solution, but only one that is  positive-definite 
"(see  Example  2.7).  It  can  be  shown  that  w*(0  ""=  F*x(t)  is  a  stabilizing  feedback "
control law and that the minimum cost is given by Jniin  =  /(w*)  =  x^(0)P*x(0), 
The  assumptions  that  (A, B, Q^'^^M)  are  controllable  and  observable  may  be 
relaxed  somewhat.  If  (A, B, Q^'-^M)  is  stabilizable  and  detectable,  then  the  uncon-
trollable and unobservable eigenvalues, respectively, are stable, and P* is the unique, 
symmetric, but now positive-semidefinite  solution of the algebraic Riccati equation. 
The matrix  F* is  still  a stabilizing  gain but it is understood  that the  uncontrollable 
and unobservable  (but stable) eigenvalues  will not be affected  by  F*. 
Note that if the time interval  of interest in the evaluation  of the cost goes  from 
343 
CHAPTER 4: 
State Feedback 
and State 
Observers 
0 to ^1 <  00, instead of 0 to oo, that is, if 
J(u)  = 
[z^(t)Qz(t)  +  u^(t)Ru(t)]  dt, 
(2.35) 
then the optimal control law is time-varying  and is given by 
u{t)  =  -R~^B^P\t)x{t), 
Q^t^ti, 
(2.36) 
where P*(0 is the unique, symmetric, and positive-semidefinite  solution of the Ric 
cati equation, which is a matrix differential  equation of the  form 
- — P{t)  =  A^P(t)  +  P(t)A  -  P(t)BR-^B^P(t)  +  M^QM, 
dt 
(2.37) 
where  P(ti)  =  0.  It  is  interesting  to  note  that  if  (A, B, Q^'^M)  is  stabilizable  and 
detectable (or controllable and observable), then the solution to this problem as ti  —> 
00 approaches the steady-state value P* given by the algebraic Riccati equation; that 
is, when  ti^ 
^  the optimal control policy is the time-invariant  control law  (2.33), 
which is much easier to implement than time-varying  control policies. 
EXAMPLE 2.7.  Consider the system described by the equations i  =  Ax+Bu,y  =  Cx, 
"where A  ""0  r "
0  0. 
and C{sl -A)  ^B =  \ls^. We wish to determine the optimal control M*(0, ^ ^  0, which 
minimizes the performance index 
C  =  [1, 0]. Then (A, B, C) is controllable and observable 
"""0"" "
.1_ 
,B  = 
J  = 
(/(O  + pu^iO) dt, 
where p is positive and real. Then R  = p>  0, zit)  = y(t), M  =  C, and Q 
the present case the algebraic Riccati equation (2.34) assumes the form 
1 >  0. In 
A^Pc  + PcA -  PcBR-^B^Pc  + M^QM 
0  0 
1  0 
0  0 
1  0 
Pr  +  Pr 
Pi 
P2 
Pi 
P3 
1 
0 
Pi 
IP2 
p 
P2 
P3. 
0  0 
0  0 
[0 l]Pc + 
[10] 
Oj 
1  Pi 
PIP2 
P2] 
P3\ 
ro  0] 
[0 
ij 
\pi 
[P2 
P2 
P3 
where Pr =  Pi  P2 
IP2  P3j 
=  P^. This implies that 
1 
~-P2  +  1 = 0, 
1 
pi  -  -P2P3  = 0, 
2p2 
P 
P 
:PI  = 0. 
P 
Now Pc is positive definite if and only if pi  >  0 and p\p3  — p\>  0. The first equation 
above implies that p2 =  ± J^.  However, the third equation, which yields p\  = 2pp2, 
344 
Linear Systems 
implies that pi  =  + yp. Then p\  = 2p J~p and p^  =  ±  2p J^.  The second equation 
yields pi  = {\lp)p2P?>  and implies that only p^  =  +  lip  J~p is acceptable, since we 
must have p\  >  0 for P^ to be positive definite. Note that pi  >  0 and P3-p\  = 2p-p  = 
p >  0, which shows that 
> 
J^P/P. 
VP 
is the positive definite solution of the algebraic Riccati equation. The optimal control law 
is now given by 
u\t)  = F*x(t)  =  -R'^B^PlxQ)  =  - - [ 0,  IjPXO. 
The eigenvalues of the compensated system, i.e., the eigenvalues of A + BF*, can now be 
determined for different  p. Also, the corresponding u*(t) and y{t) for given x(0) can be 
plotted. As p increases, the control energy expended to drive the output to zero is forced 
to decrease. The reader is asked to verify  this by plotting  u*(t)  and  y(t) for  different 
values of p when  x(0)  =  [1, 1]^. Also, the reader is asked to plot the eigenvalues of 
• 
A + BF* as a function  of p and to comment on the results. 
It  should  be  pointed  out  that  the  locations  of  the  closed-loop  eigenvalues,  as 
the  weights  Q  and  R  vary,  have  been  studied  extensively.  Briefly,  for  the  single-
input  case  and  for  Q  =  ql  and  R  =  r  in  (2.32),  it  can  be  shown  that  the  opti 
mal  closed-loop  eigenvalues  are  the  stable  zeros  of  1 +  (q/r)H^(-s)H(s),  where 
H(s)  =  M(sl  -  Ay^B.  As  q/r  varies  from  zero  (no  state  weighting)  to  infinity 
(no  control  weighting),  the  optimal  closed-loop  eigenvalues  move  from  the  sta 
ble  poles  of  H'^(-s)H(s) 
to  the  stable  zeros  of  H'^(-s)H(s).  Note  that  the  stable 
poles  of  H^(-s)H(s) 
are  the  stable  poles  of  H(s)  and  the  stable  reflections  of  its 
unstable  poles  with  respect  to  the  imaginary  axis  in  the  complex  plane,  while  its 
stable  zeros  are  the  stable  zeros  of  H(s)  and  the  stable  reflections  of  its  unstable 
zeros. 
The solution of the LQR problem relies on solving the Riccati equation. A num 
ber of numerically stable algorithms exist for solving the algebraic Riccati equation. 
The  reader  is  encouraged  to  consult  the  literature  for  computer  software  packages 
that implement these methods. A rather straightforward  method for determining  P* 
is to use the Hamiltonian  matrix  given by 
H^ 
A 
-M^QM 
-BR-^B^ 
-A^ 
(2.38) 
Let  [V\,  V2V  denote  the  n  eigenvectors  of  H  that  correspond  to  the  n  stable 
[Re (A)  <  0]  eigenvalues.  Note  that  of  the  2n  eigenvalues  of  H, n  are  stable  and 
are the mirror images reflected  on the imaginary  axis of its n unstable  eigenvalues. 
When  (A, B, Q^''^M)  is  controllable  and  observable,  then  H  has  no  eigenvalues  on 
the  imaginary  axis  [Re (A)  =  0]. In  this  case  the  n  stable  eigenvalues  of H  are  in 
fact the closed-loop eigenvalues of the optimally controlled system, and the solution 
to the algebraic Riccati equation is then given by 
P*  =  V^V^K 
(2.39) 
Note that in this case the matrix  Vi  consists of the n eigenvectors of A +  i5F*, since 
for  Ai  a stable eigenvalue  of H,  and  vi  the  corresponding  (first)  column  of  Vi,  we 
have 
[Ai/  -  (A +  5F*)]vi  =  [Ai/  -  A +  BR-^B^  V2yr^]vi 
345 
CHAPTER 4: 
State Feedback 
and State 
Observers 
{A,-BR-'B''[ 
Vi'v, 
Vx  vi 
[Ai/,0] 
0  X 
0  X 
0  X 
0  X 
where the fact  that 
Vi 
are eigenvectors  of H  was used. It is worth reflecting  for a 
moment on the relationship between (2.39) and (2.30). The optimal control F derived 
by (2.39) is in the class of F  derived by (2.30). 
D.  Input-Output  Relations 
It is useful  to derive the input-output relations for  a closed-loop system that is com 
pensated by linear state feedback,  and several are derived in this subsection.  Given 
the uncompensated  or open-loop  system  x  =  Ax  +  Bu, y  =  Cx  + Du,  with  initial 
conditions  x(0)  =  XQ, we have 
y(s)  =  C(sl  -  Ay^xo  +  H(s)u(sl 
(2.40) 
where the open-loop transfer function H(s)  =  C(sI—A)~^B-\-D.  Under the feedback 
control  law  u  =  Fx  -\-  r,  the  compensated  closed-loop  system  is  described  by  the 
equations  x  =  (A  + BF)x  -h 5r, j  =  (C  +  DF)x  +  Dr, from  which we obtain 
y{s)  =  (C  +  DF)[sI  -  (A +  BF)r^xo  +  HF(s)r{sl 
(2.41) 
where the closed-loop transfer  function  Hf(s)  is given by 
HF(S)  =  (C +  DF)[sI  -  (A +  BF)Y^B 
-f-  D. 
Alternative expressions for  HF{S)  can be derived rather easily by substituting  (2.4), 
namely, 
u{s)  =  F[sl  -  (A +  BF)r^xo  +  [/  -  F(sl  - 
Ay^Br^r(sl 
into  (2.40). This  corresponds  to working  with  an  open-loop  control  law  that  nomi 
nally  produces  the  same results  when  applied  to the  system  [see the discussion  on 
open- and closed-loop control that follows  (2.4)]. Substituting, we obtain 
"y{s)  =  [C(sl  -  A)""i  +  H(s)F[sI  -  (A -t-  BF)r^]xo "
+  H(s)[I  -  F(sl  - 
Ay^Br^r(s). 
(2.42) 
346 
Linear Systems 
Comparing with (2.41), we see that (C + DF){sI  -  (A +  BF)Y^  =  C(sl  -  A)~^  + 
H(s)F[sI  -  (A  + BF)]~\  and that 
HF(S)  =  (C  + DF)[sI  -  (A +  BF)r^B  +  D 
=  [C(sl  -  Ay^B  +  D][I  -  F(sl  -  Ay^B]-^ 
=  H(s)[I  -  F(sl  -  Ay^Br^^ 
(2.43) 
The last relation points out the fact that y(s)  =  HF(s)r(s)  can be obtained  from 
y(s)  =  H(s)u(s)  using the open-loop control  u(s)  =  [/  -  F{sl  - 
Ay^B]~^r(s). 
Relation  (2.43) can easily be derived in an alternative manner, using  fractional 
matrix descriptions for the transfer function, introduced in Section 3.4 (see the Struc 
ture  Theorem).  In  particular,  the  transfer  function  H{s)  of  the  open-loop  system 
{A, B, C, D} is given by 
H(s)  - 
N(s)D-\s\ 
where A^(^)  =  CS(s)  +  DD{s)  with S(s)  and D(s)  satisfying  (si  -  A)S(s)  =  BD(s) 
(refer to the proof of the controllable version of the Structure Theorem given in Sec 
tion  3.4).  Notice  that  it has  been  assumed,  without  loss  of  generality,  that  the  pair 
(A, B) is in controller  form. 
Similarly, the transfer function  HF(S)  of the compensated system {A+BF,  B,C+ 
DF,  D] is given by 
HF{S)  = 
NF(S)D^\S\ 
where  NF(S)  =  (C  + DF)S(s)  + DDF(S)  with S(s)  and  DF(S)  satisfying  [si  -  (A  + 
BF)]S(s)  =  BDF(S).  This relation  implies  that  (si  -  A)S(s)  =  B[DF(S)  +  FS(s)l 
from  which  we obtain  DF(S) +  FS(s)  =  D(s).  Then  NF(S)  =  CS(s)  +  D[FS(s)  + 
DF(S)]  =  CS(s)  +  DD(s)  =  N(s\ 
that is, 
HF(S)  =  N(s)Dp\s\ 
(2.44) 
where DF(S)  =  D(s)  -  FS(s).  The full justification  of the validity  of these expres 
sions  will  be  given  in  Subsection  7.4B  of  Chapter  7,  where  feedback  systems  de 
scribed in terms of polynomial matrix representations  are  addressed. 
Note  that  /  -  F(sl  -  Ay  ^B  in  (2A3)  is  the  transfer  function  of  the  system 
-FS(s)+ID(s). 
{A,B,  - F ," /} and can be expressed as D/7(5')D""^(^)", where D/7(^)  = 
"LetM(^)  =  (Z)/7(^)^~k^))""^. Then (2.44) assumes the  form "
HF(S)  =  N(s)Dp\s)  =  (N(s)D-\s))(D(s)D^\s)) 
=  H(s)M(s). 
(2.45) 
Note  that  relation  HF(S)  =  N(s)D^^(s)  also  shows  that  the  zeros  of  H(s)  [in 
N(s),  see also  Subsection  7.3B]  are invariant  under  linear  state feedback;  they  can 
be changed only via cancellations with poles. Also observe that M(s)  =  D(s)Df^(s) 
is the transfer  function  of the system {A + BF,  B, F, I] (show this). This implies that 
HF(S)  in (2.43) can also be written as 
HF(S)  =  H(s)[F(sI  -  (A +  BF)y^B  + / ], 
a result that could also be shown directly using matrix  identities. 
EXAMPLE 2.8.  Consider the system x  = Ax  + Bu, y  = Cx, where 
ro 
1 
.0 
1 
-1 
0 
B  =^  Be 
0 
2 
1 
0 
0 
0 
and 
0] 
1 
1. 
as in Example  2.5, and let  C  =  Q  =  [1, 1, 0]. Hf(s)  will now be determined.  In  view 
of  the  Structure  Theorem  developed  in  Section  3.4,  the  transfer  function  is  given  by 
H(s)  =  N(s)D-\sX  where 
N(s)  =  CcS(s)  =  [1,1,0] 
n 
s 
0 
01 
0 
1. 
=  [^ +  1,0], 
347 
CHAPTER 4: 
State Feedback 
and  State 
Observers 
-1  01 
0  Oj 
"ri  01"" "
\s  0 
Lo 
i j. 
and  D{s)=^  B-'[A{s)-AmS(s)] 
= 
1  1 
0  1 
s^  0 
0 
s 
"""2 "
1 
1 
0 
-1 
1 
s^  -\-s-2 
-1 
0 
s 
s^  + s- 
I 
Then 
H{s)  =  N(s)D-'is)  =  [s+  1,0] 
s'^ + s-  1 
-1 
[s +  1, 0] 
s 
1 
1 
s 
s^ +  S-1  ^3 +  52 -  25 
s(s^  +  5 -  2 )'  ' 
'' 
' 
'' 
[5(5+1), 5(5+1)]  = 
- ^ ± i - [ l , l ]. 
52 +  5 -2 
I f F,  = 
3  7  5 
-5  -6  -4 
(which is Fci  of Example 2.5), then 
D^(5)  =  Z)(5) -  FcS(s)  = 
5^ +  5 —  1  —5 
-1 
3 
-5 
7 
-6 
51 
-4j 
"ri  0"" "
5  0 
Lo  1. 
52 -  65 -  4 
65 +  4 
- 5 -5 
5 +  4 
Note that detDpis)  =  5^ +  452 +  65 + 4  =  (5 +  2)(52 +  25 +  2) with roots  - 2,  -1  ±  7, 
as expected.  Now 
HF{S)  =  N{s)D}\s) 
=  [5 +  1,0] 
5 +4 
-65  -  4 
5 +5 
1 
5 2 - 6 5 -4 
(5 +  2)(52 +  25 +  2) 
5+  1 
(5 +  2)(52  +  25 +  2) 
[5 +  4, 5 + 5]. 
Note  that  the  zeros  of  H{s)  and  Hp{s)  are  identical,  located  at  - 1. Then  Hpis) 
H(s)M(s),  where 
-
M(s)  =  D(s)Dp\s)  = 
52 +  5 -1 
5 +4 
- 6 5 -4 
5 +5 
1 
5 2 - 6 5 -4 
53 +452  +  65 +  4 
5^ +  I I 5 2 + 7 5 -4 
-652 -  55 -  4 
1252 +  8 5 -5 
6 5 2 - 5 5 -5 
1 
53 +452  +  65 +  4 
= 
[I~F,(sI-Acr'Bc]-K 
Note that the open-loop uncompensated  system is unobservable, with 0 being the unob-
servable eigenvalue (why?), while the closed-loop system is observable, i.e., the control 
• 
law changed the observability  of the system. 
348 
Linear Systems 
E.  Discrete-Time  Systems 
Linear  state  feedback  control  for  discrete-time  systems  is  defined  in  a way  that  is 
analogous to the continuous-time case. The definitions are included here for purposes 
of completeness. 
We consider  a linear,  time-invariant,  discrete-time  system  described  by  equa 
tions of the  form 
x(k  +  1)  -  Ax(k)  +  Bu(kl  y(k)  =  Cx(k)  +  Du(k), 
(2.46) 
"where A  G /?""><^ B  E  Z^^^^", C  G /?^><^ D  G 7?^x^, and  k  >  ko, with  k  ^  ko  =  0 
being typical (see Section 2.7). 
DEFINITION2.3.  The linear (discrete-time, time-invariant) state feedback control law 
is defined by 
"where F  G T?'""^"" is a gain matrix and r(k) G R^ is the external input vector. "
u(k)  = Fx(k)  + r(k), 
(2.47) 
• 
This  definition  is  similar  to  Definition  2.1  for  the  continuous-time  case.  The 
compensated  closed-loop system is now given by 
x(k  +  1)  -  (A 4- BF)x(k)  +  Br(k) 
y(k)  =  (C  +  DF)x(k)  +  Dr(kl 
(2.48) 
In  view  of  Section  2.7  of  Chapter  2, the  system  x(k  +  1)  =  (A  +  BF)x(k) 
is 
asymptotically  stable if and only if the eigenvalues of A + BF  satisfy  |A/| <  1, i.e., if 
they lie strictly within the unit disc of the complex plane. The stabilization  problem 
for the time-invariant  case therefore  becomes  a problem of shifting  the  eigenvalues 
of  A +  BF,  which  is precisely  the problem  studied  before  for  the  continuous-time 
case. Theorem 2.1 and Lemmas 2.2 and 2.3 apply without change, and the methods 
developed before for eigenvalue assignment can be used here as well. The only dif 
ference  in this  case is the location  of the desired  eigenvalues: they  are  assigned  to 
be within the unit circle to achieve  stability. We will not repeat here the details  for 
these results. 
Input-output  relations  for  discrete-time  systems,  which  are  in  the  spirit  of  the 
results  developed  in the preceding  subsection  for  continuous-time  systems,  can  be 
derived in a similar fashion,  this time making use of the z-transform  of x(k  +  1)  = 
Ax(k)  +  Bu(k),  x(0)  =  XQ to obtain 
x(z)  =  z(zl  -  Ay^xo  +  (zl  -  Ar^Bu(z). 
(2.49) 
The reader 
[Compare expression (2.49) with x(^)  =  (si-  A)~^xo-^(sI-A)~^Bu(s).] 
is asked to derive formulas  for the discrete-time case that are analogs to expressions 
(2.40) to (2.45) for the continuous-time  case. 
F.  The Linear  Quadratic  Regulator  (LQR): Discrete-Time  Case 
The  formulation  of  the  LQR  problem  in  the  discrete-time  case  is  analogous  to  the 
continuous-time LQR problem. Consider the time-invariant linear  system 
x(k  +  i)  =  Ax(k)  +  Bu(kl  z(k)  =  Mx(k\ 
(2.50) 
349 
CHAPTER 4: 
State Feedback 
and State 
Observers 
where  the  vector  z(t)  represents  the  variables  to  be  regulated.  The  LQR  problem 
is to determine  a control  sequence  {u*(k)}, /: >  0,  which  minimizes  the  cost  func 
tion 
J(u)  =  ^[z^(k)Qz(k) 
+  u^(k)Ru(k)] 
(2.51) 
k = 0 
for  any initial  state x(0), where the weighting  matrices  Q and R are real  symmetric 
and positive  definite. 
Assume that (A, B, Q^'^M) is reachable and observable. Then the solution to the 
LQR problem is given by the linear state feedback  control law 
u{k)  =  F*x(^)  -  -[R  +  B^PlBr^B^PlAx(k), 
(2.52) 
where  P* is the unique,  symmetric,  and  positive-definite  solution  of  the  (discrete-
time) algebraic  Riccati  equation,  given by 
Pc  =  A'^lPc  -  PcB[R  +  B^PcBr^B^PM 
+  M^QM. 
(2.53) 
Theminimum  valueof/is/(w*)  =  /min  =  x^(0)P*x(0). 
As  in  the  continuous-time  case,  it  can  be  shown  that  the  solution  P*  can  be 
determined  from  the  eigenvectors  of  the  Hamiltonian  matrix,  which  in  this  case 
is 
H 
A  + 
BR-^B^A-^M^QM 
-BR-^B^A-^ 
-A-^M^QM 
A-^ 
(2.54) 
where  it is assumed  that A~^  exists. Variations  of the above method  that relax  this 
assumption  exist  and  can  be  found  in  the  literature.  Let  [V\,  Vj]^  be  n  eigenvec 
tors  corresponding  to the  n  stable  (|A|  <  1) eigenvalues  of H.  Note  that  out  of  the 
In  eigenvalues  of //,  n  of  them  are  stable  (i.e., within  the  unit  circle)  and  are  the 
reciprocals of the remaining n unstable eigenvalues  (located outside the unit circle). 
When (A, B, Q^'^M) is controllable (-from-the-origin)  and observable, then if has no 
eigenvalues  on the unit circle (|A|  =  1). In fact  the n stable eigenvalues  of//  are in 
this case the closed-loop eigenvalues of the optimally  controlled  system. 
The solution to the algebraic Riccati equation is given by 
-1 
K  -  ^2vr 
(2.55) 
As  in  the  continuous-time  case,  we  note  that  Vi  consists  of  the  n  eigenvectors  of 
A +  5F*  (show this). 
EXAMPLE  2.9.  We consider the  system  x{k +  1)  =  Ax{k)  +  Bu{k), y(k)  =  Cx(k), 
where A  = 
"""0  1"" "
.0  0^ 
,B  = 
"""0"" "
.1_ 
C  =  [1, 0] and we wish to determine the optimal control 
sequence {u*(k)}, /: >  0, that minimizes the performance index 
J(u)  = Y.(y\k)  + puHk)), 
k = 0 
where p >  0. In (2.51), z(k)  = y(k), M  = C,Q  =  1, and /? =  p. The reader is asked to 
determine u'^k) given in (2.52) by solving the discrete-time algebraic Riccati equation 
(2.53) in a manner analogous to the solution in Example 2.7 (for the continuous-time 
algebraic Riccati equation). 
• 
350 
Linear Systems 
4.3 
LINEAR  STATE  OBSERVERS 
Since the states of a system contain a great deal of useful information, there are many 
applications  where knowledge  of the  state vector  over  some time  interval  is  desir 
able. It may  be possible  to measure  states  of  a system  by  appropriately  positioned 
sensors. This was in fact assumed in the previous section, where the state values were 
multiplied by appropriate gains and then fed back to the system in the state  feedback 
control law. Frequently, however, it may be either impossible or simply  impractical 
to  obtain  measurements  for  all  states.  In  particular,  some  of  the  states  may  not  be 
available for measurement  at all (as in the case, for example, with temperatures  and 
pressures  in  inaccessible  parts  of  a jet  engine). There  are  also  cases  where  it  may 
be impractical to obtain state measurements from otherwise available states because 
of economic reasons  (e.g., some of the sensors may be too expensive) or because of 
technical  reasons  (e.g., the  environment  may  be too noisy  for  any  useful  measure 
ments). Thus, there is a need to be able to estimate the values of the state of a system 
from  available measurements, typically  outputs and inputs (see Fig. 4.3). 
Given the system parameters A, B, C, D and the values of the inputs and outputs 
over a time interval, it is possible to estimate the state when the system is observable. 
This problem, a problem in state estimation, is discussed in this section. In particu 
lar, we will address  at length the so-called full-order  and reduced-order  asymptotic 
estimators, which are also called full-order  and reduced-order  observers. 
u 
[A, B,  C, D} 
y 
1 
f 
state observer 
• ^ 
FIGURE 4.3 
A.  Full-Order  Observers:  Continuous-Time  Systems 
We consider  systems described by equations of the  form 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
(3.1) 
"where A  G /^""><^ B  G T^^^^", C  G  RP''''  and D  G  RP'''^. 
Full-state observers: The identity  observer 
An  estimator  of the full  state  x(t)  can be constructed  in  the following  manner. 
We consider the  system 
'x =  Ax  + Bu^K(y- 
yl 
(3.2) 
^  A 
where y  =  Cx  -\-  Du.  Note that (3.2) can be written  as 
'x =  {A-  KC)x  +{B-  KD,  K] 
(3.3) 
which  clearly  reveals  the role  of  u and y  (see Fig. 4.4). The  error between  the  ac 
tual  state  x{t)  and  the  estimated  state  x{t), e(t)  =  x(t)  -  x(t),  is  governed  by  the 
differential  equation 
e(t)  =  x(t)  -  jc(t)  =  [Ax  +  Bu]  -  [Ax  + Bu  + KC(x  -  x)] 
or 
e(t)  =  [A-  KC]e(tl 
Solving (3.4), we obtain 
(3.4) 
351 
CHAPTER 4: 
State Feedback 
and State 
Observers 
e(t)  =  exp [(A 
(3.5) 
Now  if the eigenvalues  of A -  KC  are in the left  half-plane,  then  e(t)  ->  0 as ^  ^ 
00, independently  of the initial condition  ^(0)  =  x(0)  -  x(0).  This asymptotic  state 
estimator  is known as the Luenberger  observer. 
KC)t]e(0). 
Li 
B-KD 
Ht) 
:§>-
A-KC 
FIGURE 4.4 
LEMMA 3.1.  There exists K  E  R'^^P  SO that the eigenvalues of A -  KC  are assigned 
to arbitrary real or complex conjugate locations if and only if (A, C) is observable. 
Proof, The eigenvalues of (A -  KCY  =  A^ -  C^K^  are arbitrarily assigned via K^ if 
and only if the pair (A^, C^) is controllable (see Theorem 2.1 of the previous section), 
or equivalently, if and only if the pair (A, C) is observable. 
• 
If  (A, C)  is  not  observable,  but  the  unobservable  eigenvalues  are  stable,  i.e., 
(A, C)  is detectable,  then  the error  e{t)  will  still tend  to zero  asymptotically.  How 
ever, the unobservable eigenvalues will appear in this case as eigenvalues of A -  KC 
(show this), and they may affect the speed of the response of the estimator in an unde 
sirable way. For example, if the unobservable eigenvalues  are stable but are located 
close  to the imaginary  axis, then  their  corresponding  modes  will  tend  to  dominate 
the response, most likely  resulting  in  a state estimator  that converges  too slowly  to 
the actual value of the state. 
Where  should the eigenvalues  of A -  KC  be located? This problem  is dual to 
the problem  of closed-loop  eigenvalue placement  via  state feedback  and is  equally 
difficult  to resolve.  On  one  hand,  the  observer  must  estimate  the  state  sufficiently 
fast,  which  implies  that  the  eigenvalues  should  be placed  sufficiently  far  from  the 
imaginary  axis  so that the error  e{t) will tend to zero sufficiently  fast.  On the other 
hand,  this  requirement  may  result  in  a high  gain  K,  which  tends  to  amplify  exist-
352 
Linear Systems 
ing  noise, thus  reducing  the  accuracy  of  the  estimate.  Note  that  in this  case,  noise 
i^ the only Hmiting factor  of how fast  an estimator may be, since the gain K is real 
ized by  an algorithm  and is typically  implemented  by means  of a digital  computer. 
Therefore,  gains  of  any  size  can  easily  be  introduced.  Compare  this  situation  with 
the  limiting  factors  in  the  control  case,  which  is  imposed  by  the  magnitude  of  the 
required  control action (and the limits of the corresponding  actuator). Typically, the 
faster  the compensated  system, the larger the required control  magnitude. 
One may  of course balance the trade-offs  between  speed of response of the es 
timator and effects  of noise by formulating  an optimal  estimation  problem  to derive 
the best K.  For this, one commonly  assumes  certain probabilistic  properties  for  the 
process. Typically,  the measurement  noise  and the initial  condition  of the plant  are 
assumed to be Gaussian random variables, and one tries to minimize a quadratic per 
formance  index. This problem is typically referred  to as the Linear Quadratic Gaus 
sian (LQG) estimation problem. This optimal estimation or filtering problem can be 
seen to be the dual of the quadratic optimal control problem of the previous section, a 
fact that will be exploited in deriving its solution. Note that the well-known  Kalman 
filter  is such an estimator. In the following,  we shall briefly  discuss the optimal esti 
mation problem. First, however, we shall address the following  related issues. 
1.  Is it possible to take ^  =  Ointheestimator  (3.2)? Such a choice would eliminate 
the information  contained in the term y — y from the estimator, which would now 
be of the  form 
X =  Ai  +  Bu. 
(3.6) 
In  this  case  the  estimator  would  operate  without  receiving  any  information  on 
how accurate the estimate x  actually is. The error e{t)  =  x(t)  —  x(t)  would go to 
zero only when A  is stable. There is no mechanism  to affect  the speed by  which 
x(t)  would approach  x(t)  in this case, and this is undesirable. One could perhaps 
determine x(0), using the methods in Section 3.3 of Chapter 3, assuming that the 
system is observable. Then, by  setting  x(0)  =  x(0),  presumably  x(t)  =  x(t)  for 
all t  >  0, in view of (3.6). This of course is not practical for several reasons. First, 
the calculated  x(0)  is never  exactly  equal  to the  actual  x(0), which  implies  that 
^(0) would be nonzero. Therefore, the method would rely again on A being stable, 
as before,  with  the  advantage  here  that  ^(0)  would  be  small  in  some  sense  and 
so  e(t)  ->  0 faster.  Second,  this  scheme  assumes  that  sufficient  data  have  been 
collected in advance to determine (an approximation to) x(0)  and to initialize the 
estimator, which may not be possible. Third, it is assumed that this  initialization 
process is repeated whenever the estimator is restarted, which may be impractical. 
2.  If  derivatives  of  the  inputs  and  outputs  are  available,  then  the  state  x(t)  may 
be  determined  directly  (see  Exercise  3.14  in  Chapter  3).  The  estimate  x(t)  is 
in this  case produced  instantaneously  from  the values  of the inputs  and  outputs 
and  their  derivatives.  Under  these  circumstances,  x(t)  is  the  output  of  a  static 
state  estimator,  as  opposed  to  the  above  dynamic  state  estimator,  which  leads 
to a state estimate  x(t)  that  only  approaches  the  actual  state  x(t)  asymptotically 
as r -^  00 [e(t)  =  x(t)  -  x(t)  -^  0 as r ^  oo]. Unfortunately,  this  approach  is in 
general not viable since noise present in the measurements of u(t) and y(t)  makes 
accurate calculations of the derivatives problematic, and since errors in u(t),  y(t) 
353 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
and  their  derivatives  are not smoothed  by the algebraic  equations  of the static es 
timator (as opposed to the smoothing  effects  introduced by integration in  dynamic 
systems). It follows  that  in this  case  the state  estimates  may be  erroneous. 
M P L E 3.1.  Consider the observable 
0^ 
"""0  1 "
0  0 
1 
' 
.0  2  - 1_ 
A = 
pair 
C = =  [1,0,0]. 
We  wish  to assign  the eigenvalues  of A -  ^C  in a manner  that  enables  us to  design 
a full-order/full-state  asymptotic  observer. Let the desired  characteristic  polynomial be 
a J (5*) = s^ + dis^  + d\s  + do and consider 
AD  ^  AT  ^ 
0 
1 
0 
0 
0 
1 
0 
2 
-1 
and 
Bn  = C T  _ 
To reduce  (AD, BD) to controller form, we consider 
% 
[BD,ADBD,AIBD] 
= 
Then 
P  =  UAD 
IqAl 
from  which we obtain 
AD,  =  PADP~ 
ro 
0 
Ll 
0 
1 
-1 
"1"" "
-1 
3. 
0 
0 
0 
1 
0 
2 
"""1  0  0"" "
0  1  0 
.0  0  1. 
=  ^ 
and 
P-^  = 
-2  1  1 
1  1  0 
1  0  0 
and 
BD,  =  PBE 
The state feedback  is then given by FD,  =  B^^[Ad^  -  Am]  =  [-do,  -di  -  2, -d2  + I] 
and  FD  =  FDCP  =  [~d2  +  I,  d2  — d\  — 3, d\  — do  — 3d2  +  5].  Then 
K  =  -Fl  =  [d2 -hdi-d2 
+ 3, do-di+  M2 -  5]^ 
assigns the eigenvalues  of A -  KC  at the roots of 0Ld{s)  = s^ + d2S^ + d\s  + do. Note 
that the same result could also have been derived using the direct method for eigenvalue 
assignment, using  |^/ -  (A -  (^0, h,  fe)^C)|  =  ad{s).  Also, the result could have been 
derived using the observable  version  of Ackermann's  formula,  namely, 
K  =  -Fl= 
ad(A)€~'en, 
where FD  =  -el^^^ad(AD) 
from  (2.21). Note  that the given  system has eigenvalues 
at 0,1,  -2  and is therefore unstable. The observer derived in this case will be used in the 
next  section  (Example  4.1) in combination  with  state  feedback  to stabilize  the system 
X = Ax  + Bu, y  =  Cx,  where 
0' 
1 
- 1. 
"""0  1 "
1  1 
.0  0 
C  =  [1, 0, 0] 
1 
0 
2 
0 
0 
0 
B  = 
and 
(see Example 2.5), using only output  measurements. 
EXAMPLE 3.2.  Consider the system i:  =  Ax,y  =  Cx, where A  = 
andC  = 
[0,1], and where (A, C) is in observer form. It is easy to show that K  =  [do-  2,  d\-2Y 
354 
Linear Systems 
assigns the eigenvalues of A -  KC at the roots of s^ + d\s  + d^. To verify this, note that 
det{sI-{A-KC)) 
=  det\ 
s  0 
0  s 
0 
.1 
-do 
-d\\ 
s  +  d\s  + d{). 
The error e{t)  = x(t) -  x(t) is governed by the equation e(t)  = (A -  KC)e(t) given in 
(3.4). Noting that the eigenvalues of A are -1  ±  j, select different  sets of eigenvalues 
for the observer and plot the states x(t), x(t)  and the error  e(t) for  x(0)  =  [2, 2]^  and 
x(0)  =  [0, 0]^. The further  away the eigenvalues of the observer are selected from the 
imaginary axis (with negative real parts), the larger the gains in K will become and the 
faster x(t) -^  x(t) (verify this). 
• 
Partial or linear functional  state  observers 
The  state estimator  studied above is a full-state  estimator or observer,  i.e.,  x(t) 
is  an  estimate  of  the  full-state  vector  x(t).  There  are  cases  where  only  part  of  the 
state vector, or a linear combination of the states, is of interest. In control problems, 
for example, Fx(t)  is used and fed back, instead of Fx(t),  where F is an m X ^ state 
feedback  gain  matrix  (see  also  Section  4.4).  An  interesting  question  that  arises  at 
this point is: is it possible to estimate directly  a linear combination  of the state, say, 
Tx,  where T  E  R^'^^^ h^  nl  This problem is considered  next. 
We consider the  system 
z  =  Az  + Bu  + Ky, 
(3.7) 
"where A  G  R^^""""", B  G /^^x^, and K  G  R^'^P are to be determined. The error equation 
is given by 
^  =  Tx- 
z  =  TAx  +  TBu  -  Az-  Bu-  K{Cx  +  Du) 
=  Ae  + {TA  -  AT  -  KC)x  +  {TB  -  KD  -  B)u. 
Now if 
and r.  A, and K  satisfy 
B  =  TB-  KD 
TA-  AT  =  KC, 
(3.8) 
(3.9) 
then  e  =  Ae.  If  in  addition,  A is  stable,  then  e{t) -^  0  as t ^  oo  and  z(t)  will  ap 
proach  Tx(t)  asymptotically.  A key  issue is clearly  the existence  (and  calculation) 
of appropriate  solutions of (3.9). This has been  studied extensively  in the  literature 
(see for  example  O'Reilly  [18]). Here we  simply  wish to point to a special  case of 
(3.9), namely, the case of the identity observer (T  =  I)  or of the full-state  estimator: 
T  =  I  and  A  =  A  -  KC,  where  for  (A, C)  observable,  there  always  exists  K  that 
renders A stable, as was shown above. 
Note that in general  a solution  (A, K)  of  (3.9) with A stable may not exist,  i.e., 
there may not exist an observer (3.7) of order n(A  G R^^^)  to estimate n linear func 
tions  of the  state,  Tx  (T  G  R^^^).  It is possible, however,  to decouple  the order of 
the observer from  the number of linear functions  of the state to be estimated,  in the 
following  manner. 
Let w  =  Tx,  w  ^  R^,  and  consider 
z  =  Az-^  Bu-\-  Ky 
w  =  Tx{y-Du)  +  T2Z, 
(3.10) 
"where  z  G  i?^ A  G  R'""""'",  B  G  i^'^^,  K 
"f  G W""""  and  write "
G  i?'^^^^, Ti  G  /?^><^," and  72  G  R^""""'.  Let "
355 
CHAPTER 4: 
State Feedback 
and State 
Observers 
z -  ri  =  Az +  5w +  i^(Cx  +  Du)  -  r(A;c  +  5w) 
=^  Az  + (KC  -  tA)x  + {B-fB 
+  KD)u. 
-  TA  =  -AT,  where A is stable, then z-fx 
= 
-  fx(0)),  i.e.,  z(t)  -^  fx(t).  We  are  interested, 
Now  if  B  =  TB  -  KD  mdKC 
A(z  -  tx)  or z - tx  =  e^\z(0) 
however,  in estimates of w  =  Tx.  Consider therefore  w —  w  =  [TiCx  + Tiifx  + 
e^\z{Qi) -  fx(0))]  -Tx  =  {TiC  + T2f  -  T)x  +  T2e^\z{0)  -  fx(0)).  Now if T  -
TiC  +  T2f,  then w-w  =  T2e^\z{^)  -  fx(0))  and w(t)  -^  w(t)  =  Tx{t\  since A 
is stable. 
Therefore,  an observer  (3.10)  of  w  =  Tx,  T  G  R^^^  of  order  r exists  if  there 
"exist  f  G T?''^"""," Ti  G /?""><^ T2 G /?""><^ and ^  G i?^><^ such that for A stable. "
TA  -  AT  -  /TC 
and 
TiC  +  727  =  7. 
(3.11) 
We thus have B  =  TB  — KD,  We note that it can be shown that for (A, C) detectable 
and  r sufficiently  large, there  will  always  exist  a solution.  An  example  is the  case 
when 7  =  / a n dr  =  ^ - p. This is the case of the reduced-order observer discussed 
next, in Subsection B. 
Another simple case of interest is when 7 is a row vector {n  =  1). In this case it 
can be shown (Luenberger [14]) that an observer of order i^ -  1 [i^ is the observability 
index  of  (A, C)]  can  always  be  constructed  with  its  eigenvalues  freely  assignable, 
which will asymptotically  estimate the linear function  of the state, Tx.  In general it 
can be shown that an observer of order h{v  -  1) can be constructed that will asymp 
totically  estimate  Tx.  Note  that  the  problem  of  determining  an  observer  of  Tx  of 
minimum order is a very difficult  problem, except in special cases. 
B.  Reduced-Order  Observers:  Continuous-Time  Systems 
Suppose thatp  states, out of the n state, can be measured  directly. This  information 
can then be used to reduce the order of the full-state estimator from nton-p. 
Similar 
results are true for the estimator of a linear function  of the state, but this problem will 
not be addressed here. To determine a full-state estimator of order n-p,  first  consider 
the case when  C  =  [Ip, 0]. In particular,  let 
Xi 
= 
"""All "
A21 
An 
A22. 
Ixi 
[X2_ 
+ 
z 
= 
[lp,0] 
Xil 
X2y 
(3.12) 
where  z  =  xi  represents  the p  measured  states. Therefore,  only  X2(t) G  R^  ^ is to 
be estimated. The system whose state is to be estimated is now given by 
X2  =  A22X2  +  [A2b B2] 
— ^22-^2  +  Bu, 
(3.13) 
356 
Linear Systems 
where B  == [A21, B2] and  u  = 
is a known signal. Also, 
^  A  . 
y  =  xi 
Anxi 
-  Biu  = A12X2, 
(3.14) 
where y is known. An estimator for X2 can now be constructed. In particular, in view 
of (3.2), we have that the  system 
X2 =  A22X2  + Bu  + K(y  -  A12X2) 
=  (A22 -  KAn)x2  +  (A21Z +  B2U)  +  m 
-  Anz  -  Biu) 
(3.15) 
is an asymptotic  state estimator for  X2. Note that the error e satisfies  the equation 
^  =  i:2  -  ^2  =  (A22 -  KAx2)e, 
(3.16) 
and if (A22, A12) is observable, then the eigenvalues of A22 -  ^Ai2 can be arbitrarily 
assigned making use of K.  It can be shown that if the pair (A  =  [Aij\  C  =  [Ip, 0]) 
is  observable,  then  (A22. A12) is  also  observable  (prove  this  using  the  eigenvalue 
observability test of Section 3.4 of Chapter 3). System (3.15) is an estimator of order 
n-  p,  and therefore  the estimate of the entire state x is 
z 
X2 
. To avoid using z  =  xi 
in y given by (3.14), one could use X2 =  w + Kz  and obtain from  (3.15) an estimator 
in terms of w, z, and u. In particular, 
w  =  (A22 -  KAn)w  +  [(A22 -  KAn)K  +  A21 -  KAix\z  +  [B2 -  KBi]u. 
(3.17) 
Then w is an estimate of X2  -  Kz,  and of course w + ^z  is an estimate for X2 (verify 
this). 
In  the  above  derivation,  it  was  assumed  for  simplicity  that  a part  of  the  state 
xi,  is  measured  directly,  i.e.,  C  =  [Ip, 0]. One  could  also  derive  a  reduced-order 
estimator for the  system 
X =  Ax  + Bu, y  =  Cx. 
\c 
To see this, let rank  C  =  p  and define  a similarity transformation  matrix  P  =  \^ 
where  C is such that P is nonsingular.  Then 
k  =  Ax  + Bu,y  =  Cx  =  [Ip, 0]x, 
(3.18) 
where  x  =  Px,A  =  PAP'K  B  =  PB,  and  C  =  CP'^  =  [Ip, 0]  (show  this). The 
transformed  system  is  now  in  an  appropriate  form  for  an  estimator  of  order  n  -
p  to  be  derived,  using  the  procedure  discussed  above.  The  estimate  of  x  is 
and  the  estimate  of  the  original  state  x  is  P 
.  In  particular,  X2 =  w  +  Ky, 
where  w  satisfies  (3.17)  with  z  =  y, [Atj]  =  A  =  PAP  ^  and 
The interested reader should verify  this result. 
Bi 
B2 
B  =  PB. 
EXAMPLE  3.3.  Consider the system  x 
Ax  + Bu, y  =  Cx,  where A  = 
0 
1 
-2 
-2 
, and C  =  [0, 1]. We wish to design a reduced n-  p  = n-  I  = 2-  I  =  first-
ro 
[i. 
B = 
order asymptotic state estimator. 
357 
CHAPTER 4: 
State Feedback 
and State 
Observers 
The  similarity  transformation  matrix  P 
X =  PxdindA  =  PAP~^  = 
"""0  1 "
1  0 
0 
1 
-2 
-2 
C 
C. 
"""0  1 "
1  0 
"""0  1 "
.1  0 
-2  1 
-2  0 
leads  to  (3.18), where 
B  = PB = 
and 
C  =  CP  ^  =  [1,0].  The  system  {A, B, C} is now  in  an  appropriate  form  for  use of 
(3.17). We have A 
the form 
All 
An 
[A21  A22, 
-2  1 
-2  0 
,B 
L  and  (3.17)  assumes 
w  = (-K)w  + [-K^  + (-2)  -  K(-2)]y  +  (-K)u, 
a system observer of order 1. 
For K  =  -10  we have w  =  lOw -  I22y  +  lOw, and w + Ky  =  w -  lOy is an 
estimate for X2. Therefore, 
y 
w -  lOy 
is an estimate of x, and 
y 
[w —  lOy 
0  1 
1  0 
y 
w -  lOy 
w -  lOy 
y 
is an estimate of x(t) for the original system. 
C.  Optimal  State Estimation:  Continuous-Time  Systems 
The  gain  K  in  the  estimator  (3.2)  above  can  be  determined  so that  it is  optimal  in 
an appropriate  sense. This is discussed very briefly  in the following.  The  interested 
reader should consult the extensive literature on filtering theory  for additional  infor 
mation, in particular, the literature on the Kalman-Bucy  filter. 
In  addressing  optimal  state  estimation,  noise  with  certain  statistical  properties 
is introduced  in  the model  and  an  appropriate  cost functional  is  set up that  is  then 
minimized.  In  the  following,  we  shall  introduce  some  of  the  key  equations  of  the 
Kalman-Bucy  filter  and  we  will  point  out  the  duality  between  the  optimal  control 
and estimation problems. We concentrate on the time-invariant case, although, as in 
the LQR control problem discussed earlier, more general results for the time-varying 
case do exist. 
We consider the linear time-invariant  system 
X =  Ax  + Bu  + Tw,  y  =  Cx  +  V, 
(3.19) 
where  w  and  v represent  process  and  measurement  noise  terms. Both  w  and  v are 
assumed to be white, zero-mean  Gaussian  stochastic processes, i.e., they are uncor-
related in time and have expected values £[w]  =  0 and £[v]  =  0. Let 
E[ww^]  =  W, 
E[vv^]  =  V 
(3.20) 
denote their covariances, where  W and  V are real, symmetric,  and positive  definite 
matrices,  i.e.,  W  =  W^,  W  >  0,  and  V  =  V^,  V >  0. Assume  that  the  noise pro 
cesses w and V are independent,  i.e., E[wv^]  =  0. Also assume that the initial  state 
;c(0) of the plant is a Gaussian random variable of known mean, E[x(0)]  =  XQ, and 
known covariance, E[(x(0)  -  jco)(-^(0) ~  -^o)^]  =  PeO-  Assume also that x(0)  is in 
dependent of w and v. Note that all these are typical assumptions made in practice. 
Consider now the estimator  (3.2), namely, 
X =  Ax  + Bu  + K(y  -  Cx)  =  (A  -  KC)x  + Bu  +  Ky, 
(3.21) 
358 
Linear Systems 
and let (A, F W^^^, C) be controllable  (-from-the-origin)  and observable. It turns out 
that  the  error  covariance  E[(x  -  x){x  -  x)^]  is  minimized  when  the  filter  gain  is 
given by 
K*  =  PlC^V-\ 
(3.22) 
where  P* denotes  the  symmetric,  positive  definite  solution  of  the  quadratic  (dual) 
algebraic  Riccati  equation 
P,A^  +  APe  -  PeC^V'^CP, 
+  TWT^ 
0. 
(3.23) 
Note that P*, which is in fact the minimum error covariance, is the positive semidef-
inite  solution  of the  above Riccati  equation  if  (A, TW^'^, C)  is  stabilizable  and  de 
tectable. The optimal estimator is asymptotically  stable. 
The  above  algebraic  Riccati  equation  is the dual  to the Riccati  equation  given 
in  (2.34)  for  optimal  control  and  can  be  obtained  from  (2.34)  making  use  of  the 
substitutions 
A^,B 
C^,M 
and 
R  V,Q^W. 
(3.24) 
Clearly, methods that are analogous to the ones developed by solving the control Ric 
cati equation  (2.34) may be applied to solve the Riccati equation  (3.21) in  filtering. 
These methods are not discussed here. 
EXAMPLE 3.4  Consider the system i  =  Ax,y  =  CJC, whereA  =  1  0  X  =  [0,  1], 
and  let  T  = 
,V  =  p  > 0,W  =  1.  We  wish  to  derive  the  optimal filter K* 
ro  01 
P*C'^V~^  given  in  (3.22).  In  this  case,  the  Riccati  equation  (3.23)  is  precisely  the 
Riccati  equation  of  the  control  problem  given  in  Example  2.7.  The  solution  of  this 
equation was determined to be 
P: 
We note that this was expected, since our example was chosen to satisfy  (3.24). There 
fore, 
r  =  P: 
1 
i jp 
Jp 
J^p 
D.  Full-Order  Observers: Discrete-Time  Systems 
We consider described by equations of the  form 
x{k  +  1)  =  Ax{k)  +  Bu{k), 
y  =  Cx{k)  +  Du(k), 
(3.25) 
where A G 7^'^><^ B  G i?^><'^," C  G  RP""""""^"," and D  G  RP""""""^. "
The construction  of  state estimators  for  discrete-time  systems  is mostly  analo 
gous to the continuous-time  case, and the results that we established  above for  such 
systems are valid in here as well, subject to obvious adjustments  and  modifications. 
There are, however, some notable differences.  For example, in discrete-time systems 
it is possible to construct a state estimator that converges to the true value of the state 
in finite time, instead  of infinite  time  as in the case  of  asymptotic  state  estimators. 
This is the estimator known as the deadbeat  observer.  Furthermore, in discrete-time 
systems it is possible to talk about current  state estimators, in addition to prediction 
state estimators. In what follows, a brief description of the results that are analogous 
to  the  continuous-time  case  are  given.  Current  estimators  and  deadbeat  observers 
that are unique to the discrete-time case are discussed  at greater  length. 
359 
CHAPTER 4: 
State Feedback 
and State 
Observers 
Full-state observers: The identity  observer 
As in the continuous-time  case, following  (3.2) we consider  systems  described 
by equations of the  form 
x{k  +  1)  =  Ax{k)  +  Bu{k)  +  K[y{k)  -  y{k)l 
(3.26) 
where y{k)  =  Cx(k)  -h Dx{k).  This can also be written  as 
x{k  +  1)  =  (A -  KC)x(k)  +  [5  -  KD,  K] 
u(k) 
(3.27) 
It  can  be  shown  that  the  error  e(k)  =  x(k)  -  x(k)  obeys  the  equation  e(k  +  1) == 
(A -  KC)e(k).  Therefore, if the eigenvalues of A -  KC  are inside the open unit disc of 
the complex plane, then  e(k)  ^  0 as /: —>  oo. There exists K  so that the  eigenvalues 
of A -  KC  can be arbitrarily assigned if and only if the pair (A, C) is observable (see 
Lemma  3.1). 
The discussion following Lemma 3.1 for the case when (A, C) is not completely 
observable,  although  detectable,  is  still  valid.  Also, the remarks  on appropriate  lo 
cations  for  the  eigenvalues  of A -  KC  and  noise being  the  limiting  factor  in  state 
estimators are also valid in the present case. Note that the latter point should seriously 
be considered when deciding whether or not to use the deadbeat observer  described 
next. 
To  balance  the  trade-offs  between  speed  of  the  estimator  response  and  noise 
amplification,  one  may  formulate  an  optimal  estimation  problem  as  was  done  in 
the  continuous-time  case,  the  Linear  Quadratic  Gaussian  (LQG)  design  being  a 
common  formulation.  The Kalman  filter  (discrete-time  case) which is based on the 
"""current  estimator""  described  below  is  such  a quadratic  estimator.  The  LQG  opti "
mal estimation  problem can be  seen to be the dual  of the quadratic  optimal  control 
problem discussed  in the previous  section. As in the continuous-time  case,  optimal 
estimation  in the discrete-time  case will be discussed  only briefly  in the  following. 
First, however,  several other related issues are  addressed. 
Deadbeat  observer.  If the pair (A, C) is observable, it is possible to select K so 
that all the eigenvalues of A -  KC  are at the origin. In this case e{k)  =  x(k)-  x{k)  = 
(A -  KC)^e(0)  =  0, for some k^  n\ i.e., the error will be identically zero within at 
most n steps. The minimum value of k for which (A -  KC)^  =  0 depends on the size 
of the largest block on the diagonal of the Jordan canonical form of A -  KC.  (Refer 
to the discussion on the modes of discrete-time systems in Section 2.7 of Chapter 2.) 
EXAMPLE 3.5.  Consider the system x(^ +  1) =  Ax(k),  y(k)  =  CJC(^), where 
A = 
C  p  1 
0  1 
360 
Linear Systems 
is in observer form. We wish to design a deadbeat  observer. It is rather easy to show 
(compare with Example 2.5) that 
""" "
Aj  -
"'  2  11"" "
-1  0 
"0"" "
K 
r-1 
[  1 
-1 
am 
0  Oj. 
which was determined by taking the dual AD  = A^,BD  =  C^ in controller form, using 
FD  = B;,'[Ad^ -  Am] and K  = 
-F^ 
The  matrix  Aj  consists  of  the  second  and  third  columns  of  a  matrix  A^  = 
0  X 
1  X 
0  X 
in observer (companion) form with all its eigenvalues at 0. For Aj^ 
"""0  0  0"" "
1  0  0 
.0  1  0_ 
, we have 
Ki  =  1 
ro  0' 
p  0 
Li  0. 
-
"""  2  1 "
-1  0 
0  0 
-1 
1 
0 
-1 
1  1 
-1  0 
-1  0 
and for A^2  ^ 
, we obtain 
K2 
1 
-1 
0 
Note that A -  /^iC  =  A^  A 2 
_ 
and  Al 
0, and A -  K2C =  A^^,  and 
Ai 
0. Therefore,  for the observer gain Ki  the error e(k) in the deadbeat observer 
will become zero in n  =  3 steps since e(3)  =  (A -  KiC)^e(0)  = 0. For the observer 
gain K2, the error e(k) in the deadbeat observer will become zero in2  < n steps, since 
e(2) =  (A -  K2C)^e(0) = 0. The reader should determine the Jordan canonical forms 
of Ad^  and A^^ ^^^ verify that the dimension of the largest block on the diagonal is 3 and 
2, respectively. 
• 
The  comments  in  the  discussion  following  Lemma  3.1  on  taking  ^  =  0  are 
valid  in the discrete-time  case  as well. Also, the  approach  of determining  the  state 
instantaneously  in the continuous-time  case, using  the  derivatives  of the input  and 
output,  corresponds  in the  discrete-time  case  to determining  the  state from  current 
and future  input and output values  (see Exercise  3.14 in Chapter  3). This  approach 
was in fact  used to determine  x(0) when  studying  observability  in Section  3.3. The 
disadvantage  of this method is that it requires future  measurements  to calculate  the 
current  state. This issue of using future  or past measurements  to determine the cur 
rent state is elaborated upon next. 
Current  estimator 
The  estimator  (3.26)  is  called  3. prediction  estimator.  The  state  estimate  x(k) 
is  based  on  measurements  up  to  and  including  y(/: -  1). It  is  often  of  interest  in 
361 
CHAPTER 4: 
state Feedback 
and State 
Observers 
applications  to determine  the state estimate  x(k)  based  on measurements  up to and 
including  y(k).  This may  seem rather odd at first; however, if the computation time 
required to calculate  x(k)  is short compared to the sample period in a sampled-data 
system, then it is certainly possible practically to determine the estimate x(k)  before 
x(k  +  1) and  y(k  +  1) are generated  by  the  system.  If this  state estimate, which  is 
based on current measurements  of y(k),  is to be used to control the system, then the 
unavoidable computational  delays  should be taken into  consideration. 
Now  let  x(k)  denote  the  current  state  estimate  based  on  measurements  up 
through y(k).  Consider the current  estimator 
where 
x(k)  =  x(k)  +  Kc(y(k)  -  Cx{k)), 
x(k)  =  Ax(k  -  1) +  Bu(k  -  1), 
(3.28) 
(3.29) 
i.e.,  x(k)  denotes  the  estimate  based  on  model  prediction  from  the  previous  time 
estimate, x(k  -  1). Note that in (3.28), the error is y(k)  -  y(k),  where y(k)  =  Cx(k) 
(D  =  0), for  simplicity. 
Combining the above, we obtain 
x(k)  =  (I  -  KcC)Ax(k  -  1) +  [(/  -  KcC)B,  -Kc] 
\u(k -  1)1 
y(k) 
(3.30) 
The relation to the prediction estimator (3.26) can be seen by substituting (3.28) into 
(3.29) to obtain 
x(k  +  1)  =  Ax(k)  +  Bu(k)  +  AKc[y(k)  -  Cx(k)l 
(3.31) 
Comparison with the prediction estimator  (3.26) (with D  =  0) shows that if 
K  -  AKc, 
(3.32) 
then (3.31) is indeed the prediction estimator, and the estimate x(k)  used in the cur 
rent estimator (3.28) is indeed the prediction state estimate. In view of this, we expect 
to obtain for the error e(k)  =  x(k)  -  x(k)  the difference  equation 
e(k  +  1)  =  (A -  AKcC)e(k) 
(3.33) 
(show  this).  To  determine  the  error  e{k)  =  x{k)  -  x(k)  we  note  that  e{k)  = 
e(k)  -  (x(k)  -  x(k)).  Equation  (3.28)  now  implies  that  x(k)  -  x(k)  =  KcCe(k). 
Therefore, 
e(k)  = 
(I-KcC)e(kl 
(3.34) 
This establishes the relationship between errors in current and prediction estimators. 
Premultiplying  (3.31) by /  -  KcC  (assuming  |/  -  KcC\  ¥- 0), we obtain 
e(k^  1)  - 
{A-KcCA)e(k\ 
(3.35) 
which is the current estimator error equation. The gain Kc is chosen so that the eigen 
values  of A -  KcC A  are within  the  open  unit  disc  of the  complex  plane. The  pair 
(A, CA)  must be observable for  arbitrary  eigenvalue  assignment. Note that the two 
error equations  (3.33) and (3.35) have identical eigenvalues  (show this). 
EXAMPLE  3.6.  Consider the  system  x{k +  1)  =  Ax(^), y{]i) =  Cx(k),  where A  = 
0 
1 
C  =  [0,  1], which is in observer form  (see also Example 3.2). We wish to 
-21 
362 
Linear Systems 
design a current estimator. In view of the error equation (3.35), we consider 
det{sl  -  (A -  KcCA))  = det 
"l\s  0"" "
|o  s_ 
s + ko 
ki  -  1 
po 
Ui. [1  - 2] 
- 2. 
"_/ I ""0  -2"" "
.1 
2 -  Iko  ] 
s +  2-2y^iJ 
= det 
=  /  + 5(2 -  2y^i +  ko) + (2 -  2y^i) 
=  5^ + dis  -\- do = ad(s), 
a desired polynomial, from  which Kc  =  [ko, ki]^  =  [di -  do,  \{2  -  Jo)]^- Note that 
AKc  =  [do  -2,di 
-  2f  = K, found in Example 3.2, as noted in (3.32). 
The  current  estimator  (3.30)  is  now  given  by  x{k)  =  {A -  KcCA)x{k  -  1)  -
KcCBu(k -  1) + Kcy(kl  or 
x(k) 
— ko  — 2 + 2ko 
I -  ki 
-2  + 2ki_ 
x(k  -  1) + 
y(k). 
Partial or linear functional  state  observers 
The problem of estimating a linear function  of the state, Tx{k),  T  E  R^^^^ where 
ft ^  n, using a prediction estimator, is completely  analogous to the  continuous-time 
case and w^ill therefore  not be discussed further  here. 
E.  Reduced-Order  Observers: Discrete-Time  Systems 
It is possible to estimate the full  state x(k)  using an estimator of order n-  p,  where 
p  =  rank  C. If a prediction  estimator is used for that part of the state that needs to 
be estimated, then the problem in the discrete-time  case is completely  analogous to 
the continuous-time  case, discussed before. We will omit the details. 
F.  Optimal  State Estimation: Discrete-Time  Systems 
The formulation  of the Kalman filtering problem in discrete-time is analogous to the 
continuous-time  case. 
Consider the linear time-invariant  system given by 
x{k  +  1)  =  Ax{k)  +  Bu{k)  +  Tw{k\ 
y(k)  =  Cx(k)  +  v, 
(3.36) 
where  the  process  and  measurement  noises  w, v  are  white,  zero-mean  Gaussian 
stochastic processes, i.e., they are uncorrected in time with £'[vv]  =  0, andjE'[v]  ==  0. 
Let the covariances be given by 
E[ww^]  =  W, 
E[vv^]  =  V, 
(3.37) 
where  W  =  W^,  W  >  0  and  V  =  V^,  V >  0.  Assume  that  w, v  are  independent, 
that the initial state x{0) is Gaussian of known mean {E[x{0)\  =  XQ), that E[(x(0) — 
xo)(x(0)  -  XQ)^]  =  Peo, and that x(0)  is independent  ofw  and v. 
Consider now the current estimator (3.26), namely, 
x(k)  =  x(k)  +  Kc[y(k)  -  Cx(k)l 
where  x(k)  =  Ax(k  -  1) +  Bu(k  -  1), and  x(k)  denotes  the prior  estimate  of  the 
state at the time of a measurement. 
It turns out that the state error covariance is minimized  when the filter gain is 
Kl  =  PlC^(CPlC^  +  V)~\ 
(3.38) 
where P* is the unique, symmetric, positive definite  solution of the Riccati equation 
363 
CHAPTER 4: 
State Feedback 
and State 
Observers 
Pe  -  A[Pe 
-  PeC^iCPeC^ 
+  W^CPeU^ 
+  TWT^. 
(3.39) 
It  is  assumed  here  that  (A, FW^^^, C)  is reachable  and  observable.  This  algebraic 
Riccati  equation  is the dual to the Riccati equation  (2.53) that arose in the discrete-
time LQR problem and can be obtained by  substituting 
A^,B 
C^,M 
and 
R-^  V,Q  W. 
(3.40) 
It is clear that, as in the case of the LQR problem, the solution of the algebraic Riccati 
equation can be determined using the eigenvectors of the (dual)  Hamiltonian. 
The  filter  derived  above  is  called  the  discrete-time  Kalman  filter.  It  is  based 
on  the  current  estimator  (3.28). Note  that  AKc  yields  the  gain  K  of  the  prediction 
estimator  [see (3.32)]. 
4.4 
OBSERVER-BASED  DYNAMIC  CONTROLLERS 
State  estimates,  derived  by  the methods  described  in the previous  section,  may  be 
used  in  state feedback  control  laws  to compensate  given  systems. This  section  ad 
dresses that topic. 
In  Section  4.2,  the  linear  state  feedback  control  law  was  introduced.  There  it 
was implicitly  assumed that the state vector  x{t)  is available for measurement.  The 
values of the states x{t) for t  >  t^ were fed back and used to generate a control input 
in accordance with the relation  u{t)  =  Fx(t)  + r(t).  There are cases, however,  when 
it  may  be  either  impossible  or impractical  to measure  the  states  directly.  This  has 
provided the motivation to develop methods for estimating the states. Some of these 
methods  were considered  in  Section 4.3. A natural  question  that  arises  at this  time 
is  the  following:  what  would  happen  to  system  performance  if,  in  the  control  law 
u  =  Fx-\-r,  the state estimate x were used in place of x as in Fig. 4.5? How much, if 
any, would the compensated system response deteriorate? What are the difficulties  in 
designing such estimator- (observer-) based linear state feedback  controllers? These 
questions  are  addressed  in this  section. Note that  observer-based  controllers  of  the 
type described in the following  are widely  used. 
'  Itr 
1 
v^* 
- {-
• 
1 
^  u 
1 
* 
System  [ 
State 
observer 
U 
F  1-
FIGURE 
Observer-
4.5 
3ased 
contro 
Her 
364 
Linear Systems 
In  the  remainder  of  this  section  we  will  concentrate  primarily  on  full-state/ 
full-order  observers  and  (static)  linear  state  feedback,  as  applied  to  linear  time-
invariant  systems. The analysis of partial-state and/or reduced-order  observers  with 
static  or dynamic  state  feedback  is  analogous;  however,  it is  more  complex.  Such 
control  schemes  are not considered  at this point.  Instead,  they  will be  discussed  in 
the exercise section (Exercise 4.8). In this section, continuous-time  systems are ad 
dressed. The analysis of observer-based  output controllers in the discrete-time  case 
is completely  analogous and will be  omitted. 
A.  State-Space  Analysis 
We consider  systems described by equations of the  form 
x  =  Ax-\-Bu, 
y  =  Cx  + Du, 
(4.1) 
"where A  E  i?""^^'^", B  G T^^^^^, C  G i^^^^^, and D  G  RP'^'^.  For such systems, we de 
termine  an  estimate  x{t)  G  R^  of  the  state  x{t)  via  the  (full-state/full-order)  state 
observer  (3.2) given by 
=  Ax^Bu-\- 
K(y  -  y) 
=  (A-  KC)x  +  [J5 -  KD,  K] 
u 
= 
X, 
(4.2) 
where  y  =  Cx  + Du.  We now compensate  the  system by state feedback  using  the 
control law 
u  =  Fx  +  r, 
(4.3) 
where  x  is the output of the state estimator  and we wish to analyze the behavior of 
the compensated  system. To this end we first eliminate y in (4.2) to obtain 
The state equations of the compensated  system are then given by 
X =  {A-  KC)x  +  KCx  +  Bu, 
X =  Ax-^  BFx  +  Br 
k  =  KCx  + (A-KC 
+ BF)x  +  Br, 
and the output equation assumes the  form 
y  =  Cx  + DFx  + Dr, 
(4.4) 
(4.5) 
(4.6) 
where u was eliminated from  (4.1) and (4.4), using (4.3). Rewriting in matrix  form, 
we have 
X 
X 
=  A 
KC  A 
BF 
1 
KC  +  BF\ 
\x 
IX 
+  B 
B 
y  =  [QDF]  X 
X 
+ Dr, 
(4.7) 
which is a representation of the compensated closed-loop system. Note that (4.7) con 
stitutes a 2Azth-order system. Its properties  are more easily  studied if an  appropriate 
365 
CHAPTER  4: 
State Feedback 
and State 
Observers 
similarity  transformation  is used to simplify  the representation.  Such  a  transforma 
tion is given by 
X 
PK  = 
= 
X 
7 
/ 
01 
-l\ 
\x 
[x  =  X 
e 
where the error e(t)  =  xit)  -  x(t).  Then the equivalent representation  is 
X 
e 
= 
A  + BF 
0 
-BF 
A-KC 
\x 
[e  + 
B 
0 
y 
= 
[C +  DF,  -DF] 
x\ 
+  Dr, 
(4.8) 
(4.9) 
It is now quite clear that the closed-loop system is not fully  controllable with respect 
to r (explain this in view of Subsection 3.4A). In fact,  e{t) does not depend on r at all. 
This is of course as it should be, since the error  e{t)  =  x(t)  -  x(t)  should  converge 
to zero independently  of the externally  applied input  r. 
The closed-loop eigenvalues  are the roots of the polynomial 
\sln -  (A +  BF)\\sIn  -  (A -  KC)\. 
(4.10) 
Recall  that  the  roots  of  \sln -  (A  +  BF)\  are  the  eigenvalues  of  A +  BF  that  can 
arbitrarily  be assigned  via F provided  that the pair  (A, B)  is controllable. These  are 
in  fact  the closed-loop  eigenvalues  of the  system  when  the  state x  is  available  and 
the linear state feedback  control law u  =  Fx-\-  ris  used (see Section 4.2). The roots 
of |^/„ -  (A -  KC)\  are the eigenvalues of (A -  KC)  that can arbitrarily be assigned 
via K  provided  that  the pair  (A, C)  is observable.  These  are  the eigenvalues  of  the 
estimator (4.2). 
The above discussion  points out that the design  of the control  law  (4.3)  can  be 
carried  out  independently  of the design  of the estimator  (4.2).  This is referred  to as 
the  Separation  Property  and  is  generally  not  true  for  more  complex  systems.  The 
separation  property  indicates  that  the linear  state feedback  control  law  may  be de 
signed as if the state x were available and the eigenvalues of A + BF  are assigned at 
appropriate locations. The feedback  matrix F can also be determined by  solving  an 
optimal control problem (LQR). If state measurements are not available for  feedback, 
a state estimator is employed. The eigenvalues of a full-state/full-order  estimator are 
given by the eigenvalues  of A -  KC.  These are typically  assigned  so that the error 
e(t)  =  x(t)  -  x(t)  becomes  adequately  small in a short period  of time. For this, the 
eigenvalues of A -  KC  are (empirically) taken to be about 6 to 10 times further  away 
from  the  imaginary  axis  (in  the  complex  plane,  for  continuous-time  systems)  than 
the eigenvalues of A + BF.  The behavior of the closed-loop system should be verified 
since the above is only a rule of thumb. (Refer to any good book on control for  further 
discussion—see  Section 4.6, Notes.) The estimator  gain K  may  also be  determined 
by solving an optimal estimation problem  (the Kalman filter). In fact,  under the as 
sumption  of Gaussian  noise and initial conditions  given  earlier  (see Section 4.3), F 
and i^ can be found by solving, respectively, optimal control and estimation problems 
with quadratic performance  criteria. In particular, the deterministic LQR problem is 
first solved to determine the optimal control gain F*, and then the stochastic  Kalman 
filtering  problem  is  solved  to  determine  the  optimal  filter  gain  i^*.  The  separation 
property  (i.e..  Separation  Theorem—see  any  optimal  control  textbook)  guaran 
tees  that  the  overall  (state  estimate  feedback)  Linear  Quadratic  Gaussian  (LQG) 
366 
Linear Systems 
control design  is optimal in the sense that the control law  w*(0  =  F''x{t)  minimizes 
the quadratic performance  index E[\^{z^Qz  +  u^Ru)  dt].  As was discussed in pre 
vious sections, the gain matrices F* and K* are evaluated in the following  manner. 
Consider 
X =  Ax-\-  Bu-l-Tw, 
y  =  Cx-\-v,z  =  Mx 
(4.11) 
with E[ww^]  =  W >  0 and E[vv'^]  =  V >  0 and with  Q >  0, R  >  0 denoting  the 
matrix weights in the performance index E[\^(z^Qx  + u^Ru)  dt].  Assume that both 
(A, B, Q^'^M) and  (A, TW^''^,  C)  are controllable  and  observable.  Then the  optimal 
control law is given by 
u{t)  =  F'^m  =  -R-^B^Pim, 
(4.12) 
where P*  >  0 is the solution of the algebraic Riccati equation  (2.34) given by 
A^Pc  +  PcA  -  PcBR-^B^Pc  +  M^QM  =  0. 
(4.13) 
The estimate  x is generated by the optimal  estimator 
where 
k  =  Ax^  Bu  + K\y 
^*  =  Plc^y-
-  Cx), 
(4.14) 
(4.15) 
in which  P*  >  0 is the  solution  to the dual  algebraic  Riccati  equation  (3.21)  given 
by 
PeA^  +  APe 
-  PeC^V'^CPe 
+  TWT^ 
=  0. 
(4.16) 
Designing  observer-based  dynamic  controllers  by  the  LQG  control  design 
method  has  been  quite  successful,  especially  when  the  plant  model  is  accurately 
known. In this approach the weight matrices  Q, R and the covariance matrices  W, V 
are used as design parameters. Unfortunately,  this method does not necessarily  lead 
to robust designs when uncertainties  are present. This has led to an enhancement of 
this method, called the LQR/LTR  (Loop Transfer  Recovery) method, where the de 
sign parameters  W and  V are selected  (iteratively)  so that the robustness  properties 
of the LQR  design are recovered  (refer  to Section 4.6). 
Finally, as was mentioned, the discrete-time case is analogous to the continuous-
time case and its discussion will be  omitted. 
EXAMPLE 4.1.  Consider the system x  = Ax  + Bu, y  =  Cx, where 
0  1 
0  0 
0 
0 
1 
2 -1 
ro 
1 
.0 
11 
1 
0. 
C  =  [1, 0, 0]. 
This is a controllable and observable but unstable system with eigenvalues of A equal 
to 0, -2, 1. A linear state feedback  control u  = Fx  -\-  r was derived in Example 2.5 to 
assign the eigenvalues of A + BF at -2, -1  ± j.  An appropriate F to accomplish this 
was shown to be 
F  = 
2 
-2 
-1 
0 
-2 
\ 
If the state x(t) is not available for measurement, then an estimate x(t) is used instead, 
i.e., the control law  u  =  Fx  + r is employed.  In Example  3.1, a  full-order/full-state 
observer, given by 
X =  (A-  KC)x  +  [B, K^ 
was derived  [see (3.3)]  with the eigenvalues  of A -  KC  determined  as the roots of  the 
polynomial  ad{s)  =  s^  + d2S^ + dis  + do. It  was  shown  that  the  (unique)  K  is in  this 
case 
K  =  [d2~  1, Ji  -  ^2  +  3, do-di+ 
3d2 -  5]^, 
367 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
and the observer is given by 
1  -d2 
-di 
+d2-3 
_-do  + di  -  3^2  +  5 
1 
0 
2 
"0"" "
1 
- 1. 
x + 
0  1 
1  1 
0  0  do-di+ 
d2-l 
^ 1 - ^ 2 +3 
3d2 -  5 
Using  the  estimate  x  in place  of the  control  state x  in  the  feedback  control  law  causes 
some deterioration in the behavior of the system. This deterioration can be studied experi 
mentally. (See the next subsection for analytical results.) To this end, let the eigenvalues 
of  the  observer  be  at,  say,  -10,  -10,  - 1 0,  let  x(0)  =  [1, 1, 1]^  and  x(0)  =  [0, 0, 0]^, 
plot x(t),  x(t),  and e(t)  =  x(t)  — x(t),  and compare these with the corresponding plots of 
Example 2.5, where no observer was used. Repeat the above with observer  eigenvalues 
closer to the eigenvalues of A + BF  (say, at - 2,  -1  ± j)  and also further  away. In general 
the faster the observer, the faster  e(t)  -^  0, and the smaller the deterioration of response; 
however, in this case care should be taken if noise is present in the system. 
• 
B.  Transfer  Function  Analysis 
For  the  compensated  system  (4.9)  [or  (4.7)],  the  closed-loop  transfer  function  T(s) 
between  y  and  r is  given  by 
3;(^)  =  T(s)r(s)  =  [(C  +  DF)[sI 
-  (A  +  BF)Y^B 
+  D]r{s), 
(4.17) 
where  y{s)  and  r{s)  denote  the Laplace  transforms  of  y{t)  and  r ( 0,  respectively.  The 
function  T{s)  was  found  from  (4.9), using  the  fact  that  the  uncontrollable  part  of  the 
system  does  not  appear  in  the  transfer  function  (see  Section  3.4).  Note  that  T{s)  is 
the  transfer  function  of  {A  +  BF,  B,C  +  DF,  D],  i.e.,  T{s)  is  precisely  the  transfer 
function  of  the  closed-loop  system  Hp{s)  when  no  state  estimation  is  present  (see 
Section  4.2).  Therefore,  the  compensated  system  behaves  to  the  outside  world  as 
if  there  were  no  estimator  present.  Note  that  this  statement 
is  true  only  after  suffi 
cient  time  has  elapsed  from  the  initial  time,  allowing 
to  become  negli 
gible.  (Recall  what  the transfer  function  represents  in  a system.)  Specifically,  taking 
Laplace  transforms  in  (4.9)  and  solving,  we  obtain 
the  transients 
= 
[si  -(A  +  BF)] 
-1 
_ 
-[si 
(A  +  BF)]-^BF[sI 
-  (A  -  KC)]-^] 
0 
[si  -  (A-h  BF)]-^ 
+ 
[si  -(A  +  BF)]-^B 
0 
ris) 
Ks)  =  [C 
+  DF,  -DF]  Ms)] 
_e(s)\ 
+ Dris). 
\x(0) 
\\e(0) 
(4.18) 
368 
Linear Systems 
Therefore, 
y(s)  - (C  +  DF)[sI  -  (A +  BF)r^x(0) 
-  [(C  +  DF)[sI  -  (A +  BF)r^BF[sI 
+  DF[sI  -  (A +  BF)r^]e(0)  +  T(s)r{s\ 
-  (A 
KC)y 
(4.19) 
which  indicates  the  effects  of  the  estimator  on  the  input-output  behavior  of  the 
closed-loop system. Notice how the initial conditions for the error ^(0)  =  x(0) -  x(0) 
influence  the  response.  Specifically,  when  ^(0)  T^ 0,  its  effect  can  be  viewed  as  a 
disturbance that will become negligible  at steady  state. The speed by which the  ef 
fect of ^(0) on y will diminish depends on the location of the eigenvalues of A +  BF 
and A -  KC,  as can be easily  seen from relation (4.19). 
Two-input  controller 
In the following, we will find it of interest to view the observer-based  controller 
discussed  previously  as  a  one-vector  output  (u)  and  a  two-vector  input  (y  and  r) 
controller.  In  particular,  from  x  =  (A  -  KC)x  -\-  (B  -  KD)u  +  Ky  given  in  (4.2) 
and  u  =  Fx  -\-  r given in (4.3), we obtain the  equations 
X =  {A-KC  + BF  -  KDF)x  + [K,B-  KD] 
u  =  Fx  +  r. 
(4.20) 
This is the description  of the (nth order) controller  shown in Fig. 4.5. The state x  is 
of  course  the  state  of  the  estimator  and  the  transfer  function  between  u and  y, r  is 
given by 
u(s)  =  F[sl  -{A-KC 
+  [F[sl  -{A- 
+ BF  - 
KC  + BF  ~  KDF)Y\B 
KDF)Y^Ky{s) 
-  KD)  4- I]r{s\ 
(4.21) 
"If we are interested only in ""loop properties",""" then r can be taken to be zero", in which 
case (4.21) (for r  =  0) yields the output feedback  compensator, which  accomplishes 
"the same control objectives  (that are typically only ""loop properties"") as the original "
observer-based controller. This fact is used in the LQG/LTR design approach. When 
r  7^ 0, (4.21) is not appropriate for the realization of the controller since the  transfer 
function  from  r, which must be outside the loop, may be unstable. Note that an ex 
pression  for  this controller that leads  to a realization  of a stable closed-loop  system 
is given by 
u{s)  =  [F[sl  -{A-KC 
+ BF  -  KDF)Y^[K,  B  -  KD]  -I- [0, /]] 
(4.22) 
r(s) 
(see Fig. 4.6). This was also derived from  (4.20). The stability of general  two-input 
controllers  (with two degrees  of freedom)  is discussed  at length in Section 7.4D  of 
Chapter 7. 
r 
Controller 
u 
System 
y 
FIGURE 4.6 
Two-input controller 
At this point, we find it of interest to determine the relationship of the observer-
based controller and the conventional one-and-two block controller configurations of 
Fig. 4.7. Here, the requirement is to maintain the same transfer functions between in 
puts y and r and output u. (For further  discussion of stability and attainable response 
maps  in  systems  controlled  by  output  feedback  controllers,  refer  to  Section  7.4  of 
Chapter 7.) We proceed by considering  once more (4.2) and (4.3) and by  writing 
369 
CHAPTER 4: 
State Feedback 
and State 
Observers 
u(s)  =  F[sl  -  (A -  KC)r\B 
-  KD)u(s) 
+  F[sl  -  (A -  KC)r^Ky(s) 
+  r(s)  =  Guu(s)  +  Gyy(s)  +  r(s). 
This yields 
u(s)  =  (I-  Gur'[Gyy(s)  +  r(s)] 
(4.23) 
(see Fig. 4.7). Notice that 
Gy  =  F[sl  -  (A -  KOr^K, 
(4.24) 
i.e., the controller  in the feedback  path  is  stable  (why?). The matrix  (/  -  Gu)~^  is 
not necessarily  stable; however, it is inside the loop and the internal  stability  of the 
compensated  system is preserved.  Comparing with (4.21), we obtain 
(/  -  G J ~i  =  F[sl  -{A-KC 
+ BF  -  KDF)Y\B 
-  KD)  +  /. 
(4.25) 
Also, as expected, we have 
(/  -  GuT^Gy  =  F[sl  -{A-KC^-BF 
-  KDF)Y^K 
(4.26) 
(show this). These relations  could have been  derived  directly  as well by the use of 
matrix identities; however,  such derivation is quite  involved. 
r 
'  ' ^0  • 
1  + 
1 
1 
1 
FIGURE 4.7 
(1 -  Gu)-' 
'  u 
System 
y 
Gy 
EXAMPLE 4.2.  For the system x  = Ax  + Bu, y  =  Cx with A = 
B = 
and C  =  [0,  1] we have H(s)  =  C(sl  -  A)-^B  = s/(s^ + 2s + 2). In Example 3.2, it 
was shown that the gain matrix K  =  [do  -  2, di  -  2]^ assigns the eigenvalues of the 
asymptotic observer (of A -  KC) at the roots of s^ + dis + do. In fact si  -  (A-  KC)  = 
do 
s 
-1  s + di_ 
. It is straightforward  to show that F  =  [\ao —  1,2 — ai\  will assign the 
eigenvalues of the closed-loop system (of A + BF) at the roots of ^^ + ^i^ + ao. Indeed, 
si  -{A  + BF) 
2 
s 
kao  s -\- a\ 
. Now in (4.23) we have 
Gy{s) = 
F(sI-(A-KC))-^K 
s((do -  2)(iao  -  1) + (di -  2)(2 -  aQ) + ((do  -  d,){ao  -  2) + {do  -  2)(2 -  a,)) 
s^ + dis  + do 
370 
Linear Systems 
1 
s(2 — a\) — doilao  —  I) 
G,(s)  =  FisI  -  (A -  KOr'B  =  ^ 
(1 -  G„)-'  = 
''+d,s  + do 
_ 
s^ + s(di  + a\  -  2) +  haodo 
^'' 
°^^  ° 
"s""-+ dis  + do "
'-, 
4.5 
SUMMARY 
In this chapter, Hnear state feedback controllers and state observers were studied with 
an  emphasis  on  time-invariant,  continuous-time,  and  discrete-time  systems  (Sec 
tions 4.2 and 4.3). State feedback controllers and state observers were then combined 
(in Section 4.4) to develop observer-based dynamic output feedback  controllers. We 
note that output feedback  controllers are studied further  in Chapter 7. 
Linear  state  feedback  was  studied  in  Section  4.2. First,  the  need  for  feedback 
was explained by discussing open- and closed-loop control in the presence of uncer 
tainties. System  stabilization  was then  addressed  which  for  the time-invariant  case 
leads  to the eigenvalue  or pole  assignment  problem.  It was pointed  out that  an op 
timal control formulation,  such  as the Linear  Quadratic  Regulator  (LQR)  problem, 
will  also  lead  to  stable closed-loop  control  systems  while  attaining  additional  con 
trol  goals  as well. Furthermore,  the LQR  problem  formulation  can  also be used  in 
the time-varying case. The eigenvalue assignment problem was studied at length by 
introducing several such methods. Analogous results for the discrete-time case were 
established  in Subsections 4.2E and 4.2F. 
In  Section  4.3, full-order  observers  for  the  entire  state  or for  a linear  function 
of  the  state  were  presented.  Reduced-order  observers  and  optimal  observers  were 
also addressed in Subsections 4.3B  and 4.3C, respectively. The duality between the 
state feedback controller and state observer problems was explored and emphasized. 
Analogous results for the discrete-time case were also described. Current  state esti 
mators were introduced  and developed in Subsection 4.3D. 
In Section 4.4, state observers, together with state feedback controllers were used 
to derive dynamic output feedback  controllers and the Separation Principle was dis 
cussed. The degradation of performance  in state feedback  control when an observer 
is used  to estimate  the  state  was  explained.  An  analysis  of  the  closed-loop  system 
was carried out, using both state-space and transfer  function  matrix  descriptions. 
4.6 
NOTES 
The fact that if a system is (state) controllable, then all its eigenvalues can arbitrarily 
be  assigned  by  means  of  linear  state  feedback  has  been  known  since  the  1960s. 
Original  sources  include  Rissanen  [19], Popov  [17], and  Wonham  [23]. (See  also 
remarks in Kailath  [10], pp.  187,  195.) 
The present approach for eigenvalue assignment via linear state feedback,  using 
the controller form, follows the development in Wolovich [22]. Ackermann's  formula 
first appeared in Ackermann  [1]. 
The development of the eigenvector formulas for the feedback matrix that assign 
all the closed-loop eigenvalues and (in part) the corresponding  eigenvectors  follows 
371 
CHAPTER 4: 
State Feedback 
and State 
Observers 
Moore [16]. The corresponding development that uses (A, B) in controller  (compan 
ion) form  and polynomial matrix descriptions follows  Antsaklis  [3]. Related  results 
on static output feedback  and on polynomial and rational matrix interpolation can be 
found  in Antsaklis and Wolovich  [4] and Antsaklis and Gao  [5]. Note that the  flexi 
bility in assigning the eigenvalues  via state feedback  in the multi-input  case can be 
used  to  assign  the invariant  polynomials  of si  -  {A  -\r  BF)\  conditions  for  this  are 
given by Rosenbrock [20]. 
The Linear Quadratic Regulator (LQR) problem and the Linear Quadratic Gaus 
sian  (LQG)  problem  have  been  studied  extensively,  particularly  in  the  1960s  and 
early  1970s. Sources for these topics include the books by Anderson and Moore [2], 
Kwakemaak  and Sivan  [11], Lewis  [12], and Dorato et al. [9]. Early optimal control 
sources include Athans  and Falb  [6], and Bryson  and Ho  [8]. A very powerful  idea 
in optimal  control  is the Principle  of  Optimality,  Bellman  [7], which  can be  stated 
"as follows:  ""An  optimal  trajectory  has  the property  that  at  any  intermediate  point", 
no matter how it was reached, the remaining part of a trajectory  must coincide  with 
an optimal trajectory,"  computed from the intermediate point as the initial point"". For "
historical remarks on this topic, refer,  e.g., to Kailath  [10], pp.  240-241. 
The most influential work on state observers is the work of Luenberger. Although 
the asymptotic observer presented here is generally  attributed to him,  Luenberger's 
Ph.D. thesis work in  1963 was closer to the reduced-order observer presented above. 
Original  sources on state observers include Luenberger  [13], [14], and  [15]. For an 
extensive overview of observers, refer  to the book by O'Reilly  [18]. 
When  linear  quadratic  optimal  controllers  and  observers  are combined  in  con 
trol design,  a procedure  called  LQG/LTR  (Loop  Transfer  Recovery)  is used  to  en 
hance  the  robustness  properties  of  the  closed  loop  system.  For  a treatment  of  this 
procedure, see Stein and Athans  [21] and contemporary  textbooks on  multivariable 
control. 
4.7 
REFERENCES 
1.  J. Ackermann," ""Der Entwurf linearer Regelungssysteme im Zustandsraum",""" Regelungs-"
technik und Prozessdatenverarheitung, Vol. 7, pp. 297-300, 1972. 
2.  B.  D.  O.  Anderson  and  J.  B.  Moore,  Optimal Control  Linear  Quadratic  Methods, 
Prentice-Hall, Englewood Cliffs, NJ, 1990. 
3.  R J. Antsaklis," ""Some New Matrix Methods Applied to Multivariable System Analysis "
and Design,""" Ph.D. Dissertation", Brown University, May 1976. 
4.  P. J. Antsaklis  and W. A. Wolovich,"  ""Arbitrary  Pole Placement  Using Linear  Output "
Feedback Compensation,""" Int. J. Control", Vol. 25, No. 6, pp. 915-925, 1977. 
5.  P. J. Antsaklis and Z. Gao," ""Polynomial and Rational Matrix Interpolation: Theory and "
Control Applications,""" Int. J. of Control", Vol. 58, No. 2, 349-404, August 1993. 
6.  M. Athans and P. L. Falb, Optimal Control, McGraw-Hill, New York, 1966. 
7.  R. Bellman, Dynamic Programming, Princeton University Press, Princeton, NJ, 1957. 
8.  A. E. Bryson and Y. C. Ho, Applied Optimal Control, Hoisted Press, New York, 1968. 
9.  P. Dorato,  C.  Abdallah  and  V  Cerone,  Linear-Quadratic  Control:  An Introduction, 
Prentice-Hall, Englewood Cliffs, NJ, 1995. 
10.  T  Kailath, Linear Systems, Prentice-Hall, Englewood Cliffs, NJ, 1980. 
11.  H. Kwakemaak and R. Sivan, Linear Optimal Control Systems, Wiley, New York, 1972. 
12.  F  L. Lewis, Optimal Control, Wiley, New York, 1986. 
372 
Linear  Systems 
13.  D. G. Luenberger," ""Observing the State of a Linear System",""" IEEE  Trans. Mil.  Electron", 
14 
15 
16 
17 
MIL-8, pp. 74-80,  1964. 
D. G. Luenberger," ""Observers for Multivariable Systems",""" IEEE  Trans", on Auto.  Control, 
AC-ll,pp.  190-199,  1966. 
D.  G.  Luenberger,"  ""An  Introduction  to  Observers","""  IEEE  Trans",  on  Auto.  Control, 
AC-16, pp. 596-603, December 1971. 
B.  C. Moore,"  ""On  the Flexibihty  Offered  by  State  Feedback  in  Multivariable  Systems "
Beyond  Closed  Loop Eigenvalue  Assignment,"""  IEEE  Trans",  on Auto.  Control,  AC-21, 
pp. 689-692,  1976; see also AC-22, pp.  140-141,  1977 for the repeated eigenvalue case. 
V. M. Popov," ""Hyperstability and Optimality of Automatic Systems with Several Control "
Functions,""" Rev. Roum.  Sci. Tech. Sen ElectrotechEnerg.",  Vol. 9, pp. 629-690,1964. See 
also V. M. Popov, Hyperstability  of Control  Systems,  Springer-Verlag, New York, 1973. 
J. O'Reilly,  Observers for  Linear  Systems,  Academic Press, New York, 1983. 
18 
19.  J. Rissanen," ""Control System Synthesis by Analogue Computer Based on the Generalized "
Linear  Feedback  Concept,"""  in  Proc.  of  Symp.  on Analog  Comp.  Applied  to  the  Study "
of  Chem.  Processes,  pp.  1-13,  Intern.  Seminar,  Brussels,  1960.  Presses  Academiques 
Europeennes, Bruxelles, 1961. 
H. H. Rosenbrock,  State-Space  and Multivariable  Theory,  Wiley, New York,  1970. 
G. Stein and M. Athans," ""The LQG/LTR Procedure for Multivariable Feedback  Control "
Design,""" IEEE  Trans", on Automatic  Control,  Vol. AC-32, pp.  105-114, February  1987. 
W. A. Wolovich, Linear  Multivariable  Systems,  Springer-Verlag, New York,  1974. 
W.  M.  Wonham,"  ""On  Pole  Assigment  in  Multi-Input  Controllable  Linear  Systems",""" "
Vol. AC-12, pp. 660-665,  1967. 
22, 
23, 
20 
21 
4.8 
EXERCISES 
4.1.  Consider  the  system  x  =  Ax  +  Bu,  where  A 
-0.01 
0 
0 
-0.02 
and  B 
1 
1 
0.25  0.75J 
with  u  =  Ex. 
(a)  Verify  that the three different  state feedback  matrices given by 
-1.1 
0 
-3.7 
0 
0 
-1.1 
0 
1.2333 
-0.1 
0 
0 
- 0 .1 
all assign the closed-loop eigenvalues at the same locations, namely, at —0.1025 ± 
jO.04944. Note that in the first control law  (Fi)  only the first input is used,  while 
in the second law (F2) only the second input is used. For all three cases plot x(t)  = 
[xi(t),  X2(t)]^  when  x(0)  =  [0, 1]^  and  comment  on  your  results.  This  example 
demonstrates how different  the responses can be for different  designs even though 
the eigenvalues  of the compensated  system are at the same locations, 
(b)  Use the eigenvalue/eigenvector assignment method to characterize all F that assign 
the closed-loop  eigenvalues  at  -0.1025  ±  70.04944. Show how to select the  free 
parameters  to obtain Fi, F2, and F3 above. What  are the closed-loop  eigenvectors 
in these  cases? 
"4.2.  For the system  x  =  Ax  -\-  Bu  with A  E  /^""><"" and B  E  7?""^""""", where  (A, B)  is control 
lable  and  m  >  I,  choose  u  =  Fx  dis  the  feedback  control  law. It is possible to  assign 
all eigenvalues  of A +  BE  by first reducing this problem to the case of eigenvalue as 
signment for single-input  systems (m  =  1). This is accomplished by first reducing the 
system to a single-input  controllable  system.  We proceed  as  follows. 
Let  F  =  g  ' f,"  where  g  G  R^  and  /^  G  i?"" are vectors  to be  selected.  Let g  be "
373 
CHAPTER  4: 
State  Feedback 
and  State 
Observers 
chosen  such that (A, 5^)  is controllable. Then/  in 
A +  5F  =  A +  ( 5 g )/ 
can be viewed  as the state feedback  gain vector for  a single-input  controllable  system 
(A, Bg),  and  any  of  the  single-input  eigenvalue  assignment  methods  can  be  used  to 
select/  so that the closed-loop eigenvalues  are at desired locations. 
The only question that remains to be addressed is whether there exists g such that 
(A, Bg)  is  controllable.  It  can  be  shown  that  if  (A, B)  is  controllable  and A is  cyclic, 
then  almost  any  g  G  R^  will  make  (A, Bg)  controllable.  (A matrix A is  cyclic  if  and 
only if its characteristic  and minimal polynomials are equal.) In the case when A is not 
cyclic, it can be shown that if (A, B, C) is controllable  and observable, then for  almost 
any real output feedback  gain matrix //,  A +  BHC  is cyclic. So initially, by an almost 
arbitrary choice of H or F  =  HC,  the matrix A is made cyclic, and then by  employing 
a g, (A, Bg)  is made  controllable.  The  state feedback  vector  gain/  is then  selected  so 
that the eigenvalues  are at desired  locations. 
Note that F  =  gf  is always  a rank  one matrix,  and this restriction  on F  reduces 
the applicability of the method when requirements in addition to eigenvalue assignment 
are to be met. 
For  the  present  approach,  see  W.  M.  Wonham,"  ""On  Pole  Assignment  in  Multi-"
Input  Controllable  Linear  Systems,"""  IEEE  Trans.  Autom.  Control",  Vol.  AC-12, 
pp.  660-665,  December  1967,  and  F.  M.  Brasch  and  J.  B.  Pearson,"  ""Pole  Place "
ment  Using  Dynamic  Compensators,""" IEEE  Trans. Autom.  Control",  Vol. AC-15, pp. 
34-43,  February  1970.  For  a  discussion  of  cyclicity  of  matrices  see  Chapter  2,  and 
also P. J. Antsaklis," ""Cyclicity  and Controllability  in Linear Time-Invariant  Systems",""" "
IEEE  Trans. Autom.  Control,  Vol. AC-23, pp. 745-746, August  1978. 
(a)  For A, B as in Exercise 4.4, use the method described above to determine F so that the 
closed-loop eigenvalues are at —1 ±  jand—2  ±  /Comment on your choice for ^. 
(b)  For  A 
0  11 
,1  ij 
and  B 
eigenvalues  are at - 1. 
characterize  all  g  such  that  the  closed-loop 
4.3.  Consider the system  x(k  + 1) 
A  = 
Ax(k)  • 
4  0 
0 
0  1 
-1 
Bu(k),  where 
B  = 
'  0 
1 
. -1 
"0"" "
0 
1. 
Determine  a linear  state  feedback  control  law  u(k)  =  Fx{k)  such  that  all  the  eigen 
values of A  + BE  are located  at the origin. To accomplish  this, use 
(a)  reduction to a single-input  controllable  system, 
(b)  the controller form  of (A,  B), 
(c)  det  (zl  -  (A +  BF))  and the resulting nonlinear  system of equations. 
In each case, plot x(k)  with x(0)  =  [1, 1, 1]^ and comment on your results. In how 
many  steps does your compensated  system go to the zero  state? 
4.4.  For the system  x  =  Ax  + Bu,  where 
[O 
1 
0 
'l 
0 
0 
0 
"o"" "
0 
0 
1 
determine F so that the eigenvalues of A + BF  are at -
different  methods to choose F as you can. 
-1 ±  J  and  -2  ±  /  Use as many 
374 
Linear  Systems 
4.5.  Consider the system  x  =  Ax  + Bu,  where 
-1 
-1 
1 
0 
1 
-1 
(a)  Show that  -1  is an uncontrollable  eigenvalue. 
(b)  For  the  control  law  u  =  Fx,  determine  F  so that  the  controllable  eigenvalues  of 
0 
1 
0 
0 
-1 
0 
3 
-1 
-2 
0 
2 
0 
-6 
0 
6 
0 
0 
-2 
r  0 
-1 
0 
0 
1 
0 
r 
-2 
-1 
0 
2 
0 
0 
2 
1 
0 
2 
0 
B  = 
A  + BF  are 
- . l , - . 2 , - l ± j , - 2. 
4.6.  Consider  the  SISO  system  Xc  =  AcXc + BcU,y  =  CcXc +  DcU, where  {Ac, Be)  is  in 
controller form  with 
1 
0 
••• 
0  1 
[01 
Ac  = 
0 
l-ao 
0 
-ai 
••• 
••• 
1 
-an-ij 
Be  = 
Cc  =  [Co,  Ci, . . .,  Cn-ll 
and let w =  FcX + r  =  [/o,  / i , . . .,  fn-i]x  +  r be the linear state feedback  control law. 
Use the Structure Theorem of Chapter 3 to show that the open-loop transfer  function  is 
H(s)  =  Cc{sI-Ac)-'Bc 
+ Dc 
_  n{s)^ 
d(s) 
-is-n-l 
• • • +  CiS  +  Co 
s^  +  an-is^  ^ +  • • • +  ais  +  ao 
+ Dc 
and the closed-loop transfer  function  is 
HF(S)  =  (Cc +  DcFc)[sI  -  (Ac  +  BcFc)]-'Bc  + Dc 
_ 
(Cn-l  +  Dcfn-l)s''-' 
+  • • •  +  (CiS  +  Dcfx)s  +  (CQ  +  Z ) , / o) 
s^  +  (a„-i 
/„_!>«-!  +  •••  +  ( « !-  / i>  +  (ao  -  /o) 
-hD, 
^ FW 
Observe  that  state  feedback  does  not  change  the numerator  n(s)  of the transfer  func 
tion, but it can arbitrarily  assign any desired (monic) denominator polynomial dF(s)  = 
.  Thus,  state  feedback  does  not  (directly)  alter  the  zeros  of 
d(s)-Fells, 
H(s),  but it can  arbitrarily  assign the poles  of H(s).  Note that these results  generalize 
to the MIMO case  [see (2.44)]. 
4.7.  Consider the system  x  =  Ax  + Bu,y  =  Cx,  where 
[01 
ro 
A  =  \o 
1 
1 
0 
0 
01 
1  , 
- ij 
B  = 
C  =  [1, 2, 0]. 
(a)  Determine an appropriate linear state feedback  control law  u  =  Fx  + Gr(G  E  R) 
so that the closed-loop transfer function  is equal to a given desired transfer  function 
^ -W  =  s^  + \s  + 2-
We note that this is an example of model  matching,  i.e., compensating a given sys 
tem so that it matches the input-output behavior of a desired model. In the present 
case, state feedback  is used; however,  output feedback  is more common in model 
matching. 
(b)  Is the compensated  system in  (a) controllable?  Is it observable? Explain  your  an 
swers. 
(c)  Repeat  (a)  and  (b)  by  assuming  that  the  state  is  not  available  for  measurement. 
Design an appropriate  state observer, if possible. 
375 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
4.8.  Consider the nth order system  x  =  Ax  + Bu,  y  =  Cx  -\- Du. 
(a)  Let  z  =  Az  + Ky  +  [FB  -  KD]u,  A  E  R^'^^,  be  an  asymptotic  estimator  of  the 
linear function  of the state, Fx," where F  G R^^""- is the desired state feedback  gain. "
Consider the control law u  =  z + r and determine the representation and properties 
of the closed-loop  system. 
(b)  Consider a reduced-order  observer of order  n -  p  (as in Subsection 4.3B)  and the 
control law u  =  Fx  + r. Determine the representation and properties of the closed-
loop  system. 
Hint: The analysis is analogous to the full-state  observer case given in Section 4.4. 
4.9.  Design an observer for the oscillatory  system i (0  =  v{t),v{t)  =  -COQX(0, using mea 
surements of the velocity v. Place both observer poles at 5* =  -COQ. 
4.10.  Consider  the  undamped  harmonic  oscillator  xi(t)  =  X2(t), X2(t)  =  -(olxi(t)  +  u(t). 
Using  an observation  of velocity  y  =  X2, design  an observer/state  feedback  compen 
sator to control the position xi.  Place the state feedback  controller poles at ^  =  —(Oo± 
j(x)o  and both observer poles a.ts= 
-COQ. Plot x(t)  for  x(0)  =  [1, 1]-^ and  COQ  =  2. 
4.11.  A servomotor that drives a load is described by the equation  (d^O/dt^)  +  (dOldt)  =  w, 
where  6 is the  shaft  position  (output)  and  u is the applied  voltage. Choose  u so that 6 
and  (dO/dt)  will  go  to  zero  exponentially  (when  their  initial  values  are  not  zero). To 
accomplish this, proceed as  follows. 
(a)  Derive a state-space representation  of the  servomotor. 
(b)  Determine 
linear  state  feedback,  u  =  Fx  +  r,  so  that  both  closed-loop 
eigenvalues  are  at  - 1.  Such  F  is  actually  optimal  since  it  minimizes  J  = 
IQW^  +  (dO/dtf  +  u^] dt  (show this). 
(c)  Since only 9 and u are available for measurement, design an asymptotic state esti 
mator (with eigenvalues at, say,  - 3)  and use the state estimate x in the linear state 
feedback  control law. Write the transfer  function  and the state-space description of 
the overall  system and comment on stability, controllability,  and  observability. 
(d)  Plot 0 and dSldt  in (b) and (c) for  r  =  0 and initial conditions equal to  [1,1]^. 
(e)  Repeat  (c) and (d), using a reduced-order  observer of order  1. 
4.12.  Consider the LQR problem for the system  x  =  Ax  + Bu,  where (A, B) is  controllable 
and the performance  index is given by 
J{u)  =  \ 
Jo 
e^'''[x^(t)Qx(t)-\-u^(t)Ru(t)]dt, 
where a  G /?, a  >  0 and  g  >  0, /? >  0. 
(a)  Show  that  u* that  minimizes  J(u)  is  a  fixed  control  law  with  constant  gains  on 
the  states,  even  though  the  weighting  matrices  Q  =  e^^^Q, R  =  e^^^R are  time 
varying. Derive the algebraic Riccati matrix equation that characterizes this control 
law. 
(b)  The performance  index given above has been used to solve the question of relative 
stability. In the light of your solution, how do you explain  this? 
Hint:  Reformulate  the  problem  in  terms  of  the  transformed  variables  x  =  e^^x. 
376 
Linear  Systems 
4.13.  Consider the system x --
x + 
u and the performance  indices / i, J2 given by 
Ji= 
/»oo 
Jo 
{x\+X2  + u^)dt 
and 
J2= 
/»oo 
Jo 
(900ix\+X2)  +  u^)dt. 
Determine  the  optimal  control  laws  that  minimize  7i  and  J2.  In  each  case  plot  u{t), 
xi{t),X2{t)  for x(0)  =  [1,1]^  and comment on your results. 
4.14.  Consider the discrete-time  system x{k-\-l)  =Ax{k)  -\-Bu{k),y{k)  = C{k)x{k),  where 
1x2 
2^ 
C = [ 1 , 0] 
and where  T  is the sampling period. This is a sampled-data  system obtained from  (the 
double  integrator)  A 
.B 
and C =  [1,0]  via  a zero-order  hold  and  an 
ideal sampler, both of period  T  (see Chapter 2). 
Consider  the  cost  functional  J{u)  =  Yk=o(y^(^)  +  2w^(^))-  This  represents 
(2.51)  with  z{k)  =  y{k),M  =  C,Q  =  1,  and  R  =  2.  Determine  the  control  sequence 
{u*{k)},k>0, 
that  minimizes  the  cost  functional,  as  a function  of  T.  Compare  your 
results with Examples  2.7  and 2.9. 
4.15.  Consider the system x = 
(a)  Use  state  feedback  u 
x + 
"to  assign""the  eigenvalues  of  A+  BF  at  —0.5zbj0.5. "
Plot  x(t)  =  [xi(t),X2{t)]'^  for  the  open-  and  closed-loop  system  with  x(0)  = 
[-0.6,0.4]^. 
[l,0]x. 
u,y= 
1 
0 
1 
0 
=  Fx 
(b)  Design an identity observer with eigenvalues at — a  ±  y, where  a  >  0. What is the 
observer gain K in this case? 
(c)  Use the state estimate x from  (b) in the linear feedback  control law u = Fx,  where 
F  was found  in  (a). Derive the  state-space  description  of the closed-loop  system. 
If w =  Fx +  r, what is the transfer  function  between y and  r? 
(d)  For  x(0)  =  [-0.6,0.4]^  and  x(0)  =  [0,0]^  plot  x\t),x{t),y{t) 
and  u{t)  of  the 
closed-loop  system obtained  in (c) and comment  on your results. Use  a  =  1,2,5, 
and  10 and comment on the effects  on the system response. 
Remark:  This  exercise  illustrates  the  deterioration  of  system  response  when  state 
observers  are used  to  generate  the  state  estimate  that  is used  in  the  feedback  control 
law. 
4.16.  Consider the  system 
X(^+1):  --Ax{k)+Bu{k)+Eq{k), 
y{k)=Cx{k), 
where  q{k)  G R^  is  some  disturbance  vector.  It  is  desirable  to  completely  eliminate 
the  effects  of  q(k)  on the  output  y{k).  This  can happen  only  when  E  satisfies  certain 
conditions. Presently, it is assumed that q{k)  is an arbitrary  r x  1 vector. 
(a)  Express  the  required  conditions  on  E  in  terms  of  the  observability  matrix  of  the 
system. 
(b)  If A = 
,C =  [1,1], characterize  all E  that satisfy  these conditions. 
(c)  Suppose E  eR^^^,C  eRP^^,  and q{k)  is a step, and let the objective be to asymp 
totically reduce the effects  of q on the output. Note that this specification  is not as 
strict as in (a), and in general it is more easily  satisfied.  Use z-transforms  to derive 
conditions for this to happen. 
Hint:  Express the conditions in terms of poles and zeros of  {A,  E,C}. 
4.17.  Consider  the  system  {A, B, C, D} given  hy  x  =  Ax  + Bu,  y  =  Cx  + Du,  where  A  G 
377 
i?'^><«, B  e  R^^'P, C  G 7?^><^ D  G RP^'P,  and detD  #  0. 
(a)  ShowthatjA,^,  C, 5}  =  {A -  BD~^C,BD-\ 
-D'^Q  D~^} is the inverse  system 
of{A,B,C,D},i.e., 
C(5/  -  A)~^5  + D  =  H(s)-\ 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
where //(i-)  =  CC^*/ -  A) ~ ^ 5 +D  is the transfer function matrix of {A, B, C, D). Ver 
ify 
this  result  using  a  state-space  representation  of  the  system  H{s)  = 
(s^  +  l)/(^2  +  2). 
(b)  It is possible  to  show  (a) using results  involving  state  feedback.  In particular,  let 
(A, B) be controllable, let u  =  Fx+Gr,  and choose the linear state feedback control 
gain matrices (F,G)  so that//F,GW  =  (C+  DF)(sI-(A  +BF)y^BG  + DG  =  L 
Note that this choice for F makes  all eigenvalues  unobservable. Use this result to 
prove  (a). Hint:  It  can  be  shown  using  matrix  identities  that  HF,G(S)  =  H(s)  X 
[I-F(sI~A)-^C]-^G 
BF))-^B]G  [see (2A3)  to  (2A5)]. 
=  H(s)[I+  F(sI-(A+ 
Suppose now that det  D  =  0, but there exists a diagonal polynomial  matrix 
X(s)  =  diag(pi(s)), 
i  =  I,...,  p, 
with pi{s)  monic  stable polynomials  of degree  fi  such that 
\imX{s)H{s)  =  D, 
where det  D  9^ 0. 
(c)  Show that a realization  of X(s)H(s)  is x  =  Ax  + Bu,  y  =  Cx  + Du,  i.e., the A, B 
are the same as above and  C, D are some new matrices. 
(d)  Determine a control law u  =  Fx  + Gr that when applied to the system {A, B, C, D} 
yields 
HP,G{S)  = 
X-\sl 
a diagonal transfer function  matrix with stable poles at the zeros of Pi(s). Note that 
this  is  the  problem  of  diagonal  decoupling  via  state feedback  with  stability  (see 
below  and refer  to Subsection  7.4D  and the Notes of Chapter 7; see also  Exercise 
4.20). In  view  of  the  hint  in  (b), determine  a matrix  HR{S) SO that  H(S)HR(S)  = 
X-\s). 
The diagonal  decoupling  problem  via state feedback  is to determine a control 
law  u  =  Fx  -\- Gr  that  when  applied  to  the  system  {A, B, C, D]  yields  a  closed-
loop transfer  function  HF,G(S)  that is diagonal and nonsingular. The conditions  for 
existence  of  solutions  can  be  expressed  as  follows:  let X(s)  be  the  diagonal  ma 
trix X(s)  =  diag  [5^],  where  the  nonnegative  integers  {f}  are  so that  all rows of 
lim^^oo X(s)H(s)  are constant and nonzero and let 
\imX(s)H(s)  =  B\ 
Then  the  system  can  be  diagonally  decoupled  via  state  feedback  if  and  only  if 
rank  B*  =  p.  The  integers  {f}  are  called  the  decoupling  indices  of  the  system. 
(Note  that  5*  =  D.)  It  can  be  shown  that  the  p  X p  matrix  5*  can  also  be  con 
structed  from  {A, B, C, D} as follows:  if the /th row of D is nonzero, this  becomes 
the  /th  row  of  B*.  Otherwise,  if  f 
is  the  lowest  integer,  for  which  the  /th  row 
of CA^i'^B  is nonzero, then this row becomes the /th row of B*. 
(e)  Consider  the  system  {A, B, C}  of  Exercise  4.20  and  determine  whether  it  can 
be  diagonally  decoupled  via  state  feedback.  Use  both  the  state  space  matrices 
A, B, C  and  the  transfer  function  H(s)  and  verify  that  they  result  to  the  same 
matrix  B*. 
378 
Linear  Systems 
4.18.  Consider  the  system  {A, B, C, D}  given  by  x  =  Ax  +  Bu,  y  =  Cx  +  Du  with 
detD  ^  0,  where  (A, B)  is  controllable  and  (A, C)  is  observable.  If  {A, B, C, D}  = 
{A  -  BD~^C,  BD~^,  -D'^C,  D'^} 
is  its  inverse  system,  show  that  the  zeros  of 
{A, B, C, D} are thepoles  of {A, 5, C, 5}. Also, show  that the poles of {A, B, C, D} are 
the zeros of {A, 5, C, 5}. 
4.19.  Consider the system  x  =  Ax  + Bu,  y  =  Cx  + Du,  where 
c =  1  0 
1  2 
1  0 
0  1 
0  0 
0  0 
B = 
A  = 
D = 
1  0 
0  1 
Let u  =  Fx  + rbea.  linear state feedback  control law. 
(a)  Determine F so that the eigenvalues  of A +  BF  are - 1, -2  and are  unobservable 
from  y.  What  is  the  closed  loop  transfer  function  Hf(s)(y  =  Hpf)  in  this  case? 
Hint:  Select the eigenvalues  and eigenvectors  of A +  BF. 
(b)  Using the Structure Theorem of Chapter  3, verify  that  N{s)D~^{s) 
5 +  1 
0 
1 
5 +  2 
5  0 
0 
s 
-s+  1 
0 
5 +  2 
=  H(s)  =  C(sl  ~  A)-^B  +  D. 
Express your results in (a) as//(5)M(5)  =  iN(s)D-\s))(D(s)D^\s)) 
Hf(s)  (see Subsection  4.2D). 
=  N(s)Dp\s) 
4.20.  Consider the system  x  =  Ax  + Bu,  y  =  Cx,  where 
r  0  1  0] 
0  0  0 
. -1  0  1. 
B = 
ro  0] 
1  0 
Lo  1. 
c = 
fl 
1 
1 
.1  0 
0 
-1 
Note that 
H{s) =  N{s: 
)D-\s)  =  \ 
5+  1 
1 
-1 
0 1 
-1 
[1 
0 
-1 
5 
Is it possible to determine the pair (F, G)mu  =  Fx  + Gr  so that 
HFAS) 
5 +1 
(5 +  2)(5 +  3) 
0 
5+  IJ 
If your answer is yes, determine  such a pair (F,  G). 
Note that if it is required that Hf^cis)  be diagonal with poles at any stable locations, 
then this is the problem of diagonal  decoupling  via state  feedback. 
Hint:  Write H(s)  =  \ 
f. 
H(s)  and  work with H(s)  to determine  (F, G)  so 
that Hf^cis)  is diagonal with poles at desired locations. 
4.21.  Consider  the  controllable  and  observable  SISO  system  x  =  Ax  + Bu,y  =  Cx  with 
H(s)  =  C(sl  -  A)~^B. 
(a)  If  A  is not  an  eigenvalue  of A,  show  that  there  exists  an  initial  state  XQ  such  that 
the response to u(t)  =  e^\  r >  0, is y{t)  =  H{X)e^\  t  >  0. What happens if A is a 
zero  of//(5)? 
(b)  Assume that A has distinct eigenvalues. Let A be an eigenvalue of A and show that 
"there exists an initial state XQ such that with ""no input"" {u{t)  =  0)", y{t)  =  ke^\  t  > 
0, for  some  k  B  R. 
4.22. 
4.23. 
4.24. 
379 
CHAPTER  4: 
State  Feedback 
and  State 
Observers 
For the  discrete-time  case,  derive expressions  that  correspond  to formulas  (2.40)  to 
(2.45) of Subsection  4.2D. 
Consider  the  controllable  and  observable  SISO  system  x  = Ax-\-bu-\-  bw,y  =  ex, 
where  w is  a  constant  unknown  disturbance  modelled  by  w =  0.  If  an  estimate  of 
w,w  is  available,  then  we  may  attempt  to  cancel  out  the  disturbance  by  selecting 
u  =  —w. For  this,  consider  w  to  be  an  additional  state  for  the  original  system  and 
determine  an observer for this augmented  system. 
(a)  Show that the augmented  system is observable if  and only if 5 =  0 is not a zero 
of the system  [or of H{s)  =c{sl—A)~^b].  Hint:  Use the eigenvalue criterion  for 
observability. 
(b)  Assume  that  {A,b,c} 
is  stable  (or  has  been  stabilized)  and  select  the  gain  of 
the  observer  to  be  K^  =  [0,^],  where  k  e  R.  Show  that  the  compensator  u  = 
—w, which  asymptotically  cancels  out  the  constant  disturbance,  is  an  integral 
feedback  compensator. 
(c)  Consider  the  original  system  H{s)  =  c{sl  —A)~^b  and  use  the  results  of  Sub 
section  4.4B  to  design  an  output  compensator  that  compensates  for  the  above 
constant  disturbance.  For  simplicity  assume  that  H{s)  is  stable.  Hint:  There 
must be a pole ais  = 0. Note that the conditions in (a) must be  satisfied. 
Show that  {A + BHC,B,C} 
only if  {A,B,C} 
is controllable  and observable. 
"is controllable  and observable  for  any H  G  RP"""" "
if  and 
4.25. 
Consider the  system 
x{k+l)= 
2 
I  0 
0 
x{k) + 
"""1 "
0 
0 
"0"" "
1 
0 
u{k),y{k)-
0 
0 
x{k). 
4.26. 
Is  it  possible  to  determine  a  linear  state  feedback  law  u{k)  =  Fx{k)  +  r{k)  so  that 
the eigenvalues of A-\-BF  remain at exactly the same locations while  {A-\-BF,B,  C} 
becomes  observable? If the answer is affirmative,  determine  such  F. 
Static,  or constant  output feedback  u = Hy-\-r,H  G R'^^P^  can be used to compensate 
a system  X = Ax-\-Bu,  y = Cx, where A e  R^^^,C  e  R^^^  and assign the eigenvalues 
of A + BHC  of the closed-loop  system i  =  (A + BHC)x  -\-Br, y = Cx. In contrast  to 
state  feedback  compensation,  in  general  the  closed-loop  eigenvalues  cannot  be  ar 
bitrarily  assigned using H  even when  {A,B,C} 
is controllable and observable. It can 
"be  shown that one can arbitrarily  assign ""almost  always"" at least min  {m-\-p  —  l",n) 
eigenvalues  using  //;  note  that  when  p  =  m  =  1,  only  one  eigenvalue  can  be 
arbitrarily  assigned using H.  To illustrate, 
(a)  Let  A,B  be  as  in  Exercise  4.1,  let  C  =  [1,1],  and  determine  H  so  that  the 
eigenvalues of A + BHC  are at  -0.1025 ±y  0.04944. 
(b)  Let A,B  be  as  in  Exercise  4.3,  let  C =  [1,0,1],  and  determine  H  so  that  the 
eigenvalues of A-\-BHC  are all at zero. 
"(c)  For an example (of a ""nongenetic"" case) where fewer  than p-\-m—l "
eigenval 
ues can be arbitrarily  assigned,  consider 
A  = 
"""0 "
0 
0 
0 
10 
0 
0 
0 
0 
0 
"0"" "
0 
10 
1 
0 
"""0 "
1 
0 
0 
"0"" "
0 
0 
1 
c 
0 
1 
and  show  that  only  2  <  p-\-m 
aeR. 
1 =  3 eigenvalues  can be  assigned  to  i ^ / a^ 
380 
Linear  Systems 
Remark:  When only some of the n eigenvalues are assigned, as was the case when 
using  constant  output  feedback,  care  should  be taken  to guarantee  that the  remaining 
eigenvalues  will also be stable, since H  will typically  shift  all eigenvalues. 
4.27.  (Inverted pendulum)  Consider  the inverted  pendulum  described  in Exercise  1.20  of 
Ax  + Bu(dibouiy  =  0) assuming the 
Chapter  1. The linearized state-space model  x 
friction  is zero is given by 
Xi 
X2 
X3 
= 
"""0 "
1 
0 
.0 
, 
g 
^8 
L  ML 
0 
mg 
M 
0 
0 
0 
0 
1 
r^i 
\X2 
+ 
1x4 
0] 
0 
0 
oj 
r 
1 
ML 
0 
1 
M 
0 
u, 
where  xi  — 6, X2 =  9, X3 =  s, X4 =  s,  and  u  =  ^ii, the force  applied  to the cart.  Let 
L  =  1 m, m  =  0.1 kg, M  =  1 kg, and ^  =  10 m/sec^ to obtain 
Xi 
ol 
\xi 
0 
\x2 
Us 
0 
OJ 
\M 
(a)  Determine the eigenvalues  and eigenvectors  of A. 
(b)  Plot the  states when  x(0)  =  [0.01, 0, 0,0]^. Repeat for  zero initial conditions  and 
"- l"" "
0 
1 
0 
11 
0 
-1 
0 
0 
0 
0 
1 
0 
1 
0 
0 
X2 
X3 
X4 
+ 
u the unit step. Comment on your results. 
(c)  Determine the linear state feedback control law u  =  Fx  + r so thai the closed-loop 
system eigenvalues  are at  -10,  - 3,  - 1,  and  - 0 . 5. 
(d)  Use the LQR  formulation  to determine  a stabilizing  linear  state feedback  control 
law  u  =  Fx  + r. Comment on your choices for the weights. 
(e)  Letx(O)^  =  [0.5, 0, 0, 0]. Repeat (b) for the closed-loop system derived in (c) and (d). 
4.28.  (Armature  voltage-controlled  dc  servomotor)  Consider  the  armature  voltage-
controlled  dc servomotor of Exercise 2.71 in Chapter 2. Let y  =  xi. 
(a)  Design  a full-order  state observer with eigenvalues  at  - 5,  - 1,  and  -0.5  to derive 
an estimate x(t)  of the state x(t).  For x(Of  =  [77/6, 0,0], x(Of  =  [0,0, 0] plot the 
error e(t)  =  x(t)  -  x(t)  for  r >  0 and comment on your results. 
(b)  Assume  that  the  system  is  driven  by  a  zero-mean  Gaussian,  white-noise  w  and 
the measurement  noise v is also zero-mean  Gaussian,  white noise, where w and v 
"are uncorrected  in time with covariances  W  =  10""^ and  V  =  10~^", respectively. 
The state-space description of the system is now x  =  Ax  + Bu  + Fw, y  =  Cx + v, 
where F  =  [1,1, 0]^. Design an optimal observer and compare with (a). 
4.29.  (Automobile  suspension system)  Consider the automobile  suspension  system of Ex 
ercise 2.74 in Chapter 2. Assume that the state-space description  of the system is i:  = 
Ax  + Bu  + Tw,y  =  Cx  + v with A, B from  Exercise 2.74,  C  =  [0,0, 1, 0], and F  = 
[ - 1,  0, 0," 0]""^. Both process noise w and measurement noise v are assumed to be uncor-"
related, zero-mean Gaussian," stochastic processes with covariances W  =  Ix  10""""^ and "
V  =  10~^, respectively.  Let the damping  constant  c  =  750 N sec/m  and the  velocity 
of the car V =  18 m/sec. 
(a)  Design  an  optimal  LQG  observer-based  dynamic  controller.  Comment  on  your 
choice of the weights. 
(b)  Using the controller from (a), plot the states x(t)  and the control input u(t) fort  ^  0 
when  x(0)  =  [1, 0, 0, 0]^, w  =  0, v  =  0, and the reference  input  of the  system is 
r(t)  =  I  sin(27rvr/20). 
4.30.  (Aircraft  dynamics)  Consider  the  systems  describing  the  aircraft  dynamics  in  Exer 
381 
cise 2.76 in Chapter 2. 
(a)  For the  state-space representation  of the longitudinal  motion  of the  fighter  AFTI-
16, design  a linear  state feedback  control law  u  =  Fx  + r so that the  closed-loop 
system eigenvalues  are at  -1.25  ±  7*2.2651 and  -0.01  ±  j0.095. 
(b)  Let  y  =  Cx  with  C  =  [0,0,  1, 0]. Design  a full-order  state  observer  with  eigen 
CHAPTER 4: 
State  Feedback 
and  State 
Observers 
values at 0,  -0.421,  -0.587,  and - 1. 
(c)  Let  the  system  be  compensated  via  the  state  feedback  control  law  u  =  Fx  +  r, 
where  x  is the output  of the  state estimator.  Derive  the  state-space  representation 
and the transfer function  between y and r of the compensated system. Is the system 
fully  controllable from  r? Explain. 
(d)  Use the LQR  formulation  to determine  a stabilizing  linear  state feedback  control 
law  u  =  Fx  + r. Comment on your choices for the weights. 
(e)  Assume  that  process  noise  w  and  measurement  noise  v are present  and  that  both 
are uncorrelated, zero-mean Gaussian, stochastic processes with covariances  W  = 
"10""""^ and  V  =  10~^", respectively. Let T  =  [0, 1, 1, 0]^ and design an optimal ob 
server. 
(f)  Design  an  optimal  LQG  observer-based  dynamic  controller  and  determine  the 
eigenvalues  of the closed-loop  system. Discuss your answer in view  of the results 
in (c). 
4.31.  (Chemical  reaction  process)  [C. E.  Rohrs,  J.  M.  Melsa,  and  D.  G.  Schultz,  Linear 
Control  Systems,  McGraw-Hill,  1993, p. 70.] Consider the process  depicted  schemat 
ically  in  Fig.  4.8.  A  reaction  tank  of  volume  V  =  5, 000  gallons  accepts  a  feed  of 
reactant  that contains  a substance A  in concentration  CA,O- The feed  enters  at a rate of 
F gallons per hour and at a temperature  TQ. In the tank some of the reactant A is turned 
into  the  desired  product  B.  The  output  product  is removed  from  the  tank  at the  same 
rate that the feed  enters the tank. The mixture in the tank has a uniform  concentration 
of A, CA and a uniform  temperature  T. 
Temperature 
Product 
FIGURE  4.8 
Chemical reaction  process 
382 
Linear  Systems 
The temperature of the water in the jacket is assumed uniform  at Tj.  The  temperature 
of the water flowing  into the jacket  is  TIQ. The  system is controlled  by measuring  the 
temperature  T  in  the  tank  and  controlling  the  flow  of  the  water  in  the jacket  Fj  by 
activating a valve. 
The equations describing the evolution of  CA,  T, and  Tj  are 
CA 
t 
CA,Q 
• 
r-y^iCA^~^^2/n 
V 
To-
-T-hhCAC-^^^'^^-hiT-Tj) 
TJ  =  TT'^J'^  ' 
yj 
-TJ  +  k5(T  -  TJ), 
V 
where  CA,O  =  0.5,  TQ  =  70°F, Tj^o =  70°F, and  k\,  k2, fe, k4, ks  are appropriate  con 
stants. 
A  linearized  state-space  model  x  =  Ax  + Bu,  y  =  Cx  around  the  equilibrium 
point  CA  =  0.245, f  =  140, fj  =  93.3 is given by 
'xi 
X2 
> 3. 
= 
'-1.1 
696 
0 
-2 
2.13  X 10-4 
2.9 
6.5 
'xi' 
y  =  [0,1,0] 
X2 
.•^3. 
0  1 
2.4 
-19.5J 
pr U2 
+ 
L-^3. 
""" "
"""  0 "
0 
.-0.16_ 
where x\  =  8CA, X2  =  ST,  X3 =  STj,  and  u  =  8Fj. 
(a)  Determine  the  eigenvalues  and  eigenvectors  of A.  Is  the  system  asymptotically 
stable? Explain. 
(b)  Let  the  input  be  the  unit  step  indicating  that  the  cooling  flow  is  increased  and 
held  at  the  new  value.  Plot  the  states  for  /^ >  0  assuming  zero  initial  conditions 
(equilibrium  values). 
(c)  Plot the states for f >  0 for zero input but with an initial concentration of substance 
A slightly larger than the equilibrium value, namely,  x(0)  =  [0.1, 0, 0]^. 
(d)  Determine the linear state feedback  control law u  =  Fx  + r so that the closed-loop 
system eigenvalues  are at  - 5,  - 1 0,  and  - 1 0. 
(e)  Use the LQR  formulation  to derive  a stabilizing  linear  state feedback  control  law 
u  =  Fx  + r. Comment on your choices of the weights. 
(f)  Repeat  (b) and (c) for the closed-loop  system derived in (c) and (d). 
4.32.  (Economic  model  for  national  income)  Consider  the  economic  model  for  national 
income in Exercise 2.68 in Chapter 2. 
(a)  In which cases, (i), (ii), or (iii), is the system  reachable? 
(b)  For  case  (i), design  a linear  state feedback  control  law  to place  both  eigenvalues 
at  zero. This  corresponds  to  a  strategy  for  government  spending  that  will  return 
deviations in consumer expenditure  and private investment to zero. 
4.33.  (Read/write head of a hard disk) Consider the discrete-time model of the read/write 
head  of a hard disk described  in Exercise 2.77 of Chapter 2. 
(a)  Find a linear state feedback  control law to assign both eigenvalues at zero. Plot the 
response  of  the  discrete-time  closed-loop  system  to  a unit  step  and  comment  on 
your results. 
(b)  Let  y(k)  =  6(k)  be the position  of the head  at time  k.  Design  an  appropriate  ob 
server  of the  state and use it together  with the control law  determined  in  (a). Plot 
the response to a unit step and compare your results to the results in (a). 
C H A P T E RS 
Realization Theory and Algorithms 
When  a linear  system  is  described  by  an  internal  description  it is  straightforward 
to  derive  its  external  description.  In  particular,  given  a  state-space  description  for 
a linear  system,  the impulse  response,  and  also  the transfer  function  in the  case of 
time-invariant systems, were readily expressed in terms of the state-space  coefficient 
matrices in previous chapters. In this chapter the inverse problem is being addressed: 
given an external description of a linear system, specifically,  its transfer  function  or 
its  impulse  response,  determine  an  internal,  state-space  description  for  the  system 
that  generates  the  given  transfer  function.  This  is  the  problem  of  system  realiza 
tion. The name reflects  the fact that if a (continuous-time)  state-space description is 
known,  an operational  amplifier  circuit  can be built in  a straightforward  manner  to 
realize (actually  simulate) the system response. 
The ability of reaUzing systems that exhibit desired input-output behavior is very 
important in applications. In the design of a system (such as a controller or a filter), 
the desired  system behavior is frequently  specified  in terms of its transfer  function, 
which  is  typically  obtained  by  some  desired  frequency  response.  One  must  then 
implement  a system by hardware  or software  that exhibits  the desired  input-output 
behavior described by the transfer  function.  This in effect  corresponds to building a 
system  by  combining  typically  less  complex  systems  in parallel,  feedback,  or cas 
cade configurations.  In terms of block diagrams, this corresponds to building  a sys 
tem by combining simpler blocks. There are of course many ways, an infinite number 
in fact, of realizing a given transfer  function.  Presently, we are interested in realiza 
tions that contain the least possible number of energy  or memory  storage elements, 
i.e.,  in  realizations  of  least  order  (in  terms  of  differential  or  difference  equations). 
To accomplish  this, the concepts  of  controllability  and  observability  play  a  central 
role. Indeed, it turns out that realizations of transfer  functions  of least order are both 
controllable  and  observable.  The  theory  of  realizations  presented  in  this  chapter 
also sheds light on the behavior of systems that are built by interconnecting  several 
other systems, as for example, in feedback control systems. In such systems, possible 
383 
384 
Linear Systems 
pole-zero  cancellations  between  transfer  functions  of  different  subsystems  can  be 
studied, using internal descriptions and the notion of controllability and observability 
(see also Subsections  7.3B  and 7.3C in Chapter 7). 
5.1 
INTRODUCTION 
The  goal  of  this  chapter  is  to  introduce  the  theory  of  realization,  to  establish  fun 
damental  existence  and  minimality  results,  and  to  develop  several  realization  al 
gorithms.  The  emphasis  is  on  time-invariant,  continuous-time,  and  discrete-time 
systems. In what follows,  we first provide  a glimpse of the contents of this  chapter. 
This is followed  by some guidelines for the reader. 
A.  Chapter  Description 
In Section 5.2, the problem of system realization is introduced, both for continuous-
time  and  discrete-time  systems.  State-space  realizations  of  impulse  and  pulse  re 
sponses  for  time-varying  and  time-invariant  systems  and  of  transfer  functions  (in 
the case of time-invariant  systems) are  discussed. 
In  Section  5.3, the existence  of  state-space  realizations  is considered  first,  and 
results are presented for both time-varying  and time-invariant cases. The remainder 
of our development of realization theory and algorithms in this chapter  concentrates 
primarily  on  time-invariant,  continuous-time,  and  discrete-time  systems.  Minimal 
or irreducible realizations are discussed. For the time-invariant  case it is shown that 
a  state-space  realization  is irreducible  if  and  only  if  it is both  controllable  and  ob 
servable.  Also, it is  shown  that  if  two  realizations  are minimal,  then  they  must  be 
equivalent. The order of minimal realizations is considered next, and it is shown that 
it can be determined directly from a given transfer function  matrix without first find 
ing a realization. This is accomplished by use of the pole polynomial of the  transfer 
function that determines its McMillan degree and also by use of the Hankel matrix of 
the Markov parameters of a system. In addition, it is shown that in any minimal real 
ization, the pole polynomial  of the transfer  function  is the characteristic  polynomial 
of the matrix A. 
In Section 5.4, a number of realization algorithms are presented. The use of dual 
ity in obtaining realizations is also highlighted. Algorithms for obtaining realizations 
in controller  and observer form  are introduced. The SISO case is treated first in the 
interest  of  clarity.  Realizations  with  the  matrix A  in  diagonal  or block  companion 
form  are also derived. Finally, singular-value decomposition  is used to obtain trans 
fer function  realizations, such as balanced realizations, in a computationally  efficient 
manner. 
B.  Guidelines  for  the  Reader 
In  this  chapter  state-space  realizations  of  input-output  descriptions,  which  are pri 
marily  in  transfer  function  matrix  form,  are  developed.  In  the  present  treatment, 
385 
CHAPTER  5: 
Realization 
Theory and 
Algorithms 
fundamental  results  are emphasized.  We point  out that realization  theory  is  among 
the first important principal topics studied in system theory. Existence and minimal 
ity  results  of  state-space  realizations  are  established  and  several  realization  algo 
rithms are developed. We note that detailed summaries of the contents of the sections 
are given at the beginning  of Sections 5.3 and  5.4. 
Existence of time-invariant state-space realizations of a transfer function  matrix 
H(s)  is  addressed  in  Subsection  5.3A,  Theorem  3.3, while  minimality  is  fully  ex 
plored  in two results, Theorems  3.9  and  3.10  in  Subsection  5.3B. It is useful  to be 
able  to determine  the  order  of  a minimal  realization  directly  from  H(s)  and  this  is 
discussed  in Subsection  5.3C; we note that the pole polynomial  of H{s)  introduced 
in Section 3.5 of Chapter 3 is required in one of the approaches presented. In Section 
5.4,  several realization  algorithms  are developed. The use of duality  in  realizations 
is emphasized  in Subsection  5.4A. 
At  a first reading,  the reader  may  concentrate  on minimality  of realizations  in 
Subsection  5.3B  and on the order of minimal realizations  in  Subsection  5.3C;  then 
study one or two realization  algorithms, e.g., the one that leads to a realization  with 
A  diagonal  in  Subsection  5.4C,  and  to a realization  with  A, B  in controller  form  in 
Subsection  5.4B.  It  is  also  important  to  study  Subsection  5.4A  on  realizations  us 
ing duality. If realization  algorithms with good numerical properties  are of primary 
interest,  then  the reader  should  concentrate  on Subsection  5.4E,  where  realizations 
using singular-value  decomposition  are presented. 
5.2 
STATE-SPACE  REALIZATIONS  OF EXTERNAL  DESCRIPTIONS 
In  this  section,  state-space  realizations  of  impulse  responses  for  time-varying  and 
time-invariant  systems  and  of transfer  functions  for  time-invariant  systems  are  in 
troduced. Continuous-time  systems are discussed first in Subsection 5.2A,  followed 
by discrete-time  systems in Subsection  5.2B. 
A.  Continuous-Time  Systems 
Before formally  defining  the problem of system realization, we first review  some of 
the relations that were derived in Chapter 2. 
We consider a system described by equations of the  form 
X =  A(t)x  +  B(t)u, 
y  =  C{t)x  +  D{t)u, 
(2.1) 
where  A{t)  E  T^^^^^ B{t)  G  R'''''^,"  C{t)  G  i^^^""",  and  D{t)  G  /^^^^  are  continuous 
matrices  over  some open  time  interval  {a, b).  The response  of  this  system  is  given 
by 
y{t)  =  C{t)(S^{t,tQ)xo  + 
H{t,T)u{T)dT, 
(2.2) 
where ^{t,  to) is the  nX  n state transition matrix of i:  =  A(t)x,  x(to)  =  XQ  (the ini 
tial condition), and H(t,  r) is the p X m impulse response matrix of this system, given 
386 
Linear Systems 
by 
H{t,T)  = 
C(t)^(t,  T)B(T)  +  D(t)8(t  -  T), 
for t  >  r, 
0, 
for  t  < T. 
In the time-invariant  case, (2.1) assumes the  form 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
and the system response is in this case given by 
y(t)  =  Ce^^xo  +  H(t,  T)u(r)  dr, 
(2.3) 
(2.4) 
(2.5) 
where, without loss of generality,  ^o was taken to be zero. The impulse response  is 
now given by the expression 
H{t,  T) 
Ce^^'-^^B  +  DS(t  -  T), 
for  t  ^  r, 
0, 
for  t  < T. 
(2.6) 
Recall that the time invariance of system (2.4) implies that H(t,  r)  =  H(t  -  r, 0), and 
therefore, r, which is the time at which a unit impulse input is applied to the system, 
can be taken to equal zero  (r  =  0), without loss of generality, to yield H(t,  0). The 
transfer function matrix of the system is the (one-sided) Laplace transform of H(t,  0), 
namely. 
H(s)  =  iE[H(t, 0)]  =  C(sl  -  A)~^B  -h D. 
(2.7) 
Let {A(0, B(t),  C{t\  D(t)}  denote the system description  (2.1) and let H(t,  r)  be 
a /? X m matrix with real functions  of arguments  t and r  as entries. 
DEFINITION 2.1.  A realization ofH(t,  r) is any set{A(0, B(t\  C{t), D{t)}, the impulse 
response of which is H{t, r). That is, {A{t\ B(t\  C(t\  D(t)} is a reahzation of H(t, r) if 
(2.3) is satisfied.  (See Fig. 5.1.) 
• 
D{t) 
C{t) 
U(fo) 
J 
n 
x{t) 
+ ys>^ 
u{t) 
B{t)  +  ^7^ '^^\  \ 
+ 
\  A{t) 
FIGURE 5.1 
Block diagram reahzation of {A(t\  B{t), C{t), D(t)} 
Note that it is not necessary that any given pX  m matrix H(t,  r)  be the impulse 
response to some system of the form  (2.1). The conditions on H(t,  r)  under which a 
realization {A(t), B{t), C{t), D(t)}  exists are given in the next  section. 
In  the time-invariant  case,  a realization  is commonly  defined  in terms  of the 
transfer  function  matrix. We let {A, B, C, D] denote the system description  given in 
(2.4) and we let H{s) be a p  X m matrix with entries that are functions  of s. 
DEFINITION  2.2.  A realization of H{s) is any set {A, B, C, D}, the transfer  function 
matrix of which is H{s), i.e., {A, B, C, D] is a realization of H{s) if (2.7) is satisfied. 
• 
387 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
As  will  be  shown  in the next  section,  given  H{s),  a  condition  for  a  realiza 
tion {A, B, C, D} of H{s)  to exist is that all entries in H{s) are proper, rational  func 
tions. 
Alternative  conditions  under  which  a given  set {A, B, C, D] is a realization of 
some H{s) can easily be derived. To this end," we expand ^(5"") in a Laurent series to "
obtain 
"H{s)  -  //o +  ^ 1 ^""  + ^2^~  + "
(2.8) 
DEFINITION 2.3.  The terms Hu i =  0,1, 2, 
the system. 
in (2.8) are the Markov parameters of 
The Markov parameters can be determined by the formulas 
HQ  =  lim H(sl 
Hi  =  lim s(H(s)  -  HQI 
H2  =  lim s^(H(s)  -Ho- 
His'^l 
and so forth.  Recall that relations involving the Markov parameters were alluded to 
earlier in Exercise 2.63 of Chapter 2. 
THEOREM 2.1.  The set {A, B, C, D) is a realization of ^(^) if and only if 
if0  -  ^ 
and  Hi = CA^'^B, 
i  =  12,.... 
(2.9) 
Proof, H(s) = D + C(sl -  Ay^B  = D + Cs'^I  -  s'^Ay^B  =  D+ 
Cs-'{Y.U{s-'Am 
(2.8). 
= D +  Y.U[CA^-'B]s-
, from which (2.9) is derived in view of 
By  definition,  the impulse  response  description  of a linear  system  contains no 
information  about  the initial  conditions,  or the initial  energy  stored  in the system. 
In  fact,  H{t, T)  is determined  by assuming  that  the system  is at rest  before  r, the 
time  when  the impulse  input  8{t -  T) is applied.  It is therefore  apparent  that  dif 
ferent  state-space  realizations  of H{t, r)  will  yield  the same  zero-state  response, 
while  their  zero-input  response,  which  depends  on initial  conditions,  can be quite 
different. 
Note that if a realization of a given H{t, r) exists, then there are infinitely  many 
realizations.  Given {A{t), B(t), C{t), D(t)},  a realization of H(t, r), other realizations 
with the same dimension n of the state vector can readily be generated by means of 
equivalence  transformations.  Recall from  Chapter 2 that equivalent  representations 
generate the same impulse response. To illustrate, in Example 3.1 of Section 5.3, the 
system i:  -  P(t)N(t)u(t)  mdy(t)  = M(t)P~\t)x(t)  with N(t)  = ' 
and M(t) 
-t 
[t, 1] is a realization of H(t, r)  =  t -  r for any P(t) such that P  ^(t) and P(t) exist 
and are continuous. 
388 
Linear Systems 
B.  Discrete-Time  Systems 
The problem of realization in the discrete-time case is defined  as in the continuous-
time  case:  given  an  external  description,  either  the  unit  pulse  [(discrete)  impulse] 
response  H{k,  €), or in  the  time-invariant  case,  typically  the  transfer  function  ma 
trix  H{z)  (see  Chapter  2), determine  an  internal  state-space  description,  the  pulse 
response of which is the given H{k, £). 
The  realization  theory  in  the  discrete-time  case  essentially  parallels  the 
continuous-time  case.  There  are  of  course  certain  notable  differences  because  in 
the  present  case  the  realizations  are  difference  equations  instead  of  differential 
equations. We point to these differences  in the subsequent  sections. 
Some of the relations derived in Section 2.7 of Chapter 2 will be recalled  next. 
We consider systems described by equations of the  form 
x(k  +  1)  -  A(k)x(k)  +  B(k)u(k\ 
y(k)  =  C(k)x(k)  +  D(k)u(k), 
(2.10) 
"where A(k)  G  7?""><""", B(k)  G  J^^X'^, C(k)  G  /?^x^  and  D(k)  G  RP'''^,  The  response 
of this system is given by the  expression 
y(k)  =  C(k)<i>(k ko)xQ  +  ^  H(k  i)u{i), 
k  >  k^, 
(2.11) 
k-i 
where ^{k,  ko) denotes the  n  X n state transition  matrix  of the  system  x(k  +  1)  = 
A(k)x(kX  x(ko)  =  xo is the initial condition, and H(k,  i) is the p  X m pulse response 
matrix given by 
C(k)<^(k, i +  l)B{i\ 
H(k  i)  =  < 
D(k), 
0, 
k  >  /, 
k  =  /, 
k< 
i. 
The state transition matrix can readily be determined to be 
^{k,^  =  \ 
{ A{k- 
[ /, 
l)A(fc-2)---A(€), 
yt>€, 
k =  t 
(2.12) 
(2.13) 
In the time-invariant case, (2.10) assumes the  form 
x{k  +  1)  -  Ax{k)  +  Bu{k), 
y(k)  =  Cx(k)  +  Du(kl 
(2.14) 
and the system response of (2.14) is given by 
k-l 
"y(k)  =  CA^xo  +  X  ^ ( ^' ^*)""(^*)^ "
^  ^  0, 
(2.15) 
where, without loss of generality, ^o was taken to be zero. The pulse response is now 
given by 
Hik, i)  =  < 
-(i+i)B, 
CA'' 
D, 
0, 
k>  i, 
k  =  /, 
k<  i. 
(2.16) 
389 
CHAPTER  5: 
Realization 
Theory and 
Algorithms 
Recall  that  since  the  system  (2.14)  is  time-invariant,  H{k,  i)  =  H(k  -  i, 0)  and  /, 
the time the pulse  input  is  applied,  can be taken  to be  zero, to yield  H(k,0)  as  the 
external system description. The transfer  function  matrix for (2.14) is now the (one 
sided) z-transform  of H(k,  0). We have. 
H(z)  =  %{H{k, 0)}  =  C(zl  -  Ay^B  +  D. 
(2.17) 
Now  let  {A{k), B(k),  C(k),  D(k)}  denote  the  system  description  (2.10)  and  let 
H(k,  /) be a /7 X m matrix with real function  entries of arguments k and / defined  for 
k^ 
/. 
DEFINITION  2.4.  A  realization  of H(k, i) is  any  set  of  matrices  {A(k), B(k), C(k), 
• 
D(k)}, the pulse response of which is H(k, i). 
Let H(z)  be a /? X m matrix with functions  of z as entries. 
DEFINITION  2.5.  A realization  of H{z) is any set {A, B, C, D], the transfer  function 
matrix of which is H{z). 
• 
A result that is analogous to Theorem  2.1 is also valid in the discrete-time  case 
[with H{s)  replaced by H{z)\  (show this). The remarks following  Theorem 2.1 con 
cerning the zero-state response of a system and the uniqueness of realizations are also 
valid in the present  case. Thus, all realizations  of the pulse response or the  transfer 
function  will  yield  the  same  zero-state  response,  while  their  zero-input  response, 
which  depends  on initial conditions, can be quite different.  Also, if  a realization  of 
H{k,  i) or H{z)  exists, then there exists an infinite number of realizations (show this). 
5.3 
EXISTENCE AND MINIMALITY OF REALIZATIONS 
In this  section the existence  and minimality  of internal  state-space realizations  of a 
given external description  are  determined. 
The  existence  of realizations  is  examined  first.  Given  3. p  X  m  matrix  H(t,  r), 
conditions  under  which  this  matrix  is  the  impulse  response  of  a linear  system  de 
scribed by equations of the form i:  =  A(t)x  + B(t)u,y  =  C(0^ + ^ ( 0^  are given in 
Theorem  3.1. Theorem 3.2 provides the corresponding result for time-invariant  sys 
tems.  For  such  systems, H(s)  is typically  given  in place  of H(t,  r),  and  conditions 
for H(s)  to be the transfer  function  matrix of a system described by equations of the 
form  X  =  Ax  + Bu, y  =  Cx  -\-  Du  are given in Theorem  3.3. It is shown that  such 
realizations  exist if and only if H(s)  is a matrix  of rational functions  with the prop 
erty  that lims-^oo H(s)  is finite. The corresponding  results  for  discrete-time  systems 
are then developed  and presented  in Theorems  3.5, 3.6, and 3.7. 
Realizations  of  least  order,  also  called  minimal  or irreducible  realizations,  are 
of  interest  to  us  since  they  realize  a  system,  using  the  least  number  of  dynamical 
elements  (minimum number of elements with memory). The main emphasis in this 
section  is  on  time-invariant  systems  and  realizations  of  transfer  function  matrices 
H(s).  The principal  results  are given  in Theorems  3.9  and  3.10,  where  it is  shown 
that  minimal  realizations  are  controllable  (-from-the-origin)  and  observable  and 
that  all  minimal  realizations  of  H(s)  are  equivalent  representations.  The  order  of 
any minimal realization can be determined directly without first determining  a min 
imal realization, and this can be accomplished by using the characteristic polynomial 
390 
Linear Systems 
and the degree of H(s)  (Theorem 3.11) or from the rank of a Hankel matrix (Theorem 
3.13). All the results on minimality of realizations apply to the discrete-time case as 
well with no substantial changes. This is discussed  at the end of the  section. 
A.  Existence  of  Realizations 
Continuous-time  systems 
Let the /? X m matrix H(t,  r)  with t,T  E  (a, b) be given. A realization of H(t,  r) 
was  defined  in the previous  section  as an internal  description  of the form  (2.1)  de 
noted by {A{t), B{t), C{t), D(t)},  the impulse response of which is H(t,  r). 
THEOREM 3.1.  H(t, T) is realizable as the impulse response of a system described by 
(2.1) if and only if H(t, r) can be decomposed into the form 
H(t, T)  = M(t)N(T) + D(t)8(t -  r) 
(3.1) 
for r >  T, where M, A'', and D SLYQ p X n, n X m, and p X m matrices, respectively, with 
continuous real-valued entries and with n  finite. 
Proof. (Sufficiency) Assume the decomposition (3.1) is true and consider the realization 
{0, A^(0, M(t\  D(t)}, which yields the system x  = N(t)u(tX y(t)  = M(t)x(t)  + D(t)u(t). 
The state transition matrix is ^(t,  T)  =  /, since the homogeneous equation is in this case 
X = A(t)x  = 0. Applying (2.3), we obtain as the impulse response, H(t, r)  =  M(t) • / • 
N(T)  + D(t)8(t -  r) for t >  r, and H(t, T)  = Ofovt  < r, which equals H(t, r). 
(Necessity)  Let  (2.1) be a realization  of H(t, r). Then  (2.3) is true, and in view 
of the identity <!>(/, r)  =  <|)(/,  (T)^((7,  T), H(t, r) can be written for r >  r  as H(t, r)  = 
[C(t)<^(t, a)][<i>(a,  T)B(T)]  + D(t)8(t -  T)  = M(t)N(T) + D(t)8(t -  r), where M(t) = 
C(t)(!?(t, a)  and N(r)  = (t>(a,  T)B(T)  (a fixed). Therefore,  the decomposition  (3.1) is 
necessary. 
• 
Since the matrices  in  (2.1)  are taken  to be  continuous,  we require  in  Theorem 
3.1 that M(t),  N(t),  and D(t)  be continuous, although this restriction is not necessary. 
EXAMPLE 3.1.  Let H(t, T)  = t -  T,  t >  T. Then H(t, r)  =  [t,  1] 
Therefore, x 
1 
-t 
u(t), y(t)  =  [t,  l]x(t) is a reahzation. 
n 
=  M(t)N(T). 
EXAMPLE 3.2.  Let H(t, r)  =  l/(t  -  T). In this case a decomposition of the form (3.1) 
• 
does not exist, and therefore, H(t, r) does not have a realization of the form (2.1). 
If  a system  is time-invariant  and  is described  by  (2.4), its impulse  response  is 
given by  (2.6). The following  result establishes  necessary  and  sufficient  conditions 
for the existence of time-invariant  realizations. 
THEOREM 3.2.  H(t, T) is realizable as the impulse response of a system described by 
(2.4) if and only if H(t, r) can be decomposed for ^ >  r into the form 
H(t, T)  = M(t)N(T) + D(t)8(t -  T), 
(3.2) 
where M(t) and N(t) are differentiable  and 
(3.3) 
The first part of this result is identical to Theorem 3.1. For time invariance, we require 
in addition relation (3.3) and  differentiability. 
H(t, T)  = H(t  -  T, 0). 
391 
CHAPTER 5: 
Realization 
Theory and 
Algorithms 
Proof,  {Necessity)  Let (2.4) be a realization.  Then  in view  of (2.6), H{t, r)  =  H(t  -
T,0)  =  Ce^^'-'^B  +  D8{t  -  r)  =  {Ce^'Xe'^-'B)  +  Dd{t  -  r).  Let  M(t) = 
Ce^\  N(T) = e'^^B,  and note that both M(t)  and N(t)  are  differentiable. 
(Sufficiency)  The proof  of  this  part  is  much  more  involved.  The complete  proof 
can be found,  for example,  in Brockett  [1], p. 99. In the following,  we give an outline 
of  the proof  (a proof  by  construction).  First,  it  can be  shown  that  given  H(t, r)  with 
decomposion  (3.1), a realization  of the form  x  =  N(t)u(t\  y(t)  =  M(t)x(t)  +  D(t)u(t) 
can be found where n, the dimension of the state vector, is the smallest possible. Note that 
this  system  is controllable  and observable.  Now define  W(to, ti)  =  j /^ 
N(a)N^(a)da 
and  Wi(to, h)  =  j^^^  [(d/da)N(a)]  N^(a)da.  Then,  using H(t, r)  =  H(t  -  T, 0), it can 
be  shown  that {A, B, C, D)  -  {-Wi(tQ,  h)W~\tQ,  h), N(0), M(0), D} is a realization of 
H(t,  T). Note that W~H^> ^i) exists because {0, N{t), M{t), D] was taken to be of minimal 
dimension. Therefore,  this system is controllable. 
• 
EXAMPLE  3.3.  Consider  again H{t, r)  =  t -  T given  in Example  3.1, where  a time-
varying  realization  was derived. This H(t, r) certainly  satisfies  the conditions  of Theo 
rem 3.2, and thus, a time-invariant realization  x  =  Ax  + Bu, y  =  Cx  + Du also exists. 
Unfortunately,  the proof  of Theorem  3.2 does not provide us with  a means  of deriving 
such realizations. In general it is easier to consider the Laplace transform  of H(t, r) and 
use the algorithms  that we will develop in Section  5.4 to show that a time-invariant re 
alization of H(t, T)  =  t -  T is given by i:  = 
and also see Example 3.4.) 
"""0  1 "
.0  0. 
X + 
"""0"" "
1. 
u, y  =  [1, 0]x. (Verify  this 
In the remainder of this chapter we shall concentrate primarily  on  time-invariant 
realizations  of  impulse  responses.  In  fact  we  shall  assume  that  the  system  transfer 
function  matrix  H(s),  which  is  the  Laplace  transform  of  the  impulse  response, 
is  given  and  we  shall  introduce  methods  for  deriving  realizations  directly  from 
H(s). 
Given  a pX  m  matrix  H(s),  the following  result  establishes  necessary  and  suf 
ficient  conditions  for the existence  of time-invariant  realizations. 
THEOREM  3.3.  H(s)  is reahzable  as the transfer  function  matrix  of a  time-invariant 
system described by (2.4) if and only if H(s)  is a matrix of rational functions  and satisfies 
\im  H(s)  < CO, 
(3.4) 
i.e., if and only if H(s) is a. proper  rational  matrix. 
(Necessity)  If the system x  = Ax  -\- Bu, y  =  Cx  + Du is Si reahzation  of  H(s), 
Proof 
then C(sl  -  A)~^B -\- D  = H(s), which shows that H(s) must be a rational matrix. Fur 
thermore, 
\im H(s)  = D, 
(3.5) 
which is a real finite matrix. 
(Sufficiency)  lfH(s)  is a proper rational matrix, then any of the algorithms discussed 
• 
in the next section can be applied to derive a realization. 
EXAMPLE  3.4.  Loi H(s)  =  l/s^,(y(s)  =  //(^)w(^)), which is the transfer  function of 
the  double  integrator.  Then,  using  the controller  form  realization  algorithm  of  Section 
5.4,  a realization  of H(s)  is  given  by  i:  = 
"""0  1"" "
.0  0. 
X + 
0 
1. 
u,y  =  [1,0]x.  Notice  that 
^-^[H(s)]  =  ^-^[l/s^]  =  t  = H(t, 0), the same as in Examples 3.1 and 3.3. 
392 
Linear  Systems 
Theorem  3.3  can  be  used  to  show  what  types  of  entries  are  required  for  H{t,  0) 
for  it  to  be  reaUzable  as  a  Hnear  time-invariant  continuous-time  system  of  the  form 
given  in (2.4). In particular,  H{t,  0)  =  X~^[H{sy\  and the fact  that all entries  of  H{s) 
are proper  rational  functions  (Theorem  3.3)  implies  the  next  result. 
COROLLARY  3.4.  A  pX  m matrix H{i){H{t,  0)) is realizable as the impulse  response 
of a system described by equations of the form  (2.4) if and only if all entries of H{t)  are 
sums of terms of the form at^e^^  and I38(t),  where a,  /3 are real numbers, k is an integer 
(k  >  0), and A is a complex  scalar. 
Proof.  The  proof  is  left  as  an  exercise  for  the  reader.  (Refer  to  Chapter  2,  Subsection 
2.4B  for  a  review  of  Laplace  transforms.  Also,  refer  to  the  discussion  of  modes  and 
• 
asymptotic behavior of a system in that chapter.) 
EXAMPLE  3.5.  Let H(t)  =  W  +  e~^ +  ^(0. e%  In view  of the  above  corollary,  H{t) 
is  realizable  as  the  impulse  response  of  a  system  described  by  (2.4). In  fact,  H{s)  = 
^{H(t)}  = 
's^  + 2s-l 
^ 2 -1 
"1  "" "
'  s -l 
and the system i:  =  Ax  + Bu,y  =  Cx + DwwithA  = 
"r -1  2"" "
L  0 
i_ 
with Theorem  3.2, we  write 
"""2  1 "
.1  1. 
,B 
= 
,C  =  [1,0], D  =  [1, 0] is a reahzation  (verify  this).  Comparing 
,C  =  [l 
H(t  -T,0)  =  [e'- +  e-^'-^^ +  8(t  -  T),  e'-'] 
[e-\  e'  -  e-n 
e^ + e~ 
+  [ l , 0 ] 5 ( r - T) 
M(t)N(T)  +  D(t)8(t 
T), 
which shows that the given H{t)  [resp. H{t,  0)] is indeed realizable by a system described 
by  (2.4).  Actually,  in  this  case  M{t)  and  N{T)  were  chosen  so  that  M{t)  =  Ce^^  and 
N(T)  =  e  ^^B,  where e^^ 
0 
e' 
(verify  this). 
Discrete-time  systems 
Results  for  the  existence  of  realizations  of  discrete-time  systems  that  are  anal 
ogous  to  the  continuous-time  case  can  also  be  established.  In  the  following  result, 
which  corresponds  to  Theorem  3.1, H(k,  i),  k  >  /,  denotes  a. p  X  m  matrix. 
THEOREM  3.5.  H(k,i)is 
(2.10) if and only if H(k,  i) can be decomposed  into the  form 
realizable  as  the  pulse  response  of  a  system  described  by 
H(k,  i) 
M(k)N(i), 
k> 
/, 
D(k), 
k  =  i. 
(3.6) 
Proof,  {Sufficiency)  We consider the reahzation  {/, N{k),  M(k),  D(k)},  i.e.,  x(k  +  1)  = 
x(k)  +  N(k)u(k)  and  y(k)  =  M(k)x(k)  +  D(k)u(k).  In  this  case,  ^(k,  ^  =  I,k> 
t 
Applying  (2.12), it is immediately  verified  that the pulse response  of this  system is the 
given H(k,  i). 
{Necessity)  For  any  realization  (2.10),  C(k)<^(k,i  +  l)B(i)  =  C(k)A(k  -  1)... 
+  l)B(i)  =  (C(k)^(k,a))  X 
• 
i  <  a  ^  k, which in view of (2.10), implies  (3.6). 
A(i  +  l)B(i)  =  C(k)A(k  - 
(0(o-, / +  l)B(i))  =  M(k)N(i), 
l)...A(a)A(a 
l)...A(i 
- 
The discrete-time  system result corresponding  to Theorem  3.2 for  time-invariant 
systems  is  considered  next. 
THEOREM  3.6.  H(kJ) 
(2.14) if and only if H(k,  i) can be decomposed  as in (3.6), and 
is  realizable  as  the  pulse  response  of  a  system  described  by 
H(k,  i)  =  H(k  -  i, 0). 
(3.7) 
Proof,  (Necessity)  This part of the proof is the same as the necessity proof of the previous 
theorem. Also, in view of (2.16), it is clear that H(k,  i)  =  H(k  -  i, 0). 
(Sufficiency)  Let H(k,  i) satisfy  (3.6) and (3.7). The proof is by construction, consid 
ering a least-order realization x(k  + 1)  =  x(k)  + N(k)u(k),  y(k)  =  M(k)x(k)  +  D(k)u(k) 
and proceeding  along similar lines as in the proof of Theorem  3.2. 
• 
393 
CHAPTER  5: 
Realization 
Theory  and 
Algorithms 
EXAMPLE  3.6.  Let  H(k,  i)  =  k- 
/,  k  >  /.  Here  H(k,  i)  =  [k, 1] 
=  M(k)N(i), 
k  >  /,  and H(k,  i)  =  0  =  D(k),  k  =  i. In  view  of Theorem  3.5, there  exists  a realiza 
tion, the pulse response  of which  is the  given  H(k,  i).  A  particular  reahzation  is  given 
by the system equations  x(k  +  1)  =  x(k)  + 
1 
-k 
u(k),  y(k)  =  [k, l]x(k)  (see the proof 
of  Theorem  3.5).  (Verify  this.)  This  is  of  course  a  time-varying  reahzation.  However, 
here H(k,  i)  =  H(k  -  i, 0), which in view of Theorem 3.6, implies that a time-invariant 
realization  also exists. Such  a realization  is x(k  +  1)  =  Ax(k)  +  Bu(k),  y(k)  =  Cx(k), 
where  A 
B  = 
C  =  [0, 1]. [Verify  that  in the present  case H(k,  0)  = 
CA^  ^B,k>  0.] This realization  was determined using H(z)  =  ^H(k,  0) 
and the controller form realization  algorithm in Subsection  5.4B. 
zl(z -  If 
• 
Given  apXm  matrix H(z),  the next theorem establishes necessary  and  sufficient 
conditions for time-invariant realizations. This result corresponds to Theorem  3.3  for 
the  continuous-time  case.  Notice  that  the  conditions  in  these  results  are  identical. 
THEOREM  3.7.  H(z)  is  realizable  as  the  transfer  function  matrix  of  a  time-invariant 
system described by  (2.14) if and only if H(z)  is a matrix  of rational functions  and  sat 
isfies  the condition  that 
lim  H(z)  <  00. 
(3.8) 
Proof  Similar to the proof  of Theorem 3.3. 
COROLLARY  3.8.  A  pX  m  matrix  H(k)  [resp., H(k,  0)], A:  >  0,  is realizable  as  the 
pulse response of a system described by (2.14) if and only if all entries of H(k)  are sums 
of polynomial  terms of the form  a\^,  I3k(k  — 1)- • -(A: -  € +  1)A^~^, and y,  where a,  p, 
y  denote real numbers,  k, £ are nonnegative integers, and A is a complex  scalar. 
Proof  The  details  of  the  proof  are  left  to  the  reader.  Note  that  H(k,  0)  = 
^-^[H(z)\ 
where in view of Theorem 3.7, all the entries of H(z)  are proper rational functions.  Refer 
to Section  2.7  of Chapter  2 for  a review  of z-transforms  and  a discussion  of the  modes 
• 
and the asymptotic behavior of discrete-time  systems. 
EXAMPLE  3.7.  Let H(z)  =  zl(z  -  1)^. In view  of Theorem  3.7, H(z)  is realizable  as 
the  transfer  function  of  a  system  described  by  (2.14).  Such  a  realization  is  given  by 
x(k  +1)  =  Ax(k)  + Bu(k),  y(k)  =  Cx(k)  + Du(k),  with A  = 
Ic = 
[0,1],  D  =  0  (refer  to  Example  3.6).  Note  that  in  this  case,  H(k,  0)  =  ^-^[H(z)]  = 
k, k>  0, which, in view  of Corollary  3.8, imphes  that H(k,  0)  =  kis  realizable  as  the 
pulse response of a system described by (2.14). Such a reahzation  is given above. 
• 
2r-[i: 
-1 
394 
Linear Systems 
B.  Minimality  of  Realizations 
As was discussed  in Section 5.2, realizations  of an impulse response H{t,  r)  can be 
expected  to  generate  only  the  zero-state  response  of  a  system,  since  the  external 
description H{t,  r) has, by definition,  no information  about the initial conditions and 
the zero-input response of the  system. 
A second important point to take note of is the fact that if a realization  of a  given 
H(t,  T)  exists,  then  there exist  an  infinite number  of realizations.  It was pointed  out 
that if  (2.1), denoted by {A{t\  B(t),  C{t\  D{t)}, is a reaUzation  of the /? X m matrix 
H{t,  T),  then  realizations  of  the  same  order  n,  i.e.,  of  the  same  dimension  n  of  the 
state vector, can readily be generated by an equivalence transformation.  Recall that 
in  Subsection  2.6C  of  Chapter  2  it  was  shown  that  equivalent  state-space  (inter 
nal) representations generate identical impulse responses (external representations). 
There are, of course, other ways of generating  alternative realizations. In particular, 
if (2.1) is a reahzation  of H(t,  r), then, for example, the  system 
X =  A{t)x  +  B(t)u, 
y  =  C(t)x  +  D(t)u 
z  =  F(t)z  +  G(t)u 
is  also  a  realization.  This  was  accomplished  by  adding  to  (2.1)  a  state  equation 
z  =  F(t)z  + G(t)u  that does not affect  the system output. The dimension ofF,  dim F, 
and consequently the order of the realization, n + dim F, can be larger than any given 
finite number. In other words, there may be no upper bound  to the order of the real 
izations  of a given  H(t,  r). There  exists, however,  a lower bound,  and  a realization 
of such lowest order is called a least-order minimal or irreducible  realization. 
DEFINITION 3.1.  A realization 
X = A(t)x  + B(t)u, 
y  = C(t)x + D(t)u 
(3.10) 
of the impulse response H(t," r) of least order n (A(t) E /?""><"") is called a least order",  or 
a minimal order,  or an irreducible realization of H(t, r). 
• 
If  the  given  impulse  response  H(t,  r)  satisfies  the  conditions  of  Theorem  3.2, 
so that  a time-invariant  realization  exists, then  one usually  talks  about  minimal  or 
irreducible  realizations  of  tho  p  X  m  transfer  function  matrix  H{s)  =  i£[H(t, 0)], 
and this is the case on which we shall concentrate in the remainder of this chapter. It 
should be noted that results corresponding  to Theorems  3.9 and 3.10 exist for time-
varying systems as well. The interested reader is encouraged to consult, for instance, 
Brockett  [1] for  such results. Briefly,  as will be  shown  for  the time-invariant  case, 
system  (3.10) is a minimal realization  of H(t,  r)  if  and only if the representation  is 
controllable (-from-the-origin  or reachable) and observable. Note that in this chapter 
the term controllable is used in place of reachable, to conform  with accepted use in 
the literature. By controllability  we will really mean  controllability-from-the-origin 
or reachability.  This  distinction  is not important  in continuous-time  systems, but it 
is important in discrete-time  systems. 
DEFINITION 3.2.  A realization 
x  = Ax  + Bu, 
y  = Cx + Du 
(3.11) 
of the transfer function matrix H{s) of least order n{A G /?«><«) is called a least-order, or 
a minimal,  or an irreducible realization ofH{s). 
• 
395 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
Theorems  3.9  and  3.10 completely  solve the minimal realization  problem.  The 
first of these results  shows  that  a realization  is minimal  if  and  only  if  it is  control 
lable (-from-the-origin  or reachable)  and observable, while the second result  shows 
that  if  a  minimal  realization  has  been  found,  then  all  other  minimal  realizations 
can  be  obtained  from  the  determined  realization,  using  equivalence  of  representa 
tions. 
Controllability  (-from-the-origin,  or reachabihty)  and observabiHty play  an im 
portant  role  in  the  minimality  of  realizations.  This  is  to  be  expected,  since  these 
properties, as was discussed  at length in Chapter  3, characterize  the strength  of the 
connections  between  input  and  state,  and  between  state  and  output,  respectively. 
Therefore,  it is reasonable  to expect  that they  will play  a significant  role in the re 
lation between  internal  and  external  descriptions  of  systems. Indeed,  it was  shown 
in  Subsection  3.4C  that only  that part  of  a system  that is both  controllable  and ob 
servable  appears  in  H(s).  In  other  words,  H(s)  contains  no  information  about  the 
uncontrollable  and/or  unobservable  parts  of the system.  To illustrate this,  consider 
the following  specific  case. 
1/ 
"""0 "
.1 
-1 
EXAMPLE  3.8. 
t( s)  = 
is +  1). Four different  re 
L e t/ 
"""0  1 "
.1  0. 
"""0  1 "
.1  0. 
"""1 "
"0 "" "
P  - 1. 
-IB 
= 
(i)  {A  = 
(ii)  {A  = 
(iii)  {A  = 
(iv)  {A  = 
,B  = 
IC  = [-HID  =  0}. 
,B  = 
, C  =  [0, 1], D  = 0}. 
,B  = 
, C  =  [0, 1], D  = 0}. 
1. 
0 
1 
,D  =  0}. 
1 
ic 
The eigenvalue +1 that in (i) is unobservable, in (ii) is uncontrollable, and in (iii) is both 
uncontrollable and unobservable does not appear in H(s) at all. Realization (iv), which 
is of order 1, is a minimal realization. It is controllable and observable. 
• 
THEOREM  3.9.  An /2-dimensional  realization  {A, B, C, D} of H(s)  is minimal  (irre 
ducible, of least order) if and only if it is both controllable and observable. 
Proof, (Necessity) Assume that {A, B, C, D} is a minimal realization but is not both con 
trollable and observable. Then, using Kalman's Canonical Decomposition of Subsection 
3.4A, one may find another realization of lower dimension that is both controllable and 
observable. This contradicts the assumption that {A, B, C, D) is a minimal realization. 
Therefore, it must be both controllable and observable. 
{Sufficiency) Assume that the realization {A, B, C, D} is controllable and observable, 
but there exists another realization, say, {A, B, C, D} of order n < n. Since they are both 
realizations of H{s), or of the impulse response H{t, 0), then 
Ce^'B  + D8{t) = Ce^'B  + D8(t) 
(3.12) 
for all r >  0. Clearly, D  = D  = \ims-^ccH(s). Using the power series expansion of the 
exponential and equating coefficients  of the same power of t,  we obtain 
CA^B  = CA^B, 
k  =  0,1,2,. 
(3.13) 
i.e., the Markov parameters of the two representations are the same (see Theorem 2.1 in 
Section 5.2). Let 
%n  =  [B, AB,...,"  A'^-^B] E Z^^^^'""""", 
396 
Linear  Systems 
and 
C 
CA 
CA n-l 
r:  Dpnxn 
(3.14) 
Then the pn  x mn matrix product  ^n^n  assumes the  form 
CB 
CAB 
CAB 
CA^B 
• 
CA^'-^B 
CA^'B 
CA^'-^B 
CA^'B 
CB 
CAB 
CAB 
CA^B 
CA^^'-^B 
CA^'-^B 
CA^'B 
CA'^-^B 
CA'^B 
CA^^'-^B 
(3.15) 
In view of Sylvester's  rank inequality,  which relates the rank of the product of two 
matrices to the rank of its factors,  we have 
rank  0^  +  rank ^n  — ^^  rank  {^n^n)  ^  rnin {rank  ^„, rank  ^n) 
(3.16) 
"and we obtain that rank dn = ^ci^k ""^n = ^",  ^^^^ {^n^'^n) = ^- This result, however, con 
tradicts our assumptions,  since n =  rank  {dn'^n)  ^  min(ran^  dn.rank  ' ^)  <  n because 
n is the order of  {A,5, C , 5 }.  Therefore,  n<n.  Hence, n cannot be less than n and they 
• 
can only be equal. Thus, n = n and  {A,B,C,D} 
is indeed  a minimal realization. 
Theorem  3.9  suggests  the following  procedure  to realize H{s).  First,  we  obtain  a 
controllable  (observable)  realization  ofH{s).  Next,  using  a similarity  transformation, 
we  obtain  an  observable  standard  form  to  separate  the  observable  from  the  unob-
servable  parts  (controllable  from  the  uncontrollable  parts),  using  the  approach  of 
Subsection  3.4A.  Finally,  we  take  the  observable  (controllable)  part  that  will  also  be 
controllable  (observable)  as  the  minimal  realization.  We  shall  use  this  procedure  in 
the  next  section. 
Is  the  minimal  realization  unique?  The  answer  to  this  question  is  of  course  no 
since  we  know  that  equivalent  representations,  which  are  of  the  same  order,  give 
the  same  transfer  function  matrix.  The  following  theorem  shows  how  to  obtain  all 
minimal  realizations  of  H{s). 
If 
THEOREM  3.10.  Let  {A,B,C,D} 
{A,B,C,D} 
is  also  a  minimal  realization 
if  and  only  if  the  two  realizations  are  equivalent,  i.e.,  if  and  only  if  D  = D  and  there 
exists a nonsingular matrix P such that 
and  {A,5,C,5}  be  realizations  of  H(s). 
is  a  minimal  realization,  then  {A,B,C,D} 
A = PAP-\ 
B = PB, 
and 
c = cp-
Furthermore, if P exists, it is given by 
P  =  ^ ^ ( ^ ^ ^ ) -i 
or 
P  = 
(3.17) 
(3.18) 
is  minimal, 
Proof,  (Sufficiency)  Let  the  realizations  be  equivalent.  Since  {A,B,C,D} 
it  is  controllable  and  observable  and  its  equivalent  representation  {A,B,C,D} 
is  also 
controllable  and  observable,  and  therefore,  minimal.  Alternatively,  since  equivalence 
preserves the dimension of A, the equivalent realization  {A,5,C,5}  is also minimal. 
{Necessity) Suppose {A, B, C, D] is also minimal. We shall show that it is equivalent 
to {A, B, C, D}. Since they are both realizations of H{s), they satisfy  D  = D and 
(3.19) 
as was  shown  in the proof  of Theorem  3.9. Here, both realizations  are minimal, and 
therefore, they are both of the same order n and are both controllable and observable. 
CA^B  = CA^B, 
k  =  0,1,2.. 
Define ^  =  ^„  and 0  =  ©„, as in (3.14). Then, in view of (3.15), 0^  =  0^  and 
premultiplying by 0^, we obtain 0^0^  =  0^0^. Using Sylvester's inequality, we obtain 
rank 0^6  =  n, and therefore, 
397 
CHAPTER  5: 
Realization 
Theory and 
Algorithms 
"% =  [(O^O)""^©^©]^  =  P%", 
(3.20) 
"where P  =  (O^©)'^©^© G 7?""><\ Note that rank P  =  n since rank ©^© is also equal "
to n, as can be seen from  rank ©^©^  =  n and from  Sylvester's inequaUty. Therefore, 
P qualifies  as a similarity  transformation.  Similarly, ©^  =  ©^ implies that ©^^^  = 
, and 
0  = ©[^^^(^^^)-i]  = ©P, 
(3.21) 
"where P  = %%^{%%^y^  G T?""^'^ with rank P  = n. Note that P = "
P.  To  show  that  P  is  the  equivalence  transformation  given  in  (3.17),  we  note  that 
©A^  =  ©A^ from (3.15). Premultiplying by ©^ and postmultiplying by ^^, we obtain 
PA  = AF, in view of (3.20) and (3.21). To show that PB  =  fiandC  =  CP, we simply 
use the relations P^  = % and © =  ©P, respectively. 
• 
C.  The  Order  of Minimal  Realizations 
In the next  subsection  algorithms  to derive minimal realizations  of H{s)  are devel 
oped. One could ask the question whether the order of a minimal realization of  H(s) 
can be determined  directly, without having to actually derive a minimal  realization. 
The answer to this question  is yes, and in the following  we will  show how this  can 
be accomplished. When  deriving realizations, it is of advantage to know  at the out 
set what the order of a minimal realization  ought to be, since in this way  erroneous 
results can be avoided by cross checking the validity  of the results. 
Determination  via the characteristic or pole polynomial  of  H(s) 
The characteristic  polynomial  (or pole  polynomial),  PH(S),  of a transfer  func 
tion matrix H(s)  was defined in Section 3.5 using the Smith-McMillan form of  H(s). 
The polynomial PH(S)  is equal to the monic least common denominator of all nonzero 
minors of H(s).  The minimal polynomial  of a transfer function  matrix H(s),  mnis), 
was defined as the monic least common denominator of all nonzero first-order minors 
(entries) of  H(s). 
DEFINITION 3.3.  The McMillan degree of H(s) is the degree of PH(S). 
• 
The number of poles in H(s),  which are defined  as the zeros of PH(S)  in  Defini 
tion 5.1 in Section 3.5, is equal to the McMillan degree of H{s).  The degree of  H{s) 
is in fact the order of any minimal realization of H(s),  as the following  result shows. 
THEOREM 3.11.  Let {A, 5, C, D} be a minimal realization of H(s). Then the charac 
teristic polynomial of H(s\  PH{S),  is equal to the characteristic polynomial of A, a{s) = 
\sl -  A|, i.e., PH{S)  = a(s). Therefore, the McMillan degree of H(s) equals the order of 
any minimal realization. 
398 
Linear  Systems 
Proof.  The proof outlined here is based in part on results that will be established in Sec 
tions 7.2 and 7.3 of Chapter 7. (The reader may wish to postpone reading the proof  until 
Sections 7.2 and 7.3 have been covered.) First, we note that  '\fH{s)  = N(s)D(s)~^  with 
N(s),  D(s) right coprime polynomial matrices, then the characteristic or pole polynomial 
of H(s) is given  by pnis)  =  k  det  D(s), where  the real  k is such  that  k  det  D(s) is 
monic.  This  can be seen,  for example,  by reducing  H(s)  to its Smith-McMillan  form 
[see (5.3) in Chapter  3]. We have. 
Ui(s)H(s)U2(s)  = 
SMH(S) 
diagi-j^,..., 
-^) 
0 
^p—r,m—r 
diag{ijJx,...,\lJr) 
(ei,...,€r) 
0 
= 
N,{s)D-\s\ 
where  r  =  rank  H(s)  and  Ui, U2 are unimodular  matrices.  Then  H  =  (U^^Ns)  X 
(U2Ds)~^  = A^D~\whereMZ)arerightcoprime.  Notethat  A:(i^/^Z)(5)  =  iAi^2***^r  = 
PH(S),  by definition.  Now this is true for any right coprime factorization  since these are 
related by unimodular postmultiplication  (see Subsection 7.3A in Chapter 7). 
The  controllable  and observable  realization  {A, B, C, D} is now equivalent  to any 
other  controllable  and observable  realization  of the form  Dz  =  u,y  = Nz  with  D, N 
"right  coprime  (see Subsection  7.3A).  This  implies  that  15""/ -  A|  =  k\D{s%  since  such "
equivalence  relation  preserves  the system  eigenvalues.  Note  that  the same  result can 
be  derived  using  the Structure  Theorem  of Chapter  3 (show  this). Therefore,  the pole 
polynomial of H{s)  is given by PH{S)  =  \sl ~ A\. 
• 
It can also be shown  that the minimal  polynomial  ofH{s),  mnis), 
is equal to the 
minimal  polynomial  of A, am(s),  where  {A, B, C, D] is any controllable  and observ 
able  realization  of H(s).  This  is illustrated  in the following  example. 
EXAMPLE  3.9.  LQI  H(s)  = 
[1/^ 
0 
2/s^ 
-\/s\ 
. The first-order minors, the entries  of H(s), 
have denominators s, s, and s and therefore,  mnis)  =  s. The only second-order minor is 
-  l/s^ and PH(S)  = s^ with deg PH{S)  =  2. Therefore, the order of a minimal realization 
"2"" "
,"c =  ""1  0"" "
0  1_ 
is 2. Such a realization is given hy x  = Ax  + Bu and y  =  Cx with A  =  L  A,B  = 
"""1 "
.0 
then we verify  that it is controllable and observable, and therefore,  minimal. Notice that 
the characteristic  polynomial of A is a(s)  = s^  =  PH{S)  and its minimal polynomial is 
• 
a^{s)  = s  =  rriHis). 
It can be verified first that this system is a realization of H(s) and 
0  0 
- 1. 
The  above  example  also  shows  that  when  H{s)  is  expressed  as  a  polynomial 
then  the roots of 
matrix  N{s)  divided  by a polynomial,  i.e., H{s)  =  (l/mH(s))N(s), 
niH are not necessarily  the eigenvalues  of a minimal  realization  of H{s).  They  are in 
general  a subset  of those  eigenvalues,  since the minimal  polynomial  always  divides 
the  characteristic  polynomial.  In the case  when  H(s)  is a scalar,  however,  the roots 
of  rriH =  PH  are the eigenvalues  of  any minimal  realization  of H(s),  as the  next 
example  shows. 
EXAMPLE  3.10.  Let H(s)  =  n(s)/d(s)  be a scalar proper rational  function.  Applying 
Definition  5.1 of Section 3.5, we obtain  PH(S)  =  rnnis)  = d(s) and the order of a mini 
mal realization is deg PH(S)  =  degd(s).  Thus, given H(s)  =  l/(s^  +  3^ + 2), we know 
that  a minimal  realization  is of second  order  since  deg (s^  +  3^ +  2)  =  2. A  minimal 
reahzation  in controller  form  is  given  by  A 
B 
C  =  [1,0]. No 
399 
CHAPTER 5: 
Realization 
Theory and 
Algorithms 
tice that the minimal polynomial of A is am(s)  = a(s)  = s^ + 3s + 2, the characteristic 
polynomial of A, which is equal to d(s)  =  PH(S)  =  rnnis),  as expected. 
• 
The  observations  in Example  3.10 can be formalized  as the following  result. 
COROLLARY  3.12.  Let  H(s)  =  n(s)/d(s)  be  a  scalar  proper  rational  function.  If 
{A, B, C, D} is a minimal realization of H(s),  then 
(3.22) 
where a(s)  =  det (si  — A) and a^is)  are the characteristic and minimal polynomials of 
A, respectively, and A: is a real scalar so that  kd(s) is a monic polynomial. 
kd(s)  = a(s)  =  ani(s\ 
Proof,  The characteristic  and minimal  polynomials  of H{s), pnis),  and mnis)  are by 
definition  equal to d(s) in the scalar case. Applying Theorem 3.11 proves the result. 
• 
Determination  via the Hankel  matrix 
There  is an alternative  way of determining  the order  of a minimal  realization of 
H(s).  This  is accomplished  via the Hankel  matrix,  associated  with  H(s). 
Given  H(s),  we express  H(s)  as a Laurent  series  expansion  to  obtain 
H(s)  ^  Ho  + H(s)  =  Ho+  His-^  +  H2S~^  +  H^^s'^  +  • • •, 
(3.23) 
where H{s)  is strictly  proper  and the real pXm  matrices  HQ,  / / i , . ..  are the Markov 
parameters  of the system.  They  can be determined  by the  formulas 
Ho  = 
limH(s), 
Hi  = 
lims(H(s)-Ho\ 
H2  =  lim  s\H(s) 
-Ho- 
His~'l 
and  so  forth. 
DEFINITION  3.4.  The Hankel  matrix  MHH, j)  of  order  (/, j)  corresponding  to the 
(Markov parameter)  sequence H\, H2,... 
is defined  as the ip  X jm  matrix given by 
MH(iJ)  = 
Hi  H2 
H2  H3 
Hj+i 
Hi  Hi+i 
Hi+j-i\ 
(3.24) 
THEOREM  3.13.  The order  of a minimal  realization  of H(s)  is the rank  of Mnir,  r), 
where r is the degree of the least common  denominator  of the entries of H(s), i.e., r  = 
degmnis). 
Proof,  Let {A, B, C, D] be any realization  of H{s) of order  n. The Markov  parameters 
satisfy  the relationships 
Hi  =  CA'-^B, 
/  =  1,2,..., 
(3.25) 
400 
Linear  Systems 
(refer to Exercise 2.63 in Chapter 2). Therefore, the Hankel matrix Mnir,  r) can be writ 
ten as 
C 
CA 
Mnir,  r) 
[B,AB,...,A'-^Bl 
026) 
Using Sylvester's Inequahty, we have rank Mnir,  r) <  n, since the common  dimension 
in the product given by (3.26) is n. This imphes  that any reaHzation of H(s) is of order 
higher  than  or equal  to rank  Mnin  r). We now must  show  that  there  exists  a realiza 
tion of order exactly  equal to rank  Mnir,  r), where r is the degree of the least  common 
denominator of the entries of H{s).  Let {A, B, C} be given by 
0„ 
0„ 
A = 
-dolp 
^p 
-dil^ Up 
^p 
-dr-\Ip 
Hi 
H2 
B = 
and  C =  Up, 0, 
,0], 
-h  ••• -h 
where  A  E  RP'^'P^  B  E  RP''''^,  and  C  G  RP^'P'  with  mnis)  =^ s'  + dr-is''^ 
d\s  + d{),  the minimal  polynomial of H{s). We have  that {A, B, C) is an  observable re 
alization  of H{s)  (see Section  5.4). Furthermore,  note  that  |^/ -  A|  =  (mH(s))P. Now 
Hr 
rankMH{r,r)  =  rank 
C 
CA 
CA' 
[B,...,  A'-^B]  = rank  [B,...,  A'-^B].  This is true be-
=  Ipr, as can easily  be seen  from  above.  Note  now that  mniA)  = 0. 
C 
CA 
CA'-^ 
This  is true  since  (m//(A))^  =  0, in view  of the  Cay ley-Hamilton  Theorem.  There 
fore,  A\  i >  r, can be expressed  as a linear  combination  of /, A , . . .,"  A'""""^  which im "
plies that rank  Mnin  r)  = rank[B,  ...,A'-^B] 
-  rank  [ 5 , . . .,  AP^'^BI  Therefore, the 
rank  of the controllability  matrix  of the  above  realization  is equal  to rank  Mnir,  r). 
Hence, if {A, B, C} is reduced by means of a transformation  to a standard  uncontrollable 
form 
Ai 
0 
An 
Ai. 
[Ci, C2] \ (see Subsection 3.4A) with (Ai, Bi) controllable, then 
{Ai, Bi, Ci} will be a controllable and observable (minimal) realization of H(s) of order 
equal to rankMnir,  r), since this is the rank of the controllablity matrix of (A, B) and the 
dimension of Ai. 
• 
EXAMPLE  3.11.  Let 
H{s)  = 
1 
s+  1 
-1 
s+  1 
1 
{s + l){s + 2) 
s + 2 
Here the minimal polynomial is muis)  = (s+l)(s  + 2), and therefore, r = deg  mnis) 
2. The Hankel matrix M//(r, r) is then 
Mnir,  r)  = MH(2, 2) 
Hi  H2 
H2  H3 
an r/7 X  rm  =  4 X 4 matrix, and 
H\  = \im sH(s)  =  lim 
s^  °° 
S^  00 
5+  1 
—s 
Is 
s+  1 
s 
1  2 
0  1 
{s +  1)(^ + 2)  ^ + 2 
and 
401 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
H2  =  lim 
5->oo 
y^(i/(5)  -  His-
') 
r 
.2 
2s' 
o 
=  lim 
5—»oo 
[(s+ 
- .2 
l)(s  + 2) 
s^ 
s +  2 
-s 
s+  1 
=  lim 
[(s+ 
l)(^  + 2) 
-2s  -
s+  1 
-2s 
s +  2. 
= 
Similarly, H^ = 
1  2 
3  4 
.No> 
N 
rank MH (2, 2)  = rank 
1 
0 
1 
1 
2 
1 
-2 
-2 
-1 
-1 
1 
3 
-2 
-2 
2 
4 
=  3, 
which is the order of  any minimal  realization,  in  view  of Theorem  3.12. The reader 
• 
should verify this result, using Theorem 3.11. 
EXAMPLE  3.12.  Consider  the  transfer  function  matrix  H(s)  = 
Ills 
21s 
LO  - 1 /^ 
as m 
Example 3.9. Here r  = degmnis)  = degs  =  1. Now, the Hankel matrix Mnir, r) 
Example 3.9. Here r  =  degmnis) 
n 
MH(1  I)  =  HI  =  lim^-^oo sH(s)  = 
[0 
2 
-1 
.  Its  rank  is  2,  which  is  the  order  of  a 
minimal realization of H(s). This agrees with the results in Example 3.9. 
D.  Minimality  of Realizations: Discrete-Time  Systems 
All  definitions  and  theorems  given  thus  far  in  this  section  for  the  continuous-time 
case, apply directly to the discrete-time case with no substantial changes. Thus, mini 
mal or irreducible realizations are defined as in Definitions  3.1 and 3.2, where H(k,  i) 
and H{z)  should be used in place of H{t,  r)  and H(s),  respectively.  The main crite 
ria for  establishing  minimality  are given by results  that  are essentially  the  same  as 
Theorems  3.9  and  3.10.  The  McMillan  degree  of  H(z)  is  as  defined  in  Definition 
3.3, while results that are essentially the same as Theorems  3.11 and 3.13 provide a 
means of determining the order of the minimal realizations. 
402 
Linear Systems 
The fact  that the results  on minimality  of realizations  in the discrete-time  case 
^^^ essentially  identical to the corresponding  results for the continuous-time  case is 
not surprising  since we are concentrating here on the time-invariant cases for  which 
the transfer function  matrices have the same forms: H(s)  =  C(sl  -  A)~^B  + D and 
H(z)  =  C(zl  -  A)~^B  + D.  Accordingly,  the results  on how  to  generate  4-tuples 
{A, B, C, D] to  satisfy  these relations  are of  course  the  same. The  realization  algo 
rithms developed in Section 5.4 apply directly to the discrete-time case as well, since 
they  are  algorithms  for  time-invariant  realizations  of  transfer  matrices. The  differ 
ences in the realization theory between continuous- and discrete-time  systems  arise 
primarily  in  the  time-varying  case  (compare  Theorems  3.1  and  3.5,  for  example). 
However, these differences  are rather  insignificant. 
5.4 
REALIZATION  ALGORITHMS 
In  this  section,  algorithms  for  generating  time-invariant  state-space  realizations 
of  external  system  descriptions  are  introduced.  In  particular,  it  is  assumed  that  a 
proper  rational  matrix  H{s)  of  dimensions  p  X  m  is  given  for  which  a  state-space 
reahzation  {A, B, C, D}  of  H{s)  given  by  i  =  Ax  +  Bu, y  =  Cx  + Du  such  that 
C{sl  -  A)~^B  -\-  D  =  H(s)  has  been  derived  (see  Theorem  3.3).  This  problem  is 
equivalent  to realizing H(t,  0)  =  5£~^[H(s)], A  brief  outline of the contents  of this 
section  follows. 
Realizations of H(s)  can often be derived in an easier manner if duality is used, 
and this is demonstrated first in this section. Realizations  of minimal order are both 
controllable and observable, as was shown in the previous  section. To derive a min 
imal reahzation  of H(s),  one typically  derives  a realization  that is controllable  (ob 
servable)  and then  extracts  the part that is also observable  (controllable), using  the 
methods  of Subsection  3.4A  of Chapter  3. This involves in general  a two-step pro 
cedure. However,  in certain  cases a minimal realization  can be derived in one step, 
as for  example, when H(s)  is a scalar transfer  function.  Algorithms  for  realizations 
in a controller/observer  form  are discussed  first.  In the interest  of clarity, the  SISO 
case  is  presented  separately,  thus  providing  an  introduction  to the  general  MIMO 
case. Realization  algorithms, where A is diagonal  or in block companion  form,  are 
introduced  next. Finally, balanced realizations are  addressed. 
It  is  not  difficult  to  see  that  the  above  algorithms  can  also  be  used  to  derive 
realizations described by equations of the form  x(k  +  1)  =  Ax(k)  +  Bu{k),  y{k)  = 
Cx(k)  +  Du(k)  of  transfer  function  matrices  H(z)  for  discrete-time  time-invariant 
systems.  Accordingly,  the  discrete-time  case  will  not  be  treated  separately  in  this 
section. 
A.  Realizations  Using  Duality 
If the system described by the equations x  =  Ax-\- Bu, y  =  Cx  + Du is a realization 
of if (^), then 
H{s)  =  C(sl  -  AY^B  +  D. 
(4.1) 
403 
CHAPTERS: 
Reahzation 
Theory and 
Algorithms 
If  H(s)  =  H^{s), 
C^,  C  =  B^,  and D  =  D^,  is a reahzation  of H(s)  since in view of (4.1), 
then  x  =  Ax  + Bu  dind  y  =  Cx  + Du,  where  A  =-  A^,B  = 
H(s)  =  H^(s) 
=  B^{sl-  A^y^C^ 
+D^ 
=  C(sl  -Ay^B 
+ D. 
(4.2) 
The  representation  {A, B, C, D]  is  the  dual  representation  to  {A, B, C, D},  and 
if  {A, B, C, D}  is  controllable  (observable),  then  {A, B, C, D}  is  observable  (con 
trollable)  (see  Chapter  3).  In  other  words,  if  a  controllable  (observable)  real 
ization  {A, B, C, D}  of  the  p  X m  transfer  function  matrix  H{s)  is  known,  then 
an  observable  (controllable)  realization  of  the  m  X />  transfer  function  matrix 
H{s)  =  H^(s)  can  be  derived  immediately:  it  is  the  dual  representation,  namely, 
{A, B, C, D}  =  {A^, C^, B^,  D^}.  This fact is used to advantage in deriving  realiza 
tions in the MIMO case, since obtaining first a realization  of H^(s)  instead  of  H(s) 
and then using duality, leads sometimes to simpler, lower order, realizations. 
Duality  is  very  useful  in  realizations  of  symmetric  transfer  functions,  which 
have  the property  that H(s)  =  H^(s),  as, e.g.,  in the  case  of  SISO  systems  where 
H(s)  is a scalar. Under these conditions, if {A, B, C, D} is a controllable  (observable) 
realization of H(s),  then {A^, C^,  B^,  D^}  is an observable (controllable)  realization 
of the same H{s).  Note that in this case, 
H{s)  =  C(sl  -  Ay^B  + D  =  H^{s)  -  B^{sl  -  A^y^C^ 
-h  D^. 
In realization  algorithms  of MIMO  systems, a realization that is either control 
lable or observable  is typically  obtained  first.  Next,  this realization  is reduced  to a 
minimal  one by  extracting  the part  of  the  system  that  is both  controllable  and  ob 
servable, using the methods of Subsection 3.4A. Dual representations may  simplify 
this  process  considerably.  In  the  following,  we  summarize  the process  of  deriving 
minimal realizations for the reader's  convenience. 
transfer 
function  matrix  H(s),  with 
lims-^ooH(s) <  00 (see  Theorem  3.3),  we  consider  the  strictly  proper  part  H(s)  = 
H(s)  -  lirris-^a:, H(s)  =  H(s)  -  D  [noting that working with H(s)  instead of H(s)  is 
optional]. 
Given  a  proper  rational  p  X  m 
1.  If  a realization  algorithm  leading  to  a  controllable  reahzation  is  used,  then  the 
following  steps are taken, 
H(s)  -^  (H(s)  =  H^(s))  -^  {A, B, C}->  {A  =  A^, B  =  C^,C  =  B^l 
(4.3a) 
where {A, B, C] is a controllable realization of H{s)  and {A, B, C} is an observable 
realization of  H(s). 
2.  To obtain a minimal  realization. 
{A, B, C} 
An 
A2 
0 
[Ci, C2] 
(4.3b) 
where {A, B, C} is an observable realization  of H(s)  obtained  from  step  (1), and 
(Ai, Bi)  is controllable  (derived  by using  the method  of  Subsection  3.4A),  then 
{Ai, Bi,  Ci} is a controllable and observable, and therefore, a minimal realization 
of H(s),  and furthermore,  {Ai, Bi,  Ci, D} is a minimal realization  of  H{s). 
404 
Linear Systems 
B.  Realizations  in  Controller/Observer  Form 
We shall first consider realizations  of scalar transfer  functions  H(s). 
Single-input/single-output  (SISO) systems (p  =  m  =  1) 
Let 
H{s)  = 
n(s) 
d(s) 
bnS^ +  • • • +  bis  +  Z?o 
s^  +  an-\s^  1 +  • • • +  a\s  +  UQ 
(4.4) 
where  n{s)  and  ^(5*) are  prime  polynomials.  This  is  the  general  form  of  a  proper 
transfer  function  of (McMillan)  degree n. Note that if the leading coefficient  in the 
numerator  n{s) is zero, i.e., bn  =  0, then H(s)  is strictly proper. Also, recall that 
"bnu^""""^  +  '""  + biu^'^  + bou", 
(1) 
(4.5a) 
or 
"d{q)y{t)  =  {q""""  + an-iq""""  '  +  •••+  ^ i^ +  ao)y{t) "
"=  (bnq^  +  -""bxq  +  bo)u(t)  =  n(q)u(t)", 
7 2 -1 
(4.5b) 
where  q  =  d/dt,  the  differential  operator.  This  is the  corresponding  nth-order  dif 
ferential  equation that directly gives rise to the map y(s)  =  H(s)u(s)  if the Laplace 
transform  of both sides is taken, assuming that all variables and their derivatives  are 
zero 3tt  =  0. 
Controller form  realizations 
Given  n(s)  and d(s),  we proceed  as follows  to derive a realization  in  controller 
form. 
"1.  Determine  Cj  G  R""""  and Dc  ^  R  so that "
where S(s)  =  [l,s,..., 
implies that 
n(s)  =  CcS(s)  +  Dcd(sX 
(4.6) 
s^~^]^  is an n X 1 vector of polynomials. Equation  (4.6) 
Dc  =  limH(s)  =  bn. 
(4.7) 
Then n(s)  — bnd(s)  is in general a polynomial of degree n- 
a real vector  Q  that satisfies  (4.6) always exists. 
I,  which shows that 
[bo,...,  bn-i],  i.e., Cc consists of the coefficients  of the n- 
If  bn  =  0,  i.e.,  if  H(s)  is  strictly  proper,  then  from  (4.6)  we  obtain  Q  = 
I degree  numerator. 
If  bn #  0, then  (4.6) implies  that the entries  of  Q  are a combination  of the 
coefficients  bt and a/.  In particular, 
Cc  =  [bo -  bnao, bi  -  bnUi,...,  Z?„_i  -  Z?«a„-i]. 
(4.8) 
2.  A realization of H(s)  in controller form  is given by the equations 
yi'C 
"-^^C ""^ C "
JJ Q Id' 
1 
0 
0 
0 
-flo 
0 
-a„-\ 
Xc + 
y  =  CcXc + DcU. 
(4.9) 
The  n  states  of  the  reaUzation  in  (4.9)  are related  by 
-^/+i  = Xj 
or  X, i +i 
.(0 
1, 
n—1, 
and 
-aoxi 
n-l 
^atXi^i^u 
i=\ 
-aoxi 
.(i) 
n-\ 
i=l 
It can  now  be  shown  that xi  satisfies  the  relationship 
d{q)xi{t)  =  u{t), 
y{t)  = 
n{q)xi{t), 
(4.10) 
where  q  =  d/dt, 
the  differential  operator.  In  particular,  note  that 
d{q)xi{t) 
405 
CHAPTER  5: 
Realization 
Theory  and 
Algorithms 
1...W 
u(t)  because  Xn =  — E/Lo  ^iH 
"view  of  Xn =  -^i""^ derived  from  Xn =  x\' "
^\  implies  that  —d{q)xi  +  w  =  0.  The 
relation y{t)  =  n{q)xi  {t)  can easily be verified  by multiplying both  sides ofn{q)  = 
CcS{q)  -\-Dcd{q)  given  in  (4.6)  by  xi. 
Sn) 
x^\  which  in 
-d{q)xi 
» ^» 
> - l) 
In) 
~^ 
LEMMA  4.1.  The representation  (4.9) is a minimal realization of H(s)  given in (4.4). 
Proof,  We must  first  show  that  (4.9) is indeed  a realization,  i.e.,  that  it  satisfies  (4.1). 
This is of course true in view of the Structure Theorem in Subsection 3.4D of Chapter 3. 
Presently, this will be shown directly, using  (4.10). 
Relation  d{q)x\{t)  =  u{t)  implies  that  x\{s)  =  (d(s))~^u(s).  This  yields  for 
=  S(s)(d(s))~^i2(s). 
the  state  that  x(s)  =  [xi(s),...,Xn(s)]'^  =  [l,s,...,s''~^]'^xi(s) 
However, we also have x{s)  =  {si — Ac)~^Bcu{s).  Therefore, 
Now  CcisI-Ac)-^Bc+Dc 
n{s)/d{s)  =H{s), 
i.e., (4.9) is indeed  a realization. 
{sI-Ac)S{s)=Bcd{s). 
(4.11) 
=CcS{s){d{s))-^+Dc 
=  (QSis)  + Dcd{s)){d{s))-^  = 
System (4.9) is of order n, and is therefore,  a minimal, controllable, and observable 
realization.  This is because the degree of H{s)  is n, which in view of Theorem  3.11, is 
the order of any minimal realization. Controllability and observability can also be estab 
lished  directly  by  forming  the controllability  and  observability  matrices.  The reader  is 
encouraged to pursue this approach. 
• 
According  to Definition  3.3  given in Section  5.3, the McMillan  degree  of  a ratio 
nal  scalar  transfer  function  H{s)  =  n{s)/d{s) 
is  n  only  when  n{s)  and  d{s)  are  prime 
polynomials;  if  they  are  not,  all  cancellations  must  first  take  place  before  the  degree 
can be determined.  If n{s)  and  d{s)  are not prime, then the above algorithm  will  yield 
a  realization  that  is  not  observable.  Notice  that  realization  (4.9)  is  always  control 
lable,  since it is in controller  form.  This can  also be  seen  directly  from  the  expression 
ro  0 
"•••  1"" "
[5c,Ac5c,...,A^  Be 
1 
X 
(4.12) 
which is of full  rank.  The realization  (4.9) is observable if and only if the  polynomials 
d{s)  and  n{s)  are  prime. 
In  Fig.  5.2  a  block  realization  diagram  of  the  form  (4.9)  for  a  second-order 
transfer  function  is  shown.  Note  that  the  state  xi{t)  and  X2{t)  are  taken  to  be  the 
voltages  at  the  outputs  of  the  integrators.  This  is  common  when  realizing  transfer 
functions  using  analog  computer  circuits. 
406 
Linear  Systems 
_b2_ 
u 
.^ 
. 
X2 
Efi 
^ 
b-\ —  b23-\ 
LU 
* 
^'i 
bo -  ^231  + 
+ 
lifi 
FIGURE 5.2 
Block realization of H(s) in controller form of the system 
0 
-ao 
»  = 
\x2 
+  0 
1 1 
1 
-ai\ 
b2S^ + bis  + bo 
.2  + ais-\-ao 
w,y =  [bo-b2ao,bi  - M l] 
-\-b2U; 
Observer form  realizations 
Given  the  transfer  function  (4.4),  the  nth-order  realization  in  observer  form  is 
given by 
XQ  ^ 
/\QXQ 
-\-IJQU 
• 
• 
0 
1 
0 
0 
-ao 
—ai 
bo -  bnao 
bi  -  bnai 
^0  + 
0 
• 
• 
1 
—Cln-l 
bn-l 
-K^n-1 
y =  CoXo + DoU =  [0,0,..., 0, l]xo + bnU. 
(4.13) 
This realization was derived by taking the dual of realization  (4.9). Notice that A^  = 
Al,Bo=Cl,Co=Bl, 
midDo=Dl. 
LEMMA 4.2.  The representation (4.13) is a minimal realization of H{s) given in (4.4). 
Proof, Note that the observer form realization  {Ao,Bo,Co,Do} described by (4.13) is 
the dual of the controller form realization  {Ac,Bc,Cc,Dc} described by (4.9), used in 
• 
Lemma 4.1. 
The  realization  (4.13)  can  also  be  derived  directly  from  H{s),  using  defining 
relations  similar  to  (4.6).  In  particular.  Bo  and  Do  can  be  determined  from  the 
expression 
n{s)=S{s)Bo^d{s)Do, 
(4.14) 
where 5(^)  =  [1,^,.  ..,^^~^]. 
It can be  shown  (by taking transposes)  that the corresponding  relation to  (4.11) 
is now given by 
and that 
corresponds to (4.10). 
S{s){sI-Ao)=d{s)Co 
d{q)z{t)  = n{q)u{t),y{t)  = z{t) 
(4.15) 
(4.16) 
Figure  5.3  depicts  a  block  realization  diagram  of  the  form  (4.13)  for  a  second-
407 
order  transfer  function. 
CHAPTERS: 
Realization 
Theory  and 
Algorithms 
FIGURE  5.3 
Block realization  of H(s)  in observer form  of the  system 
Xi 
0 -^o] 
1 
-ai\ 
b2S^  +  bx 
\x{ 
U2. 
5 + 
+ 
bo-
Pi-
-  b2ao 
-  bzai 
= 
X2_ 
H{s 
)  = 
u.y  = [0,1] 
+  b2U\ 
EXAMPLE  4.1.  We  wish  to  derive  a  minimal  realization  for  the  transfer  function 
H{s)  =  (s^  + s  -  l)/(s^  -\-  2s'^ -  s  -  2).  Consider  a reahzation  {A^  Be, Cc, Dc}, where 
(Ac, Be)  is  in  controller  form.  In  view  of  (4.6)  to  (4.9),  Dc  =  lims^oo H(s)  =  1  and 
n(s)  =  s^  -\-  s  — 1  =  CcS(s)  +  Dcd(s),  from  which  we have  CcS(s)  =  (s^  + s  — I)  -
(s^  + 2s^  -  s  -2)  =  -2s^  +  2^ +  1  =  [1, 2, -2][1, s, s^f.  Therefore,  a realization  of 
H{s)  is Xc  =  AcXc +  BcU, y  =  CcXc +  DcU, where 
Ac  = 
0 
0 
2 
1 
0 
1 
"0"" "
1 
-2 
Be  = 
ro 
0 
1 
Cc  =  [1,2,-2], 
Dc 
This is a minimal realization  (verify  this). 
Instead of solving n(s)  =  CcS(s)  +  Dcd(s)  for  Cc as was done above, it is possible 
to derive  Q  by inspection  after  H(s)  is written  as 
H(s)  =  H(s)  +  lim^(^)  =  H(s)  +  Dc, 
(4.17) 
where  H(s)  is now  strictly  proper.  Notice that  if  H(s)  is  given  by  (4.4), then  Dc  =  bn 
and 
H(s) 
+  •••  +  Ci5  +  Co 
Cn-lS'' 
•  Un-is^  1 +  •••  +  ais  +  ao 
(4.18) 
where in fact,  c/  =  hi -  bnUi,  i  =  0 , . . .,  /t -  1. The realization {Ac, Be, Cc) of H(s)  has 
(Ac, Be) precisely the same as before; however,  Cc can now be written directly  as 
Cc  = 
[Co,  Ci, 
...,Cn~ll 
(4.19) 
i.e., given H(s)  there are three ways of determining  Q:  (i) using formula  (4.8), (ii) solv 
ing CcS(s)  — n(s) — Dcd(s)  as in (4.6), and (iii) calculating H(s)  =  H(s)  -  lim^^^oo  H(s). 
The reader should verify  that in this example, (i) and (iii) yield the same Q  =  [1, 2,  - 2] 
as in method  (ii). 
Suppose now that it is of interest to determine a minimal reahzation {Ao, Bo, Co, Do}, 
where  (Ao, Co)  is  in  observer  form.  This  can  be  accomplished  in  ways  completely 
408 
Linear  Systems 
analogous  to  the  methods  used  to  derive  realizations  in  controller  form.  Alternatively, 
one could use duality directly  and show that 
AQ  —  A„  — 
0 
0 
1 
Co  =  Bl  =  [0,0,1], 
0 
1 
0 
2 
1 
-2 
Bo  -  Cc 
-
Do  =  Di  =  I 
is a minimal realization, where the pair (A^, Co) is in observer form. 
• 
EXAMPLE  4.2.  Consider now the transfer  function  H(s)  =  (s^ -  l)/(s^  +2s^  - s-  2), 
where the numerator is n(s)  =  ^^ -  1 instead of ^-^ + s -  1, as in Example 4.1. We wish 
to  derive  a  minimal  realization  of  H(s).  Using  the  same  procedure  as  in  the  previous 
example, it is not difficult  to derive the realization 
Ac 
0 
0 
2 
1 
0 
1 
0^ 
1 
-2 
Be  = 
ro 
0 
1 
Cc  =  [1,1,  - 2 ], 
Dc 
This realization  is controllable,  since  (A^  Be) is in controller  form  (see Exercise  5.11); 
however,  it is not observable,  since rank  €  =  2  <  3  =  n, where 0  denotes the  observ 
ability matrix given by 
Cc  ' 
C-c-^c 
QA?. 
= 
r  1 
-4 
10 
1 
-1 
1 
-2 
5 
-11 
(show  this).  Therefore,  the  above  is  not  a  minimal  realization.  This  has  occurred  be 
cause  the  numerator  and  denominator  of H(s)  are not prime polynomials,  i.e.,  ^ -  1 is 
a  common  factor.  Thus,  strictly  speaking,  the  H(s)  given  above  is  not  a transfer  func 
tion,  since it is  assumed  that in  a transfer  function  all cancellations  of common  factors 
have  taken  place.  (See  also  the  discussion  following  Lemma  4.1.)  Correspondingly,  if 
the algorithm for deriving an observer form would be applied to the present case, the re 
alization {Ao, Bo, Co, Do] would be an observable realization, but not a controllable one, 
and would therefore  not be a minimal  realization. 
To obtain a minimal realization of the above transfer function  H{s),  one could either 
extract the part of the controllable realization {Ac, Be, Cc, Dc) that is also observable, or 
simply cancel the factor 5 -1  in H{s)  and apply the algorithm again. The former  approach 
of reducing a controllable realization will be illustrated when discussing the MIMO case. 
The latter approach is perhaps the easiest one to apply in the present case. We have 
His)  = 
1 
2^2 
s^  + s  +  \ 
s^  + 3s  + 2 
-2s-  1 
s^ +  3s-\-2 
+  1, 
and a minimal realization  of this is then determined  as 
0 
-2 
1 
- 3. 
Be 
Cc 
[ - 1 , - 2 ], 
Dc 
The reader  should verify  this. 
Multi-Input-Multi-Output  (MIMO)  Systems  (pm  >  1) 
Let  Si(p  X  m)  proper  rational  matrix  H(s)  be  given  with  lim^^oo H(s)  <  oo (see 
Theorem  3.3).  We  now  present  alogrithms  to  obtain  realizations  {Ac,  Be,  Cc, Dc}  of 
H(s) 
in  observer  form. 
in  controller  form  and  realizations  {Ao,  Bo,  Co, Do}  of  H(s) 
409 
CHAPTER  5: 
Realization 
Theory and 
Algorithms 
Minimal realizations can then be obtained by separating the observable  (controllable) 
part of the controllable (observable)  realization. 
Controller form  realizations 
Consider  a  transfer  function  matrix  H{s)  =  [nij{s)/dij{s)],i  =  l,...,p,7  = 
1,..., m,  and  let  ij (s)  denote  the  (monic)  least  common  denominator  of  all  entries 
in the  jth  column  of H{s).  The ij{s)  is the least degree polynomial  divisible by  all 
dij {s)J=  1,..., p. Then H{s)  can be written as 
H{s)=Nis)D-\s), 
a ratio of two polynomial matrices, where N{s)  =  [nij{s)]  and D{s)  = 
.,im{s)].  Note that  nij{s)/ij{s)  = nij{s)/dij{s)  for  / =  1, 
diag[ii{s),.. 
j =  1,..., m. Let dj  =  deg ij  (s) and assume that dj  >1.  Define 
A(^)  =  diag  (y 
4i 
(4.20) 
, p,  and  all 
and 
S{s)  =  block diag 
(4.21) 
and note that S{s)  ism\n(= 
E7=i ^j)  ^^  polynomial matrix. Write 
\  s'lj-' 
/ 
D{s)  = DhA{s) + DiS{s) 
(4.22) 
and note that D^ is the highest column degree coefficient  matrix of D{s).  Here  D{s) 
is  diagonal  with  monic  polynomial  entries,  and  therefore,  D/^ =  Im- If.  for  exam-
, then the highest column degree coefficient  matrix D^  = 
[3^2 j^ ^  2s] 
pie, D{s)  =  \  ^ 
2s 
, and DiS{s)  given in (4.22) accounts for the remaining lower column degree 
terms in D{s),  with D^ being a matrix of  coefficients. 
Observe that  \Dh\ 7^ 0, and define the mxm  and mxn  matrices 
respectively. Also, determine Cc and Dc such that 
-Dn'Di 
and note that 
N{s)=CcS{s)^DcD{s), 
Dc =  lim  H{s). 
(4.23) 
(4.24) 
(4.25) 
We have H{s)  = N{s)D-^  (s) = CcS{s)D-^  (s) +Dc  with CcS{s)D-^  {s) being  strictly 
proper (show this). Therefore,  only Cc needs to be determined from  (4.24). 
A controllable  realization  of H{s)  in controller  form  is now given by the  equa 
tions 
Here Cc and Dc were defined  in (4.24) and (4.25), respectively. 
^c-^mi 
Be — BcByy 
(4.26) 
410 
Linear Systems 
where Ac  =  block  diag  [Ai, A2..., A^]  with 
^j 
= 
\' 
0  0 
Id, 
... 
0 
j^djXdj 
Be  =  block  diag 
G R'^J,  j  = 
I.. .,  m 
and Am, Bm were defined  in (4.23). Note that if dj  =  /JLJ, j  =  1,...,  m, the control-
labiHty indices, then (4.26) is precisely the relation  (4.63) given in Section  3.4. 
LEMMA 4.3.  The system {Ac, Be, Cc, Dc} is an w( =  2  J.. 1 ^;)-th-order controllable re 
alization of H(s) with (Ac, Be) in controller form. 
Proof. First, to show that {Ac, Be, Cc, Dc} is a realization of H(s), we note that in view 
of the Structure Theorem given in Subsection 3.4D, we have Cdsl  -  Ae)~^Be  + Dc = 
N(s)D(s)-\whQYQ 
D(s)  ^  B;,'[A(S) 
-  AmS(s)l 
N(s)  ^  CeS(s) + DcD(s). 
However, 5(5)  =  D(s)mdN(s)  =  A^(5),in view of (4.22) to (4.24). Therefore,  Q ( 5 /-
AcT^Bc  + De = N{s)D-\s)  = //(5), in view of (4.20). 
It is now shown that (Ac, Be) is controllable. We write 
[si  Ac, Be] =  [sl -Ac-  BcAm, BcB^] 
=  [si  -  Ac,  Be] 
I 
0 
Brr 
(4.27) 
and notice that rank [sjl  -  Ac, Be] =  n for any complex Sj. This is so because of the 
special form of A^, Be. (This is, in fact, the Brunovski canonical form.) Now since \Bm\  ^ 
0, Sylvester's Rank Inequality implies that rank [sjl  -  Ac, Be] =  n for any complex Sj, 
which in view of Subsection 3.4B, implies that {Ac, Be) is controllable. In addition, since 
Bm = Im^ it follows  that (Ac, Be) is of the form (4.69) given in Subsection 3.4D. With 
dj  =  )LiJ, the pair (Ac, 5c) is in controller form. 
• 
An alternative way of determining  Q  is to first write H(s)  in the  form 
H(s)  =  H(s)  +  lim H(s)  =  H(s)  + Dc 
(4.28) 
where  H(s)  =  H(s)  -  Dc  is  strictly  proper.  Now  applying  the  above  algorithm  to 
H(s),  one  obtains  H(s)  =  N(s)D~^(s),  where  D(s)  is  precisely  equal  to  the  ex 
pression  given  in  (4.20). We note, however,  that N(s)  is  different.  In  fact,  N(s)  = 
N(s)  -  DcD(s).  The matrix  Q  is now found  to be of the  form 
A^(^)  -  CcS(sl 
(4.29) 
Note  that  this  is  a generalization  of  the  scalar  case  discussed  in  Example  4.1  [see 
(4.17) to (4.19)]. 
In  the  above  algorithm  the  assumption  that  dj  >  1 for  all  j  =  1,...,  m,  was 
made.  If  for  some 7, dj  =  0,  this  would  mean  that  the jth  column  of H(s)  will  be 
a  real  m  X  1 vector  that  will  be  equal  to  the jth  column  of  Dc  [recall  that  Dc  = 
411 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
lim^-^oo H(s)].  The strictly proper H(s)  in (4.28) will then have its jth  column  equal 
to zero, and this zero column can be generated by a realization where theyth column 
of Be is set to zero. Therefore,  the zero column  (thejth  column)  of H{s)  is  ignored 
in this case and the algorithm is applied  to obtain  a controllable realization. A zero 
column is then added to Be. (See Example  4.4.) 
Finally, we note that given H(s)  =  N(s)D~^{s)  with A^(^), D(s)  not  necessarily 
from  (4.20), the above algorithm  leads to a controllable realization  if dj  =  column 
degrees  of D(s),  provided  that  D^,  the highest  column  degree  coefficient  matrix  is 
nonsingular  (\Dh\ #  0). This,  in  fact,  means  that  D(s)  is  column  proper  (see  Sub 
section 7.2B). The resulting pair (Ac, Be) is in controllable, companion form but not 
necessarily  in controller  form,  since Bm  =  D^^  is not necessarily  upper  triangular 
with ones on the diagonal. (See Example  4.5.) 
Observer form  realizations 
These realizations are dual to the controller form realizations and can be obtained 
by duality  arguments  [see  (4.2)  and Example  4.3]. In the following,  observer  form 
realizations  are obtained directly for completeness  of exposition. 
We  consider  the  transfer  function  matrix  H{s)  =  [nij{s)ldij{s)\ 
i  =  1,...,  p, 
j  =  1,...,  m, and let £i{s) be the  (monic) least common  denominator  of  all  entries 
in the /th row of H(s).  Then H(s)  can be written as 
H(s)  =  D'\s)N(s\ 
(4.30) 
where  N(s)  =  [nij(s)]  and  D(s)  =  diag  [ti{s\  . ..Jp{s)l  Note  that  nij{s)l'ii{s)  = 
nij(s)/dij(s)  for  7  =  1,...,  m, and all /  =  1,...,  p. 
Let di  =  deg  (((s),  assume that J^- >  1, define 
A(^)  =  diag  ( /s  . . .,  / ^ ), S(s)  =  block  diag  ([I, ^,...,  / ~ ^ ],  /  =  1, 
and note that S(s)  is a p  X n (=  Xf= i di) polynomial matrix. Now, write 
D(s)  =  Ms)Dh  +  S(s)De 
(4.31) 
(4.32) 
and note that Dh is the highest row degree coefficient  matrix of D(s).  Note that  D(s) 
is diagonal, with entries monic polynomials, so that Dh  =  Ip, the pX  p identity ma-
trix. If,  for example, D(s)  = 
\3s^  +  1  2^1 
2s 
, then the highest row degree  coefficient 
matrix  is Du 
and S(s)D^  in  (4.32)  accounts  for  the remaining  lower  row 
degree terms of D(s),  with D^ a matrix of  coefficients. 
Observe that  \Dh\ y^ 0; in fact Dh  =  Ip. Define  the p  X p  and nX  p  matrices 
Cp  =  Dh^ 
and 
Ap  =  -DeDh\ 
respectively. Also, determine Bo and Do such that 
N(s)  =  S(s)Bo  +  D(s)Do. 
Note that 
and therefore,  only Bo needs to be determined from  (4.34). 
Do  =  lim H(s\ 
(4.33) 
(4.34) 
(4.35) 
412 
Linear Systems 
An observable realization of H(s)  in observer form is now given by 
Xo  =  AQXO  +  BQU, 
y  —  CQXO  +  DQU, 
where Bo and Do were defined  in (4.34) and (4.35), respectively, and 
where Ao  =  block  diag  [Ai, A2,..., Ap\  with 
(4.36) 
Ai  = 
0  . ..  0  0 
0 
^di-\ 
0 
j^diXdi 
Co  =  block  diag  ([0,.. .,0,1]  E  R^^^\  i  =  1,...,  p),  and  Ap, Cp  is  defined  in 
(4.33).  Note  that  (4.36)  is  exactly  relation  (4.85)  of  Section  3.4  if  di  =  vt,  i  = 
1,...,/?, the observability  indices. 
LEMMA 4.4.  The system {Ao, Bo, Co, Do} is an n (=  2f=i  <iJ)th-order observable re 
alization of H{s) with (Ao, Co) in observer form. 
Proof, This is the dual result to Lemma 4.3. The proof is completely analogous and is 
omitted. 
• 
We  conclude  by noting  that  results  dual  to the results  discussed  after  Lemma 
4.3 are also valid here, i.e., results  involving  (i) a strictly proper H(s),  (ii) an  H(s) 
with di  =  0 for some row /, and (iii) H(s)  =  D~^(s)N(s),  where D(s), N{s) are not 
necessarily determined using (4.30) (refer to the following  examples). The reader is 
encouraged to explicitly  state these results. 
EXAMPLE  4.3.  Let  H(s)  = 
S^ +  I  S +  I 
. We wish to derive a minimal realization 
for H(s). To this end we consider realizations {Ac, Be, Cc, Dc), where {Ac, Be) is in con 
troller form. Here €1(5) =  s^, €2(5) =  s^, and H{s) can therefore be written in the form 
(4.20) as 
H{s)  =  N{s)D~\s)  = {s^  -^\,s+  1] 
Here di  = 2,d2 = 3 and A(s) 
0 
, S(s) 
1 ^ 0 00 
0  0 
I  s  s^ 
. Note that n = 
di  + d2 = 5, and therefore, the realization will be of order 5. Write D{s) =  DhA(s)-\-
DeS(s), and note that Dh = h, D^ = 
. Therefore, in view of (4.23), 
ro  0  0  0  01 
0  0  0  0  0 
Bm — 
1  0 
0  1 
and 
Am  =  -DP  = 
0  0  0  0  0 
0  0  0  0  0 
Here Dc = lims^oo H(s)  =  [1, 0] and (4.24) implies that CcS(s) = N(s) -  DcD(s) = 
[s^ + 1, 5 + 1] -  [s^, 0]  -  [l,s  + 1] from which we have Q  =  [1, 0, 1, 1, 0]. A control 
lable  realization  in controller  form  is therefore  given  by x  -  AcXc  + BcU  and y = 
^~^ C  C 
-^-^C  9 
413 
CHAPTERS: 
Realization 
Theory  and 
Algorithms 
where 
Ac  = 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
1 
0 
Be 
'0 
1 
0 
0 
0 
"0"" "
0 
0 
0 
1 
Cc 
[1,  0,1,1,  0], 
and 
I 
=  [1,0]. 
Note  that  the  characteristic  (pole)  polynomial  of  H{s)  is  s'^ and  the  McMillan  degree 
of H{s)  is  3. The  order  of  any  minimal  reaUzation  of H{s)  is therefore  3 (see  Theorem 
3.11). This  implies  that the controllable  fifth-order  realization  derived  above cannot  be 
observable  [verify  that  (A^, Cc) is not observable]. To derive  a minimal realization,  the 
observable  part  of  the  system  [Ac, Be, Cc, Dc) needs  to be  extracted,  using  the  method 
described in Subsection 3.4A. In particular, a transformation  matrix P needs to be deter 
mined  so that 
A  =  PAcP  -1  _  Ai 
0 
A21  A2, 
and 
C  =  CcP~ 
[Ci,0], 
where  (Ai, Ci)  is  observable.  If  B  =  PBc 
,  then  {Ai, 5i,  Ci, Di}  is  a  minimal 
realization of H{s).  To reduce (Ac, Cc) to such standard form for unobservable  systems, 
we let AD  =  AJ,  BD  =  C j,  and  Co  -  B^  and  we reduce  (AD, BD) to a standard  form 
for uncontrollable  systems. Here the controllability  matrix  is 
10 
0  10 
10 
1 10 
0  1 10 
0  0  0 
0  0 
0  0  0 
0  0 
0 
Pj)^  are taken to be the 
Note that rank ^^  =  3. Now if the first three columns of  QD 
first three linearly independent columns of ^ D,  while the rest are chosen so that  \QD\  ¥=  0 
(see Subsection  3.4A),  then 
QD  = 
and 
QD'-
0 
1 
0 
1 
1 
0 
0 
0 
0 
1 
—; 
-] 
1 
0 
1 
1 
0 
0 
0 
0 
0 
1 
0 
0 
1 
0 
0 
0 
0 
0 
1 
0 
1 
0 
0 
0 
0 
1 
0 
0 
-1 
- 1 
0 
0 
1 
0 
0 
414 
Linear  Systems 
This implies  that 
AD  =  QDAUQD 
= 
ADI 
[  0 
ADU 
AD2 
• 
'  1 
0 
0 
0 
0 
BD  — QD  ^D  — 
BDI 
_BDI\ 
Then 
0 
1 
0 
0 
0 
0 
0 
1 
0 
0 
0 
0 
0 
0 
0 
1 
-1 
0 
0 
1 
-1 
-1 
-1 
1 
1 
CD  —  CDQD 
-
0  10 
0  1 10 
0  0 
0 
0 
0 
0 
1 
1 
1 
0 
0 
0 
1 
0 
1 
0 
0 
0 
0 
0 
0 
0 
0 
-1 
-1 
-1 
1 
1 
C  =  Bl  =  [Ci, 0]  =  [1,0, 0,: 0,0]. 
A  = 
0 
Ai 
.A21  A2. 
^  AT  ^ 
B  =  Cl  = 
"""0 "
1 
0 
0 
0 
"0"" "
1 
1 
0 
0 
Clearly, A  =  A^, C  =  Bj  is in standard form. Therefore,  a controllable and  observable 
realization,  which  is  a minimal  realization,  is given  by  Xco =  Aco^co +  BcoU  and  y  = 
Cco^co +  J^coU, where 
0 
0 
0 
"1  0"" "
0  1 
0  Oj 
Bco 
-
"""0 "
1 
.0 
0 
1 
1 
Ceo =  [1,0,0], 
Dc 
[1,0]. 
A  minimal  realization  could  also  have  been  derived  directly  in  the  present  case 
if  a realization  {A^, Bo, Co, Do} of  H(s),  where  (Ao, Bo)  is  in  observer  form,  had  been 
considered  first,  as  is  shown  next.  Notice  that  the  McMillan  degree  of  H(s)  is  3,  and 
therefore,  any realization of order higher than 3 will not be minimal. Here, however, the 
degree of the least common denominator of the (only) row is 3, and therefore, it is known 
in advance that the realization in observer form, which is of order three, will be minimal. 
A realization {Ao, Bo, Co, Do} of H(s)  in observer form  can also be derived by con 
sidering H^(s)  and deriving  a realization  in controller  form.  Presently, {Ao, Bo, Co, Do} 
is  derived  directly.  In  particular,  we  write  H(s)  =  JD ^(s)N(s)  =  (s^)  ^[s(s^  +  1), 
s  +  1]. Then  di  =  3[=  deg  \{s)  =  deg  s\  and  A^  =  s^,S{s)  =  [l,s,s^l  Then 
D(s)  =  s^  =  Ms)Dh  +  S(s)Di  implies  that  Dh  =  1 and  De  =  [0, 0, 0]^.  In  view  of 
(4.33), we have 
Cp  =  1, 
Ap  =  [0,0, 0 ]^ 
415 
CHAPTERS: 
Realization 
Theory  and 
Algorithms 
Do  =  liiRs^^  H(s)  =  [1,0],  and  (4.34)  implies  that  S(s)Bo  =  N(s)  -  D(s)Do  = 
[s(s^  +  1), 5 +  1]  -  [s^, 0]  =  [s,s  -\-  1], from  which  we  have  Bo 
0  1  0 
[1  1  OJ 
.  An 
observable realization  of H(s)  is the system  x  =  AoXo +  BoU, y  =  CoXo +  DoU, where 
Ao  = 
0  0  01 
1  0  0 
0  1  0 
Bo = 
ro  r 
1  1 
0  0 
Co =  [0,0,1], 
Do =  [1,0] 
with  (Ao, Co) in observer  form  (see Lemma  4.4). This realization  is minimal  since it is 
of order 3, which is the McMillan  degree of H(s).  (The reader  should verify  this.)  Note 
how much easier it was to derive a minimal realization, using the second approach. 
• 
EXAMPLE  4.4.  Let  H(s)  = 
s + 1 
1 
s 
.  We  wish  to  derive  a  minimal  realization. 
Here €1(5)  =  s(s+I)  with  di  =  2and€2(^)  =  lwith(i2  =  0. In view of the discussion 
following  Lemma  4.3, we  let  Dc  = 
lims^o,H(s) 
[0  1 
0  0 
] 
2 
and  H(s) 
We now  consider  the transfer  function  H(s) 
ization. 
s+  1 
1 
and  determine  a minimal  real 
Note that the McMillan degree of H(s)  is 2, and therefore, any realization of order 2 
will be minimal. Minimal realizations are now derived using two alternative approaches: 
1.  Via  a  controller  form  realization.  Here  £\(s)  =  s(s  +  1),  Ji  = 2,  and  H(s)  = 
2 
s+  1 
1 
s 
[s(s  +  l)]-i  =  N(s)D-\s). 
Then  A(s)  =  s^  and  S(s)  =  [hsf,  D(s) 
"""  2s "
5 +1 
s(s  +  1)  -  Is^  +  [0, 1][1,5 
0  2 
1  1 
-[0,1].  Also, Cc 
CcS(s).  Then  a  minimal  realization  for  H(s)  is  Ac  = 
ro 
0 
DhA(s)  +  D^S(s).  Therefore,  B^r, 
1 
,  which  follows  from  N(s) 
""" 2s "
.5+ 1 
1] 
- i j' 
rr 
[s 
1  and  Am  = 
ro  21 
1  1 
ro] 
.ij' 
Cc 
Be  = 
Adding a zero column to 5^, a minimal realization of H(s)  is now derived as 
0  2 
1  1 
A  = 
B  = 
0  0 
1  0 
c =  0  2 
1  1 
D  = 
0  1 
0  0 
We  ask  the  reader  to  verify  that  by  adding  a  zero  column  to  B^  controllability  is 
preserved. 
2.  Via an observer form  realization.  We consider H  (s)  =  [2/(s +1),  l/s]  and derive a 
realization in controller form.  In particular,  ^i  =  s  +  I, £2 =  s, H^(s)  = 
416 
Linear  Systems 
0 
s 
1  0 
0  1 
[2,1] 
s+l 
0 
5 + 1 0^ 
s 
1  0 
0  0 
0 
[2,1] 
1  0 
0  1 
"1  0"" "
0  0 
namely, Ao  = 
tion of H(s)  is 
1  0 
0  1 
-1 
,di  =  d2  =  I, A(s)  = 
s  0 
0 
s 
1  0 
0  0 
s  0 
0 
s 
1  0 
0  1 
, and S(s)  = 
1  0 
0  1 
. Then D(s)  = 
=  DhA{s) + DiS(s)mdB^ 
= 
1  0 
0  1 
Also, Cc  =  [2, 1], from  which we obtain A^(^)  =  [2, 1]  = 
=  CcS(s).  Therefore,  a minimal realization {A, B, C} of H^(s)  is 
, [2, 1] [.  The dual of this is a minimal realization  of  H(s), 
0 
0  0 
,Bo 
, and Co 
1  0 
0  1 
. Therefore,  a minimal  realiza-
r -1 
0 
0  0 
B  = 
2  0 
1  0 
C  = 
1  0 
0  1 
D  = 
0  1 
0  0 
EXAMPLE  4.5.  Let 
H(s)  = 
1 
^2 +  1 
1 
^ 2 +1 
0 
I 
^ s+  1 
\l 
\s 
s -l 
0 
s+  1 
0 
S 
5^ +  1 
N(s)D'\s). 
We  wish  to  derive  a  minimal  realization  based  on  the  given  factorization  N(s),  D{s). 
Since  the McMillan  degree  of H(s)  is  3 (show  this), any realization  of  order  3 will  be 
minimal. Note that in the present  case di  =  I  and  J2  =  2, the degrees  of the  first  and 
second  columns  of D(s),  respectively.  Then  A(^) 
D(s)  = 
1  0 
1  1 
0 
0 
+ 
1  0  0 
0  1  0 
1  0  01 
0  1  ^J 
0 
s' 
0 
,S(s) 
1  0  0 
0  1 
s 
,  and 
=  DhA(s)  +  D^S(s).  Here  \Dh\ #  0, 
and therefore,  the  algorithm  above  still  applies. Note that Dh is not in upper  triangular 
form with ones on the diagonal, and therefore,  the resulting controllable realization  will 
not  be  in  controller  form;  A^  however,  will  be  in  companion  form.  Let  B^  =  Dj^^  = 
1  0 
1 
-1 
, A, 
-D-,'D, 
-1 
1 
"0  0"" "
0. 
-1 
and 
= 
N(s)  =  CcS(s)  +  DcD{s)  = 
1 
. -1 
-1 
0 
11 
OJ 
"ri  0"" "
0  1 
LO  S_ 
"+  ""0  01 "
.1  OJ 
s+l 
s 
0 
s^ + I 
A minimal realization is now given by 
Ac  = 
Cc 
0 
0 
0 
-1 
,  Be 
-
1 
"0"" "
0 
-1 
0 
1 
-1  r 
0  0 
Dc  = 
0  0 
1  0 
Verify  this. 
417 
CHAPTER  5: 
Realization 
Theory  and 
Algorithms 
C.  Realizations  with Matrix A  Diagonal 
When  the  roots  of  the  minimal  polynomial  mnis)  of  H(s)  are  distinct,  there  is  a 
realization  algorithm  due to Gilbert  [2] that provides  a minimal realization  of  H(s) 
with A  diagonal. Let 
mnis)  =  /  +  dr-is'' 
"'-{-'""+dis "
-^ do 
(4.37) 
be the (monic) least common denominator of all nonzero entries of the p  X m matrix 
H(s)  which  in view  of Section  3.5, is the minimal polynomial  of H(s).  We  assume 
that its r roots A/ are distinct and we write 
i = i 
(4.38) 
Note  that  the  pole  polynomial  of  H(s\  PH(S),  will  have  repeated  roots  (poles)  if 
PH(S)  ¥=  mnis)  (see  Section  3.5  and  Example  4.6).  We  now  consider  the  strictly 
proper  matrix  H(s)  = H(s)  -  lims-^oo H(s)  =  H(s)  -  D  and  expand  it  into  partial 
fractions  to obtain 
H(s) 
1 
rriHis) 
N(s)  ±7^^.''-
! = 1 
The pX  m residue matrices R,  can be found  from  the relation 
Ri  =  lim(s  -  \i)H(s). 
We write 
Ri  =  CiBi, 
/  - 
l , . . . , r, 
(4.39) 
(4.40) 
(4.41) 
where  C/  is  a /? X pi  and  Bi  is  a  p/  X m matrix  with  p/  =  rank  Ri  <  min  (p, m). 
Note that the above expression is always possible. Indeed, there is a systematic pro 
cedure  of  generating  it, namely,  by  obtaining  an LU  decomposition  of  Ri  (refer  to 
the Appendix). Then 
All Upi 
A2/; P2 
) 
B = 
^rlpr. 
Bi 
B2 
Br 
C  =  [Ci,C2,...,C,], 
D = 
lim/ 
i(s) 
(4.42) 
is a minimal realization  of order n  =  XL 
I  Pi 
LEMMA  4.5.  Representation  (4.42) is a minimal realization  of  H(s). 
Proof,  It can be  verified  directly  that  C(sl  -  A)~^B  + D  =  H(s),  i.e., that  (4.42)  is  a 
realization of H(s).To  verify  controllability,  we write 
=  [B^AB, 
'B]  = 
B2 
X\Im 
Aj 
Im 
Br 
Xrlm> '•• 
418 
Linear Systems 
The second matrix in the product is a block Vandermonde matrix of dimensions mr X 
mn. It can be shown that this matrix has full  rank mr since all A/ are assumed to be 
distinct. Also note that the (n  = %pi)  X mr matrix block diag [Bi\ has rank equal to 
2/^=1 rank Bt  =  2[=i  P/  =  n ^  mr. Now, in view of Sylvester's Rank Inequality, as 
applied to the above matrix product, we have n + mr -  mr ^  rank ^  <  min (n, mr), 
from which rank % = n. Therefore, {A, B, C, D} is controllable. Observability is shown 
in a similar way. Therefore, representation (4.42) is minimal. 
• 
EXAMPLE  4.6.  Let 
H(s)  = 
Is+l 
s(s+l)i 
Herem/zW  =  ^(5+1) with roots Ai  =  0, A2 =  -1 distinct. We write//(5)  =  (l/s)Ri + 
[l/(s  +  l)]/?2, where Ri  = lims^o sH(s)  = lim^^o 
1 
2s 
s+  1 
0 
1 
s+l\ 
n  01 
0  1  .Ri 
— 
\ims^-i(s-\-l)H(s)  = lim^ L 5 - » -l 
0 
2 
0 
-1 
, pi  =  rank Ri  =  2, and p2  = 
rank R2 =  I, i.e., the order of a minimal realization is n  =  pi  + p2  =  3. We now write 
Ri  = 
Ri 
1  0 
0  1 
0 
2 
-
1  0 
0  1 
1  0 
0  1  =  C,B, 
[2 -  1] =  C2B2. 
Then 
A = 
A1/2 
0 
01 
A2J 
C 
[Ci, C2]  = 
_ 
ro 
0 
[0 
ri  0 
[0  1 
0 
0 
0 
01 
0 
- ij 
01 
1 
B  = 
«1 
kJ = 
n 
0 
.2 
01 
1 
- 1. 
is a minimal realization with A diagonal (show this). Note that the characteristic polyno 
mial of H{s) is PH{S)  = s'^(s +1), and therefore, the McMillan degree, which is equal 
to the order of any minimal realization, is 3, as expected. 
• 
D.  Realizations  with Matrix A in Block  Companion  Form 
The realizations  derived using the algorithms  described below  are in general  either 
controllable or observable and of order mr or pr,  where r is the degree of the minimal 
polynomial  of  ^(.s*). Most  often  it is  also  necessary  to use  the  methods  of  Subsec 
tion 3.4A  to reduce these realizations  to the standard forms  for unobservable or un 
controllable  systems and in this way derive minimal realizations. 
419 
CHAPTER 5: 
Realization 
Theory  and 
Algorithms 
Using the numerator polynomial  matrix 
Consider a proper pxm  matrix H{s)  and let 
mnis) 
-dr-lS  r-l 
-dis^do 
be its minimal  polynomial,  as in (4.37).  The  polynomial  mnis)  is the monic  least 
common denominator of all entries of  H{s). 
Let Nh{s) =  mH{s)H{s)  be a polynomial matrix and write 
N}y{s) = CbcSb{s)  ^Dbcmnis), 
(4.43) 
where  St{s) =  [Im^slm^ ...^s^~^Im].  Note  that  Dj^c  =  lim^^ooH(^),  and  therefore, 
C}jc  is the only  unknown  in (4.43).  A solution  Q^ always  exists  since the highest 
possible  degree  in  N}y{s)  — Df^c^nis)  is  r —  1  because  H{s) is  proper.  Expres 
sion  (4.43)  is  analogous  to  (4.24).  In addition,  we can also  write  mnis)  = s^ — 
-dQ,...,-dr-i][\,s, 
r-UT 
. . ,y 
, from  which we have 
mH{s)Im 
= S^im —  [—dolm^  • • • ,  —dr-lIm\Sb{s)^ 
(4.44) 
which corresponds to D{s) in (4.22). 
A controllable realization in block controllable companion form is given by x --
Ai,cX + Bi,cU^y = ChcS -\-DfycU with Q^  and Df^c  specified  in (4.43) and 
o„ 
A be 
0„ 
0. 
B, be  • 
(4.45) 
-dolm 
-d\Im 
-dr-]Ir l^m 
Note  that if the  strictly  proper  matrix H{s)  =  H{s) — lim^^ooH(^)  =  H{s) — D^c 
is used,  then 
Nt{s)  ^  mH{s)H{s)  = Rr-is'-^  +  • • • +/^o, 
where /^/, / =  0 , . . ., r — 1, are real pxm  coefficient  matrices. It is now  not  difficult to 
see that in this  case 
Q,  =  [/^o,/^i,...,/^r-i]. 
(4.46) 
The realization  {A/^c? ^/?C5 Qc? ^/?c} in (4.45) is of order mr and is a direct  generaliza 
tion of the  SISO  realization  (4.9) to the MIMO case. In general it is only  controllable 
but  not observable.  It is  also  observable  when  m =  1, and therefore,  it is  minimal 
for  m =  1.  This  is  true  because  of  Theorem  3.11 and the  fact  that  in  this  case 
r  =  deg  mH{s)  =  deg  PH{S), 
the  McMillan  degree  of  H{s). 
L E M M A 4.6.  The representation  (4.45) is a controllable realization of H(s). 
Proof,  The proof is similar to the proof of Lemma 4.1. First to show that (4.45) is a real 
ization,  we consider the  rmxm  matrix X{s) = [X[ (s),.  ..,Xj^{s)]'^  = {si — Ai,c)~^Bi,c. 
Then sX —A^cX  = B^c and sXi = Xi^i,/  =  1,...,r —  1, or X^+i =  s^Xi,i=  1,...,r — 1. 
Also,  sXf — [—dQlm,---,—dr-\Im\X  = Im,  which  implies,  in  view  of  X^+i  = s^Xi, 
that  mH{s)X\  = I^.  Thus,  Xi =  {mH{s))~^s^~^Im,i  =  1,... ,r,  and in view  of X{s) = 
{sI-Abc)-^Bbc, 
{sI-Abc)Sb{s)=BbcmH{s), 
(4.47) 
420 
Linear  Systems 
which is of course analogous to (4.11). (Refer also to the algorithm for the controller  form 
realization  in the MIMO  case  and the  Structure  Theorem  in  Subsection  3.4D,  where  a 
similar  relation  is  valid.)  Note  that  \sl  —  A^J  =  (mnis))^ 
(show  this).  To  show  that 
(Ab^, Bbc) is controllable, we observe that 
[Bbc, AbcBbc, 
He  Bbc 
.,Air'Bbc] 
= 
Om  0, 
X 
X 
(4.48) 
which has full  rank mr,  since the first mr  columns are linearly  independent. 
We  may  also  easily  obtain  an  observable  realization  of  H{s)  using  duality.  In 
particular 
On 
0, 
0„ 
-dolp 
-d\Ip 
Abo  = 
LOP 
In 
-dr-llpj 
Bbo 
Ri 
R r -l 
(4.49) 
Cbo  =  [0/7. 
Dbo  =  lim  H(s) 
is  an  observable  realization  of  order  pr  (use  duality  arguments  to prove  this). 
In  both  of  the  above  cases  of  controllable  realization  {Abo  Bbc,  Cbo  Dbc}  or  ob 
servable  realization  {Abo, Bbo,  Cbo, Dbo},  the  methods  of  Subsection  3.4A  may  be 
used  to  obtain  minimal  realizations  [see  (4.3b)]. 
EXAMPLE  4.7.  Let 
H(s) 
. 5 +1 
5(5-+  1). 
as in Example 4.6. We wish to determine an observable realization with A in block com 
panion form. To this end, duality will be used and the procedure described by (4.3a) will 
be  followed. 
In  this  case  we  have  mnis)  =  s^  + s  =  s^  + dis  + do, from  which  we  conclude 
that r  =  2,  Ji  =  1, and Jo  =  0. Note that H(s)  is stricdy proper. Let H(s)  =  H^(s)  = 
1 
s(s  +  1) 
s +  1  2s 
1 
0 
=  Nb(s)(mH(s))  ^ and  write 
Nb(s)  = 
1  2 
0  0  s + 
1  0 
0  1 
=  Ris  + /?o. 
(4.50) 
Then a controllable realization  of H(s)  is given by 
Ahr  = 
O2 
-doh 
h 
-dih. 
0 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
1 
-1 
0 
0 
-1 
Bbc  — 
[Ol 
[h\ 
"""0 "
0 
1 
0 
"0"" "
0 
0 
1 
Cbc  — [^0>  ^ l] 
1 0 : 12 
0 
1 : 00 
and an observable realization of H(s) is given by 
421 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
Abo  —  ^Z?c 
0 
0 
1 
0 
0 
0 
0 
1 
: 
: 
: 
: 
0 
0 
0 
0 
-1 
0 
0 
-1 
Bbo  — Cz?c 
""" 1 "
0 
1 
_2 
"0"" "
1 
0 
0 
Cbo  -  Bi  — 
^bc 
0  0 
0  0 
1  0 
0  1 
Note  that  the system  {Abo^ Bboy Cbo) is not controllable.  We ask the reader  to use  the 
procedure  shown  in (4.3b)  to obtain  a minimal  realization.  The order  of any minimal 
realization is 3 (why?). 
• 
Using the Hankel  Matrix 
We consider  a proper p  X  m transfer  function  matrix H(s)  and let 
muis)  =  s^ + dr-is^ 
r -l 
+  • • • +  dis  + do 
be its minimal polynomial,  as in (4.37). We write 
H{s)  =  HQ+  His-^  +  H2S~^ +  • • •, 
(4.51) 
where the Hi  are the Markov parameters  of the system. Let 
Op 
Ip 
.. 
• 
0, 
A  = 
Op 
-dolp 
0, 
-dilp 
.. 
.. 
• 
• 
ip 
-~dr-llp_ 
C  =  [lp,{)p,...,Opl 
D  =  Ho. 
B  = 
Hi 
H2 
Hr 
(4.52) 
LEMMA  4.7.  The representation  (4.52) is an observable realization of H(s). 
Proof,  To show  that  (4.52) is a realization,  we note that {A, B, C, D} is a realization of 
H{s)  if  and only  if  D  =  HQ and CA^~^B  =  ///, /  =  1, 2 , . ..  (prove  this,  referring  to 
Exercise 2.63). Here 
C 
CA 
ICA'-^ 
(4.53) 
and therefore, CA^'^B  = Hi, i  =  1,...,  r. To show that this is also true for /  =  r + 1 , . . ., 
a relationship between Hi and di is required. In particular, we let H{s)  = H{s) -  HQ and 
we write 
422 
Linear  Systems 
"mH(s)H(s)  =  (s'  +  dr-is'  +  '""  +dis  + doXHis  ^ +H2S  ^ +  • • •) "
Equating coefficients  of equal powers of s, we obtain 
'+Ro 
.r-2 
. 
Hi 
H2 
Rr-ly 
Rr-2  ~  dr-\H\, 
(4.54) 
(4.55) 
s 
'.  Hr  =  RQ ~  dr-iHf-i  — • • • —  d\Hiy 
and 
Hr+i  =  —dr-\Hr+i-\  —  •••  —  d{)Hi, 
i  =  1, 2, , 
Using the above relations, it can be shown that CA^~^B  =  Hi fori  =  1, 2, 
Now, 
in view of (4.53), the observability matrix has rank pr,  which is equal to the order of the 
system. Therefore,  the system is observable. 
• 
We  can  now  use  duality  arguments  to  show  that 
'Om 
^m 
•• 
.  Om 
.  On, 
-dolm 
-dllm 
A  = 
, 
B  = 
(4.56) 
% 
.. 
• 
c  =  m,H2, 
Im 
—dr-\Im_ 
....Hrl 
D = 
-H^ 
is a controllable  realization. 
EXAMPLE  4.8.  Let 
H(s)  = 
-  1 
5' 
2 
0 
1 
L^ +  l 
^(5 +  1) 
as  in  Example  4.7.  We  wish  to  determine  an  observable  realization.  Here  muis)  = 
s^ + s  =  5'^ + (ii5 + (io.fromwhichr  =  2, Ji  =  l,anddo 
-  0. Let//(5)  =  /fo+^i^~^  + 
H^s'^  +  • • •. The Markov parameters  can be found  directly  from  //Q  =  lim^y^oo H{s)  = 
0,  Hi  =  lims-.^s(H(s) 
-Ho) 
^^  H2  =  lims-..o s\H(s) 
^ 
2  0 
-  (Ho  +  His-'))  = 
and  so forth,  or from  (4.55)  since  /?o, • • • > ^r-i  are  already  known  from  Ex 
0  0 
-2  1 
ample  4.7  (after  the  transpose  is  taken).  We  have  Hi  =  Ri  = 
diHi 
= 
1  0 
0  1 
n  0 
[2  0. 
0  0 
-2  1 
,  and  H2+i 
-diH2+i 
[2  0 
-  doHi  = 
,H2  —  RQ — 
—Hi+i,  i  = 
1,2,...; that is, 
ro 
[2 
0 
- 1. 
=  -H2  =  H3  =  -H4  =  Hs  =  •••. Therefore,  an observable 
reahzation  (4.52) is given by 
A  = 
O2 
-doh 
h 
-dih. 
0 
0 
0 
0 
0 
0 
0 
0 
1 
0 
-1 
0 
0 
-1 
B  = 
\Hi] 
[H2\ 
1 
2 
0 
-2 
"0"" "
0 
0 
1 
C  =  [/2,02]  =  1  0 
0  1 
0  0 
0  0 
D  = 
ro  01 
0  0 
This realization is not controllable, since a minimal realization is of order 3. We ask the 
reader to use Theorem 3.13 to show this. 
• 
423 
CHAPTERS: 
Realization 
Theory and 
Algorithms 
E.  Realizations  Using  Singular-Value  Decomposition 
Internally balanced  realizations 
Given  a proper  p  X  m  matrix  H(s),  we  let  r denote  the  degree  of  its  minimal 
polynomial  mnis),  we write 
H(s)  = Ho^His-^  +//: 2^-^  +  ... 
to obtain the Markov parameters Hi,  and we  define 
T  ^  Mnir,  r) 
\Hi 
... 
Hr 
Hr 
H 2r-\ 
f'  A 
Ht 
H, r+l 
H, 
r +1 
H2r 
(4.57) 
where Mnir,  r) is the Hankel matrix  (see Definition  3.4)  and  T, f  are real  matrices 
of dimension  rp  X  rm. 
Using singular-value  decomposition  (see the Appendix), we write 
T  =  K  s  0 
0  0 
(4.58) 
where  X  =  diag  [Ai,...," A„]  £  R""^""  with  n  =  rank  T  =  rank  Muir",  r),  which 
in view  of Theorem  3.13 is the order of a minimal reahzation  of H(s).  The A, with 
Ai  s  A2 ^  • • • >  A„ >  0 are the singular values of T, i.e., the nonzero  eigenvalues 
of T^T.  Furthermore, KK^  =  K^K  =  Ipr and LL^  =  L^L  =  I,nr- We write 
T  =  K,XU 
=[K,"X""^[X""^LA=VU", 
(4.59) 
where Ki  denotes the first n columns of K, L\  denotes the first n rows of L,  K\K\  = 
In, and LiL[  =  /„. Also, V  G  R'P''''  and  U  E  R^''''^. 
We  let  V^  and  Lf^  denote  pseudoinverses  of  V  and  U, respectively  (see  Ap 
pendix), i.e., 
"V  =  ^-""^Kl "
and 
^^+  - 
U^  =  L [ S-
"^^^-""^ "
(4.60) 
where  V^V  =  In and  UU^  =  In. Now  define 
A  =  V^fu^, 
B  = UIL 
^p,pr  V, 
D  =  Ho. 
(4.61) 
where 4,^  =  Uh ^e-kl  k  <  ^, i.e., Ik^^ is a fc X € matrix  with its first k columns  de 
termining  an identity  matrix  and the remaining  (-  k columns being  equal to zero. 
Thus, B is defined  as the first m columns of  C/, and C is defined  as the first/? rows of 
"V. Note that A  G 7?""X^ B  G Z^^^^'"""," C  G T^^^""", and D  G  RP'''^, 
LEMMA 4.8.  The representation (4.61) is a minimal reahzation of H(s). 
424 
Linear Systems 
Proof, It can be shown that CA^'^B  = Hi, i  =  1, 2,...  (see also the proof of Lemma 
4.7). Thus, {A, B, C, D} is a reahzation. We note that V and U are the observabiHty and 
controllabihty  matrices, respectively,  and that both  are of full  rank  n. Therefore,  the 
reahzation is minimal. Furthermore, we notice that V'^V =  UU^  = 2.  Realizations of 
this type are called internally balanced realizations. 
• 
The term  internally  balanced  emphasizes  the fact  that realizations  of this  type 
"are  ""as  much  controllable  as  they  are  observable","""  since  their  controllability  and "
observability  Gramians are equal and diagonal (see Exercise 5.20). Using such rep 
resentations, it is possible to construct reasonable reduced-order  models of  systems 
"by deleting that part of the state space that is ""least controllable"" and therefore  ""least "
"observable"" in accordance with some criterion. In fact", the realization procedure de 
scribed can be used to obtain a reduced-order  model for a given system.  Specifically, 
if the system is to be approximated  by a ^-dimensional  model with  q  <  n, then  the 
reduced-order model can be obtained  from 
T  =  Kqdiag[Xi,...,\q\Lq, 
(4.62) 
where Kq denotes the first q columns of K in (4.58), and Lq denotes the first q rows 
ofL. 
5.5 
SUMMARY 
The theory of state-space realizations of input-output descriptions given by  impulse 
responses, and the time-invariant case by transfer function descriptions, were studied 
in this  chapter. 
In  Section  5.2  the  problem  of  state-space  realizations  of  input-output  descrip 
tions  was  defined  and  the  existence  of  such  realizations  was  addressed.  In  Sub 
section  5.3A  time-varying  and  time-invariant  continuous-time  and  discrete-time 
systems  were  considered.  Subsequently,  the  focus  was  on  time-invariant  systems 
and  transfer  function  matrix  descriptions  H{s).  The  minimality  of  realizations  of 
H{s)  was  studied  in  Subsection  5.3C,  culminating  in two results, Theorem  3.9  and 
Theorem  3.10,  where  it was first shown  that  a realization  is minimal  if  and  only if 
it is controllable  and observable, and next, that if a realization  is minimal, all other 
minimal realizations of a given H{s)  can be found  via similarity transformations.  In 
Subsection  5.3C  it  was  shown  how  to determine  the  order  of minimal  realizations 
directly  from  H{s).  Several  realization  algorithms  were  presented  in  Section  5.4, 
and the role of duality was emphasized  in Section  5.4A. 
5.6 
NOTES 
A  clear  understanding  of  the  relationship  between  external  and  internal  descrip 
tions  of  systems  is one of  the principal  contributions  of  systems  theory.  This  topic 
was  developed  in  the  early  sixties  with  original  contributions  by  Gilbert  [2]  and 
Kalman [4]. 
The  role  of  controllability  and  observability  in  minimal  realizations  is  due  to 
Kalman  [4]. See also Kalman, Falb, and Arbib [5]. 
The  first  realization  method  for  MIMO  systems  is  attributed  to  Gilbert  [2]. It 
was  developed  for  systems  where  the  matrix A  can  be  taken  to  be  diagonal.  This 
method  is presented  in this  chapter.  For extensive  historical  comments  concerning 
this topic, see Kailath  [3]. 
Additional information  concerning realizations for the time-varying case can be 
found,  for  example,  in  Brockett  [1], Silverman  [9], Kamen  [6], Rugh  [8], and  the 
literature cited in these  references. 
Balanced realizations were introduced in Moore [7]. 
425 
CHAPTER 5: 
Realization 
Theory and 
Algorithms 
5.7 
REFERENCES 
1.  R. W. Brockett, Finite Dimensional Linear Systems, Wiley, New York, 1970. 
2.  E. Gilbert," ""Controllability  and Observability in Multivariable Control Systems",""" SIAM "
J. Control,  Vol. 1, pp. 128-151, 1963. 
3.  T  Kailath, Linear Systems,  Prentice Hall, Englewood Cliffs, NJ, 1980. 
4.  R. E. Kalman," ""Mathematical Description of Linear Systems",""" SIAM J. Control",  Vol. 1, 
5.  R.  E.  Kalman,  R  L.  Falb,  and  M.  A.  Arbib,  Topics in Mathematical System  Theory, 
pp. 152-192, 1963. 
McGraw-Hill, New York, 1969. 
6.  E. W. Kamen,"""New Results in Realization Theory for Linear Time-Varying Analytic Sys "
tems,""" IEEE Trans",  on Automatic Control,  Vol. AC-24, pp. 866-877, 1979. 
7.  B.C. Moore,"""Principal Component Analysis in Linear Systems: Controllability", Observ 
ability and Model Reduction,""" IEEE Trans", on Automatic Control, Vol. AC-26, pp. 17-32, 
1981. 
8.  W. J. Rugh, Linear System Theory,  Second Edition, Prentice-Hall, England  Cliffs,  NJ, 
1996. 
9.  L. M. Silverman," ""Realization of Linear Dynamical Systems",""" IEEE Trans", on Automatic 
Control,  Vol. AC-16, pp. 554-567, 1971. 
5.8 
EXERCISES 
5.1.  Given the transfer function matrix 
H{s) 
s-  1 
s 
0 
5+ 1 
s-2 
s + 2 
0 
determine the McMillan degree of H{s) and find a minimal realization for H{s). Verify 
your results. 
5.2.  Consider the transfer function matrix 
H{s) 
\s-  1 
s+\ 
1 
1 
s^  -\ 
0 
(a)  Determine the pole polynomial  and the McMillan degree of II{s),  using both the 
Smith-McMillan form and the Hankel matrix. 
426 
Linear  Systems 
(b)  Determine an observable realization  of  H(s). 
(c)  Determine  a minimal realization  of  H(s). 
Hint:  Obtain realizations  for 
1 
1 
s +  1  s^ 
1 
5.3.  Consider the transfer function  matrix  H(s) 
for H(s)  a minimal realization in controller  form. 
(s +  1)(-^  +  5) 
(s -  l)(s^  -9)' 
s 
s-1 
and determine 
5.4.  Consider the transfer  function  matrix 
His)  =  I 
-3s^ 
-6s-2 
3 ^-  1 
1 
(^ + 1)^ 
s 
(S +  1)3 
(s -  2)(s  +  1)3 
(s -  2)(s  +  1)2 
s 
(s-2)(s+ 
s 
1)3 
( ^ - 2 ) ( ^+  1)2 J 
(a)  Determine the pole polynomial  of H(s)  and the McMillan  degree of  H(s). 
(b)  Determine a minimal realization  of H(s)  in observer  form. 
5.5.  Consider the scalar proper rational transfer function//(>s')[})(5')  =  //(5')M(^)], and assume 
-. Note that this can be done when  the 
that H(s)  can be written  as H(s)  =  2 Li  -
s  -  Ai 
poles A/, /  =  1,...,  w, are distinct  (see Subsection  5.4C  on realizations  with A  in diag 
onal  form). 
(a)  Show that H(s)  can be realized as the sum or the parallel combination of realizations 
of terms  in the form  —^-—; i.e., H(s)  is realized  by  the  system represented  in  the 
block  diagram  of Fig.  5.4,  where  r/  =  QZ?/, /  =  1,...,  n,"  with  cj  G  /?"""," bi  E  /?""", 
with 
q-  Xi 
, and q = didt  denotes the integrator circuit shown in Fig. 5.5. Note that 
this realization of H{s)  has advantages with respect to sensitivity to parameter  vari 
ations. 
"""' "
^ 
1 
(7-X1 
1 
q-K 
<=1 
^n 
FIGURE  5.4 
Block diagram of the system in Example  5.5a 
""")"""" "
) 
c Vr 
^T 1 
I 
^i 
FIGURE  5.5 
Block diagram of an integrator 
(b)  Show that when poles are repeated, as, e.g., in the transfer  function 
H(s)  = 
"-""TT + "
+ 
;r,  then  a  parallel  realization  is  as  shown  in  the 
(5+1)2 
^ +1 
5 +  2 
block diagram given in Fig. 5.6. 
^ 
427 
CHAPTER  5: 
Reahzation 
Theory  and 
Algorithms 
1 
qr+2 
u 
1 
q+^ 
1 
(7+1 
W 
\ J 
FIGURE  5.6 
Block diagram of the system in Example  5.5b 
(c)  When  there  are complex  conjugate  poles,  as, e.g.,  in the  transfer  function  H(s) 
as  + b 
J, then H(s)  can be written as  H(s) 
(S +  C)2 +  ^2^—-^-^-- 
and can be realized  as indicated in the block diagram given in Fig. 5.7. 
--^-^ 
^ 
al{s +  c) 
(b  -  ac)/(s  +  cf 
I  +  (j2/(^  +  c)2)  •' 1 +  (dVis  +  C)2) 
a 
""" "
k 
1 
q  + c 
1 
g  + c 
^ 
b-  ac  1 
^ 
i 
d^ 
1 
• c^ 
k/ 
FIGURE  5.7 
Block diagrams of the system in Exercise  5.5c 
Note that in addition to sum or parallel  realizations  discussed in (a) to (c), there 
5 +1 
(5 +  2)(5 +  3) 
are also product  or cascade  realizations  where, for example,  H(s) 
is realized  as 
5+  1 
5 +  2  5 +  3 
1 
1 
5+  1 
5 +  2  5 +  3' 
5.6.  Consider the transfer  function 
H(s)  = 
5 +  3 
5+  1 
5 
•5 +  3 
5 + 1-
(a)  Determine the pole polynomial of H(s)  and the McMillan  degree of  H(s). 
(b)  Determine a minimal realization {A, B, C, D] of H(s),  where A is a diagonal matrix. 
5.7.  Consider  a system described  by equations  of the  form 
0 
Xi 
AIJL^IJ 
[0 
Bi\ 
y  =  [Ci, Ci] 
, where Ai is the Jordan block associated with the eigenvalue A, and Ai 
428 
Linear  Systems 
is the complex conjugate of Ai associated with A. Show that the similarity  transformation 
matrix P given by P  =  . 
. 
can be used to reduce the representation given above 
to one that involves only real system parameters, namely, 
Xi 
X2\ 
ReAi 
-ImAi 
Im  A\ 
ReAi 
2 Re  Bi 
-llmBi 
y  =  [ReCi, 
ImCi\ 
Note that this is a way of obtaining representations involving only real coefficients  from 
realizations  with A  in diagonal or in Jordan form  that may contain complex numbers. 
5.8.  Determine an observable reaHzation oiH{s)  given in Exercise 5.1, where the matrix A 
is in block companion form, by using 
(a)  the numerator polynomial  matrix, 
(b)  the Hankel  matrix. 
5.9.  Show that if the system {A, B, C, D} reaHzes H{s)  =  -^—;r 
and  \sl  -  A\  =  s^ + 
2 ^ + 1,  then  (A, B)  must  be  controllable  and  (A, C)  must  be  observable.  Hint:  Use 
Theorem 3.11. 
s  + 2 
s^  + 2s  -\-  \ 
5.10.  Show  that  if  the  system  {A, B, C, D]  realizes  the  transfer  function  matrix  H{s)  and 
1^/ -  A|  =  mnis),  the  monic  least  common  denominator  of  the  entries  of  H(s),  then 
{A, B, C, D} is a minimal realization of H(s).  Can one always find a realization of  ^(^) 
that satisfies  this property? Hint:  Use Theorem 3.11. 
5.11.  Consider  a  scalar  proper  rational  transfer  function  H(s)  =  n(s)/d(s),  and  let  x  = 
AcXc +  BcU, y  =  CcXc +  DcU be a realization  of H(s)  in controller form  (see Subsec 
tion  5.4B). 
(a)  Show that the realization {A^, B^  Cc, Dc} is always  controllable. 
(b)  Show  that  {Ac, Be, Cc, Dc] is  observable  if  and  only  if  n{s)  and  d{s)  do not  have 
any factors  in common, i.e., they  are prime polynomials. 
(c)  State the dual results to (a) and (b) involving  a realization  in observer  form. 
5.12.  Consider  3. p  X  m proper rational transfer  function  matrix H(s)  and the algorithm that 
leads  to  a  reaHzation  {Ac, Be, Cc, Dc} of  H(s)  =  N(s)D(s)~^  in  controller  form  [see 
(4.22) and (4.24)]. 
(a)  Show that (Ac, Cc) is observable if and only if rank  ' 
N(\)\ 
' 
=  m for any A complex 
scalar. Hint:  Use the eigenvalue/eigenvector  tests for  observability.  Note that  this 
rank condition is a necessary  and sufficient  condition for N(s)  and D(s)  to be right 
coprime (see Theorem 2.4 in Subsection  7.2D). 
(b)  State  the  dual  result  to  (a)  that  involves  a  realization  in  observer  form  {Ao, Bo, 
Co, Do) of His)  =  D-\s)N(s). 
^  -i^  X 
5.13.  Let H(s)  =  ^K  =  -^ 
rr^  X 
^(S) 
d(s) 
z 
T 
^5 -  ^4 +  s^ 
S'^ -  S  +  1 
+  s-  1 
form. Is your realization minimal? Explain your answer. Hint:  Use the results of Exer 
cise 5.11. 
.  Determine  a realization  in  controller 
5.14.  For the transfer  function  H(s)  = 
s+  1 
^2 +  2' 
,find 
(a)  an uncontrollable  realization, 
(b)  an unobservable  realization, 
(c)  an uncontrollable  and unobservable  realization, 
(d)  a minimal  realization. 
429 
CHAPTERS: 
Realization 
Theory  and 
Algorithms 
5.15.  Find minimal discrete-time  state-space realizations  of the transfer  function  matrix 
-z  +  2 
H(z)  =  z +1 
z 
- z +1 
1 
z +  3 
z +1 
z +  2-
using all the realization  methods described  in this  chapter. 
5.16.  Given  is  the  system  depicted  in  the  block  diagram  of  Fig.  5.8,  where  H(s)  = 
s^  +  1 
—  —  —. Determine  a minimal  state-space representation  for the  closed-
{s +  1)(^ +  2){s +  3) 
loop system, using two approaches. In  particular: 
F 
F 
u 
His) 
y 
^ 
:^ L 
FIGURE  5.8 
Block diagram of the system in 
Exercise  5.16 
(a)  First, determine  a state-space realization  for H(s),  and then, determine  a minimal 
state-space representation  for the closed-loop  system. 
(b)  First, find the closed-loop transfer  function,  and then, determine  a minimal  state-
space representation  for the closed-loop  system. 
Compare the two  approaches. 
5.17.  Consider  the  system  depicted  in  the  block  diagram  of  Fig.  5.9,  where  H(s)  = 
s  +  I 
—  —  and  G(s)  = 
^(^ +  3) 
system to be controlled  and G{s) could be regarded  as a feedback  controller. 
with  k,a  EL R.  Presently,  H{s)  could  be  viewed  as  the 
s  + a 
k 
"r^ "". "
V 
-J t 
H{s) 
G(s) 
y 
FIGURE  5.9 
Block diagram of the  system 
in Exercise  5.17 
(a)  Obtain a state-space representation  of the closed-loop system by 
(i)  first,  determining realizations  for H{s)  and G{s) and then combining  them; 
(ii)  first,  determining Hds),  the closed-loop transfer  function. 
(b)  Are there any choices for the parameters k and a for which your closed-loop state-
space  representation  is  uncontrollable  and  unobservable?  If  your  answer  is  yes, 
specify. 
5.18.  For H{s)  as in Exercises 5.1, 5.2, and 5.3, determine internally balanced minimal real 
izations, using  singular-value  decomposition. 
430 
Linear  Systems 
5.19.  Let 
H{s) 
1 
^2 +  1 
5^ +  1 
^4 
5^ +  1 
7T3 
5^ +  1 
^3 +  2 5 +1 
1 
5 +  2 
^3 +  1 
be a transfer  function  matrix. 
(a)  Find a minimal realization  for H(s)  in controller  form. 
(b)  Find an internally balanced minimal realization for  H{s). 
5.20.  Consider  the  controllable  (-from-the-origin)  and  observable  system  given  by  i  = 
Ax-\-Bu,  y  =  Cx-\- Du  and its equivalent representation x  = Ax-\-Bu,  y  = Cx-\-  Du, 
where  A  =  PAP-\  B  =  PB,C  =  CP~\  and  D  =  D.  Let  Wr  and  Wo denote  the 
reachability  and observability  Gramians,  respectively. 
(a)  Show that Wr = PWrP* and Wo  =  {p-^yWoP~\  where P* denotes the  complex 
conjugate  transpose  of P.  Note  that P* =  P^  when  only  real  coefficients  in  the 
system equations are involved. 
Using  singular-value  decomposition  (refer  to the Appendix),  write 
where  WU  =I,VV 
values of W.  Define 
Wr = Ur^rV; 
and 
Wo =  Uo^oV;, 
/,  and  E  =  diag  (Ei,E2,... ,S„)  with  E/  the  singular 
H=iY}J'yu:Ur{Y}J').. 
and using  singular-value  decomposition,  write 
where U^UH 
'-1J VHVH  = ^' Prove the  following: 
, l / 2 x -l 
"(b)  IfP  = Pin =  y//(E;/^)"">;",thenW;=/,W^,: 
(c)  If P  =  Pout =  Ufj(E^)  V,*, then Wr =  ^]i,Wo-
(d)  If P  =  Pib  =  Pin^ll^  =  ^]i^Pouu  then Wr = Wo=  S//.  Note  that the  equivalent 
in  (b),  (c),  and  (d)  are  called,  respectively,  input-
representations  {A,B,C,D} 
normal,  output-normal,  and internally  balanced  representations. 
= 1. 
5.21.  Show that the representation  (4.61) in Section  5.4  is internally  balanced,  in view of 
Exercise  5.20(d). 
5.22.  Consider  the  transfer  function  H{s) 
realization for  H{s). 
4^3 +  3 5 +1 
and  determine  a  minimal 
5.23.  Transform  the  system 
"""  -1 "
0 
1 
2 
1 
0 
"- 2"" "
1 
-1 
x + 
"""2"" "
0 
1 
u, 
};=[l,l,0]x 
into Xc = AcXc -\-BcU,  y  =  CcXc,  an equivalent  representation  in  controller  form  uti 
lizing the following  two methods: 
(a)  Use of a similarity  transformation. 
(b)  Determination  of the transfer  function  H{s)  and use of a realization  algorithm. 
5.24.  Consider  the  two  system  5*1  and  5*2  in  series  as  depicted  in  the  block  diagram 
given  in  Fig.  5.10.  Suppose  that  5*1  is  described  by  yi{s)  =  Hi{s)Ui{s),  where 
^i('^)  ^ 
^  +  1'  ^^^  similarly,  that  5*2  is described  by 3^2('^) =  ti2(s)u2(s),  where 
5 +  2 
U2{s)=yi{s)  and7/2(5)  =  ——-. 
431 
CHAPTER  5: 
Realization 
Theory  and 
Algorithms 
^1 
1 
1 
V 
1 
l_ 
y,  =u^ 
^1 
^2 
"""  ~ i^ "
>2 
* 
FIGURE  5.10 
Block diagram of the 
system in Exercise  5.24 
(a)  Determine controllable and observable state-space descriptions for the individual 
subsystems 5*1  and 5*2. 
(b)  Determine a state-space representation for the entire  system S, using your answer 
in (a). 
(c)  Is the  state-space  description  of  S in  (b)  controllable?  Is  it  observable?  What  is 
the transfer  function  H{s)  of 5*? 
5.25.  Consider a system described by 
1 
( 5 + 1 )2 
0 
2 
5 +1 
^1(5) 
U2{s) 
(a)  What is the order of a controllable  and observable realization of this  system? 
(b)  If  we  consider  such  a realization,  is  the  resulting  system  controllable  from  the 
input W2? Is it observable from  the output yi ? Explain your  answers. 
5.26.  Consider  the  system  described  by  H{s) 
1 
5 - (l  +  e) 
(y(s)  =H(s)u(s)) 
and  C(5) 
5 -1 
5 +  2 
(^(5)  =  C{s)f{s))  connected in series  (e G /?). 
(a)  Derive  minimal  state-space  realizations  for  H{s)  and  C{s)  and  determine  a 
(second-order)  state-space description  for the system y{s)  =  H{s)C{s)f{s). 
(b)  Let e =  0 and discuss the implications regarding the overall transfer  function  and 
your  state-space  representations  in  (a).  Is  the  overall  system  now  controllable, 
observable,  asymptotically  stable?  Are the poles  of  the  overall transfer  function 
stable?  [That  is,  is  the  overall  system  BIBO  stable?  (See  Chapter  6.)]  Plot  the 
states and the output for  some nonzero initial condition  and a unit step input  and 
comment on your results. 
(c)  In  practice,  if  H{s)  is  a  given  system  to  be  controlled  and  C{s)  is  a  controller, 
it  is  unlikely  that  e  will  be  exactly  equal  to  zero  and  therefore  the  situation  in 
(a),  rather  than  (b),  will  arise.  In  view  of  this,  comment  on  whether  open-loop 
stabilization can be used in practice. Carefully  explain your reasoning. 
C H A P T ER  6 
Stability 
432 
Dynamical  systems, either occurring  in nature or manufactured,  usually  function 
in  some specified  mode. The most common  such modes are operating points that 
frequently  turn out to be equilibria. 
In this chapter we will concern ourselves primarily with the qualitative behavior 
of equilibria. Most of the time, we will be interested in the asymptotic stability of 
an equilibrium (operating point), which means that when the state of a given system 
is displaced (disturbed) from its desired operating value (equilibrium), the expecta 
tion is that the state will return to the equilibrium. For example, in the case of an 
automobile under cruise control, traveling at the desired constant speed of 50 mph 
(which determines the operating point, or equilibrium condition), perturbations due 
to hill climbing (hill descending), will result in decreasing (increasing) speeds. In a 
properly designed cruise control system, it is expected that the car will return to its 
desired operating speed of 50 mph. 
Another qualitative characterization of dynamical systems is the expectation that 
bounded system inputs will result in bounded system outputs, and that small changes 
in inputs will result in small changes in outputs. System properties of this type are 
referred  to as input-output stability. Such properties are important, for example, in 
tracking  systems, where the output  of the  system is expected  to follow  a desired 
input. Frequently, it is possible to establish a connection between the input-output 
stability properties and the Lyapunov stability properties of an equilibrium. In the 
case of linear systems, this connection is well understood. 
6.1 
INTRODUCTION 
In this chapter we present a brief introduction to stability theory. We are concerned 
primarily with linear systems and systems that are a consequence of linearizations 
finite-  433 
CHAPTER 6 
Stability 
of  nonlinear  systems.  As  in  the  other  chapters  of  this  book,  we  consider 
dimensional  continuous-time  systems  and  finite-dimensional  discrete-time  systems 
described  by  systems  of  first-order  ordinary  differential  equations  and  systems  of 
first-order ordinary difference  equations, respectively. We will consider both internal 
descriptions and external descriptions of systems. For the former,  we present results 
for  various types  of Lyapunov  stability  of an equilibrium  (under  assumptions  of no 
external  inputs),  while  for  the  latter  we  develop  results  for  input-output  stability 
(under  assumptions  of zero initial  conditions). We also present  results  that  connect 
these two  stability  types. By  considering  both Lyapunov  stability  and  input-output 
stability, we are frequently  able to conduct  a more complete  qualitative  analysis of 
a system than can be accomplished by applying only one type of stability  analysis. 
Recall that in Subsections 2.4C and 2.7E we have already encountered  stability 
properties  of  an equilibrium  for  time-invariant,  continuous-time,  and  discrete-time 
systems, respectively. 
A.  Chapter  Description 
This  chapter  is  organized  into  three  parts. In  Part  1 (Sections  6.3  through  6.8)  we 
address  the  Lyapunov  stability  of  an  equilibrium,  in  Part  2  (Section  6.9)  we  con 
sider  input-output  stability,  and  in  Part  3  (Section  6.10),  we  treat  both  Lyapunov 
stability  and input-output  stability  of (time-invariant)  discrete-time  systems. Part 1 
is preceded  by  Section  6.2,  which  contains  some background  material  from  linear 
algebra. 
In Section 6.2 we provide additional background in linear algebra dealing  with 
bilinear  functional  and  congruence,  Euclidean  vector  spaces,  and  linear  transfor 
mations  on Euclidean  vector  spaces. This material  constitutes  a continuation  of the 
material presented in Subsections  I.IOA and I.IOB and Section 2.2, and the notation 
used in those sections will also be employed in the second  section of this  chapter. 
In Section 6.3 we introduce the concept of equilibrium of dynamical systems de 
scribed by  systems  of  first-order  ordinary  differential  equations, and in Section  6.4 
we give definitions  of various types of stability in the sense of Lyapunov  (including 
stability, uniform  stability,  asymptotic  stability, uniform  asymptotic  stability, expo 
nential stability, and instability). 
In  Section  6.5  we  establish  conditions  for  the  various  Lyapunov  stability  and 
instability  types  enumerated  in  Section  6.4  for  linear  systems  {LH),  (L),  and  (P), 
Most  of  these  results  are  phrased  in  terms  of  the  properties  of  the  state  transition 
matrix for  such  systems. 
In  Section  6.6  we  state  and  prove  necessary  and  sufficient  conditions  for  the 
exponential  stability  of the equilibrium  of nth-order  ordinary  differential  equations 
with constant coefficients  and systems of linear first-order ordinary differential  equa 
tions  (L). These  involve  geometric  criteria  (the interlacing  theorem)  and  algebraic 
criteria (the Routh-Hurwitz  criterion). 
In  Section  6.7  we  introduce  the  Second  Method  of  Lyapunov,  also  called  the 
Direct Method of Lyapunov, to establish necessary and sufficient  conditions for var 
ious Lyapunov stability types of an equilibrium for linear systems (L). These results, 
which  are phrased  in  terms  of  the  system  parameters  [coefficients  of  the  matrix  A 
for  system (L)], give rise to the Lyapunov matrix  equation. 
434 
Linear Systems 
In Section 6.8 we use the Direct Method of Lyapunov in deducing the asymptotic 
stabihty and instabiUty of an equihbrium of nonhnear autonomous systems (A) from 
the stabihty properties of their hnearizations. 
In  Section  6.9  we  estabhsh  necessary  and  sufficient  conditions  for  the  input-
output  stabihty  (more  precisely,  for  the  uniform  bounded  input/bounded  output 
stability) of continuous-time, linear, time-varying systems, and linear, time-invariant 
systems. These results involve the  system impulse  response  matrix. In this  section 
we also establish  a connection  between  the bounded input/bounded  output  stability 
of linear systems and the exponential  stability of an equilibrium of linear  systems. 
The stability results presented in Sections 6.3 through and including Section 6.9 
pertain  to continuous-time  systems. In  Section  6.10  we present  analogous  stability 
results  for  discrete time  systems; however,  in the interests  of economy,  we  confine 
ourselves in this section to time-invariant systems. Also, to give the reader a glimpse 
into the qualitative  theory  of dynamical  systems  described  by  nonlinear  equations, 
we present in this section Lyapunov stability results for  finite-dimensional  dynamical 
systems described by systems of nonlinear first-order ordinary difference  equations. 
We  conclude  the  chapter  with  comments  concerning  some  of  the  existing  lit 
erature  dealing  with  the  present  topic.  As  in  all  the  other  chapters,  problems  are 
provided  at the end of the chapter to further  clarify  the subject  at hand. 
B.  Guidelines  for the  Reader 
In  a first reading,  the background  material  on linear  algebra,  given  in  Section  6.2, 
can be reviewed rather quickly, as needed. 
In a first course on linear  systems, the reader needs to acquire familiarity  with 
the  notion  of  an  equilibrium  (Section  6.3)  and  various  stability  concepts  of  an 
equilibrium  (Section  6.4).  Such  a course  may  be confined  to  studying  the  stability 
properties of an equilibrium for time-invariant  systems  (L) (refer  to Theorem 5.6 in 
Section 6.5). This may be followed  by coverage of Section 6.7, where the principal 
Lyapunov  stability  results  for  time  invariant  systems  (L)  are  established  in  terms 
of  the  properties  of  the  Matrix  Lyapunov  Equation.  In  a  first  reading.  Section  6.8 
should  also be covered  in its entirety,  where  conditions  are established  that  enable 
one to deduce the stability properties of a time-invariant  nonlinear  system  (A)  from 
the hnearization  of  (A). 
The  reader  should  concentrate  on  the  input-output  stability  results  for  linear, 
time-invariant,  continuous-time  systems  given  in  Theorems  9.4  and  9.5  in  a  first 
course on linear  systems. 
Finally,  in  a first reading,  the  reader  may  consider  some  or  all  of  the  counter 
parts of the above results for the case of linear, time-invariant, discrete-time  systems 
developed in Section  6.10. 
6.2 
MATHEMATICAL  BACKGROUND  MATERIAL 
In this  section we provide  additional background  material  from  linear  algebra  and 
matrix  theory.  As in previous  sections where we present  such material, we  assume 
that the reader has  some background  in these areas, and therefore,  our presentation 
will be in the form  of a summary, rather than a development of the subject  at hand. 
This  section  consists  of  three  subsections.  In  the  first  subsection  we  address 
bilinear functionals  and congruence, in the second subsection we present material on 
Euclidean vector spaces, and in the third subsection we address some issues dealing 
with linear transformations  on Euclidean  spaces. 
435 
CHAPTER 6: 
Stability 
A.  Bilinear Functionals  and  Congruence 
We consider here the representation of bilinear functionals  on real  finite-dimensional 
vector spaces. Throughout this subsection,  V is assumed to be an /i-dimensional vec 
tor space over the field of real numbers  R. 
We define  a bilinear functional  on  V as a mapping  f  : V  X  V -^  R having  the 
properties 
f(av^  +  jSv^ w)  =  af(v\  w)  +  )8/(v^  w) 
/(v, yw^  +  8w^)  =  yf(v,  w^)  +  8f(v,  w^) 
(2.1) 
(2.2) 
for  all  a,  I3,y,d  G  R  and  for  all  v^ v^, w^, w^  in  Y.  A  direct  consequence  of  this 
definition  is the more general  property 
for  all aj,  ^^  G R and v^, w^  ^  V, j  =  1,...,  r,-and  k  =  1,..., ^. 
Now let {v^ . . .,"  v""} be a basis for the vector space  V and let "
fij  =  f(y\vJ), 
i,j  =  l , . . . , n. 
(2.3) 
The matrix F  =  [ftj^  is called the matrix  of the bilinear functional  f  with  respect to 
The  characterization  of  bihnear  functionals  on  real  finite-dimensional  vector 
spaces  is given  in the following  result,  which  is a direct  consequence  of the  above 
definitions  and  the  properties  of  bases:  l e t/  be  a bilinear  functional  on  V  and  let 
{v^ . . .,"  v""} be  a basis  for  V.  Let  F  be  the  matrix  of  the  bilinear  functional/  with "
respect  to the basis {v^ ...,  v'^}. If x  and y  are arbitrary  vectors in V,  and if ^  and 7] 
are their coordinate representations  with respect to the basis {v^ ...,"  v""}", then 
f{x, y) = eFv  = XJlM^^J' 
/ -I  7 = 1 
(2.4) 
Conversely, if we are given  any  nX  n matrix F, we can use (2.4) to define  the 
bilinear  functional/  whose matrix  with respect  to the given basis {v^ . . .,"  v""} is", in 
turn, F again. In general it therefore follows that on  finite-dimensional  vector spaces, 
bilinear  functionals  correspond  in  a one-to-one  fashion  to matrices.  The  particular 
one-to-one correspondence  depends on the particular basis  chosen. 
A bilinear functional/  on  V is said to be symmetric  if f(x,  y)  =  f(y,  x)  for  all 
x,yGV 
and skew  symmetric  if f(x,  y)  =  — f{y,  x)  for  all x, y  E  V. 
436 
Linear Systems 
For symmetric and skew symmetric bilinear functional  the following results are 
easily proved: let {v^ . . .,  v^} be a basis for  V, and let F be the matrix for  a bilinear 
functional  with respect to {v^ . . .,  v'^}. Then 
1. /  is symmetric if and only if F  =  F^. 
2.  f  is skew symmetric if and only if F  = 
3.  For  every  bilinear  functional/,  there  exists  a  unique  symmetric  bilinear  func 
-F^. 
tional /i  and a unique skew symmetric bilinear functional  fz  such that 
/  =  /i  +  fi. 
(2.5) 
We call /i  the symmetric  part  off  and /2 the skew  symmetric  part  of/. 
The above result motivates the following  definitions:  an n  X n matrix F is  said 
to ht  symmetricif  F  =  F^  dind skew  symmetric  if F  =  —F^. 
Using  definitions,  the  following  result  is  easily  established:  l e t/  be  a  bilinear 
functional  on  V and let /  and  /2 be the  symmetric  and  skew  symmetric parts  of/, 
respectively.  Then 
/i(v,w)  =  ^[/(v,w)  +  /(w,v)] 
and 
/2(v, w)  =  \ [/(v,  w)  -  f{w,  v)] 
(2.6) 
(2.7) 
for all V, w G  V. 
Next,  we  define  the quadratic form  induced  by  a bilinear  functional/  on  V as 
f(y)  =  /(^^ v) for all V  E  y.  It is easily verified  that in terms of matrices we have 
fix)  =  fF^  = ^JlfiMp 
(2-8) 
where  ^  denotes  the  coordinate  representation  of  x  with  respect  to  the  basis 
{v^...,"v""}. "
For quadratic  forms  we have the following  result:  l e t/  and g be bilinear  func 
tional  on  V. The quadratic  forms  induced  b y/  and g are equal if and only iff  and 
g have  the  same  symmetric  part.  In other  words,  /(v)  =  g(v)  for  all v E  V if  and 
only if 
k [/(v,  w)  +  /(w, V)]  =  i [g(v, w)  +  g(w^ V)] 
(2.9) 
for all v,w  EiV.  From this result we can conclude that when treating quadratic  func 
tional, 
it suffices  to work  with  symmetric  bilinear  functionals. 
It is also easily verified  from  definitions  that a bilinear functional/  on a vector 
space V is skew  symmetric if and only if /(v, v)  =  0 for  all v G  V. 
Next, let/ be a bilinear functional  on a vector space V, let {v\  . . .,  v'^} be a basis 
for y, and let Fbe the matrix off  with respect to this basis. Let {v^ . . .,  v'^} be another 
basis whose matrix with respect to {v^ . . .,  v'^} is P. It can readily be verified that the 
matrix F  off  with respect to the basis {v^ ...,"  v""} is given by "
F  =  P^FP. 
(2.10) 
This result  gives rise to the following  concept:  annX  n matrix  F  is  said to be 
congruent  to an nXn  matrix F if there exists a nonsingular matrix P such that (2.10) 
holds. We express  congruence  of  two  matrices  F, F  by  writing  F--F.lt 
is  easily 
shown that ~  is reflexive, symmetric, and transitive, and as such it is an equivalence 
relation. 
For practical reasons  we are interested  in determining  the simplest matrix  con 
gruent  to  a given  matrix,  or what  amounts  to the  same thing, the  most  convenient 
basis  to use  in  expressing  a given  bilinear  functional.  If,  in particular,  we  confine 
our interests to quadratic functional,  then it suffices,  as observed earlier, to consider 
symmetric bilinear functionals. The following result, called Sylvester's  Theorem, ad 
dresses this issue. The proof of this result is rather lengthy, and the interested  reader 
should consult one of the references  on linear algebra cited at the end of this chapter 
for details. 
Let/  be any symmetric bilinear functional  on a real n-dimensional vector  space 
such that the matrix  of/  with  respect 
V. Then there exists  a basis {v^,...,v^}ofV 
to this basis is of the  form 
437 
CHAPTER  6: 
Stability 
1 
\n. 
(2.11) 
-1 
0 
The integers  r and p  in this matrix are uniquely determined by the bilinear  form. 
Sylvester's  Theorem  allows  the  following  classification  of  symmetric  bilinear 
functionals:  the integer r in (2.11) is called the rank of the symmetric bilinear  func 
tional/,  the  integer p  is  called  the  index  of/,  and  n  is  called  the  order  off.  The 
integer s  =  2p-r 
(i.e., the number of  + I's minus the number of  -1 's) is called the 
signature  of/. 
A  bilinear  functional /  on  a  vector  space  V  is  said  to  be positive  (or  positive 
semidefinite)  if  /(v, v)  >  0 for  all v E  V and  strictly  positive  (or positive  definite) 
if  /(v, v)  >  0  for  all  V  7^ 0, V  G  y  [note  that  /(v, v)  =  0  for  v  =  0]. It  is  readily 
verified  that  a  symmetric  bilinear  functional  is  strictly  positive  if  and  only  \i  p  = 
r  =  n in (2.11) and positive if and only if  p  =  r. 
Finally, we say that a bilinear functional/  is negative  (or negative  semidefinite) 
if  -/  is positive and strictly  negative  (or negative  definite)  if  -/  is strictly positive. 
Also, a bilinear functional/  is said to be indefinite  if in (2.11) r  >  /? >  0. 
B.  Euclidean  Vector  Spaces 
As in the preceding subsection, we assume throughout this subsection that Visa real 
vector space. 
A  bilinear  functional  /  defined  on  V  is  said  to  be  an  inner product  if  (i) /  is 
symmetric  and  (ii) /  is  strictly  positive.  A  real  vector  space  V  on  which  an  inner 
product is defined  is called a real inner product  space,  and a real  finite-dimensional 
vector space on which an inner product is defined  is called a Euclidean  space. 
Since we will always be concerned with a given bilinear functional  on V, we will 
write (v, w) in place of f(v,  w) to denote the inner product of v and w.  Accordingly, 
438 
the axioms of a real inner product are given as 
Linear Systems 
^  (v, v) >  0 for all v 7^ 0 and (v, v)  =  0 when v  =  0. 
2.  (v, w)  =  (w, v) for  all v, w e  V. 
3.  (av  +  ^w,  u)  =  a(v,  u)  +  ^{w,  u) for all u,v,w  ^V  and all a,  (3 ^  R. 
4.  (w, av  +  j8w)  =  a(M, v) +  J8(M, W) for all u,v,w  G  V and all a,  (3 G  R. 
In the following  we enumerate several results on Euclidean spaces, all of which 
are easily  proved: 
1.  The inner product (v, w)  =  0 for all v E  F  if and only if w  =  0. 
2.  Let ^  G L(V, V), Then (v, ^w)  =  0 for  all v^wGVif 
and only if ^  =  0. 
3.  Let ^,  gS G L(K  V). If (v, siw)  =  (v, ^w)  for  all v, w G  V, then ^  =  ^. 
"4.  Let A G /^""x^ If ^^AT;  =  0 for  all ^", r^ G  7?^ then A  =  0. 
We now define  the  function 
||v||  =  (v,v)^/2 
(2.12) 
for  all  V  G  y.  It  is  easily  verified  (using  definitions  and  the  properties  of  bilinear 
functionals)  that  this  function  satisfies  the  axioms  of  a  norm  (refer  to  Subsection 
I.IOB), i.e., for all v, w in  V and for  all scalars a,  the following  hold: 
L  ||v||  >  0 for all V  7^ 0 and ||v||  =  0 when v  =  0. 
2.  ||a:v||  =  |«|  • ||v||, where  \a\ denotes the absolute value of the scalar  a. 
3.  ||v +  w\\ < 
||v|| +  ||w||. 
In the usual proof of 3, use is made of the Schwarz  Inequality,  which states that 
\{y,w)\  <  IMI'IMI 
(2.13) 
for all V, w G  V, and 
|(v, w)|  =  ||v|| •  IHI 
if and only if v and w are linearly  dependent. 
Another  result  for  Euclidean  spaces  that is easily  proved  is the  parallelogram 
law, which asserts that for all v,w  G  V, the equality 
||v +  wf  +  ||v -  w|p  =  2||v|p  +  2|Hp. 
(2.14) 
Before  proceeding,  we recall that a vector  space  V on which  a norm is  defined 
is called a normed  linear space.  It is therefore clear that Euclidean vector spaces are 
normed  linear  spaces  with norm defined  by  (2.12)  (refer  to Subsection  l.lOB). We 
also recall that any norm can be used to define  a distance function,  called  a  metric, 
on a normed vector space by  letting 
d{u,v)  =  \\u-v\\ 
(2.15) 
for all w, V  G  V (refer to Subsection  l.lOB). Using thepropertiesofnorm,  it is readily 
verified  that for  all w, v, w G  V, it is true that 
1.  d(u,  v)  =  d(v,  u). 
2.  d{u, v) >  0 and d{u, v)  =  0 if and only if  w == v. 
3.  d{u, v) <  d{u, w) +  d{w, v). 
Without making use of inner products or norms, one can define  a distance func-  439 
CHAPTER 6: 
Stabihty 
tion having  the properties  enumerated  above  on  an  arbitrary  set.  Such  a set,  along 
with the distance function, is then called a metric space. It is thus clear that Euclidean 
vector spaces are metric  spaces as well. 
The concept of inner product enables us to introduce the notion of orthogonality: 
two vectors v,w  ^V  are said to be orthogonal  (to one another) if  (v, w)  = 0. This 
is usually written as v ± w. 
With  the  aid  of  the  above  concept  we  can  immediately  establish  the  famous 
Pythagorean  Theorem:  for v, w G  V, if v _L w, then ||v + w|p  =  ||v|p + ||w|p. 
A  vector  v E V is  said  to be a unit  vector  if ||v|| =  1. Let  w  T^ 0,  and  let u  = 
(l/||w||)w.  Then  the  norm  of  u is  ||w|| = (l/||w||)||w||  ^  1, i.e.,  w  is a unit  vector.  We 
call the process of generating  a unit vector from  an arbitrary  nonzero vector w nor 
malizing  the vector  w. 
Now  let  {w^,...,  w^} be  an  arbitrary  basis  for  V and  let F = [fij]  denote  the 
matrix of the inner product with respect to this basis, i.e., fij = (w^ w^) for all / and 
j.  More specifically,  F denotes the matrix of the bilinear functional/  that is used in 
determining  the inner product on  V with respect to the indicated basis. Let ^  and rj 
denote the coordinate representation of vectors x and y, respectively, with respect to 
{w^ . . .,"  w""""}. Then we have by (2.4)", 
(X,  y)  =  ^Fv  = V^F^  =  XXfiJ^J^i' 
(2.16) 
Now  by  Sylvester's  Theorem  [see  (2.11)  and  the  discussion  following  that  theo 
rem],  since the inner product is symmetric  and  strictly positive, there exists a basis 
{v^ .. .yV^} for  V such that the matrix of the inner product with respect to this basis 
is the nX n identity matrix /,  i.e., 
(v\vJ)  = Sij  = 
'  0, 
1 
1, 
.
if  /  7^ J, 
.
lii  =  J. 
.. 
(2.17) 
This  motivates  the  following  definition:  if {v\  . . .,"  v""} is a basis  for  V such  that "
(v^, v^)  = 0 for  all / T^ J, i.e., if  v^ J_ v^ for  all / T^ j, then {v^ ...,  v'^} is called  an 
orthogonal  basis.  If in addition,  (v^ v^  =  1, i.e., ||v^|| = 1 for all /, then {v^ . . .,"  v""} "
is said to be an orthonormal  basis for  V [thus, {v^ . . .,"  v""} is orthonormal if and only "
if{v\vJ)^8ijl 
Using  the properties  of inner product  and  the definitions  of orthogonal  and  or 
thonormal bases, we can easily establish  several useful  results: 
1.  Let {v^ ...,  v^} be an orthonormal basis for  V. Let x and y be arbitrary vectors in 
y,  and  let the  coordinate  representation  of x  and y with  respect  to this basis  be 
^^  = (^1, ...,^n)  and  7]^ = (171,..., 7]n), respectively.  Then 
(x,y) = ev  = V^^ =X^iVi 
(2.18) 
and 
ll^ll = (e^f^  =  7^f  + - - - +e 
(2.19) 
2.  Let {v^ . . .,  v^} be an orthonormal basis for  V and let x be an arbitrary vector. The 
coordinates of x with respect to {v^ . . .,"  v""} are given by the  formula "
^.  =  (x,v'), 
i = l...,n. 
(2.20) 
440 
Linear Systems 
3.  Let {v^ . . .,"  v""} be an orthogonal basis for  V. Then for  all x  E  V", we have 
/^  ^l\ 
/^  ^n\ 
( ^ v'  +  -  +  i ^ v «. 
.= 
(2.21) 
4.  {ParsevaVs identity)  Let {v^ ...,"  v""} be an orthogonal basis for  V. Then for  any "
x,y  ^V,  we have 
(„)  = X ^ ^. 
(2.22) 
5.  Suppose that x^,..., 
x^  are mutually orthogonal nonzero vectors in V, i.e., x^  ± 
;c^, /  ^  7. Then  x^  . . .,  x^ are linearly  independent. 
6.  A  set  of  k  nonzero  mutually  orthogonal  vectors  is  a basis  for  V  if  and  only  if 
k  =  dimV  =  n. 
7.  For  V there exist not more than n mutually  orthonormal  vectors  (called  a  com 
plete  orthonormal  set of  vectors). 
8.  {Gram-Schmidtprocess)  Let {w^,...,"  w""} be an arbitrary basis for  V. Set "
11 
^  ^  ^ 
1 
^ 
M 
n il 
(2.23) 
« -i 
V 
== 
i i— 
Then {v^ ...,  v^} is an orthonormal basis for  V. 
9.  If v^  ...,  v^, k  <  n, are mutually orthogonal nonzero vectors in  V, then we can 
"find  a  set  of  vectors  v^""*""^ . . .",  v^  such  that  the  set  {v\  . . .,"  v""} forms  a  basis "
forV. 
10.  {BesseVs inequality)  If {w^ ...,  w^} is an arbitrary  set of mutually  orthonormal 
vectors in  V, then 
k 
^ 
/ =  i 
|(w, wOP ^  IMP 
(2.24) 
for all w  E.V.  Moreover, the vector 
k 
u  =  w — ^_^(w, w^)w^ 
is orthogonal to each w\i  =  1,...,  k. 
11.  Let  ]¥ be a linear subspace of  V, and let 
W^  =  {v^V 
:(v,w)  =  0 for  all w  G  W}. 
(2.25) 
(i)  Let  {w^,...,  w^}  span  W.  Then  v  G  W-^  if  and  only  if  v  ±  w^  for  j  = 
l,...,yt. 
(ii)  W^  is a linear subspace of  V. 
(iii)  ^  =  dimV  =  dimT^  4- dimW^. 
(iv)  (W^)-^  =  W. 
(v)  V  =  WeW^. 
(vi)  Let  u,v  ^  V.  If  u  =  u^  -\-  u^  and  v  =  v^  +  v^,  where  u^, v^  G  W  and 
u^, v^  G  W^,  then 
{u,v)  =  (u\v^)  + (u^,v^) 
and 
||M||  =  V||wi|P  +  \\uY. 
(2.26) 
(2.27) 
441 
CHAPTER 6: 
Stability 
We conclude this subsection with the following  definition: let W be a linear sub-
space of V. The subspace W^  defined in (2.25) is called the orthogonal  complement 
ofW, 
C.  Linear  Transformations  on Euclidean  Vector  Spaces 
In this  subsection  we  consider  some of the properties  of three important  classes  of 
linear transformations  defined  on Euclidean  spaces: orthogonal transformations,  ad 
joint  transformations,  and  self-adjoint  transformations.  Unless  otherwise  explicitly 
stated,  V will denote an n-dimensional  Euclidean vector  space. 
Let  {v^...,"v""}  be  an  orthonormal  basis  for  V",  let  v^  =  ^1=\  PjiV^,i  = 
1,...,  /2, and  let  P  denote  the  matrix  determined  by  the  real  scalars  pij.  The  fol 
lowing question arises: when is the set {v^ . . .,"  v""} also an orthonormal basis for  VI "
To determine the desired properties of P, we consider 
(v^ vO  =  (X  Pki^'^ S  PuA  =  X  PkiPiM.  v^ 
(2.28) 
\k=i 
1 = 1 
J 
k,i 
So that {v\  v^)  =  0 for  /  T^ j  and (v^ v^)  =  1 for  i  =  j,  we require that 
n 
n 
{v\vJ)  =  X  PkiPijSki  =  ^PkiPkj 
=  Sij, 
(2.29) 
k,i =  i 
k=i 
i.e., we require that 
P^P  =  I, 
(2.30) 
where, as usual, /  denotes the n X n identity  matrix. 
The  above discussion  is summarized  in the following  result:  let {v^ ...,"  v""} be "
an orthonormal basis for  V and let v^  =  X}= i Pji^jy  i  =  \,.. 
.,n.  Then {v^ ...,"  v""} "
is an orthonormal basis for  V if and only if P^  =  P~^.  This result, in turn, gives rise 
to the concept of orthogonal matrix. Thus, a matrix  P  G R^^^  such that P^  =  P~^, 
i.e., such that P^P  =  P~^P  =  /,  is called an orthogonal  matrix. 
It is not difficult  to show that if P is an orthogonal matrix, then either det  P  =  \ 
or det  P  =  -I.  Also, if P  and  Qsire nX  n orthogonal matrices, then so is  PQ. 
The nomenclature used in the next definition  will become clear shortly. We say 
that a linear transformation  si  from  V into  V is an orthogonal  linear  transformation 
if (^v,  siw)  =  (v, w) for  all v,w  G  V. 
We now enumerate several properties of orthogonal transformations. The proofs 
of these statements are  straightforward. 
1.  Let  si  G L(V, V).  Then  ^  is orthogonal  if  and only if  \\siv\\ =  \\v\\  for  all v G  V. 
[Note that if si  is an orthogonal linear transformation, then v _L  w for all v, w G V 
if and only if siv  1  siw  since (v, w)  =  0 if and only if (^v,  siw)  =  0.] 
442 
Linear Systems 
2.  Every orthogonal linear transformation  of  V into  V is  nonsingular. 
3.  Let {v^ ...,"  v""} be an orthonormal basis for  V. Let ^  G L(V", V),  and let A be the 
matrix  of  ^  with  respect  to this basis. Then M^  is orthogonal  if  and  only  if A is 
orthogonal. 
4.  Let d  e  L(V, V). If si  is orthogonal, then det  d  =  ± 1. 
5.  Let si,^  E. L(V, V). If M and 2^ are orthogonal linear transformations,  then 64SS 
is also an orthogonal linear  transformation. 
The next result  enables  us to introduce  adjoint  linear transformations  in  a nat 
ural  manner.  Let ^  G L{V, V)  and  define  g  : V  X  V -^  Rby  g(v, w)  =  (v, ^w)  for 
all v,w  GV.  Then g is a bilinear functional  on V, Moreover, if {v^ . . .,  v'^} is an or 
thonormal basis for  V, then the matrix of g with respect to this basis, denoted by  G, 
is the matrix of ^  with respect to {v^ . . .,"  v""}. Conversely", given an arbitrary  bilinear 
functional  g  defined  on  V, there  exists  a unique  linear  transformation  ^  G L(V,  V) 
such that (v, ^w)  =  g(v, w) for  all v,w  E.  V, 
It should be noted that the correspondence between bilinear functionals  and lin 
ear  transformations  determined  by  the  relation  (v, ^w)  =  g(v, w)  for  all  v, w  G  V 
does not depend on the particular basis chosen for  V; however, it does depend on the 
way the inner product is chosen for  V at the outset. 
Now  let  ^  G  L(V, V),  set  g(v, w)  =  (v, ^w),  and  let  h(v, w)  =  g(w, v)  = 
(w, ^v)  =  (^v, w).  By  the  result  given  above,  there  exists  a  unique  linear  trans 
formation, denote it by ^*, such that h(v, w)  =  (v, Ww)  for all v,w  G  V. We call the 
hnear transformation  ^*  G L(V, V) the adjoint  of^.  We have the following  results: 
1.  For  each  ^  G  L(V, V),  there  is  a  unique  «*  G  L(V, V)  such  that  (v,^*w)  = 
(^v, w) for  all V, w G  y. 
2.  Let {v\  . . .,  v^} be an orthonormal basis for V, and let G be the matrix of the Hnear 
transformation  ^  G L(V, V) with respect to this basis. Let G* be the matrix of ^* 
with respect to {v^ . . .,"  v""}. Then G*  =  G^. "
The above results allow the following  equivalent definition  of the adjoint  linear 
transformation:  let  ^  G  L(V, V).  The  adjoint  transformation,  ^*,  is  defined  by  the 
formula 
(v,^*w)  =  (^v,w) 
(2.31) 
for  all v,w  EV. 
In the following, we enumerate some of the elementary properties of the  adjoint 
of linear transformations.  The proofs  of these assertions  follow  readily  from  defini 
tions. 
Let ^,  gS G L(V, V),  let d*,  9^* denote their respective  adjoints,  and let a  be a 
real scalar. Then 
1.  (^y  = M. 
2.  (^  + my  -  64* +  m\ 
3.  (asiT  =  aM\ 
4.  (^SS)*  =  a*^*. 
5.  ^*  =  S>, where ^  denotes the identity  transformation. 
6.  ©*  =  0, where 0  denotes the null  transformation. 
7.  ^  is nonsingular if and only if ^4* is nonsingular. 
8.  If^  is nonsingular, then (6^*)-^  = 
(si-^. 
The following  results (the proofs  of which are straightforward)  characterize or- 
thogonal transformations  in terms of their adjoints.  Let si  E  L(V, V).  Then si  is or- 
thogonal if and only if 6^*  =  si~^.  Furthermore, si  is orthogonal if and only if si~^ 
is orthogonal, and si~^  is orthogonal if and only if si* is orthogonal. 
Using adjoints, we now introduce two additional important types of linear trans 
formations.  Let si  E  L(V, V).  Then si  is said to be self-adjoint  if si*  =  si,  and it is 
said to be skew-adjoint  if si*  =  -^.  Some of the properties of such  transformations 
are as  follows. 
1.  Let si  E  L(V, V),  let {v^ . . .,  v'^} be an orthonormal basis for  V, and let A  be the 
matrix of si  with respect to this basis. The following  are  equivalent: 
443 
CHAPTER 6: 
Stability 
(i)  si  is  self-adjoint, 
(ii)  ^  is symmetric, 
(iii)  (^v,  w)  =  (v, siw)  for all v,w  E. V. 
2.  Let si  E  L(V, V), let {v\  . . .,  v'^} be an orthonormal basis for  V, and let A  be the 
matrix of si  with respect to this basis. The following  are equivalent: 
(i)  ^  is  skew-adjoint, 
(ii)  si  is  skew-symmetric, 
(iii)  (^v,  w)  =  -(v, siw)  for  all v, w E  V. 
The next result follows  from  part  (iii) of the above result. Let ^  E  L(V, V), let 
{v^ . . .,  v'^} be an orthonormal basis for  V, and let A be the matrix of si  with respect 
to this basis. The following  are equivalent: 
(i)  si  is  skew-symmetric, 
(ii)  (v, siv)  =  0 for all v E  V. 
(iii)  ^v  1  V for all v E  V. 
The  following  result  enables  one  to  represent  arbitrary  linear  transformations 
as the sum of self-adjoint  and skew-adjoint  transformations.  Let si  E  L(V, V).  Then 
there  exist  unique  ^di, ^2  ^  L(V,V)  such  that  ^  =  sii  + ^2,  where  ^i 
is  self-
adjoint  and si2 is skew-adjoint.  This has the direct consequence that every real  nXn 
matrix can be written in one and only one way as the sum of a symmetric and skew-
symmetric  matrix. 
The next result is applicable to real as well as complex vector spaces. (We will 
state it for complex  spaces.) 
Let y  be a complex vector space. Then the eigenvalues of a real symmetric ma 
trix A are all real. If all eigenvalues of A are positive (negative), then A is called po^-
itive (negative)  definite. If all eigenvalues of A are nonnegative (nonpositive), then A 
is cailod positive  (negative)  semidefinite.  If A has positive and negative eigenvalues, 
then A is said to be  indefinite. 
Next, let A be the matrix of a linear transformation  d^  E  L(V,V)  with respect to 
some basis. If A is symmetric, then as indicated above, all its eigenvalues are real. In 
this case d- is self-adjoint  and all its eigenvalues are also real; in fact, the eigenvalues 
of si  and A are identical. Thus, there exist unique real scalars Ki,..., 
\p,  p  ^  n, such 
that 
"det  (si  -  X3)  =  det  (A  -  XI)  =  (Ai  -  A)^i(A2 ""  A)'^^... (A;", -  A)'^^ 
(2.32) 
We summarize the above observations  in the following.  Let si  E  L(V, V).  If  si 
is self-adjoint,  then si  has at least one eigenvalue. Furthermore, all eigenvalues of  si 
444 
Linear Systems 
are real and there exist unique real numbers  Ai,..., A^, /? <  n, such that Eq.  (2.32) 
holds. 
As  in  Eq.  (3.17)  of  Chapter  2,  we  say  that  in  (2.32)  the  eigenvalues  A/, /  = 
1,...,  p  <  n, have algebraic  multiplicities  mi, i  =  1,..., /?, respectively. 
Next, we examine some of the properties of the eigenvalues and eigenvectors of 
self-adjoint  linear transformations. The proofs of these assertions are  straightforward 
and follow  mostly from  definitions. 
Let si  G L(V, V) be a self-adjoint  transformation,  and let Xi,...,  Xp, p  ^  n, de 
note the distinct eigenvalues of ^4. If v^ is an eigenvector for A/ and if v^ is an eigen 
vector for  \j,  then v'  J_ v^ for  all i  y^  j. 
Now  let ^  G L(V, V)  and  let  A/ be  an eigenvalue  of ^.  Recall  that Xi  denotes 
the null space  of the linear transformation  d- -  A/^, i.e.. 
Xi  =  {vGV 
:(d-  A/J^)v  = 0}. 
(2.33) 
Recall  also  that Mi is  a linear  subspace  of  V. From  the last result  given  above,  the 
following  result follows  immediately. 
Let d  G L(V, V) be a self-adjoint  transformation  and let A/ and A^ be eigenval 
ues of 5i. If A/ 7^ Ay, then Mi 1  Mj. 
The proof of the next result is somewhat lengthy and involved. The reader should 
consult the references  on linear algebra cited at the end of this chapter for details. 
Let si  G L(V, V) be a self-adjoint  transformation,  and let Ai,..., A^, p  <  n, de 
note the distinct eigenvalues  of si.  Then 
dim V  =  n  =  dim^Ti  +  dim>r2  +  ...  +  dim^Tp. 
(2.34) 
The next two results are direct consequences  of the above result. 
1.  Let ^  G L(V, V).  If d  is self-adjoint,  then 
(i)  there exists an orthonormal basis in V such that the matrix of si  with respect 
to this basis is diagonal; 
(ii)  for each eigenvalue  A/ of si  we have dim>f/  =  algebraic multiplicity  of A/. 
We note that in the above theorem,  the matrix A  of the linear  transfor 
mation si  with respect to the chosen orthonormal basis in V is given by 
A  = 
A2 
A2 
(2.35) 
2.  Let A be a real  nX  n symmetric  matrix. Then  there exists  an orthogonal  matrix 
P such that the matrix A  defined  by 
A  -  P-^AP  =  P^AP 
(2.36) 
445 
CHAPTER 6: 
Stability 
is  diagonal. 
For symmetric bilinear functionals  defined on Euclidean vector spaces, we have 
the following result. Let f(v,  w) be a symmetric bilinear functional  on V. Then there 
exists an orthonormal basis for  V such that the matrix of/  with respect to this basis 
is diagonal. 
For quadratic forms, the following  useful  result is easily  proved. 
Let  f(x)  be  a quadratic  form  defined  on  V.  Then  there  exists  an  orthonormal 
basis  for  V  such that if ^^  =  (^i,..., ^„) is the coordinate representation  of x  with 
h a„^^ for some real scalars o^i,...,  a„. 
respect to this basis, then f(x)  =  ai^f-\ 
The final result of this section, which we state next, is called the Spectral  Theo 
rem for  self-adjoint  linear transformations.  For the proof of this result, the interested 
reader  should consult one of the references  on linear algebra cited at the end of this 
chapter. Before  stating this theorem,  we recall that a transformation  2P G L(y, V)  is 
a projection  on  a linear  subspace  of  V if  and  only  if  2^^  =  2?*  (refer  to  Subsection 
2.2K). Also, for  any projection  SP, T  =  91(2^) 0  >r(S?>), where 2/l(2P) is the range of 
2^ and M{^)  is the null space of 2^ (refer  to Subsection  2.2K). Furthermore, we call 
2^ an orthogonal  projection  if 2/1(9^) 1  >r(2^). 
The Spectral  Theorem for  self-adjoint  linear  transformations:  let ^  E  L{V, V) 
be a self-adjoint  transformation,  let Ai,..., A^ denote the distinct eigenvalues of  si, 
and  let  Mi be  the  null  space  oi  d^ -  Xi3.  For  each  /  =  1,...,  p,  let  ^t  denote  the 
"projection  on Xi  along JV""-^. Then "
1.  ^i  is an orthogonal projection  for each  /  =  1,..., /?. 
2.  ?Pi?Pj  =  0  for  /  7^ J,  i,j  =  1,...,  p, 
"3.  Xy^^i Sy"" =  3","  where 3""  ^  L(V",V)  denotes the identity  transformation. 
4.  ^  =  S ; . i A # ;. 
PARTI 
LYAPUNOV STABILITY 
6.3 
THE  CONCEPT  OF AN  EQUILIBRIUM 
In this section we concern ourselves with systems of first-order ordinary  differential 
"equations  (£"")", i.e., 
X =  fit,  x\ 
(E) 
where x  G R^. When discussing global results, we shall assume that f  : R^  XR^  ^ 
R^,  while when considering local results, we may assume that f  : R^  X B(h)  ->  R^ 
for some h>  O.On  some occasions, we may assume that t  G R, rather than t  ^  R^. 
Unless otherwise stated, we shall assume that for every (to, XQ), to G R'^, the initial-
value problem 
X =  fit,  x), 
xito)  =  xo 
il) 
446 
Linear Systems 
possesses  a  unique  solution  (pit, to, XQ) that  exists  for  all  t  >  t^  and  that  depends 
continuously on the initial data (^o. -^o)- Refer to Chapter  1  for conditions that ensure 
that (/)  has these properties. 
DEFINITION 3.1.  A point Xe  E R^ is called an equilibrium point of (E), or simply an 
equilibrium of (E) (at time f G R^), if 
fit,  Xe)  = 0 
for all t>  t. 
m 
"We note that if  Xe is an equilibrium  of (£"") at f",  then it is also an equilibrium  at 
all T ^  f. We also note that in the case of autonomous  systems 
and in the case of T-periodic  systems 
X =  fix), 
X =  fit,  X), 
fit,  X)  =  fit  +  T, X), 
(A) 
iP) 
a point  Xe E  R^  is an equilibrium  at some time  f if  and  only if it is  an  equilibrium 
at all times.  [Refer  to Chapter  1 for  the definitions  of  symbols  in  (A) and  (P).]  We 
"further  note that if Xe is an equilibrium at f of (£"")", then the transformation  s  =  t -  t 
yields 
dx 
r. 
~  ^ 
"and  Xe is  an  equilibrium  at 5"" =  0 of this  system.  Accordingly",  we  will  henceforth 
assume that  f  =  0 in Definition  3.1  and we will not mention  f again.  Furthermore, 
we note that for  any to >  0, 
(f)it, to, Xe)  =  Xe 
for all t  >  to, 
i.e.,  the  equilibrium  Xe  is  a  unique  solution  of  iE)  with  initial  data  given  by 
(/)(^,  to,  Xe)  =  Xe. 
We will call an equilibrium point Xe of iE)  an isolated  equilibrium  point  if there 
is an r  >  0 such that Bixe,  r)  C  R^ contains no equilibrium point of iE)  other than Xe 
itself. [Recall that Bixe,  r)  =  {x  E. R^  : \\x -  Xe\\  <  r}, where || • || denotes some norm 
defined on R^.] Unless stated otherwise, we will assume throughout this chapter that 
a  given  equilibrium  point is  an isolated  equilibrium.  Also, we will usually  assume 
that in a given discussion, unless otherwise  stated, the equilibrium  of interest is lo 
cated at the origin of R^. This assumption can be made without loss of generality by 
noting that if  Xg T^ 0 is an equilibrium  point of  (£*), i.e.,  fit,  Xe)  =  0 for  all t  ^  0, 
then by letting w  =  x  -  Xe,we  obtain the transformed  system 
with Fit,  0)  =  0 for  all t  >  0, where 
w  =  Fit,w) 
Fit,  w)  =  fit,  w  +  Xe). 
(3.1) 
(3.2) 
Since  (3.2)  establishes  a  one-to-one  correspondence  between  the  solutions  of  iE) 
and  (3.1), we may  assume  henceforth  that the equilibrium  of interest  for  iE)  is lo 
cated at the origin. This equilibrium, x  =  0, will be referred to as the trivial  solution 
of  iE). 
Before  concluding  this section, it may be fruitful  to consider  some specific  cases. 
447 
EXAMPLES.1.  In Example 4.4 in Chapter  1 we considered the simple pendulum given 
in Fig.  1.7. Letting xi  =  x  and X2 =  i  in Eq. (4.12) of Chapter  1, we obtain the  system 
of equations 
CHAPTER  6: 
Stability 
Xi  =  X2 
X2 =  -/csinxi, 
(3.3) 
where ^  >  0 is a constant. Physically,  the pendulum has two isolated equilibrium points: 
one where the mass M  is located vertically  at the bottom of the figure (i.e., at 6  o'clock) 
and  the  other  where  the  mass  is  located  vertically  at  the  top  of  the  figure  (i.e.,  at  12 
o'clock).  The  model  of  this  pendulum,  however,  described  by  Eq.  (3.3),  has  count-
ably  infinitely  many  isolated  equilibrium  points  which  are  located  in  R^  at  the  points 
(7Tn,0f,n  =  0, ±1, ± 2 , . . .. 
• 
EXAMPLE  3.2.  The linear homogeneous  system of ordinary  differential  equations 
X =  A(t)x 
(LH) 
has a unique equilibrium that is at the origin if A(to) is nonsingular for all to ^  0.  [Refer 
to Chapter  1 for the definitions  of symbols in (LH).] 
m 
EXAMPLE  3.3.  The  linear,  autonomous,  homogenous  system  of  ordinary  differential 
equations 
X =  Ax 
(L) 
has a unique equilibrium that is at the origin if and only if A is nonsingular. Otherwise, (L) 
has nondenumerably  many equilibria.  [Refer to Chapter  1 for the definitions  of symbols 
in (L).] 
• 
EXAMPLE  3.4.  Assume that for the autonomous  system of ordinary  differential  equa 
tions, 
X =  fix), 
{A) 
f  is continuously  differentiable  with respect to all of its arguments, and let 
where dfldx  denotes the n X « Jacobian  matrix  defined  by 
J{Xe) 
(X) 
dx 
dx 
dXj 
If  f{Xe)  =  0 and J(Xe)  is nonsingular, then Xe  is an isolated equilibrium of (A). 
EXAMPLE  3.5.  The system of ordinary  differential  equations given by 
xi  =  k  + sin(xi  +  X2) +  xi 
X2 =  k  + sin(xi  +  X2) — xi, 
with  k>  I,  has no equilibrium points at all. 
6.4 
Q U A L I T A T I VE  C H A R A C T E R I Z A T I O NS  OF  AN  E Q U I L I B R I UM 
In this section we consider several qualitative characterizations that are of  fundamen 
tal importance in systems theory. These characterizations  are concerned  with  various 
448 
Linear Systems 
types of stability properties of an equilibrium  and are referred  to in the literature as 
Lyapunov  stability. 
Throughout this section," we consider systems of equations (£"")", 
X =  f(t,  x), 
(E) 
and we assume that (E) possesses an isolated equilibrium at the origin. We thus have 
fit,  0)  =  0 for  all t  >  0. 
DEFINITION 4.1.  The equilibrium ;c =  0 of (E) is said to be stable if for every e > 0 
and any ^o ^  R^  there exists a 8(6, to)  > 0 such that 
||(/)(^, ^0, -^0)11  <  ^ 
for all t > to 
whenever 
Ikoll <  5(6, to). 
(4.1) 
(4.2) 
In Definition  4.1, || • || denotes  any  one  of the equivalent  norms  on  R^,  and  (as 
in Chapters  1 and 2) (/)(^, to, XQ) denotes the solution of (E)  with initial condition  XQ 
at initial  time  to. The  notation  8(e,  to) indicates  that  8  depends  on the  choice  of to 
and  e.  If  in particular  it is true that  8  is independent  of  ^o, i-^-,  S  =  8(e),  then  the 
equilibrium  x  =  0 of (E)  is said to be uniformly  stable. 
In words, Definition 4.1 states that by choosing the initial points in a  sufficiently 
small  spherical neighborhood,  when the equilibrium  x  =  0 of (E)  is stable, we can 
force the graph of the solution for t  ^  toto  lie entirely inside a given cylinder. This 
is depicted in Fig. 6.1 for the case x  G  R^. 
We note that if the equilibrium x  =  0 of (E)  satisfies condition (4.1) for a single 
initial condition  ^o when (4.2) is true, then it will also satisfy  this condition at every 
initial  time  t^  >  to, where  a different  value  of  8  may  be  required.  To  see this,  we 
note that  the  solution  (l)(t, to, xo)  determines  a mapping  g  of  B(8(€, to)) (at  t  =  to) 
onto  g(B{8(€, to)))  (at  t  ^  t'  >  to) that  contains  the  origin  by  assigning  for  every 
Xo E  B{8{e,  to))  one  and  only  one  xo = (p(t\  to, xo)  E  g(B(8(€,  to)).  By  reversing 
time, cj) determines a mapping of g(B(8(6,  to)) onto B(8(e,  to)), which is the inverse 
of ^, denoted by ^~^  Since cf) is continuous  with respect to t, to, and  xo, then g and 
g~^  are  also  continuous.  Since  5(S(6, ^o)) is  a neighborhood  (an  open  set), then  so 
is g(B(8(e,  to)) (refer,  e.g., to  [16], pp. 320-321). This neighborhood  contains in its 
interior  a spherical  neighborhood  centered  at the origin  and with  a radius  §'.  If  we 
choose  X'Q  E  B(8'), 
then (4.1) implies that \\(t)(t, t',  X'Q)\\  <  e for all t  >  t^. This argu-
"• V"" "
\ ^ 
.• 
FIGURE 6.1 
Stability of an equilibrium 
ment  shows that in Definition  4.1 we  could have chosen  without  loss of generality 
the single value to  =  0 in (4.1) and (4.2). 
DEFINITION 4.2.  The equilibrium x  =  0 of (E) is said to be asymptotically stable if 
(i)  it is stable, 
(ii)  for every ^  ^  0 there exists an i7(^) >  0 such that lim?_oo (l>(t, to, xo)  =  0 when 
449 
CHAPTER 6: 
Stability 
ever ||xo|| < rj. 
m 
"The  set  of  all  XQ  G  J^"" such  that  (pit", to, XQ) ^  0  as  ^ ->  oo for  some  ^o —  0  is 
called  the domain  of attraction  of the equilibrium  x  =  0 of (E)  (at to). Also, if  for 
(E)  condition  (ii) is true, then the equilibrium  x  =  0 is said to be attractive  (at to). 
DEFINITION4.3.  The equilibrium x  =  0 of (E) is said to be uniformly asymptotically 
stable if 
(i)  it is uniformly stable, 
(ii)  there is a 5o >  0 such that for every e >  0 and for any to  G R'^, there exists a r(e)  > 
0, independent of to, such that \\(t)(t, to, xo)\\  < e for all ? >  ^ + T{e) whenever ||xo|| < 
5o. 
• 
Condition  (ii) in Definition  4.3 can be paraphrased by saying that there exists a 
So >  0 such that 
lim (j){t +  to, to, xo)  =  0 
uniformly  in (^o, xo) for ^  ^  0 and for ||xoi| <  SQ. In words, this condition states that 
by  choosing  the  initial  points  xo  in  a  sufficiently  small  spherical  neighborhood  at 
t  =  to, WQ  can  force  the  graph  of the  solution  to lie inside  a given  cylinder  for  all 
t  >  to -^ Tie).  This is depicted in Fig. 6.2 for the case x  E  R^. 
In  linear  systems  theory,  we  are  especially  interested  in  the  following  special 
case of uniform  asymptotic  stability. 
^0 +  m) 
FIGURE 6.2 
Attractivity of an equilibrium 
DEFINITION 4.4.  The equilibrium x  =  0 of (E) is exponentially stable if there exists 
an a  >  0, and for every e >  0, there exists a 6(e) >  0, such that 
U(t, to," xo)\\  <  e^-""^'-^o) "
for all t > ^o 
whenever \\xo\\  < 6(e) and ^  >  0. 
• 
Figure  6.3  shows the behavior  of  a solution  in the vicinity  of  an  exponentially 
stable equilibrium  x  =  0. 
450 
Linear Systems 
U(o 
K^ 
^ 
^ee-«(f-^o) 
/ 
^ 
/ 
^  # 
• o .^ 
r 
1 
1 
1 
y 
"L'^""' "
•< 
^  V 
\ 
\ 
\ 
-^ 
^ 
"~""~""""~~---"
"^''""' "
\_ee-a(f-g 
FIGURE 6.3 
An exponentially stable equilibrium 
DEFINITION 4.5.  The equilibrium ;t  =  0 of {E) is unstable if it is not stable. In this 
case, there exists  a ^  >  0, an e  >  0, and a sequence  X;„ ^  0 of initial points and a 
sequence {r^} such that ||(/)(^o + ^m, ^o. -^m)!!  —  ^ for all m, ^^ —  0. 
• 
"If  X =  0 is an unstable  equilibrium  of  (£"")", then  it  still can happen  that  all  the 
solutions tend to zero with increasing t. This indicates that instability and attractivity 
of an equilibrium are compatible concepts. We note that the equilibrium x  =  0 of {E) 
is necessarily unstable if every neighborhood of the origin contains initial conditions 
corresponding  to unbounded  solutions  (i.e., solutions  whose norm grows to  infinity 
on  a  sequence  tm-^  °°)- However,  it  can  happen  that  a  system  (E)  with  unstable 
equilibrium  x  =  0 may have only bounded  solutions. 
The concepts that we have considered  thus far  pertain  to local properties  of  an 
equilibrium. In the following, we consider global characterizations of an equilibrium. 
DEFINITION 4.6.  The equilibrium x  =  0 of {E) is asymptotically stable in the large 
if it is stable and if every solution of {E) tends to zero as r ->  oo. 
• 
When  the  equilibrium  x  =  0  of  (E)  is  asymptotically  stable  in  the  large,  its 
domain of attraction is all of R^. Note that in this case, x  =  0 is the only  equilibrium 
of(£). 
DEFINITION 4.7.  The equilibrium x  =  0 of iE) is uniformly asymptotically stable in 
the large if 
(i)  it is uniformly stable, 
(ii)  for any a  >  0 and any 6 >  0, and to G R'^, there exists T(e, a)  >  0, independent 
of to, such that if ||xo|| <  a,  then \\(f)(t, to, xo)|| <  e for all t ^  to  + T{e, a). 
• 
DEFINITION 4.8.  The equilibrium x  =  0 of {E) is exponentially stable in the large if 
there exists a  >  0 and for any /3 >  0, there exists ^(j8) >  0 such that 
for all t > to 
U{t, to, xo)|| <  k(P)\\xo\\e-''^'-''^ 
whenever II xo 11  < (3. 
We conclude this section with a few  specific  cases. 
The scalar differential  equation 
• 
X  =  0 
(4.3) 
has for any initial condition x(0)  =  XQ the solution <p(t, 0, XQ)  =  XQ, i.e., all solutions 
are  equilibria  of  (4.3). The  trivial  solution  is  stable;  in  fact  it  is  uniformly  stable. 
However, it is not asymptotically  stable. 
451 
CHAPTER 6: 
Stability 
The scalar differential  equation 
X =  ax 
(4.4) 
has for every x(0)  == XQ the solution (/)(r, 0, XQ)  =  xoe^^andx  =  0 is the only equi 
librium of (4.4). If (3  >  0, this equilibrium is unstable, and when a  <  0, this equilib 
rium is exponentially  stable in the large. 
The scalar differential  equation 
i = {j=^} 
(4.5) 
has for every  x(to)  =  XQ,  ^O ^  0, a unique solution of the  form 
0(r, to, xo)  -  (1 +  ^o)^o I ^-^Tj j 
(4.6) 
and X =  0 is the only equilibrium of (4.5). This equilibrium is uniformly  stable and 
asymptotically  stable in the large, but it is not uniformly  asymptotically  stable. 
As mentioned  earlier, a system 
X =  fit,  X) 
(E) 
can have all solutions approaching  an equilibrium,  say, x  =  0, without this equilib 
rium being  asymptotically  stable. An  example  of this type of behavior  is given  by 
the nonlinear  system of equations 
Xi 
^2  = 
x\{X2  —  Xi)  +  x\ 
{x\ -h  xl)[\  + {x\ + X^)2] 
x]{x2  -  2xi) 
{x\  + xl)[\+{x\  + xl)^] 
For  a detailed  discussion  of  this  system,  refer  to Hahn  [7], cited  at the  end  of  this 
chapter. 
Before proceeding any further,  a few comments are in order concerning the rea 
sons for considering equilibria and their stability properties as well as other types of 
stability that we will encounter. To this end we consider linear time-varying  systems 
described by the  equations 
X -  A{t)x  +  B{t)u 
y  =  C(t)x  +  D(t)u 
and linear time-invariant  systems given by 
X =  Ax  + Bu 
y  =  Cx  + Du, 
(4.7a) 
(4.7b) 
(4.8a) 
(4.8b) 
where  all symbols in (4.7)  and  (4.8) are defined  as in Eqs. (6.1) and  (6.8) of Chap 
ter 2, respectively. The usual qualitative analysis of such systems involves two con 
cepts, internal  stability  and input-output  stability. 
452 
Linear Systems 
In the case  of  internal  stability,  the output  equations  (4.7b)  and  (4.8b) play  no 
^^^^ whatsoever,  the system input u is assumed to be identically  zero, and the  focus 
of the analysis  is concerned  with  the qualitative behavior  of the  solutions  of  linear 
time-varying  systems 
or linear time-invariant  systems 
X -  A{t)x 
X =  Ax 
(LH) 
(L) 
near the equilibrium x  =  0. This is accomplished by making use of the various types 
of  Lyapunov  stability  concepts  introduced  in  this  section.  In  other  words,  internal 
stability of systems (4.7) and (4.8) concerns the Lyapunov stability of the equilibrium 
X =  0 of systems  (LH)  and  (L), respectively. 
In the case of input-output  stability,  we view  systems  as operators  determined 
by  (4.7)  or  (4.8)  that  relate  outputs  y  to  inputs  u  and  the  focus  of  the  analysis  is 
concerned with qualitative relations between  system inputs and system outputs. We 
will address this type of stability in Section 9 of this  chapter. 
6.5 
LYAPUNOV  STABILITY  OF LINEAR  SYSTEMS 
In  this  section  we  first  study  the  stability  properties  of  the  equilibrium  x  =  0  of 
linear autonomous homogeneous  systems 
and linear homogeneous  systems 
X =  Ax, 
t^  0, 
X =  A{t)x, 
t> 
tQ>0, 
(L) 
{LH) 
where A{t)  is assumed to be continuous. Recall that x  =  0 is always an equilibrium 
of (L) and {LH)  and that x  =  0 is the only equilibrium of {LH)  if A{t) is nonsingular 
for  all t>Q.  Recall also that the solution of {LH)  for  x(^)  =  XQ is of the  form 
^{t,  to, xo)  -  ^{t,  to)xo, 
t  >  to, 
where  O  denotes  the  state  transition  matrix  of A{t)  and  that  the  solution  of  (L)  for 
x{to)  =  Xo is given by 
(l){t,  to,  Xo)  =  ^{t, 
to)Xo  =  ^{t 
- 
to,  0)X0 
^  0(r  -  to)xo  =  e^^'-'^^xo, 
where in the preceding equation, a slight abuse of notation has been  used. 
We first consider some of the basic properties of system  {LH). 
THEOREMS.1.  The equilibrium jc =  0 of {LH) is stable if and only if the solutions of 
{LH) are bounded, i.e., if and only if 
sup||0(r,^)||^  k{to)<^, 
where ||0(r," ro)|| denotes the matrix norm induced by the vector norm used on /?""",  and 
k{tQ) denotes a constant that may depend on the choice of to. 
Proof,  Assume  that the equiUbrium  x  =  0 of  {LH)  is  stable. Then  for  any  ^o — 0  and 
for e  =  1 there is a 5  =  5(1, ^)  >  0 such that ||(^(r, t^, XQ% <  1 for all t  >  t^ and all  XQ 
with  ||xo|| ^  6. In this case 
453 
CHAPTER  6 
Stability 
U{t,  to, xo)\\  =  \\^(h  to)xo\\ = 
Ikoll 
< 
c^(t, to){xo8) 
Ikoll 
w 
8 
for  all  ;co ^  0  and  all  t  ^  to. Using  the  definition  of  matrix  norm  [refer  to  (10.17)  in 
Chapter  1] it follows  that 
\\^(tJo)\\^S-\ 
t^to. 
We have  proved  that  if  the  equilibrium  x  =  0 of  {LH)  is  stable,  then  the  solutions  of 
{LH)  are bounded. 
Conversely,  suppose  that  all  solutions  (^{t, to, xo)  =  0(r, ^o)-^o  are  bounded.  Let 
{ei,...,  en} denote the natural basis for ^-space  and let ||(/)(^, to, ej)\\ <  (Sj for  all t  >  ^o-
Then for  any vector xo  =  X'/=i  <^7^; we have that 
U{t.  to, xo)\\ =  y^ 
aj(f){t,to,ej) 
7 = 1 
<  (max jS;)X 1^7-1 
^ 
; = i 
7 = 1 
k\\xo\\ 
for some constant  ^  >  0 for ^ >  ^o- For given e  >  0, we choose 8  =  elk.  Thus, if ||xo||  < 
6,  then  ||(^(^, to, xo)|| <  ^||^o||  <  ^  for  all t  >  to- We have proved  that  if the  solutions of 
{LH)  are bounded, then the equilibrium  x  =  0 of {LH)  is stable. 
• 
THEOREM  5.2.  The equilibrium  x  =  0 of {LH)  is uniformly  stable  if and only if 
sup ^(^o)  =  sup(sup||0(r, 
ko <oo. 
The  proof  of  this  theorem  is  very  similar  to the proof  of Theorem  5.1  and  is  left 
as  an  exercise. 
EXAMPLES.1.  We consider the system given by 
with  x{0)  =  Xo. We transform  (5.1) by means of the relation  x  =  Py,  where 
0 
e~' 
P  = 
1  1 
0  1 
pi  = 
and obtain the equivalent  system 
Ji 
LJ2j 
0 
(5.1) 
(5.2) 
with y{0)  =  yo  =  P~^xo.  System  (5.2) has the solution  (//(r, 0," jo)  =  ""^{t", 0)}^o, where 
^(r,  0) 
^1/2(1-^-^0 
0 
0 
g(l-.-0 
Thesolutionfor(5.1)isobtainedas(/>(r,0,  Xo)  =  0(r, 0)xo, where ^(r, 0)  = 
From this we obtain for ^o ^  0, 4){t, to, xo)  =  ^{t,  to)xo, where 
P'^{t,0)P~\ 
454 
Linear  Systems 
Now 
^(t,  to) 
0 
Je~'0-e-^) 
"^l/2e""2^0 "
^e~^0  __  ^l/le'^^O 
lim^itJo)  = 
0 
(5.3) 
y Xlj=i\ct>ij(tJo)\^  <  Xlj=i\cl>ij(^>to)\l  that  sup,^^^(sup,^J^(tJo)\\) 
We  conclude  that  limy^^oolimr^oo||4)(^, ^o)||  <  oo,  and  therefore  (since  ||(|>(r, ro)||  ^ 
<  ^.  There 
fore,  the  equihbrium  x  =  0  of  system  (5.1)  is  stable  by  Theorem  5.1  and  uniformly 
stable  by Theorem 5.2. 
• 
THEOREM  5.3.  The following  statements  are  equivalent. 
(i)  The equilibrium  x  =  0 of (LH)  is asymptotically  stable, 
(ii)  The equilibrium  x  =  0 of (LH)  is asymptotically  stable in the large, 
(iii)  lim,_oo||c|>(r,ro)||  =  0. 
Proof,  Assume  that  statement  (i)  is  true.  Then  there  is  an  17(^0) >  0  such  that  when 
||xo|| ^  vOo)^ then (^(^, to, xo) ->  0 as ? ->  00. But then we have for any  xo ^  0 that 
(f){t,tQ,Xo) =  Mt,tQ,y]{tQ)  • ^0 
Ikoli 
0 
as r —>  CO. It follows  that statement  (ii) is true. 
Next, assume that statement (ii) is true and fix ^0 ^  0. For any 6 >  0 there must exist 
a Tie)  >  0 such that for all t  ^  to + T(e)  we have that \\(l)(t, to, xo)\\  =  \\^(t, to)xo\\  <  e. 
To  see  this,  let  {e^  . . .,  ^„} be  the  natural  basis  for  R^.  Thus,  for  some  fixed  constant 
^  >  0, if  xo  =  ( a i , . . ., a«)^  and if  ||xo|| ^  1," then  xo  =  2 "" =i  (^jej  and  2y==i  \o^j\  — "
k.  For  each J  there  is  a  Tj{e)  such  that  \\<^{t, to)ej\\ <  elk  and  ^ >  ^0 +  Tj{e).  Define 
T{e)  =  max {Tj{e)  : j  =  I,..  .,n}.  For ||xo|| ^  1 and t  ^  to + T(e),  we have that 
ll^(^,^)^o|| 
^aj<^(tJo)ej 
"7 = 1  1'""^-"
By  the  definition  of  the  matrix  norm  [see  (10.17)  of  Chapter  1],  this  means  that 
||0(r, ^)|| <  6 for f >  ^0 +  T(e).  Therefore,  statement  (iii) is true. 
Finally,  assume  that  statement  (iii)  is  true.  Then  \\^(t, to)\\ is  bounded  in  t  for  all 
t  >  to. By  Theorem 5.1, the equihbrium  x  =  0 is stable. To prove asymptotic  stability, 
fix  ro >  0  and  e  >  0.  If  ||xo|| <  r](to)  =  1, then  Uit,  to, xo)|| <  ||^(^, ^)|| ||xo|| ^  0  as 
t -^  CO, Therefore,  statement  (i) is true. This completes the proof. 
• 
EXAMPLE  5.2.  The equilibrium  x  =  0 of system (5.1) given in Example 5.1 is  stable 
but it is not asymptotically  stable since lim^^oo ||^(^, ^)|| 7^ 0 [see Eq.  (5.3)]. 
• 
EXAMPLE5.3.  The solution of the  system 
-e^'x, 
x(to)  =  Xo 
(5.4) 
is (/)(?, to, Xo) =  ^(t,  to)xo, where 
^(t,  to)  = e' ,(l/2)(e2^0-e20 
Since lim^-^ 00 ^(^, ^0)  =  0, it follows that the equilibrium x  =  Oof system (5.4) is asymp 
totically  stable (in the large). 
• 
THEOREM  5.4.  The equilibrium  x  =  0 of  ilM)  is uniformly  asymptotically  stable if 
and only if it is exponentially  stable. 
Proof, The exponential stability of the equilibrium x  = 0 implies the uniform asymp 
totic stability of the equilibrium x  =  0 of systems {E)  in general, and hence, for systems 
(L//) in particular. 
Conversely, assume that the equilibrium x  =  0 of {LH)  is uniformly asymptotically 
stable. Then there is a 6 >  0 and a 7  >  0 such that if ||xo|| ^  5, then 
455 
CHAPTER  6: 
Stability 
for all t, to >  0. This implies that 
\\^{t + to + T, to)xo\\  <  ^ 
||cD(/ + /o + r,ro)||<  i 
ifr,ro^O. 
(5.5) 
From Theorem 3.6 (iii) of Chapter 2 we have that (^(t,  r)  =  <[>(r, o-)0(a-, r) for any t, cr, 
and T.  Therefore, 
\\^(t +  to + 2T, to)\\  = \\^(t +  to  + 2Tj  +  to + T)^{t  +  to + T, to)\\ ^ 
|, 
in view of (5.5). By induction, we obtain for tJo  — O that 
\\^(t  +  to + nT, to)\\  ^  T\ 
(5.6) 
Now let a  = (\n2)/T. Then (5.6) implies that for 0 <  ^ <  T we have that 
Uit  + to + nT, to," xo)\\ <  2||xo||2-(«+i>  =  2||xo|k-""^""^^^^ "
which proves the result. 
EXAMPLE 5.4.  For system (5.4) given in Example 5.3 we have 
"<  2||;co|k-""^^^'^^>", 
U(tJo.xo)\\  =  |c/>(Uo,"xo)|  =  \xoe^""^^^'''e-^""'^^''\ "
"<  \xo\e^""^^'""''e-"
r >  ?o >  0, 
since e^^ > 2t. Therefore, the equilibrium x  =  0 of system (5.4) is uniformly asymptot 
ically stable in the large, and exponentially stable in the large. 
• 
Even though the preceding results require know^ledge of the state transition ma 
trix $(r, ro) of {LH), they are quite useful in the qualitative analysis of linear systems. 
In view of the above results, we can  state the following  equivalent  definitions.  The 
equilibrium x  =  0 of {LH)  is stable  if and only if for any ^  ^  0 there exists a finite 
positive  constant  y  =  y{to)  (which  in general  depends  on ^o) such that for  any  XQ, 
the corresponding  solution  satisfies  the inequality 
U{tJo.xo)\\^ 
y{to)\\xol 
t^ 
to. 
Also, the equilibrium  x  =  0 of {LH)  is uniformly  stable  if and only if there exists a 
finite positive constant y  (independent  of  to),  such that for  any to and  JCQ, the corre 
sponding  solution satisfies  the  inequality 
U{t,to,xo)\\^ 
rllxoll, 
t^  to. 
Furthermore, in view of the above results, if the equilibrium x  =  0 of {LH) is asymp 
totically stable, then in fact it must be globally asymptotically  stable, and if it is uni 
formly  asymptotically stable in the large, then in fact it must be exponentially  stable 
(in the large). In this case there exist finite constants y  >  1 and  A >  0 such that 
\mto>xo)\\^ye-^^'-'^^\\xo\\ 
"for  r >  /o >  0 and xo  E  R"""". "
The results in the next theorem, which are important in their own right, will be 
required  later. 
456 
Linear  Systems 
THEOREMS.5.  Let A be bounded on (-  oo,  oo).  Then any one of the following  statements 
^^ equivalent to the exponential  stability of the origin  x  =  0 of  {LH): 
cifox^wh^to. 
c2fox^\\h^  to. 
\;^\\^{h,T)fdT^C^foX^\\h^to. 
(i) \;^mt,to)\?dt^ 
(ii) \;^mtjo)\\dt^ 
(iii) 
(iv)  \;^mh,T)\\dT^ 
(The constants ci are independent of ^  or h,  and  ||  • || denotes a matrix norm induced 
C,for2i\\h^to. 
"by any one of the equivalent vector norms on /?"".) "
Proof,  If the  equilibrium  x  =  0 of  {LH)  is  exponentially  stable, then  there  exist  con 
stants y  >  0,  A  >  0 (independent  of to) such that  \\^{t, ro)|| ^  y^-^(^-^o), t  >  t^. Substi 
tuting this estimate into (i) to (iv) and evaluating the integrals yields ci  =  C3 =  y^l{2K) 
andc2  =  C4 =  y/A. Therefore, if the equilibrium  X  =  0 of (L//) is exponentially stable, 
then the integrals  (i) to (iv) are bounded. 
We now prove the converse  statements by considering each case  individually. 
(a) Assume that the bound c\  in (i) exists. Since A is bounded, there exists an a  >  0 
such that 
||ci>(Uo)||  =  ||A(Ocl>(Uo)||^  ||A(0||||^a^)|| 
<  a\\^{t,  to)\\, 
t  >  ^0. 
Therefore, 
||cD(ri, ^o)^^(^b ^0) -  /|| 
[6(r, tof^it, 
to)  + ^{t, tof(^{t,  to)]  dt\\ 
to 
'  \\^{t, to)^^(t,  to) +  (D(^, to)^i(t, 
\\\[A{t)^(t, to)n  mt,  to)\\ + mt,  to)^ IIA(O^(^, to)\\}dt 
to)\\dt 
<  2a 
rh 
J  to 
||0(r, to)fdt  <  2aci, 
t  >  to. 
Using the triangle inequality  of norms  yields 
mti,  to)^^(tu to)\\  = mtu  to)^^(tu 
to)-i+1\\ 
<  ||<D(^i, to)^^(tu 
to) -  I\\ +  ||/|| ^  2aci  +  1, 
ti^ 
to. 
This shows that ||^(ri, ^)|| is itself bounded  for ti  >  ^  by a constant  Li. 
To determine an exponential bound for ||0(f,  ^o)||  we note that 
mt,to)fdT= 
tQ 
J  to 
i'mt,T)^(TJo)fdT 
mt,  rt 
• mr, 
toifdr  <  Lf  f'  ||<I.(T, 
to)fdr 
to 
^  LW 
Jto 
Noting that the integrand  on the left  side does not depend on r,  we obtain 
{t -  to)\\^{t, to)f  <  L\ci, 
t  >  ^0. 
Let  ^  =  ^  -f-  7  and let T  =  AL\ci.  Then 
mto  +  Tjo)\\^ 
i 
Repeating the above procedure, we obtain 
and in general we have 
110^0 +2r,ro)N  ^5 
||<D(^ +  nT,  to)\\  < 
457 
CHAPTER  6: 
Stability 
Proceeding now as in the proof of Theorem 5.4, it follows  that ||<l>(^, ^)||  is  exponentially 
bounded. 
(b) As in (a), but using ^{t\, 
to) instead of 4>(ri, to)^(^(ti,  to),  and using the inequality 
||i>(r, ^)|| <  a||0(f, ^o)||, we obtain 
llcD^i, ro) - / ||  = 
\\r^{tJo)dt\\ 
rh 
f'||(i>(Uo)||^^^c.f'||0(Uo)||^^ 
Jto 
JtQ 
using  the inequality property  of norms, we have 
<  Q;C2, 
h  >  ho 
||c|>(ri, ^0)11  =  ||^(ri, to)-I  + I\\ ^  mh, 
to) -  I\\ +  ||/|| 
Using this estimate, we now  obtain 
<  ac2  +  1. 
llcDfe to)fdt  <  (ac2  +  1) f''  ||Oa  to)\\dt 
JtQ 
JtQ 
<  (aC2  + 
l)C2. 
This  shows  that  (ii) implies  (i), and  therefore,  it follows  that  ||0(/, /o)|| is  exponentially 
bounded. 
(c) The proof of this part follows the proof of (i)  with some modifications. Since A is 
bounded there exists a  >  0 such that ||A(0|| ^  «  for all t. From Exercise 2.35 in Chapter 
2,  we have 
^-^(t,  T)  =  -(D(?,  T)A(T), 
dr 
^^(t,T) 
=  ||-OaT)A(T)||<  a\\^(t,T)\ 
and  therefore. 
Then 
•^(ti,to)'^^(hJo)\\ 
Mtu  rf  ^{ti,  T)  + ^(^1,  rf 
^{h,  T)  dr 
As in (a), we now  obtain 
||/  -  ^(^1,  tof^ty, 
to)\\ ^  2ac3, 
ti  >  to. 
Using the triangle inequality, we obtain 
mt,, 
to)^^{ti, to)\\ ^ mtx,  to)^^{t,, to) -1\\  + ii/ii 
This  shows that  ||0(^, ^)||  is bounded  for  all ^ >  ro by  a constant  L3 that is  independent 
of rand  ^0-
<  2Q:C3  +  1. 
458 
To obtain an exponential bound we proceed similarly as in (a) to obtain 
Linear Systems 
u  ^  ,.\\^u. 
..M|2  ^  f'licT...  ..M|2 
J to 
to 
J to 
< Ln 
3 
||cD(ri,T)|pjT<L3C3 
^0 
Therefore, we have 
from which we obtain, letting T  = 4L3C3, 
and more generally, we obtain 
11^^0 + 7,^0)11^  h 
mto  +  nT,to)\\^{kJ^ 
Again, as in part (a), we conclude that O is exponentially bounded. 
(d) Assume that (iv) is satisfied. Then as in (b), we can show that (iv) implies (iii), 
which in turn implies that <I> is exponentially bounded. We obtain 
110(^1, ^o) -  /|| <  ac4, 
t > to, 
where a  is defined  as before  and C4  is given in (iv). From this we can conclude that 
\\^(ti, to)\\ is bounded for all ^1  >  ^0 by a:c4 +  1. This in turn yields the inequality 
[''  \\^(t, rtdr  <  (ac4 +  1) f'  mtu  r)\\dT 
Jto 
JtQ 
<  (ac4  + 1)C4. 
From this it follows that (iv) implies (iii). This concludes the proof of the theorem. 
• 
We  now  turn  our  attention  to  linear,  autonomous,  and  homogeneous  systems 
given by 
X =  Ax, 
r >  0, 
(L) 
referring to the discussion in Subsection 2.4A  [refer to Eqs. (4.11) to (4.27) in Chap 
ter 2] concerning  the use of the Jordan  canonical  form  to compute exp  (At).  We let 
J  =  P~^AP  and defi[ne x  =  Py.  Then (L) yields 
y  =  p-^APy  =  Jy. 
(5.7) 
It  is  easily  verified  (the  reader  is  asked  to  do  so in  the  Exercises  section)  that  the 
equilibrium  jc  =  0 of  (L) is  stable  (resp., asymptotically  stable  or unstable)  if  and 
only if  y  =  0 of (5.7) is stable (resp., asymptotically  stable or unstable). In view of 
this, we can  assume  without  loss of generality  that the matrix A  in  (L) is in  Jordan 
canonical form,  given by 
where 
for the Jordan blocks Ji,.. 
/Q =  diag [Ai,..., A^] 
.,Js. 
A  =  diag [Jo> Ji,' 
and 
-, Js\y 
Jk  =  )^k+iU  +  M 
As in (4.21), (4.22), (4.26) and (4.27) of Chapter 2, we have 
oAt 
^ 
(?Jof 
0 
where 
"e-"""" =  diagle""""",..., 
0 
o^st 
„Atn 
"e""'''] "
1 
t 
and 
^•fit  = 
g^k+it 
0  1 
tm-i 
••• 
( « , - l )! 
{rii  -  2)! 
2 
t 
0  0  0 
1 
459 
CHAPTER  6: 
Stability 
(5.8) 
(5.9) 
for  /  =  1,...,  s. 
Now  suppose  that  Re kt  <  j8  for  all  /  =  1,...,  k.  Then  it  is  clear  that 
\imt-,oo (ll^-^o^ll/^^O  <  °°^ where  ||^^°^||  is  the  matrix  norm  induced  by  one  of  the 
equivalent  vector norms defined  on R^.  We write this as \\e-^^%  =  €(e^^).  Similarly, 
if jS  =  Re Xk+i," then for  any e  >  0 we have that ||^""^^^|| =  ©(r^^-^^^O  = "
€(e^^^^^'). 
From the foregoing  it is now  clear  that  \\e^^\\  ^  K  for  some  ^  >  0 if  and  only 
if  all  eigenvalues  of A  have  nonpositive  real  parts,  and  the  eigenvalues  with  zero 
real  part  occur  in  the  Jordan  form  only  in  JQ and  not  in  any  of  the  Jordan  blocks 
J I, 1 <  /  <  5-. Hence,  by  Theorems  5.1  and  5.2,  the  equilibrium  x  =  0  of  (L)  is 
under these conditions  stable, in fact uniformly  stable. 
Now  suppose that  all eigenvalues  of A have  negative  real parts. From the pre 
ceding  discussion  it is clear that there is a constant  ^  >  0 and  an a  >  0  such  that 
"ll^^^ll <  Ke-""""'",  and  therefore,  Uit,  to, xo)|| <  Ke-''^'-'^^xo\\  for  alW  >  ro >  0  and 
for  all  xo  ^  R'^. It follows  that the  equilibrium  x  =  0 is uniformly  asymptotically 
stable in the large, in fact  exponentially  stable in the large. Conversely, assume that 
there is  an eigenvalue  A/ with  nonnegative  real part.  Then  either  one term  in  (5.8) 
does not tend to zero, or else a term in (5.9) is unbounded  at ^ ^  oo. In either case, 
^^^x(0) will not tend to zero when the initial condition x(0)  =  XQ is properly chosen. 
Hence, the equilibrium  x  =  0 of (L) cannot be asymptotically  stable  (and hence, it 
cannot be exponentially  stable). 
Summarizing the above, we have proved the following  result. 
THEOREM 5.6.  The equihbrium x  = Oof (L) is stable, in fact uniformly stable, if and 
only if all eigenvalues of A have nonpositive real parts, and every eigenvalue with zero 
real part has an associated Jordan block of order one. The equilibrium x  =  0 of (L) is 
uniformly asymptotically stable in the large, in fact exponentially stable in the large, if 
and only if all eigenvalues of A have negative real parts. 
• 
A direct consequence of the above result is that the equilibrium  x  =  0 of (L) is 
unstable  if  and  only  if  at least  one  of  the  eigenvalues  of A has  either  positive  real 
part or has zero real part that is associated with a Jordan block of order greater  than 
one. 
At this point, it may be appropriate to take note of certain conventions  concern 
ing matrices that are used in the literature. It should be noted that some of these are 
460 
Linear Systems 
not entirely consistent with the terminology used in Theorem 5.6. Specifically,  a real 
nXn  matrix A is called stable or a Hurwitz  matrix if all its eigenvalues have negative 
real parts. If  at least  one of the  eigenvalues  has  positive  real part,  then A  is  called 
unstable.  A  matrix A,  which is neither stable nor unstable, is called critical,  and the 
eigenvalues with zero real parts are called critical  eigenvalues. 
We  conclude  our  discussion  concerning  the  stability  of  (L)  by  noting  that  the 
results  given  above  can  also be  obtained  by  directly  using  the  facts  established  in 
Subsection  2.4C, concerning modes and asymptotic behavior of time-invariant  sys 
tems. 
EXAMPLE 5.5.  We consider the system (L) with 
A 
0  1 
-1  0 
The eigenvalues of A are Ai, A2 =  ±j.  According to Theorem 5.6, the equilibrium x  = 0 
of this system is stable. This can also be verified by computing the solution of this system 
for a given set of initial data x(0)^  = (xi(0), X2(0)), 
(j)i(t,0,xo)  = xi(0)cosr  + X2(0)sin^ 
4>2(t, 0, XQ) =  -xi(0)smt  + jC2(0)cosr, 
r >  0, and then applying Definition 4.1. 
EXAMPLE 5.6.  We consider the system (L) with 
ro  n 
A  =  0  0 
• 
The eigenvalues of A are Ai  =  0, A2 =  0. According to Theorem 5.6, the equilibrium 
X =  0 of this system is unstable. This can also be verified by computing the solution of 
this system for a given set of initial data x(0)^  = (xi(0), ^2(0)), 
(l)l(t, 0, Xo)  = Xi(0) + X2(0)t 
(f>2it, 0, Xo)  = X2(0), 
^  >  0, and then applying Definition  4.5. (Note that in this example, the entire xi-axis 
• 
consists of equilibria.) 
EXAMPLE 5.7.  We consider the system (L) with 
^  [2.8 
[9.6 
9.6] 
-2.8j* 
The eigenvalues  of A are Ai, A2 =  ±10. According  to Theorem  5.6, the  equilibrium 
X =  0 of this system is unstable. 
• 
EXAMPLE 5.8.  We consider the system (L) with 
The eigenvalues of A are Ai, A2 =  - 1 , - 2.  According to Theorem 5.6, the equilibrium 
X =  0 of this system is exponentially stable. 
• 
[-1 
-2\-
Next, we consider linear periodic systems given by 
(P) 
where A(t)  is  a continuous  real  matrix  for  all  f G  (-00, 00). We recall from  Section 
2.5 of Chapter 2 that if 0(^, ^0) is the state transition matrix for (P), then there exists 
A(t)  =  A(t  +  Tl 
X =  A(t)x, 
461 
CHAPTER  6: 
Stability 
"a constant nX  n matrix R and a nonsingular  nX  n matrix ""^(t", to) such that 
^(t,  to)  =  nt, 
to) exp [R(t  -  to)l 
(5.10) 
where 
^(?  +  T," to)  =  ""i^it", to) 
for  all  t  E  (-00, oo). Now  according  to  the  discussion  at  the  end  of  Section  2.5  of 
Chapter 2, the change of variables  x  =  '^(t,  to)y transforms  (P)  to the  system 
y  = Ry^ 
(5.11) 
where R is given in  (5.10). Since ^(t,  to) is nonsingular,  it is clear that the equilib 
rium X =  0 of (P) is uniformly  stable (resp., uniformly  asymptotically  stable) if and 
only if the equilibrium  j  == 0 of system (5.11) is uniformly  stable (resp.,  uniformly 
asymptotically  stable).  Now  by  applying  Theorem  5.6  to  system  (5.11)  we  obtain 
the following  result. 
THEOREM  5.7.  The cquiHbrium  x  =  0 of (P) is uniformly  stable if  and only if all 
eigenvalues  of the matrix R  [given  in  (5.10)]  have nonpositive  real parts,  and every 
eigenvalue with zero real part has an associated Jordan block of order one. The equi 
librium X =  0 of (P) is uniformly asymptotically stable in the large  if and only if all 
eigenvalues of R have negative real parts. 
• 
6.6 
SOME GEOMETRIC AND ALGEBRAIC STABILITY  CRITERIA 
In  this  section  we  concern  ourselves  with  nth-order  linear  homogeneous  ordinary 
differential  equations  of the  form 
"aox^""""^  + axx^""""-^^  + • -h an-ix^^""^  -h anX  =  0", 
ao 7^0, 
(6.1) 
where the coefficients  ao,..  .,an  are all real numbers. We recall from  Chapter  1 that 
(6.1) is equivalent to the system of first-order ordinary differential  equations 
where in (6.2) A  denotes the companion  matrix  given by 
X =  Ax, 
A  = 
0 
0 
1 
0 
0 
1 
On 
ao 
_ a „ -i 
ao 
_ 
"' ^ "" -2 "
flo 
0 
0 
fll 
flO 
(6.2) 
(6.3) 
To determine  whether  the equilibrium  x  =  0 of  (6.3) is  asymptotically  stable, 
it suffices  to determine if  all the eigenvalues  of A have negative real parts, or what 
amounts to the same thing, if the roots of the polynomial 
"/(A)  =  aoX""""  +  (21A""""""^  -h • • • +  (2^-1 A  -h an "
(6.4) 
all  have  negative  real  parts.  To  see  this,  we  must  show  that  the  eigenvalues  of  A 
coincide  with  the  roots  of  the  polynomial  f(s).  This  is  most  easily  accomplished 
and  therefore 
by  induction.  For  the  first-order  case  k  =  1, we  have  A  =  -ajao 
det(\I\ 
1.  Next, 
assume that the assertion is true for k  =  n -  I.  Then 
-  A)  ^  A -h aJao,  h  =  I,  and  so  the  assertion  is  true  foYk= 
462 
Linear Systems 
det{XIn  -  A)  = 
0 
-1 
A 
0 
flO 
0 
-1 
0 
ao 
0 
0 
0 
0 
-1 
A 
02  A +  fli 
ao 
ao 
-1 
A 
0 
"""n "
ao 
=  Xdet(Xln-\ 
-  Ai)  +  (-1> 
n+l 
0 
-1 
A 
0 
0 
-1 
0 
0 
0 
where 
Ai  = 
0 
0 
a„-i 
flO 
and In, In-\  denote the n  X /i and {n- 
1 
0 
0 
1 
0 
0 
0 
0 
_an-2 
ao 
\)X  {n-  1) identity matrices.  Therefore, 
an-3 
ao 
flo 
ai 
det(\In  -  A)  =  Xdet(\In-i 
-  Ai)  +  — 
ao 
"=  A"" +  ^ A "" -i  + "
ao 
0 
A+  — 
ao 
ao 
is equivalent to /(A)  =  0. 
Analogously  to matrices, we now make the following  definitions.  An  nth-order 
polynomial  /(A)  with real coefficients  [such as (6.4)] is called stable  if  all zeros of 
/(A) have negative real parts, it is called unstable  if at least one of the zeros of  /(A) 
has a positive real part, and it is called critical  if /(A) is neither stable nor unstable. 
Also, a stable polynomial is called a Hurwitz  polynomial. 
In view  of the  above, the  stability  problem  for  nth-order  differential  equations 
with constant coefficients  has now been reduced to a purely algebraic problem of de 
termining whether the zeros of a polynomial  [such as (6.4)] all have negative (resp., 
nonpositive)  real  parts.  In  case  zeros  with  vanishing  real  parts  exist,  it  is  further 
necessary  to determine their  multiplicity. 
In the following,  we first present  some graphical  criteria  that  enable us to de 
termine the stability  of a polynomial  (6.4), without  determining  its roots  explicitly. 
These results, which are important in their own right, are then used to arrive at some 
algebraic  criteria  to determine the stability  of a polynomial  (6.4). 
A.  Some  Graphical  Criteria 
In establishing  our first result we assume that the polynomial  f(s)  [given by  (6.4)] 
has p  zeros  in the right  half  of the ^--plane and  (n  -  p)  zeros  in the left  half  of  the 
^--plane, and we assume that there shall be no zeros on the imaginary  axis. We let C 
denote the counterclockwise contour formed by a semicircle C with radius r and cen-
tered at the origin, together with its diameter  on the imaginary  axis, and we choose 
r so large  that  the p  zeros  of  f(s)  in the right  half  of the ^-plane  lie in the interior 
of the circle. We now recall from  a well-known result from the elementary theory of 
functions  of a complex variable (called Cauchy's  integration formula)  that 
463 
CHAPTER 6: 
Stability 
P=  ^ 'l 
^ T T ^^  =  ^ 8c  In f(sl 
(6.5) 
277-J )c  f{s) 
27TJ 
f'(s)  denotes  the  derivative  off  with 
where  5-  is  a  complex  variable,  j  =  ^-l, 
respect to s, \(^[f'(s)/f(s)]  ds  denotes the integral of f'(s)/f(s) 
along the contour C, 
and 8c In f(s)  represents the increment of In f(s)  along the contour C. Let Sq  In  f(s) 
"denote the increment  of ln/(^)  along the  semicircular  arc  C  with  s  =  re^""^.  For s "
on C  we have 
"f{s)  =  aor'^^^'""^(l  +  0(r""^)) "
"ln/(^)  =  Inao  +  ^Inr  +  njcf) +  0(r""^). "
and 
Hence, 
8c>lnf(s)  = 
njl^^'^ 
"=  niTJ +  ©(r""^). "
Letting  r ^  oo and using (6.5), we conclude that 
-n^^j  +  hs—: ]8i In  f(s) 
277 j 
\27rj 
=  ^+  2 : ^ 5 / I n / ( ^ ), 
(6.6) 
where S/ In f(s)  denotes the increment of the logarithm of f(s)  along the imaginary 
axis /  from  -oo to  +oo. To determine this increment,  we let s  =  jo)  and let 
f(s)  =  f(jay)  ^  Ri(o)eJ'(^^  ^  U{co)  +  jVico), 
(6.7) 
in  (6.7)  describe  the frequency  response  or frequency  plot  for 
and  we  consider  R, 6  as polar  coordinates  and  U,  V  as  coordinates  in  the  complex 
plane. As  the real parameter  co  (the real  frequency  w)  ranges  from  +00 to  -00, the 
points  f(jo)) 
f(s). 
Since/(s-) has real coefficents,  we must have 7?(CL))  =  R(-a))  and 0((o)  = 
-6(-(o). 
It therefore  suffices  to consider the part of the response curve belonging to the posi 
tive values of the parameter 0;. It follows  from  (6.6) that 
6(00) 
(6.8) 
n  _  ^(00)  _  1 
2  ~V~  ~  2 
where  ^(00) is the limit  to which  the polar  angle  6(a))  =  tan~^[V(o))/U((o)]  of  the 
frequency  response diagram tends as co  becomes unbounded. Since  U(co) and  V((o) 
are polynomials of different  degrees,  \V(CO)/U((JO)\ will tend to either zero or infinity. 
In either case, in view of (6.8), ^(00) must be an integral multiple of 77/2. Now when 
in particular p  =  0, then by necessity  we have that 6(00) =  n(7r/2). This yields the 
following  result. 
THEOREM 6.1. (LEONHARD-MIKHAILOV  STABILITY CRITERION)  The poly 
nomial f(s)  has only zeros with negative real parts if and only if its frequency response 
diagram f(jco),  0 <  co <  00, passes through exactly n quadrants in the positive sense.  • 
464 
Linear Systems 
(a)  Frequency response plot 
for f{s)  stable (n = 6) 
(b)  Frequency  response plot 
for f{s)  unstable (n = 6) 
FIGURE 6.4 
Frequency response plot for f(s)  stable (n 
6) 
In Fig.  6.4  we  depict  the frequency  response  plots  of  a  stable  and  an  unstable 
polynomial. 
Next, since f(s)  has real coefficients,  there are real polynomials  f\  and /2  such 
that 
fijco)  ^  Moj^)  4-  j(of2(co^\ 
(6.9) 
If  n  =  2k,  then  deg fi(u)  =  k  and  deg f2(u)  =  k  -  I,  and  if  n  =  2k  -{-  1, then 
deg f\{u)  =  k  and deg f2(u)  =  k. To the zeros  uik,  i  =  1, 2 and  k  =  1, 2, 3 , . .. of 
the polynomials  fi(u),  /2(w), respectively,  correspond  those  values  of  co^ at  which 
the frequency  response  diagram  intersects  the  axes.  In  the  case  of  stability,  these 
values  ofcx)^ must  be  real  and  increasing,  i.e.,  the  zeros  ui^ must  be  positive  and 
alternate. 
0  <  Wii  <  U2\  <  Ui2  <  U22 < 
"'"" "
(6.10) 
since otherwise the response curve f{jco)  will not make the proper number of turns at 
the appropriate locations. These considerations lead to the interlacing  of the roots u\k 
with the roots  U2k,  k  =  1, 2, 3 , . . .,  which  is sometimes  called the gap  and  position 
criterion.  In Fig. 6.5 we depict typical situations for stability and instability (in terms 
of the variables  U and  V). 
We summarize the above in the following  result. 
u,  V k 
u,  V  k 
CO r 
(a) Stable case 
FIGURE 6.5 
(a) Unstable case 
THEOREM  6.2.  (GAP  AND  POSITION  STABILITY  CRITERION)  The  polynomial 
f(s)  has only zeros with negative real parts if and only if the zeros of the polynomials 
defined in (6.9) are real and satisfy the inequalities (6.10). 
• 
The frequency  response plot  f(j(o) 
is unbounded  and hence can never be dis 
played  completely.  We  therefore  frequently  make  use  of  the  reciprocal  frequency 
response  diagram,  i.e., the response  diagram  of  the function  l/f(jo)).  Such  a plot 
approaches  zero asymptotically,  and in case of stability, it rotates exactly through n 
quadrants in the negative  sense.  In applications of Theorem 6.1, the entire plot is not 
needed. It can be shown that it suffices  to consider the interval 0  <  w  <  CDQ^ where 
465 
CHAPTER 6* 
Stability 
(OQ  =  1 + 3  max\p\\. 
(6.11) 
We will not pursue the details concerning the proof of this  assertion. 
B.  Some Algebraic  Criteria 
In the next results, we develop the Routh-Hurwitz criterion, which yields  necessary 
and  sufficient  conditions  for  f(s)  to be  a Hurwitz  polynomial.  To accomplish  this, 
we will make use of Theorem  6.2. We begin by establishing  a set of necessary  con 
ditions. 
THEOREM  6.3.  For 
"f(s)  =  aos""""  + ais'""''^  +  • • •  + an-is  + <2„ "
(6.12) 
to be a Hurwitz polynomial it is necessary that the inequalities 
^ > 0 , ^ > 0 , . . . , ^ >0 
Go 
UQ 
ao 
(6.13) 
hold. 
Proof, Let si,..  .,SnhQ the zeros of (6.12), and in particular, let s'j be the real roots and 
s'l the complex roots. Then 
f(s)  = aoYlis  -  s'j)Yl(s  -  s'l) 
j 
k 
=  aoYlis  -  s'j)Yl(s^  -  {2Res'l)s + |4f). 
j 
k 
If all the numbers s'j and Re s'l are negative, then we can obtain only positive coefficients 
for the powers of s when we multiply the product out to obtain f{s). 
• 
Without loss of generality, we assume in the following  that ao  >  0. In the next 
result, we will require the Routh  array: 
c\Q  =  ao, 
Cii  =  ai, 
C20 =  <32 
C21  =  as, 
C30  =  a4, 
C31  =  as, 
C40 = 
C41  = 
as,... 
aj,... 
C12 =  a2- 
r2fl3, 
C22 =  a^  -  r2as, 
^332  =  ^6  -  ^2<37,... 
Ci3  =  C21  - 
r3C22, 
C23  =  C31  - 
r3C32, 
C33  =  C41  - 
r3C42,  . . . 
ao 
ri  =  —, 
ax 
Cll 
r^  = 
, 
cn 
<^1,/-1 
Cij  =  Ci+ij-2  -  rjCi+ij-i, 
i=l,2,..., 
J  =  2,  3 ,. 
C\n  =  an 
466 
Linear Systems 
Note  that  if  n  =  2m,  we  have 
^ 
^ ^ _^ 
^ ^ _^ 
^ 
^ ^ _^ 
.—  n 
and  if  n  =  2m  -  1, we  have 
The above array terminates  after  {n—\)  steps in case all the numbers  ctj  are  different 
from  zero. The  last  line  defines  ci„. 
In  addition  to the  inequalities  (6.13), we  shall  require  the  inequalities  given  by 
C\\  >  0, Ci2  >  0, . . .,  Cin  >  0. 
(6.14) 
THEOREM  6.4.  (ROUTH-HURWITZ  STABILITY  CRITERION)  The  polynomial 
f{s)  given  in  (6.12)  is  a Hurwitz  polynomial  if  and  only  if  the  inequalities  (6.13)  and 
(6.14) hold. 
Proof,  First we assume that the degree of f{s)  is even by letting n  =  2m. We define the 
polynomials 
hi(s)  =  i[/(^)  +  f(-s)l 
h2(s)  =  l[/(^)  -  f(-s)l 
(6.15) 
Applying the Euclidean algorithm to determine the greatest common divisor of hi (s) and 
h2(s),  we obtain 
hi(s)  =  r2sh2(s) — hsis) 
h2(s)  =  r!^sh3(s)  -  h^is) 
(6.16) 
where the linear factors  arising in the division have no constant term and the remainders 
have been written with negative signs. It is readily verified that the constants r[ in (6.16) 
are related to the constants  r/  in the Routh array by the expression  r-  =  (-  1)V/. 
Next, we define  a sequence of polynomials  given by 
h2i-i{s)  =  g2i-i(s^X 
h2i{s)  ^  sg2i{sh 
i  =  \,,.,,m. 
(6.17) 
From (6.16) and (6.17) we obtain the recursion formulas  given by 
gii+iiz)  =  r2iZg2i(z)  -  g2i-i(z) 
g2i+2(z) =  r2i+ig2i+i(z) -  g2i(z). 
The first two members of this sequence are given by 
gi(z)  =  aoz^  +  a2Z^-i  + 
"giiz)  =  aiz""""-'  + a^f""-^  +  •••  +  a2m-x. "
"'""+a2m "
(6.18) 
(6.19) 
We can readily verify  that the above two polynomials agree with the polynomials /i  and 
/2 given in (6.9), except for  sign. In fact,  we have 
fi{u)  =  gi{-u) 
i  =  1,2. 
(6.20) 
We are now in a position to construct the Routh array of a polynomial f{s)  by utiliz 
ing the coefficients  of the sequence of polynomials gi{z)- If in the process of doing so we 
encounter  a zero row  (i.e., an identically  vanishing  polynomial,  say, gi),  then  h\  and /z2 
[and thus, f{s)  and f{-s)\ 
have a common divisor. In this case f{s)  possesses a divisor 
of the form s^ + a. and is not a Hurwitz  polynomial. 
Next, we  assume that the hypotheses  of this theorem  are satisfied  [i.e., (6.13)  and 
(6.14) hold]. Applying  definitions,  we can readily verify  that the numbers  r[ have alter-
nating signs, that the signs of the leading coefficients  of the polynomials gi, i = 1,2,...  467 
are siven bv 
-^ 
^ 
/: 
CHAPTER 6: 
+,  +, -, -, +, +,  - , - , ••  •, 
(6.21) 
Stability 
and that the degrees of these polynomials  are given by 
m,m—  \,m  — 1, m — 2, m —  2 , . . .,  1, 1, 0. 
(6.22) 
Next, for fixed z, -oo < z < oo, we consider the sequence of numbers given by 
gl{z),g2{z\...,g2m{z). 
(6.23) 
Note that the last term gimiz)  is a constant for all z. Let W{z) denote the number of sign 
changes in this sequence. When z > 0 and is very large, then the signs of the gi in (6.23) 
correspond  to the signs of the leading  coefficients  of these polynomials. When  -z > 0 
and  is very  large,  then  the signs of gi in (6.23)  will  alternate. It now follows  that the 
difference  W{-^)  —  W{+^)  is always  equal  to m. Thus,  as z varies  from  -oo to +°o, 
m  sign  changes  in the sequence  (6.23)  will disappear.  Such a disappearance  can occur 
only at a zero of g\{z),  since if z passes through a zero, say, z', of gi{z), \ < i < 2m, no 
disappearance in the number of sign changes  occurs, because by (6.18), sgngi-\{z')  ^ 
sgn gi+i. We conclude that gi{z) has exactly m real zeros, and since by hypothesis all its 
coefficients  are positive, no positive zeros can occur. 
A  similar  argument  as  above  shows  that  g2 has exactly  (m -  I) negative  zeros. 
Now, since in the sequence (6.23) the largest possible number of disappearances of sign 
changes  occurs  (as z is varied  from  -oo to  +oo), a disappearance in sign  change  must 
actually  occur  each  time z passes  through a zero of ^i. This, however,  is possible  only 
if  g2 in turn  changes  sign between  every  two zeros of ^i; otherwise  there  would be an 
additional change of signs in the sequence (6.23). It follows that the zeros of g2 separate 
the zeros of ^i  (the zeros of g2 are interlaced with the zeros of ^i). Now, in view of (6.20), 
the  above  statement  concerning  the zeros of ^i  and g2 is equivalent  to the  inequahty 
(6.10);  thus. Theorem  6.2  applies.  Therefore,  condition  (6.14) is sufficient  for f{s) to 
be a Hurwitz  polynomial. It is also a necessary  condition,  since otherwise  the count of 
the sign changes in the sequence  (6.23) is too small and the hypotheses of Theorem 6.2 
are not satisfied,  i.e., either ^i  has too few zeros or the polynomial does not satisfy  con 
dition (6.10). 
To complete the proof, we assume next that n = 2m + 1, i.e., n is odd. In this case 
we interchange the definitions  of hi(s)  and h2(s) given in (6.16), and we let 
h2i+l(s)  = Sg2i + \(S^\ 
h2i(s)  = g2i(s'^y 
The degrees of the polynomials gi formed in this manner are m, m, m - 1, m - 1 , . . .,  1, 1, 0. 
Following a similar procedure  as before,  we show that the polynomials  gi(z)  and g2(z) 
each have m negative zeros and that Theorem 6.2 applies. This concludes the proof.  • 
EXAMPLE6.1.  We apply the Routh-Hurwitz criterion (Theorem 6.4) to the polynomial 
f(s)  = (s + 2)(s + 1 -  j)(s + 1  + j)(s + 1) 
=  /  + 5^^ + 10^2 + 10^ + 4. 
(6.24) 
For this  polynomial 
we form the Routh array and obtain 
/ 
s^ 
s^ 
s' 
s' 
1 
5 
i ( 5 - 1 0 - 1 - 1 0)  = 8 
| ( 8 - 1 0 - 5 - 4)  = 7.5 
7 ^ [ ( 7 . 5 ) - 4 - 8 - 0]  = 4 
10 
10 
4 
0 
1 ( 5 - 4 - 0)  = 4  0 
i ( 8 - 0 - 5 - 0)  = 0  0 
0 
0 
468 
Lh^i^Systems 
The conditions  of Theorem  6.4  are clearly  satisfied.  Hence,  (6.24)  is  a Hurwitz 
polynomial. 
• 
EXAMPLE6.2.  We apply the Routh-Hurwitz criterion (Theorem 6.4) to the polynomial 
f(s)  = (s + 2)(s +  1  -  j)(s  +  1  + jXs  -  1) 
=  /  + 3^^ + 2s^ -2s-4. 
(6.25) 
We note that condition (6.13) is violated, and therefore, the polynomial (6.25) is not a 
Hurwitz polynomial. Condition (6.14) is also not satisfied. To see this, we form the Routh 
array for (6.25), given as 
/I 
s^ 
s^ 
s' 
s' 
3 
2
-4 
-2 
i(3-2  + 2 ) =f 
i [ 3 . ( - 4 ) - 0]  =  -4 
i[f  •(-2)-(-4)-3]  =  f 
i[f  •(-4)-0]  =  -4 
0 
0 
0. 
0 
• 
6.7 
THE MATRIX  LYAPUNOV  EQUATION 
In Section 6.6 we established a variety of stability results that require explicit knowl 
edge of the solutions of (L) or (LH).  We also derived  some geometric and  algebraic 
stability criteria for  (L) when the matrix A  is in companion form  that do not require 
explicit knowledge of solutions, but instead,  are deduced directly  from  the parame 
ters of A. 
In  this  section  we  will  develop  stability  criteria  for  (L)  with  arbitrary  matrix 
A.  In doing so, we will employ Lyapunov's  Second  Method  (also called  Lyapunov's 
Direct  Method)  for  the  case  of  linear  systems  (L). This  method  utilizes  auxiliary 
real-valued functions  v(x),  called Lyapunov functions,"  that may be viewed as  ""gen "
"eralized  energy functions''  or ""generalized  distance functions''  (from the equilibrium "
X =  0), and the stability properties  are then deduced directly from  the properties of 
v{x)  and its time derivative v(x), evaluated  along the solutions of (L). 
A logical choice of Lyapunov function  is v(x)  =  x^x  =  ||x|p, which represents 
the square of the Euclidean distance of the state from  the equilibrium  x  =  0 of (L). 
The  stability  properties  of  the  equilibrium  are  then  determined  by  examining  the 
properties of v(x),  the time derivative of v(x)  along the solutions of (L), 
This derivative can be determined without explicitly  solving for the solutions of (L) 
by noting that 
X =  Ax. 
(L) 
v(x)  =  xF X +  x^ X  =  (Ax)^x  +  x^(Ax) 
=  Jc^(A^  +  A)x. 
If  the  matrix A  is  such  that  v(x)  is  negative  for  all  x  T^  0,  then  it  is  reasonable  to 
expect that the distance of the state of (L) from  x  =  0 will decrease with increasing 
time,  and  that  the  state  will  therefore  tend  to  the  equilibrium  x  =  0  of  (L)  with 
increasing time  t. 
It turns out that the Lyapunov function  used in the above discussion is not  suffi 
"ciently flexible. In the following we will employ as a ""generalized distance  function"" "
the quadratic form  given by 
v(x)  =  X  Px, 
P\ 
(7.1) 
where P is a real nXn  matrix. The time derivative of v{x)  along the solutions of (L) 
is determined  as 
v{x)  =  x^Px  +  x^Px  =  x^A^Px  +  x^PAx 
469 
CHAPTER  6: 
Stability 
I.e., 
where 
=  x^{A^P  +  PA)x, 
V  =  x^Cx, 
C  =  A^P  +  PA. 
(7.2) 
(7.3) 
Note that C is real and C^  =  C. The system of equations given in (7.3) is called the 
Lyapunov  Matrix  Equation. 
We  recall  from  Section  6.2  that  since  P  is  real  and  symmetric,  all  its  eigen 
values  are real. Also, we recall  that P is  said  to be positive  definite  (resp.,  positive 
semidefinite)  if  all its eigenvalues  are positive  (resp., nonnegative),  and it is  called 
indefinite  if P has eigenvalues  of opposite  sign. The definitions  of negative  definite 
and negative  semidefinite  (for P)  are  similarly  defined.  Furthermore,  we recall  that 
thQ function  v(x)  given in  (7.1) is said to be positive  definite, positive  semidefinite, 
indefinite,  and  so forth,  if  P has  the  corresponding  definiteness  properties  (refer  to 
Section  6.2). 
Instead of solving for the eigenvalues of a real symmetric matrix to determine its 
definiteness properties, there are more efficient  and direct methods of accomplishing 
this. We now digress to discuss some of these. 
Let G  =  [gij] be a real nX  n matrix  (not necessarily  symmetric). Referring  to 
Subsection  2.2G, we recall that the minors  of G are the matrix itself  and the matrix 
obtained  by  removing  successively  a row  and  a  column.  The principal  minors  of 
G  are  G itself  and  the matrices  obtained  by  successively  removing  an  ith row  and 
an  ith  column,  and  the  leading  principal  minors  of  G  are  G itself  and  the  minors 
obtained by successively removing the last row and the last column. For example, if 
G  =  [gij]  G  R^^^,  then the principal minors  are 
gn 
821 
_g3l 
gn 
_g3l 
gn 
gii 
g32 
gl3 
g33_ 
gu] 
g23 
^33 J 
> 
gn 
g2l 
gl2 
g22_ 
[gnl 
g22 
g23 
[g32  ^33. 
[g22l 
[g33l 
The  first  three  matrices  above  are the  leading  principal  minors  of  G.  On  the  other 
hand, the matrix 
g21 
_g3l 
g22 
g32 
is a minor but not a principal  minor. 
The following results, due to Sylvester, allow efficient  determination of the def 
initeness properties of a real, symmetric  matrix. 
PROPOSITION 7.1.  (i) A real symmetricmatrix P  =  [pij] G R''^''is positive definite 
if and only if the determinants of its leading principal minors are positive, i.e., if and 
only if 
470 
Linear  Systems 
Pn  > 0, 
det 
\Pn 
[Pl2 
Pul 
Pll] 
>0,...,detP>0. 
(ii) A real symmetric matrix P is positive  semidefinite  if and only if the determinants of 
all  its principal  minors  are nonnegative. 
• 
Still  digressing,  we  consider  next  the  quadratic  form 
v(w)  =  w^Gw, 
G  =  G^, 
where  G  G  R^^^,  Referring  to  Subsection  6.2C  [in  particular,  Eqs.  (2.35)  and 
(2.36)],  there  exists  an  orthogonal  matrix  Q  such  that  the  matrix  P  defined  by 
is  diagonal.  Therefore,  if  we  let  w  =  Qx,  then 
P  =  Q-^GQ  =  Q^GQ 
v(2;c)  =  v{x)  =  x^Q^GQx 
= 
x^Px, 
where  P  is  in  the  form  given  in  Eq.  (2.35),  i.e.. 
A2 
0 
From  this, we  immediately  obtain  the  following  useful  result. 
PROPOSITION  7.2.  Let P  =  P^  G  R''^'',  let \M(P)  and A^(P) denote the largest and 
smallest eigenvalues  of P, respectively, and let || •  || denote the Euclidean norm. Then 
A^(P)||x|p  <  v(x)  =  x^Px  < 
\M(P)\\xf 
(7.4) 
for  all X E  R\ 
Let  ci  =  \m(P)  and  C2  =  ^M(P)'  Clearly,  v(x)  is  positive  definite  if  and  only 
is 
is  positive  semidefinite  if  and  only  if  C2  ^  ci  >  0,  v(x) 
if  C2 ^  ci  >  0,  v(x) 
indefinite  if  and  only  if  C2 >  0,  ci  <  0,  and  so  forth. 
We  are  now  in  a position  to prove  several  results. 
THEOREM  7.1.  The equilibrium  x  =  0 of (L) is uniformly  stable  if there exists a real, 
symmetric, and positive definite  nX  n matrix P such that the matrix  C given in (7.3) is 
negative  semidefinite. 
Proof.  Along any solution (/)(r, to, XQ)  =  (f)(t) of (L) with (/>(^, ^o, XQ)  =  (^(^) 
have 
xo, we 
ct>(tfPct>(t) 
xlPxo  +  I  ^(j>{y]fP(i>{r])dr]  =  x^Pxo  + 
d 
(fy{r]f C(j>{'r])dri 
for  all t  >  to >  0. Since P is positive  definite  and C is negative  semidefinite,  we have 
471 
(l>{tYP(fy{t)  -  xlPxo  <  0 
for  all t  >  to >  0, and there  exist  C2 ^  ci  >  0 such  that 
ciwmf  ^ m^pm  < xiPxo < c2iixoip 
for  all ^ >  ^.  It follows  that 
||<^(ONgj  Nl 
CHAPTER 6: 
Stability 
for  allr  >  ^  >  0 and for any XQ  G R^.  Therefore,  the equilibrium  x  =  0 of (L)  is  uni 
formly  stable  (refer  to Sections  6.4 and 6.5). 
• 
EXAMPLE  7.1.  For the system  given  in Example  5.5 we choose  P  =  I,  and we  com 
pute 
C  =  A^P  + PA  =  A^ + A  =  0. 
According  to Theorem  7.1, the equilibrium  x  =  0 of this  system  is stable  (as  expected 
from  Example  5.5). 
• 
THEOREM  7.2.  The equilibrium  x  =  0  of  (L) is  exponentially 
stable  in  the  large  if 
there  exists  a real,  symmetric,  and positive  definite  nX  n matrix  P  such  that  the matrix 
C  given  in (7.3)  is negative  definite. 
Proof,  We let (f){t, to, xo)  =  cf>(t) denote  an arbitrary  solution  of (L)  with  (/>(^)  =  ;co. In 
view  of the hypotheses  of the theorem,  there  exist  constants  C2 ^  ci  >  0 and C3  >  C4 > 
0  such  that 
and 
"for  all /  >  ^  >  0 and for any ;co e  /?"".  Then "
-C3\\m\? ^ v(0(O) = m ^ cm  ^ -C4\\m\? 
v(m) = j^im^pm] ^ (-^Am^pm 
- | ) v ( c ^ ( 0) 
for alU  >  ^  >  0. This implies, after  multiplication by the appropriate  integrating  factor, 
and  integrating  from  to to t,  that 
V((/>(0)  =  (f)(tf  P(t>{t) <  xJPX0^~^'4/c2)a-%) 
or 
or 
ciWmf 
^  m'^Pm 
\l/2 
I 
^ C2\\xo\fe-^'^''^^^'-'^^ 
| | c / > ( 0 | | <^ 
||xo|k-^^/^^^^4/c2)a-^o), 
t^to^^. 
This  inequality  holds  for  all  xo  E  R^  and  for  any  to ^  0.  Therefore,  the  equilibrium 
X =  0 of (L) is exponentially  stable in the large (refer  to Sections 6.4 and 6.5). 
• 
In Fig.  6.6  we provide  an interpretation  of Theorem  7.2  for  the  two-dimensional 
case  {n  ^  7).  The  curves  Q,  called  level  curves,  depict  loci  where  v{x)  is  constant, 
i.e.,  Ci  =  {x  G  R^  \ v(x)  =  x^Px  =  Ci}, i  =  0,  1, 2, 3, 
When  the  hypotheses 
of  Theorem  7.2  are  satisfied,  trajectories  determined  by  (L)  penetrate  level  curves 
corresponding  to  decreasing  values  of  c/  as  t  increases,  tending  to  the  origin  as  t 
becomes  arbitrarily  large. 
472 
Linear  Systems 
C2 = {xeR^:v{x) 
= C:i} 
Ci  =[xeR^: 
v{x)  = c-]} 
\ 
Co = {xe  R^  : v(x)  = Co = 0} 
|  C2 = {x€H^ : v(x)  = C2} 
"0  =  CQ<  C-\  <  C2  <  C3  •  •  "" "
to<t^ 
<  f2  <  ^3  •  • • 
V(X)  =  C3 ' 
- fc 
"v{x) = C2 -""""^ "
\/(x) = ci 
-^ 
^^N^^^Vl 
— ^ - ^2 
^^ 
>^1 
FIGURE  6.6 
Asymptotic  stability 
EXAMPLE  7.2.  For the system given in Example 5.8, we choose 
^  n  0 
0  0.5 
and we compute the matrix 
C  =  A^P  +  PA  = 
-2 
0 
0 
-2 
According to Theorem 7.2, the equilibrium  x  =  0 of this system is exponentially  stable 
in the large (as expected from  Example 5.8). 
• 
THEOREM  7.3.  The  equilibrium  x  =  0 of  (L) is  unstable  if  there  exists  a real,  sym 
metric nX  n matrix P that is either negative definite or indefinite  such that the matrix  C 
given in (7.3) is negative  definite. 
Proof,  We first assume that P is indefinite. Then P possesses eigenvalues of either sign, 
and every neighborhood  of the origin contains points where the  function 
v(x)  = x^Px 
is positive and negative. Consider the neighborhood 
B{e)  =  {x e  /?^ : \\x\\  < e}, 
where || • || denotes the EucHdean norm, and let 
G  =  {x e  B{e) : v(x) <  0}. 
473 
CHAPTER  6: 
Stability 
On the boundary of G we have either ||x||  =  e or v{x)  = 0. In particular, note that the 
origin x  = 0 is on the boundary of G. Now, since the matrix C is negative definite, there 
exist constants C3  >  Q  >  0 such that 
-csll^lp  <  x^Cx  =  v(x)  <  -QII^IP 
"for all X  E  /^"". Let (t)(t", to,  XQ) = (i){t)  and let xo  =  (/>(^) G G. Then v(xo)  =  -(3 <  0. 
The  solution  (f){t)  starting  at  JCQ must  leave the  set  G. To see this, note that  as long 
as  (f){t)  E  G,  v((/)(0)  ^  -«  since  v(x)  <  0 in  G.  Let  -c  =  sup  {v(x)  : x  ^  G and 
v(x) <  -fl}. 
Then c >  0 and 
v{(f){t))  = v(xo) + 
v((t)(s))ds  <  -(2 - 
C(i5 
=  —a  —  (t  —  to)c,  t  >  tQ. 
This inequality  shows that 4>{t)  must escape the set G (in finite time) because v{x) is 
bounded from below on G. But (f){t) cannot leave G through the surface determined by 
v{x)  = 0 since v((/)(0) ^  - a. Hence, it must leave G through the sphere determined by 
||x||  =  6. Since the above argument holds for arbitrarily small 6 >  0, it follows that the 
origin x  =  0 of (L) is unstable. 
Next, we assume that P is negative definite. Then G as defined is all of B(e), The 
• 
proof proceeds as above. 
The  proof  of  Theorem  7.3  shows  that  for  e  >  0  sufficiently  small  when  P  is 
negative definite, all solutions (pit) of (L) v^ith initial conditions  XQ  E  B(e)  w^ill tend 
aw^ay from  the  origin. This  constitutes  a severe case  of instability,  called  complete 
instability. 
EXAMPLE 7.3.  For the system given in Example 5.7, we choose 
P = 
0.28 
-0.96 
-0.961 
0.28 
and we compute the matrix 
C  = A^P  + PA  = 
-20 
0 
0 
-20 
The eigenvalues of P are ±1. According to Theorem 7.3, the equilibrium x  =  0 of this 
system is unstable (as expected from Example 5.7). 
• 
In  applying  the  results  derived  thus  far  in  this  section,  we  start  by  choosing 
(guessing)  a  matrix  P  having  certain  desired  properties.  Next,  we  solve  for  the 
matrix  C, using  Eq.  (7.3). If  C possesses  certain  desired  properties  (i.e., it is  neg 
ative  definite),  we  draw  appropriate  conclusions  by  applying  one  of  the  preceding 
theorems of this section; if not, we need to choose another matrix P. This points to the 
474 
Linear Systems 
principal  shortcoming  of Lyapunov's  Direct  Method,  when  appHed  to general  sys-
terns. However, in the special  case of linear systems described by  (L), it is possible 
to construct  Lyapunov  functions  of the form  v(x)  = x^Px  in a systematic  manner. 
In doing  so, one first chooses the matrix  C in (7.3)  (having  desired properties),  and 
then  one  solves  (7.3) for  P.  Conclusions  are  then  drawn  by  applying  the  appropri 
ate results of this section. In applying this construction procedure, we need to know 
conditions under which (7.3) possesses a (unique) solution P for a given  C. We will 
address this topic next. 
We consider the quadratic  form 
v(x)  =  x^Px, 
P =  P^, 
and the time derivative of v(x)  along the solutions of (L), given by 
where 
C =  A^P  + PA 
v(x)  =  x^Cx, 
C =  C^, 
(7.5) 
(7.6) 
(1.1) 
and where all symbols are as defined  in (7.1) to (7.3). Our objective is to determine 
the as yet unknown matrix P in such a way that v(x)  becomes a preassigned  negative 
definite  quadratic form,  i.e., in such a way that  C is a preassigned negative  definite 
matrix. 
Equation  (7.7) constitutes  a system of  n(n + l)/2  linear  equations. We need to 
determine under what conditions we can solve for the n(n +  l)/2 elements, pik, given 
C and A. To this end, we choose a similarity transformation  Q such that 
or equivalently, 
QAQ-^  =  A, 
A  = Q-^AQ, 
(7.8) 
(7.9) 
where  A is  similar  to A and 2 is  a real nX n nonsingular  matrix.  From  (7.9)  and 
(7.7) we obtain 
(AfiQ-^PQ-^  + (Q'VPQ'^A 
= (Q-VCQ~^ 
or 
(A/Q ^QA = C, 
P =  (Q~VPQ~\ 
C = {Q-^fCQ'K 
(7.10) 
(7.11) 
In (7.11), P and  C are subjected  to a congruence  transformation  and  P  and  C  have 
the  same  definiteness  properties  as P and  C,  respectively.  Since  every  real nX n 
matrix  can be triangularized  (refer  to Subsection  2.2L), we can choose  Q in  such a 
fashion  that  A  == [dij] is  triangular,  i.e.,  dtj  = 0 for / > j. Note  that  in  this  case 
the eigenvalues  of A, Ai,..., A„, appear  in the main diagonal  of A. To simplify  our 
notation, we rewrite (7.11) in the form  (7.7) by dropping the bars, i.e., 
A^P^-PA  = C, 
C = C^, 
(7.12) 
2indwe assume  that A  = [aij] has been triangularized,  i.e., atj  =  0 f o r /> 
the eigenvalues  Ai,..., A„ appear in the diagonal of A, we can rewrite (7.12) as 
j.  Since 
2Xipn  =  cii 
^2iPii  + (Ai  + X2)pn  =  ci2 
(7.13) 
Since this system of equations is triangular, and since its determinant is equal to 
475 
2^Ar  • -A^ n ( A/  +  A/), 
i^j 
(7.14) 
CHAPTER6: 
Stability 
the matrix P can be determined  (uniquely) if and only if its determinant is not zero. 
This is true when all eigenvalues of A are nonzero and no two of them are such that 
\i  +  Xj  =  0.  This  condition  is  not  affected  by  a  similarity  transformation  and  is 
therefore  also valid for the original system of equations (7.7). 
We summarize the above discussion in the following  lemma. 
"LEMMA  7.1.  Let  A  E  /?""^"" and  let  Ai",..., A„ denote  the  (not  necessarily  distinct) 
eigenvalues of A. Then (7.12) has a unique solution for P corresponding to each  C E 
/?«><« if and only if 
A, 7^ a  A, + Ay 7^ 0 
for all /, ;. 
(7.15) 
• 
To construct v(x), we must still check the definiteness  of P. This can be done in 
a purely  algebraic  way; however,  in the present  case it is much  easier to apply  the 
results of this section and argue as  follows: 
1.  If  all  eigenvalues  of A have  negative  real  parts  [or equivalently,  if  the  equilib 
rium  jc  =  0 of  (L) is exponentially  stable in the large], and if  C in  (7.7) is neg 
ative  definite,  then  P  =  P^  must  be  positive  definite.  To prove  this  assertion, 
we choose for  (L) the function  v given in  (7.5) with v along the solutions of  (L) 
given by  (7.6)  and  (7.7). For purposes  of contradiction  we  assume  that P is not 
positive  definite.  Then  there  exists  XQ T^ 0  such  that  V(JCO)  =  :^o ^^o  —  0.  For 
the  solution  (pit) with  4>(to)  =  XQ,  V((/)(0)  is monotone  decreasing  with  increas 
ing  t,  since  v((/)(0)  — 0.  Also,"  since  v(0|r=^o  ""^  ^QQ^O <  0",  it  follows  that  for 
t  >  to, v((f)(t)) <  v(x(to))  =  v(jco)  ^  0.  Since  by  assumption  all  the  eigenval 
ues  of A have  negative  real  parts,  we  know  that  the  equilibrium  JC =  0  of  (L) 
is  uniformly  asymptotically  stable.  Thus,  lim^-^oo v((/)(0)  =  0,  which  leads  to  a 
contradiction. Thus, P must be positive  definite. 
2.  If  at least  one  of the  eigenvalues  of A has  positive  real  part  and  no real part  of 
any eigenvalue of A is zero and if (7.15) is satisfied,  and if C in (7.7) is negative 
definite, then P cannot be positive definite; otherwise we could apply Theorem 7.2 
to come up with  a contradiction.  If in particular the real parts of all  eigenvalues 
of A  are  positive,  then  P  must  be  negative  definite.  [Note  that  in  this  case  the 
equilibrium  JC =  0 of (L) is completely  unstable.] 
Now suppose that at least one of the eigenvalues of A has positive real part, and 
suppose  that  any  one  of  the  two  conditions  or both  conditions  given  in  (7.15)  are 
not satisfied.  Then we cannot construct v(x)  given in (7.5) in the manner  described 
above (i.e., we cannot determine P in the manner described above). In this case we 
form  a  matrix  Ai  =  A  -  81,  where  /  denotes  the  ^  X n  identity  matrix  and  8  is 
chosen  so that A\  has as many eigenvalues  with positive real part as A, but none of 
the conditions in (7.15) are violated. Then the equation 
A\P  +  PAi  =  C, 
with C negative definite, can be solved for P, and P is then clearly not positive defi 
nite. The derivative of the function  v(x)  =  x^Px  is a quadratic  form  whose  matrix 
476 
Linear Systems 
is of the  form 
(Ai  +  81/P  +  P(Ai  ^81)  =  C  +  28P, 
which  is negative  definite  for  a sufficiently  small  8.  The function  v(x)  constructed 
in this way now satisfies  the hypotheses of Theorem 7.3 for  system x  =  Ax. 
Summarizing  the above discussion, we have the following  result. 
THEOREM 7.4.  If all the eigenvalues of the matrix A have negative real parts, or if at 
least one eigenvalue has a positive real part, then there exists a Lyapunov function of the 
form 
v(x)  = x^Px,  P  =  P^, 
whose derivative along the solutions of (L) is definite (i.e., it is either negative definite 
or positive definite). 
• 
EXAMPLE 7.4.  We consider the system (L) with 
0  11 
-1  oj' 
The eigenvalues of A are Ai, A2 =  ±j  and therefore  condition  (7.15) is violated. Ac 
cording to Lemma 7.1, the Lyapunov matrix equation 
A^P  + PA  = C 
does not possess a unique solution for a given  C. We now verify  this for two  specific 
cases. 
(i) When C  =  0, we obtain 
"""0 "
1 
- 1] 
OJ [pn 
Pn 
P22. 
+  Pn 
.Pn 
P12I 
Pii]  [-1 
0.  = 
-2p\2 
Pn  -  P22 
2/712 
.Pn  -  P22 
0  0 
0  0. ' 
OT pi2  = 0 and pu  = ^22- Therefore, for any a E:  R, the matrix P  = al is d. solution of 
the Lyapunov matrix equation. In other words, for C  =  0, the Lyapunov matrix equation 
has in this example denumerably many solutions, 
(ii) When C  =  -21,  we obtain 
-2/712 
Pn  -  P22 
Pn  -  P22 
2/712 
-2 
0 
0 
-2 
or Pn  = P22 and pu  =  1 and pu  =  - 1,  which is impossible. Therefore, for C 
the Lyapunov matrix equation has in this example no solutions at all. 
-2/, 
It turns out that if all the eigenvalues of matrix A have negative real parts, then 
we can compute P in (7.7)  explicitly. 
THEOREM 7.5.  If all eigenvalues of a real n X n matrix A have negative real parts, 
"then for each matrix C E /?""><""", the unique solution of (7.7) is given by 
/•CO 
Jo 
(7.16) 
Proof, If all eigenvalues of A have negative real parts, then (7.15) is satisfied and there 
fore (7.7) has a unique solution for every C E R^^f^, To verify that (7.16) is indeed this 
solution, we first note that the right-hand side of (7.16) is well defined,  since all eigen 
values of A have negative real parts. Substituting the right-hand side of (7.16) for P into 
(7.7), we obtain 
r°° 
T 
f^  T 
A^P  + PA=\ 
"A^e""^  \-C)e'^'dt+\ "
e^'i-Qe'^'Adt 
Jo 
0  at 
Jo 
All 
JJ. 
CHAPTER 6 
"=  e^X-Oe""""'  =  C", 
10 
which proves the theorem. 
6.8 
LINEARIZATION 
In this section we consider nonlinear,  finite-dimensional,  continuous-time  dynamical 
systems described by equations of the  form 
w  =  f(w\ 
(A) 
where  /  G  C^(R^, R^).  We assume  that  w  =  0 is  an  equilibrium  of  (A). In  accor 
dance with Subsection  1.11 A, we linearize  system (A) about the origin to obtain 
X G R^,  where F  G  C(R^,  R^)  and where A denotes the Jacobian of f(w)  evaluated 
at w  =  0, given by 
x  =  Ax  + F(x), 
(8.1) 
A  =  ^ ( 0 ), 
dw 
and where 
Associated with (8.1) is the linearization  of (A), given by 
F(x)  =  o(\\x\\) 
||;c|| ^  0. 
as 
(8.2) 
(8.3) 
(L) 
In the following, we use the results of Section 6.7 to establish criteria that allow 
us to deduce the stability properties of the equilibrium w  =  0 of the nonlinear system 
(A) from  the stability properties of the equilibrium  y  =  Oof  the linear system (L). 
y  =  Ay, 
THEOREM  8.1.  Let A  G R''^''  be a Hurwitz matrix," let F  G C(/?"""," R"""")",  and assume 
that (8.3) holds. Then the equilibrium x  =  0 of (8.1) [and hence, of (A)] is exponentially 
stable. 
Proof. Theorem  7.4  applies  to (L)  since all the eigenvalues  of A have negative real 
parts. In view of that theorem (and the comments following Lemma 7.1), there exists a 
symmetric, real, positive definite nX  n matrix P such that 
where C is negative definite. Consider the Lyapunov function 
PA + A^P  = C, 
v{x)  = x^Px. 
The derivative of v with respect to t along the solutions of (8.1) is given by 
v(x)  =  x^Px  +  x^Px 
=  {Ax + F{x)fPx  + x^P{Ax  + F{x)) 
=  x^Cx  + 2x^PF(x). 
(8.4) 
(8.5) 
(8.6) 
478 
Linear Systems 
Now  choose  7 <  0  such  that x^Cx  <  3/  \\x\\^ for  all x  G  R^.  Since  it  is  assumed  that 
(^•^)  holds,  there  is  a  5  >  0  such  that  if  ||x||  <  5,  then  ||PF(x)||  <  —7  ||x||  for  all 
:\\x\\<  d}.  Therefore,  for  all x  G B{d)  we obtain, in view of (8.6), 
X e  B{d)  =  {xeR'^ 
the  estimate 
(8.7) 
Now,  let  a  =  minn^^-n^^ v(x).  Then  a  >  0  (since P  is positive  definite).  Take  A  G 
v(x)<3r||x||2-27||x||2  =  7||x||2. 
(0, a ),  and let 
C^={xe 
B{5)  =  {xeR'': 
\\x\\ <  5}  : v(x)  <  A}. 
(8.8) 
Then C^  C B{5).  [This can be  shown by  contradiction.  Suppose that C^  is not  entirely 
inside B{5).  Then there is a point xeC^ 
that lies on the boundary of 5(5). At this point, 
v(x)  >  a  >  A. We have thus arrived at a contradiction.] The set C^  has the property that 
any solution of (8.1) starting inC^  ait  = to will stay in Q  for ^H ^  >  ^0 ^  0- To see this, 
we  let  (l){t,to,xo)  =  0(r)  and  we recall that  v(x)  <  7||x|p,7<  0,x  G B{d)  D Q-  Then 
v(0(O)  <  0 implies  that  v{^{t))  <  v(xo)  <  A for  all ^ >  ^o >  0. Therefore,  ^{t)  G  Q 
for  all 
t>to>0. 
We now  proceed  in  a  similar  manner  as in the  proof  of  Theorem  7.1  to  complete 
this proof. In doing  so, we first obtain the  estimate 
v((|)(0)<(^^)v((|)(0), 
where  7 is given in (8.7) and C2 is determined by the relation 
ci\\xf  < v{x)=x^Px<C2\\xf. 
(8.9) 
(8.10) 
Following now in an identical manner as was done in the proof of Theorem 7.1, we have 
m)\\<(-] 
||xo|k^/'(^/^^)(^-^°\ 
t>to>0, 
(8.11) 
whenever  XQ  G  5 ( / ),  where  /  has  been  chosen  sufficiently  small  so  that  B(r')  C  C^. 
• 
This proves that the equilibrium x =  0 of (8.1) is exponentially  stable. 
It is important to recognize that Theorem  8.1 is a local  result  that yields  sufficient 
conditions  for  the  exponential  stability  of  the  equilibrium  x  =  0  of  (8.1);  it  does  not 
yield  conditions  for  exponential  stability  in  the  large.  The  proof  of  Theorem  8.1, 
however,  enables  us  to  determine  an  estimate  of  the  domain  of  attraction  of  the 
equilibrium x  =  0  of  (A), involving  the  following  steps: 
1.  Determine  an  equilibrium,  x^,  of  (A)  and  transform  (A)  to  a  new  system  that 
translates Xe to the  origin x  =  0  (refer  to  Section  6.3). 
2.  Linearize  (A)  about  the  origin  and  determine  F(x),A,  and  the  eigenvalues  of A. 
If all eigenvalues  of A have negative  real parts, choose  a negative  definite  matrix 
3. 
C  and  solve the  Lyapunov  matrix  equation 
4.  Determine  the  Lyapunov  function 
C=A^P^PA. 
v{x) 
=x^Px. 
5.  Compute  the  derivative  of  V along  the  solutions  of  (8.1), given  by 
6.  Determine  5  >  0  such  that  v(jc)  <  0 for  all x  G B{d)  -  {0}. 
v{x)=x^Cx^2x^PF{x). 
479 
CHAPTER  b 
Stability 
7.  Determine  the  largest  A  =  AM  such  that  Cx^  ^  ^ ( S ),  where 
"CA  =  {x  G  B!"" : v(x)  <  A}. "
8.  Cxyi is  a  subset  of the  domain  of attraction  of the  equiUbrium  x  =  0 of  (8.1),  and 
hence,  of  (A). 
The  above  procedure  may  be  repeated  for  different  choices  of  matrix  C  given 
in  step  (3),  resulting  in  different  matrices  P/,  which  in  turn  may  result  in  different 
estimates  for  the  domain  of  attraction,  C\ 
,  /  G  A,  where  A  is  an  index  set.  The 
union  of  the  sets  C\^  =  Di,  D  =  U/D/,  is  also  a  subset  of  the  domain  of  attraction 
of  the  equilibrium  x  =  0  of  (A). 
THEOREM  8.2.  Assume  that A is a real  nX  n matrix  that has at least one  eigenvalue 
"with positive real part. Let F  E  C(/?""", /?''), and assume that  (8.3) holds. Then the equi 
librium  X  =  0 of (8.1)  [and hence, of (A)] is  unstable. 
Proof,  We  use Theorem  7.4  to choose  a real,  symmetric  n  X  n matrix  P  such  that  the 
matrix PA  + A^P  =  C is negative definite. The matrix P is not positive definite, or even 
positive semidefinite  (refer to the comments following  Lemma 7.1). Hence, the  function 
v(x)  =  x^  Px  is  negative  at  some points  arbitrarily  close  to  the  origin.  The  derivative 
of  v(x)  with  respect  to  t  along  the  solutions  of  (8.1)  is  given  by  (8.6). As  in  the  proof 
of Theorem  8.1," we can  choose  a y  <  0 such that  x^Cx  <  3711x11^ for  all x  E  P""",  and 
in  view  of  (8.3)  we  can  choose  a  5  >  0  such  that  ||PF(x)||  <  y\\x\\  for  all  x  E  B(8). 
Therefore,  for all x  E  B(8),  we obtain  that 
Now let 
Hx) ^  3r||x|p  -  2r||x|p  = rll^lp. 
G  =  {xE  B(8)  : v(x)  <  0}. 
The boundary  of G is made up of points where either v(x)  =  0 or where  ||x||  =  8.  Note 
in particular that the equilibrium  x  =  0 of (8.1) is in the boundary of G. Now  following 
an identical procedure as in the proof of Theorem 7.3, we show that any solution (/)(0 of 
(8.1) with 4>(to)  =  XQ E: G must escape G in finite time through the surface  determined 
by  Ikll  =  8.  Since the  above argument  holds for  arbitrarily  small  5  >  0, it follows  that 
• 
the origin  x  =  0 of (8.1) is unstable. 
Before  concluding  this  section,  we  consider  a few  specific  cases. 
EXAMPLES.1.  The Lienard  Equation  is given by 
w  +  g{w)w  +  w  =  0, 
where g  E  C^(R,  R) with ^(0)  >  0. Letting  xi  =  w and  X2  =  w, we obtain 
Xi  =  X2 
X2  =  - Xi  -  g(Xi)X2. 
X2  =  - Xi  -  g{Xi)X2. 
(8.12) 
(8.13) 
Let x^ 
Then 
(xi,  X2), f{xf  =  (/i(x),  /2(x)), and let 
"""1^(0)  1^(0)"" "
dxi 
1^(0)  1^(0) 
_dX\ 
7(0)  =  A  = 
dX2 
dX2 
= 
0 
-1 
1 
• 
- ^ ( 0 ). 
X =  A^ 
: +  [/(x)  -  Ax]  = 
Ax 
+  F(x\ 
480 
Linear  Systems 
where 
F(x) 
0 
l[^(0)  -  g(Xi)]X2\ 
The origin x  =  0 is clearly an equilibrium of (8.12) and hence of (8.13). The eigenvalues 
of A are given by 
Ai,  A2  = 
JgW 
and therefore, A is a Hurwitz  matrix. Also, (8.3) holds. Therefore,  all the conditions of 
Theorem 8.1 are satisfied. We conclude that the equilibrium x  =  0 of (8.13) is  exponen 
tially  stable. 
• 
EXAMPLE  8.2.  We consider the system given by 
X\  =  -Xi  +  X\{x\  +  x\) 
X2  =  -X2  +  X2(xj  +  x\). 
(8.14) 
The  origin  is  clearly  an  equilibrium  of  (8.14). Also, the  system  is  already  in  the  form 
(8.1) with 
-1 
0 
0 
-1 
F{x)  = 
\x\{x\  +  X2)l 
[x2{x\ +  xl)y 
and  condition  (8.3)  is  clearly  satisfied.  The  eigenvalues  of A are  Ai  =  - 1,  A2  =  - 1. 
Therefore,  all conditions of Theorem  8.1  are satisfied  and we conclude that the equilib 
rium  x^  =  (xi,  X2) =  0 is exponentially  stable;  however,  we cannot conclude  that  this 
equilibrium  is exponentially  stable in  the large. Accordingly,  we  seek to determine  an 
estimate for the domain of attraction  of this  equilibrium. 
We choose C  =  -I  (where /  G R^^^  denotes the identity matrix) and we solve the 
matrix equation A^P  +  PA  =  C to obtain  P  =  (1/2)/, and  therefore, 
V(xi,  X2) =  x^Px  =  \(x]  +  xl). 
Along the solutions of (8.14) we obtain 
v(xi,  X2) =  x^Cx  +  2x^PF(x) 
=  -(x^  +  xj)  +  (xi  + 
xjf. 
Clearly,  v(xi, X2) <  0  when  (xi, X2) ^  (0, 0)  and  Xj  +  ^2  <  1. In  the  language  of  the 
proof of Theorem  8.1, we can therefore  choose 8  =  1. 
Now let 
Ci/2  =  {xeR^: 
v(xi, X2)  =  \(x1  + x\)  <  i}. 
Then clearly. Cm  C  B(8X  8  =  1, in fact  Cm  =  B(8).  Therefore, the set {x  1 
X2 <  1} is  a subset  of the domain  of  attraction  of the equilibrium  (xi, X2)^ 
tem(8.14). 
R^:xj  + 
•-  0  of  sys-
• 
EXAMPLES.3.  The differential equation governing the motion of a pendulum is given by 
6  -\-  asinO  =  0, 
(8.15) 
where  a  >  0 is  a constant  (refer  to Chapter  1). Letting 6 
the system  description 
xi  and  6  =  X2, we  obtain 
Xi  =  X2 
X2 = 
-asinxi. 
(8.16) 
The points  x^.^^  =  (0, 0)^ and xf^  =  (77, 0)^ are equilibria of (8.16). 
(i) Linearizing (8.16) about the equilibrium x^^\ we put (8.16) into the form (8.1) 
with 
A = 
0  1 
0 
-a 
481 
CHAPTER  6 
Stability 
The eigenvalues of A are Ai, A2  =  ±7 V^. Therefore, the results of this section (Theo 
rem 8.1 and 8.2) are not applicable in the present case. 
(ii) In (8.16), we let y\  ~  x\  -  TT and 3^2 =  ^2- Then (8.16) assumes the form 
yi 
-(2sin(yi  +  77). 
(8.17) 
The point  (3^1, 3^2)^  =  (0,0)^  is clearly  an equilibrium  of  system  (8.17). Linearizing 
about this equilibrium, we put (8.17) into the form (8.1), where 
A = 
0  1 
a  0 
F(yh  yi)  = 
0 
-a(sin(3;i  +77)  +  yO. 
The eigenvalues of A are Ai, A2 =  a, -a.  All conditions of Theorem 8.2 are satisfied and 
we conclude that the equilibrium xf^  =  (TT, 0)^ of system (8.16) is unstable. 
• 
PART 2 
INPUT-OUTPUT STABILITY OF CONTINUOUS-TIME SYSTEMS 
6.9 
INPUT-OUTPUT STABILITY 
We now turn our attention to systems described by the state equations 
X =  A(t)x  +  B(t)u 
y  =  C(t)x  +  D(t)u, 
(9.1) 
where  A  G  C(R,  T^'^^'^), B  G  C(R,"  7^""^^)","  C  G  C(K  R^'""'')",  and  D  G  C(R,"  RP""""""^) "
[resp.,  A  G  C{R^,"  i?""^^'^)",  B  G  C{R^,"  R'""'""'^)",  C  G  C{R+," RP"""""""")",  and  D  G  C(R^, 
RP^^)].  In the preceding sections of this chapter we investigated the internal  stability 
properties  of system  (9.1) by  studying the Lyapunov  stability  of the trivial  solution 
of the associated  system 
w  =  A(t)w. 
(LH) 
In  this  approach,  system  inputs  and  system  outputs  played  no role. To account  for 
these,  we  now  consider  the  external  stability  properties  of  system  (9.1),  called 
input-output  stability:  every  bounded  input  of  a system  should  produce  a  bounded 
output. More specifically, in the present context, we say that system (9.1) is  bounded-
input/bounded-output  (BIBO)  stable  if for all to and zero initial conditions at f  =  to, 
every bounded input defined  on  [to, ^)  gives rise to a bounded response on  [to, 0°). 
A  bounded  matrix  D(t)  does  not  affect  the  BIBO  stability  of  (9.1),  while  an 
unbounded  D(t)  will give rise to an unbounded response to an appropriate  constant 
input. Accordingly,  we will consider  without  any loss of generality  the case  where 
D(t)  =  0, i.e.,  throughout  this  section  we  will  concern  ourselves  with  systems  de 
scribed by equations of the  form 
482 
Linear Systems 
X  =  A{t)x  4- B{t)u 
y  =  C(t)x. 
(9 2) 
We will find it useful  to use a more restrictive concept of input-output  stability 
in establishing  various results: we will say that the system  (9.2) is uniformly  BIBO 
stable  if there  exists  a constant  k>  Q that  is independent  of  ^,  such that  for  all  ^ 
the  conditions 
X{tQ)  =  0 
||w(0|| ^ 1, 
t^ 
to, 
imply that ||j(Oli  — k for all t  >  to. (The symbol || •  || denotes the Euclidean  norm.) 
It turns out that for the class of problems considered herein, BIBO stability  and 
uniform  BIBO  stability  amount to the same concepts. (We will not, however,  prove 
this  assertion  here.)  Accordingly,  we will phrase  all  subsequent  results  in terms of 
uniform  BIBO  stability,  rather  than  BIBO  stability.  These  results  will  involve  the 
impulse response matrix of (9.2) given by 
Har) = f^«*(''-)^(->'  ^;^' 
t <  T, 
[  U, 
and the controllability  and observability  Gramian  given, respectively, by 
W(to, ^i)  - 
and 
M(% ^i)  = 
J/o 
ch 
0 (%  t)B(t)B^(t)^^(to, 
t)dt 
^{t,  tof  C{tf  C{t)^{t,  to) dt, 
(9.3) 
(9.4) 
(9.5) 
In these results we will establish  sufficient  conditions for uniform  BIBO stability of 
(9.2) and also necessary and sufficient  conditions for uniform BIBO stability of (9.2). 
Furthermore,  we  will  present  results  that  make  a connection  between  the  uniform 
BIBO  stability  of  (9.2)  and  the  Lyapunov  exponential  stability  of  the  equilibrium 
w  =  0 of (LH).  In view of the latter results, we will usually  assume that to ^  0. 
At the end of this section we will also present specialized stability results for the 
time-invariant  systems described by equations of the  form 
X =  Ax  +  Bu 
y  ^  Cx, 
(9.6) 
"where  A  G  Z^'^^^""", B  E  Z^^^^'^, and  C  G  RP''''.  Associated  with  system  (9.6)  is  the 
free  system described by equations of the  form 
Recall that for  system (9.6) the impulse response matrix is given by 
P  =  Ap, 
H(t)  =  Ce'^'B, 
=  0, 
t  >  0, 
/  <  0, 
and the transfer  function  matrix is given by 
H(s)  =  C(sl  -A)-^B. 
(L) 
(9.7) 
(9.8) 
THEOREM 9.1.  The system (9.2) is uniformly BIBO stable if and only if there exists a 
finite  constant L >  0 such that for all t and to, with t > to, 
\\H{t,T)\\dr£L. 
(9.9) 
483 
CHAPTER 6: 
Stability 
The first part of the proof of Theorem 9.1 (sufficiency)  is straightforward.  In 
deed, if ||M(r)|| <  1 for all t^tQ  and if (9.9) is true, then we have for all f ^  fo that 
lb(Oll = 
to 
Hit,  T)U{T)  dr 
< 
\\H(t,T)u(T)\\dr 
Jto 
rt 
\\H(t,T)\\\\u(T)\\dT 
I 
<  \ 
Jto 
\\H(t,T)\\dT^L. 
Therefore, system (9.2) is uniformly BIBO stable. 
In proving the second part of Theorem 9.1 (necessity), we simplify  matters by 
first  considering in (9.2) the single-variable case (n = 1) with the input-output de 
scription given by 
y(t)  = 
h(t,T)u(r)dT. 
(9.10) 
For purposes of contradiction,  we assume that the system is BIBO stable, but no 
finite  L exists such that (9.9) is satisfied. Another way of stating this is that for every 
finite L, there exist to = to(L) and ti  = ^i(L), ti > to, such that 
We now choose in particular the input given by 
\h(tuT)\dr>  L. 
to 
r +1 
u(t) = \  0 
[ -1 
if/z(^,T)>0, 
ifh(t,r)  = 0, 
ifh(t,T)<0, 
(9.11) 
to ^  t ^  ti. Clearly, \u(t)\ <  1 for all t ^  to. The output of the system att  = ti due 
to the above input, however, is 
rti 
rti 
y(ti)  = 
h{ti,  T)U{T)dr 
= 
\h{ti,T)\dT  >  L, 
Jto 
Jto 
which contradicts the assumption that the system is BIBO stable. 
The above can now be extended to the multivariable case. In doing so, we apply 
the single-variable result to every possible pair of input and output vector compo 
nents, we make use of the fact  that the sum of a finite number of bounded  sums 
will be bounded,  and we recall that a vector is bounded if and only if each of its 
components is bounded. We leave the details to the reader. 
In the preceding argument we made the tacit assumption that u is continuous, 
or piecewise continuous. However, our particular choice of u may involve nonde-
numerably  many  switchings  (discontinuities)  over a given finite-time interval.  In 
such cases, u is no longer piecewise continuous; however, it is measurable (in the 
484 
Linear Systems 
Lebesgue sense). This generalization can be handled, though in a broader mathemat-
i^al setting  that we do not wish to pursue  here. The interested  reader  may want to 
refer,  e.g., to the books by Desoer and Vidyasagar  [5], Michel and Miller  [17],  and 
Vidyasagar  [25] and the papers by Sandberg  [21] to [23] and Zames  [26], [27]  for 
further  details. 
From Theorem 9.1 and from  (9.7) it follows  readily that a necessary  and suffi 
cient condition for the uniform  BIBO stability of system (9.6) is the condition 
\\H(t)\\dt<^. 
(9.12) 
Jo 
COROLLARY 9.1.  Assumc that the equilibrium w =  0 of (L^) is exponentially stable 
and suppose there exist constants ^  > 0 and y > 0 such that for all t, \\B{t)\\  <  j8  and 
||C(0|| ^  7- Then system (9.2) is uniformly BIBO stable. 
Proof, Under the hypotheses of the corollary, we have 
H{t,T)dTl  <  [  \\H(t,T)\\dT 
^0 
II 
-'^0 
=  f'  \\C(t)^(t, T)B(T)\\dT <  7i8 f'  ||cD(^, T)|| Jr. 
Since the equilibrium w =  0 of (LH) is exponentially  stable, there exist 6 > 0, A > 0 
such that ||0(r, T)|| <  8e~^^^~^\ t >  r. Therefore, 
\\H{t,T)\\dT^  [  ypde-^^'-'-Ur 
to 
JtQ 
ySp  A 
A 
for all T, t with r >  r. It now follows from Theorem 9.1 that system (9.2) is uniformly 
BIBO stable. 
• 
As  indicated  earlier,  we seek  to  establish  a  connection  between  the  uniform 
BIBO  stability  of (9.2) and the exponential  stability  of the trivial  solution of (LH). 
We will  accomplish  this by means  of an intermediate  result for systems  described 
by equations of the  form 
X = A(t)x  + B(t)u 
^'' 
y  = X. 
^' 
(9.13) 
Before stating and proving the next result, we recall that if 5  G R^^^^ J  E R^^^ 
are  symmetric,  then the notation  S  > 0 signifies  that S is positive  definite,  and the 
notation S  > T indicates  that the matrix S -  T is positive definite,  i.e., S -  T  > 0. 
Also,  if  Q(t)  =  Q(tf  G C(R," /^""><"")", the condition  that  there  is a constant  r] > 0 
such that Q(t)  >  17/ for all ^ E  i? is equivalent to the statement that z^Q(t)z  ^  r]\\z\\^ 
"for all f E  /? and all z E R"""". "
Next,  suppose that there is a constant a  > 0 such that ||A(0|| ^  oc for all t ^  R, 
and  let $(^, r)  denote  the state  transition  matrix  of (LH). In the proof  of the next 
result we will require the estimate 
||(I)(r,"T)||<  ^""^ "
k - T| <  8. 
(9.14) 
To  obtain  this  estimate  we let (f)(t, r, ^)  =  0 (0  denote  the solution  of  (LH)  with 
(/)(T)  == ^, and we compute 
^Mfm 
at 
= ^U(tt  = ktfm  + <i>itfm 
=  <f){tY Aitf 
^{t)  +  (i){tf  Ait)<f){t) 
at 
——^ 
CHAPTER 6: 
Stability 
for  all  t  >  T. Letting  ||(^(0|F  =  v{t),  we  have 
— < lav, 
V(T)  = ll^lp, 
which  yields 
or 
mt 
^  e-^'-^m  ^ 
e-'\U 
which  in  turn  yields  (9.14). The  case  when  r  >  ns  treated  similarly. 
THEOREM  9.2.  Suppose that there exist positive constants a,  /3, e, and 8 such that for 
all t, \\A{t)\\  <  a,  \\B{t)\\  <  j8, and ^(^0, ^o, +5)  ^  e/,  where /  denotes the n X w identity 
matrix  and  W(-)  denotes  the  controllability  Gramian  given  in  (9.4). Then  the  system 
(9.13) is uniformly BIBO stable if and only if the trivial solution of {LH) is exponentially 
stable. 
Proof,  Under  the  above hypotheses, it follows  from  Corollary  9.1 that if the trivial so 
lution of {LH)  is exponentially  stable, then  system (9.13) is uniformly  BIBO  stable. 
Conversely,  assume  that  the  system  (9.13)  is  uniformly  BIBO  stable  and  assume 
that the hypotheses of the theorem are satisfied  with the given constants a,  /3, 6, and  e. 
The assumption  W(^, t^ + 8)>  el  ensures that  W~^{tQ, to +  8)  exists, is bounded,  and 
is independent  of ^o- We now  consider 
/  =  [ 
Jr-8 
[(I>(T, r])B(r])Bir]Y^(T,  r]f  d7]W\T 
-  8, r). 
(9.15) 
Since  B(r])  is  bounded  and  since  ^(r,  r]) is  bounded  over  |T -  r/l  <  5,  there  exists  a 
constant  c  >  0 such that 
||5(r/)^cI)(T, r])'^W~\T  -  8, T)||  <  c. 
(9.16) 
Premultiplying  (9.15) by ^(t,  r)  and using the bound (9.16) and the properties of norms, 
we obtain 
| | c D a T ) | | < c f'  m,rj)B(rj)\\dri. 
JT-8 
(9.17) 
Since system (9.13) is uniformly  BIBO stable, there exists a /: >  0 such that 
mt,r])B(v)\\dri<k 
Jt-n8 
(9.18) 
for all positive integers n, where k is independent  of n and t. From (9.18) it follows  that 
m.V)B(v)\\dv 
=  f  mt,v)B(ri)\\d7]+[ 
\\^(t,7])B(rj)\\drj 
t-nd 
Jt-S 
+  •••+ 
rt-n8+8 
Jt-28 
\\^(t,r))B{'n)\\dy)<k. 
(9.19) 
From (9.17) to (9.19) it follows  that 
c-^W^it," Oil +  c-^W^iU t  -  8)\\ +  •""  + c-^W^it", t-n8  + 5)11 
Jt-n8 
\\^{t,y))B{y])\\d7)<k. 
t-n8 
486 
Linear Systems 
Since the above is true for  any positive integer n, we have 
c'Wl^it, 
t)\\  + \\^(t, t  -  d)\\ +  • • • +  \\^{t, t -  nd  + 8)\\ +  •••)<  ^ 
or 
\\^{t, Oil +  ll^a  t -  5)11  +  • • • +  \\^{t," t-nd  +  5)11  +  ""•  <ck. "
To complete the proof, we must show that \[^  \\^{t, y]% drj  is finite. We will accom 
plish this by  showing that |_^g ||^(^,  17)11 drj  is finite for  any positive integer. To this end 
we observe that for  any n, t given, there exists a positive integer m such that 
||a>(/, T/)|Mr7  <  f 
\m,7j)\\drj. 
-n8 
Jt—m8 
If we apply the Mean Value Theorem for Integrals to 
||cDar;)||Jr^= 
f 
Jt-m8 
f  mt,v)\\d7i+C 
Jt~8 
Jt-28 
110^77)11^7, 
+  •••+ 
rt-(m-l)8 
Jt-m8 
mt,v)\\dv> 
we obtain for  fjt  ^  [t -  id, t -  (i  -  1)5], /  =  1,...,  m, that 
||(Da 77)11^7, <  [ 
110^77)11^7, 
-nS 
Jt-m8 
<  5[||oa 77011 + l|oa 772)11 + • • • + iioa 77^)111 
Now invoking Theorem 5.5(iv)  of this chapter, we conclude that the equilibrium w  =  0 
• 
of (LH)  is exponentially  stable. 
THEOREM  9.3.  Suppose  that  there  exist  positive  constants  a,  jS,  and  y  such  that 
||A(0|| ^  «, II^Wll  —  P^ and ||C(0|| ^  y for all t and assume that there exist positive con 
stants e 1, 62, 5i, and 52  such that for all to,  W(to, ^o + ^i)  —  ^ i^ and M(to,  to + 82)  ^  62/, 
where M(')  denotes  the observability  Gramian  given  in (9.5). Then  the system  (9.2)  is 
uniformly  BIBO  stable  if  and  only  if  the  equilibrium  w  =  0 of  (LH)  is  exponentially 
stable. 
Proof,  Uniform  exponential  stability  of the trivial  solution of (LH)  and the  hypotheses 
of this  theorem  imply  the uniform  BIBO  stabiHty  of  system  (9.2)  by  Corollary  9.1. To 
complete the proof, we show that the hypotheses  of the theorem and the BIBO  stability 
of system (9.2) imply the exponential  stability of the equilibrium w  =  0 of  (LH). 
To set up a contradiction,  assume that uniform  BIBO stability of system (9.2) does 
not imply  exponential  stability  of the trivial  solution  of  (LH).  Then by Theorem  9.2, it 
must not imply uniform  BIBO stability  of system (9.13). For if there is no bound on the 
state, then there can be no bound on the output. To see this, let  w  =  0 on  ^ <  r  <  r +  5 
and  obtain 
t+8 
|b(T)|pdr  =  xitf[\ 
rt+8 
Jt 
<Dft rfdryCirmt, 
r)dr]x{t) 
=  x(tfM(t, 
t  +  8)x(t)  <  max  d\\y(T)f, 
t<T<t  + 8 
and  therefore, 
max 
||>;(T)f  >  d-'\\x(t)f\,^AM(t, 
t<T<t + 8 
t + 5)], 
where Amin[^(^, t +  5)1 denotes the smallest eigenvalue of M(t,  t +  5). Thus, if the state 
X is not bounded for all bounded  w, then y will also not be bounded. This shows that the 
uniform  BIBO  stability  of (9.2) implies the uniform  BIBO stability  of (9.13). Applying 
Theorem 9.2, we conclude that the equilibrium  w  =  Oof  (LH)  is exponentially  stable. 
• 
487 
CHAPTER 6* 
Stability 
EXAMPLE  9.1.  We consider the system described by the scalar  equations 
. 
X  +  U 
1 
^^^' 
y  =  X. 
(9.20) 
This  system is clearly  controllable  and observable. The zero-input response of this sys 
tem is determined by the differential  equation 
•^ 
Jw, 
w(to)  =  xo, 
to >  0. 
(9.21) 
It is easily verified  that the solution of (9.21) is given by 
ct>(t,to,xo)=  \ ^ ^o 
(9.22) 
[refer to Eqs. (4.5) and (4.6)]. The origin w  =  0 is the only equilibrium of (9.21), and as 
seen  from  (9.22), this  equilibrium  is uniformly  stable  and  asymptotically  stable;  how 
ever, it is not uniformly  asymptotically  stable, and hence, it is not exponentially  stable. 
The state transition matrix of system (9.21) is given by 
1'(Uo)  =  y ^. 
With ^  =  0 and bounded input u(t)  =  1, /  >  0, the zero-state response of system (9.20) 
is 
y(t,to>xo)= 
r  t 
^(t,T)u(T)dT  = 
Jo 
r  ^  1  _(_ 
/T-
T-r-dr 
Jo  ^ + ^ 
=  ^. 
(9.23) 
Summarizing,  even  though  the  zero  input  response  of  system  (9.20)  tends  to  zero 
as  ^ -^  00, the  hypotheses  of  Theorem  9.3  are  not  satisfied  since  this  decay  is  not  ex 
ponential  and  uniform  [i.e., the  origin  w  =  0 of  (9.21)  is  not  exponentially  stable]. In 
accordance with Theorem 9.3, we cannot expect the zero-state response of system (9.18) 
• 
to be bounded for  arbitrary bounded inputs. This is evident from  expression  (9.23). 
Next,  we  consider  in particular  the  time-invariant  system  (9.6). For  this  system 
it  is  easily  verified  that  Theorem  9.3  reduces  to  the  following  appealing  result  that 
connects  the uniform  BIBO  stability  of  system  (9.6)  and  the  exponential  stability  of 
the  trivial  solution  of  (L). 
THEOREM  9.4.  Assume  that  the  time-invariant  system  (9.6)  is  controllable  and  ob 
servable. Then  system  (9.6) is uniformly  BIBO  stable if and only if the trivial  solution 
• 
of (L) is exponentially  stable. 
EXAMPLE9.2.  Consider the  system 
where 
"""^  "" "
0  1 
i  or 
.1  0. 
X =  Ax  +  Bu 
y  =  Cx, 
0 
ir 
.1.  ' 
B  = 
"^"" "
^  =  ^^ 
- H-
The eigenvalues  of A are A i  =  1, A2  =  - 1, and therefore  the equilibrium w 
of the system w  =  Aw  is unstable. The state transition matrix of this system is 
488 
Linear Systems 
0(^, 0)  = 
and the impulse response of the system is 
H{t)  =  COaO)5  = 
-e-\ 
Thus, even though the equihbrium  w  =  0 of w  =  Aw is unstable, the system is uni 
formly BIBO stable. The reason for this is that the system is not observable, as is verified 
by noting that 
C 
CA 
1 
-1 
-1 
1 
which is singular. Thus, the hypotheses of Theorem 9.4 are not valid, with the conse 
quence that the unstable mode of the system is not observable at the system output. 
• 
EXAMPLE9.3.  We no w consider the system 
X  =  Ax  ^- Bu 
y =  Cx, 
where A and B are as in Example 9.2 and 
C  =  [\  2]. 
The  eigenvalues  and  the  state  transition  matrix  of  this  system  are  identical  to those 
of the system given in Example 9.2. This system is both controllable and observable, 
and the impulse response is 
H{t)  =\e'- 
\e-\ 
Since the system is controllable and observable and since the equilibrium w =  0 of 
the system w  = Aw is unstable, it follows from Theorem 9.4 that the system cannot be 
• 
uniformly BIBO stable. This can be verified directly by inspecting H(t) above. 
Next,  we  recall  that  a  complex  number  Sp is  a pole  of  H(s)  =  [hij(s)]  if  for 
some pair (/, j),  we have \hij(sp)\  =  oo (refer to the definition  of pole in Section 3.5). 
If  each  entry  of  H(s)  has  only  poles  with  negative  real  values,  then,  as  shown  in 
Chapter  2, each  entry  of H(t)  =  [hij(t)]  has  a sum of exponentials  with  exponents 
with real part negative. It follows  that the integral 
\\H(t)\\dt 
0 
is finite, and  any realization  of H(s)  will result in a system that is uniformly  BIBO 
stable. 
Now conversely, if 
r  00 
0 
\\H(t)\\dt 
is  finite,  then  the  exponential  terms  in  any  entry  of  H(t)  must  have  negative  real 
parts. But then every entry of H(s)  has poles whose real parts are negative. 
We have proved the following  result. 
THEOREM 9.5.  The time invariant system (9.6) is uniformly BIBO stable if and only 
if all poles of the transfer function H(s) given in (9.8) have only poles with negative real 
• 
parts. 
PART  3 
STABILITY  OF  DISCRETE-TIME  SYSTEMS 
^ • H ^ ^ H ^ ^H 
6.10 
DISCRETE-TIME  SYSTEMS 
489 
^^^^6: 
Stability 
In this section we address the Lyapunov  stability of an equilibrium of  discrete-time 
systems  (internal  stability)  and  the  input-output  stability  of  discrete-time  systems 
(external stability). We could establish results for discrete-time systems that are anal 
ogous  to  practically  all  the  stability  results  that  we  presented  for  continuous-time 
systems.  Rather  than  follow  such  a  plan,  we  will  instead  first  develop  Lyapunov 
stability  results  for  nonlinear  discrete-time  systems  and  then  apply  these  to  obtain 
results  for  Hnear  systems.  This  will  broaden  the  reader's  horizon  by  providing  a 
glimpse  into  the  qualitative  analysis  of  dynamical  systems  described  by  nonlinear 
ordinary  difference  equations. In the Exercise  section  we  ask the reader  to  imitate 
these  results  in  establishing  Lyapunov  stability  results  for  dynamical  systems  de 
scribed by nonlinear ordinary differential  equations. To keep our presentation  simple 
and manageable, we will confine ourselves throughout this section to time-invariant 
systems. Among other issues, this approach will allow us to avoid most of the issues 
involving  uniformity. 
This section is organized into seven  subsections. In the first subsection  we pro 
vide essential preliminary material. In the second we establish results for the stabil 
ity, instability, asymptotic stability, and global asymptotic stability of an equilibrium 
and boundedness  of  solutions  of systems  described  by  autonomous  ordinary  differ 
ence equations. These results are utilized in the third and fifth subsections to arrive 
at stability  results  of an equilibrium  for  linear time-invariant  systems  described  by 
ordinary difference  equations. In the fourth  subsection we briefly  address a result for 
discrete-time  systems, called  the  Schur-Cohn  criterion,  which  is in the  same  spirit 
as  the  Routh-Hurwitz  criterion  is  for  continuous-time  systems.  The  results  of  the 
second  and  fifth  subsections  are used  to develop Lyapunov  stability  results  for Hn-
earizations  of  nonlinear  systems  described  by  ordinary  difference  equations  in  the 
sixth subsection. In the last subsection we present results for the input-output  stabil 
ity of time-invariant  discrete-time  systems. 
A.  Preliminaries 
We concern ourselves here with  finite-dimensional  discrete-time  systems  described 
by difference  equations of the  form 
x(k  -\-l)  =  Ax(k)  +  Bu(k) 
y(k)  =  Cx{k), 
(10.1) 
"where  A  G  /^'^X""", B  G W''''^, C  G  /?^><^ k  ^  k^,  and  k, ko^Z+. 
time-invariant,  we  will  assume  without  loss  of  generahty  that  ko  =  0,  and  thus, 
X  : Z+  ->  7?^  J  : Z+  ->  RP,"  and w  : Z+  ^  R""^. "
Since  (10.1)  is 
The internal  dynamics  of  (10.1) under  conditions  of no input  are described  by 
equations of the  form 
490 
^ 
x(k  +  1)  =  Axik). 
(10.2) 
Such equations may arise in the modehng process, or they may be the  consequence 
of the hnearization  of nonlinear  systems described by equations of the  form 
x(k  +  1)  =  g(x(k)), 
(10.3) 
where  g  : R^  ->  R^.  For  example,  if  ^  E  C^{R^, R^),  then  in  linearizing  (10.3) 
about, e.g.,  x  =  0, we obtain 
x(k  +  1)  =  Ax(k)  +  f(x(k)\ 
(10.4) 
where A  =  (df/dx)(x)\^^Q  and  where  f  : R^  ^  R^  is  o(\\x\\)  as a norm of x (e.g., 
the Euclidean norm) approaches zero. Recall that this means that given e  >  0, there 
is a S >  0 such that \\f(x)\\  <  e||x|| for  all ||x|| <  8. 
As  in  Section  6.9,  we  will  study  the  external  qualitative  properties  of  system 
(10.1) by  means  of  the BIBO  stability  of  such  systems.  Since  we  are dealing  with 
time-invariant  systems, we will not have to address  any issues  of uniformity.  Con 
sistent  with  the  definition  of  input-output  stability  of  continuous-time  systems,  we 
will  say that the  system  (10.1) is BIBO  stable  if there exists  a constant  L >  0  such 
that the  conditions 
jc(0)  -  0 
\\u{k)\\  <  1, 
yt >  0, 
imply that \\y{k)\\  <  L for  all fc >  0. 
We will  study  the  internal  qualitative  properties  of  system  (10.1) by  studying 
the Lyapunov  stability  properties  of  an  equilibrium  of  (10.2). We  will  accomplish 
this in a more general context by  studying the stability properties of an  equilibrium 
of system (10.3). 
Since system (10.3) is time-invariant, we will assume without loss of generality 
that  ko  =  0. As  in  Chapters  1 and  2, we  will  denote  for  a given  set  of  initial  data 
x(0)  =  XQ  the  solution  of  (10.3)  by  (p^k,  XQ).  When  XQ  is understood  or  of  no  im 
portance, we will frequently  write (/)(fc) in place of (/)(A:, XQ).  Recall  that for  system 
(10.3)  [as well as systems (10.1), (10.2), and (10.4)], there are no particular  difficul 
ties concerning the existence  and uniqueness  of solutions, and furthermore,  as long 
as g in  (10.3) is continuous, the  solutions  will be  continuous  with respect  to initial 
data. Recall also that in contrast to systems described by ordinary differential  equa 
tions, the  solutions  of  systems  described  by  ordinary  difference  equations  [such  as 
(10.3)] exist in general only in the forward  direction of time (k  >  0). 
We say that Xe E  R^  is an equilibrium  of system  (10.3) if cl)(k, Xe) =  Xe for  all 
/: >  0, or equivalently, 
g{Xe)  =  Xe. 
(10.5) 
As in  the continuous-time  case, we  will  assume  without  loss  of  generality  that  the 
equilibrium of interest will be the origin, i.e., Xe =  0. If this is not the case, then we 
can  always  transform  (similarly  as in the continuous-time  case)  system  (10.3)  into 
a  system of equations  that have an equilibrium  at the origin. Also, as in the case of 
continuous-time  systems,  we  will  generally  assume  that  the  equilibrium  of  (10.3) 
under  study is an isolated  equilibrium. 
EXAMPLE  10.1.  The system  described  by the equation 
x{k  +  1)  =  x{k)[x{k) 
-  1] 
has  two equihbria,  one dX Xe\  =0  and another  at Xg2  =  2. 
EXAMPLE10.2.  The system  described by the equations 
xi{k  +  1)  =  ^lik) 
X2(k +  1) =  -^i(^) 
has an equiUbrium at xf  =  (0, 0). 
491 
CHAPTER 6: 
Stabihty 
• 
• 
Throughout this section we will assume that the function  g in (10.3) is continu 
ous,  or if required, continuously differentiable.  The various definitions  of Lyapunov 
stability  of  the  equilibrium  x  == 0  of  system  (10.3)  are  essentially  identical  to  the 
corresponding definitions of Lyapunov stability of an equilibrium of continuous-time 
systems described by ordinary  differential  equations, replacing  ^ G /?+  by  ^  G  Z+. 
Since  system  (10.3) is time-invariant,  we will not have to explicitly  address the is 
sue of uniformity  in these  definitions.  We will concern  ourselves  with  stability,  in 
stability, asymptotic stability, and asymptotic stability in the large of the equilibrium 
X =  Oof  (10.3). 
We  say that the  equilibrium  x  == 0 of  (10.3)  is stable  if  for  every  e  >  0  there 
exists  3.  8  =  S(e)  >  0  such  that  \\4>(k,  xo)\\  <  e  for  all  /: ^  0  whenever  ||xo|| <  8. 
If  the  equilibrium  x  =  0  of  (10.3)  is  not  stable,  it  is  said  to  be  unstable.  We  say 
that  the  equilibrium  x  =  0 of  (10.3)  is asymptotically  stable  if  (i) it is  stable,  and 
(ii) there  exists  an  17 >  0 such that  if  ||xo|| <  17, then  lim^^^oo ||</)(^, xo)||  =  0. If  the 
equilibrium  x  =  0 satisfies  property  (ii), it is  said  to be attractive,  and  we call  the 
set  of  all  XQ G  R^  for  which  x  =  0  is  attractive  the  domain  of  attraction  of  this 
equilibrium. If x  =  0 is asymptotically  stable and if its domain of attraction is all of 
R^,  then it is said to be asymptotically  stable  in the large or globally  asymptotically 
stable.  Finally, we say that a solution of (10.3) through  XQ is bounded  provided there 
is a constant M  such that ||(/)(/:, xo)|| ^  M  for all ^  >  0. 
In establishing  results for  the various  stability  concepts  enumerated  above,  we 
will make use of  auxiliary  functions  v G  C{R^, R),  called Lyapunov functions.  We 
define  the first forward  difference  ofv  along  the solutions  (9/(10.3) as 
Dv{x)  =  v(g(x))  -  v(x). 
(10.6) 
To see that this  definition  makes  sense, note that  along any  solution  (/)(^) of  (10.3) 
we have 
v[ct,(k  +  1)] -  v[cl>(k)]  =  v[g{cl>(k))]  -  vmk)] 
^^Q ^^ 
=  Dvmk)] 
for  all fc >  0.  Note  that  in  evaluating  the  first  forward  difference  of  v  along  the 
solutions of (10.3), we need not know explicitly the solution (/>(/:) of (10.3). 
We will require several characterizations of the Lyapunov functions. We say that 
a function  v G  C(R^,  R)  is positive  definite  if  v(0)  =  0 and if v(x)  >  0 for  all  x G 
"B{j])  -  {0} for  some ry >  0.  [Recall that B{j])  =  {x G /?"" : ||x|| <  ry}.] The  function "
V is negative  definite if  -v  is positive definite. A function  v G  C{R^, R) is said to be 
positive  semidefinite  if v(0)  =  0 and if v(x)  >  0 for all x  G ^(17), and it is said to be 
negative  semidefinite  if  -v  is positive semidefinite. A positive definite  function  v is 
"said to be radially  unbounded  if v(x)  >  0 for all x  G  7?"" -  {0} and if limiij^iuoo v(x)  = "
492 
Linear Systems 
00. Finally, a function  v E  C(R^,  R) is said to be indefinite if v(0)  =  0 and if in every 
neighborhood  of the origin v assumes positive and negative values. 
B.  Lyapunov  Stability  of an  Equilibrium 
In establishing various Lyapunov stability results of the equilibrium x  =  0 of system 
(10.3),  we will find it useful  to employ  a preliminary  result  that  is important  in  its 
own right. To present  this result,  we require  some  additional  concepts  given  in  the 
following. 
"We  say  that  a  subset  A  C  7^"" is positively  invariant  [with  respect  to  system "
(10.3)]  if  g{A)  C  A," where  g{A)  =  {y  E. R""""  \ y  =  g{x)  for  some x  G A}. Thus", if 
X EL  A,  then g{x)  G A. 
EXAMPLE 10.3.  It is clear that any set consisting of an equilibrium solution of (10.3) 
is positively invariant. Also, the set {^{k, XQ), k E Z^}  [where 4> is the solution of (10.3), 
with (/)(/co)  =  ^o], which is called i\\Qpositive orbit of XQ for (10.3), is positively invari 
ant. In particular, for arbitrary initial conditions x(0)^  == (^i(O), ^2(0)), the system given 
in Example 10.2 has iho periodic solution with period 4 and positive orbit given by the 
set 
A =  {(xi(0), X2(0))^, (X2(0), -xmV, 
(-xm, 
-^2(0))^, (-X2(0), 
xmYl 
and in general we have (f)(k, XQ) = (t)(k -\-  3, xo\  k  = 0, 1, 2, 3, 
positively invariant. 
The set A is clearly 
• 
Next, consider a specific  solution (/)(/:," XQ) for  system  (10.3). A point y  E  R""^  is "
called Si positive  limit point  of 4>{k,  XQ) if there is a subsequence {hi} of the sequence 
{k}, /: >  0, such that (f){ki,  XQ) -^  y. The set of all positive limit points of (f){k,  XQ) is 
called the positive  limit set (o(xo) of (/)(/:, XQ),  or simply the co-limit set. 
Before  stating  and  proving  our  first  result,  which  is  a  preliminary  result,  we 
recall  that  a  sequence  {x^}  C  R^  is  said  to  approach  a  set  A  C  R^,  if  d(x^,  A)  = 
inf {||x^  -  y\\ : y  E  A} approaches zero as fc ^  oo  [d(x, y) denotes the distance  func 
tion defined  in Subsection  I.IOC]. 
THEOREM  10.1.  If  the  solution  (t)(k, XQ) of  (10.3)  is bounded  for  all  k  E  Z+, then 
(o(xo) is a nonempty, compact, positively invariant set. Furthermore, (t)(k, XQ) -^  w(jco) 
as  /: ^  00. 
Proof, The complement of (O(XQ) is open, and therefore, the set (w(xo) is closed. Since 
4>(k, XQ) is bounded,  ||(^(/:, xo)|| ^  M  for  some fixed M. Therefore,  (o(xo)  is bounded 
and IIJII <  M for all y  E  (O(XQ). Thus, (JO(XO) is compact. Since (f>(k,  XQ) is bounded, the 
Bolzano-Weierstrass Theorem guarantees the existence of at least one limit point, and 
therefore, (x)(xo) is not empty (refer to Subsection 1.5A). 
Next, let y E co(xo) so that (/)(A:/, XQ) -^  y as / ^  OO.  Since the function  g in (10.3) 
is continuous, it follows that (l)(ki  + I, XQ) = g{4^{ki,  XQ)) -^  g{y) or g{y) E  O){XQ). The 
set  O){XQ)  is positively  invariant  [with respect  to  system  (10.3)]. Also, d{(j){k,  XQ), CL>) 
is  bounded  since  both  (j){k, XQ) and  w(xo)  are  bounded.  To  set  up  a  contradiction, 
assume  that  d{(f){k,  XQ), O){XQ)) does  not  converge  to  zero.  Then  there  is  a  subse 
quence  [ki] such  that  (/)(/:/, XQ) ->  y  and d((p(ki, XQ), (i^(xo)) ->  a  >  0.  But  then  y E 
ct)(xo), d{(j){ku  XQ), (I>{XQ))  <  d{(f)(ku  XQ), y) -^  0, and therefore,  d(<p(ki,  XQ), CO(XO)) -^ 
0, which is a contradiction. 
• 
We are now  in  a position  to  state  and prove  several  Lyapunov  stability  results 
for  system (10.3). 
493 
CHAPTER 6-
Stability 
THEOREM  10.2.  The  equilibrium  x  =  0  of  system  (10.3)  is  stable  if  there  exists  a 
positive definite  function  v such that Dv  is negative  semidefinite. 
Proof,  We take r/  >  0 so small that v(x)  >  0 for all x  E  5(7]) -  {0} and Dv(x)  <  0 for all 
X E  5(77) [recall that Birf)  =  {x  ^  R^  \ ||x|| <  r/}]. Let e  >  0 be given. There is no loss 
of generality  in choosing  0  <  e  <  17. Let m  =  min {v(x)  : \\x\\  =  e}. Then m is positive 
since we are taking the minimum  of a positive continuous  function  over a compact  set. 
Let  G  =  {x  B  R^  : v(x)  <  mil},  which  may  consist  of  several  disjoint  connected  sets 
called  connected  components  of  G. Let  Go denote  the  connected  component  of  G  that 
contains  the  origin  x  =  0.  Then  both  G  and  Go  are  open  sets.  Now  if  XQ E  GO,  then 
DV{XQ)  <  0  and  so  v(^(xo))  ^  V{XQ)  <  m/2,  and  therefore,  g^xo)  E  G.  Since  XQ  and 
the origin  x  =  0 are both in the same component  of G, then  so are ^(0)  =  0 and g(xo). 
Therefore,  Go is an open positively invariant set containing x  =  0 and contained in  B{e). 
Since  v is  continuous  there  is  a  5  >  0  such  that  B{b)  C  Go. Therefore,  if  xo  E  B{d), 
then  Xo  E  Go and ^(xo)  E  Go C  B{e).  This shows that the equilibrium x  =  0 of system 
(10.3) is stable. 
• 
EXAMPLE  10.4.  For  the  system  given  in  Example  10.2  we  choose  the  function 
v(xi, X2)  =  x\  + x\.  Then 
Dv(xi, X2)  =  v(g(xi, X2)) -  v(xi, X2) 
=  (xif  +  (-xif 
-  xj- 
xl  =  0. 
Therefore,  by Theorem  10.2 the equiUbrium  x  =  0 of the system is stable. 
• 
By  using  a  similar  argument  as  in  the  proof  of  Theorem  10.2  we  can  prove  the 
boundedness  result  given  below.  We  will  not present  the  details  of  the  proof. 
THEOREMIO.3.  Ifvis  radially  unbounded  and Dv(x)  <  0 on the set where ||x|| >  M 
(M is some constant), then all solutions of system (10.3) are bounded. 
• 
EXAMPLE  10.5.  For  the  system  given  in  Example  10.2  we  choose  the  radially  un 
bounded  function  v(xi, X2)  =  x^  +  X2. As  shown  in Example  10.4, Dv{x\,  X2) ^  0  for 
all X E  /?^.  It follows from Theorem  10.3 that all the solutions of the system are bounded. 
• 
By  definition,  the  equilibrium  x  =  0  of  system  (10.3)  is  asymptotically  stable 
if  it  is  stable  and  attractive.  Theorem  10.2  provides  a  set  of  sufficient  conditions 
for  the  stability  of  the  trivial  solution  of  system  (10.3).  In  the  next  result,  known  as 
's  Theorem  or the Invariance  Principle,  we  present  a method  that  enables  us 
LaSalle 
to determine the attractivity  of a set. If this set consists only of the equilibrium  x:  =  0, 
this result yields a method  of determining  the attractivity  of the trivial  solution  x  =  Q 
of  system  (10.3). 
Let  V E  C{R'',  R)  and  let  v(x)  -  c.  In the  following,"  we  let v~^{c)  =  {x  B  R""""  : "
v(x)  =  c}. 
"THEOREM  10.4.  Let V  E  C(/?"""," R)  and let G  C  R"""". Assume that (i) Dv(x)  <  0 for  all "
X G  G,  and  (ii) the  solution  4>(k, XQ) of  (10.3)  is in  G for  all  A: >  0 and is bounded  for 
all  ^  >  0. Then  there  is a number  c  such  that  (/)(^, xo) ^  M  Pi v~^(c), where M  is  the 
largest positively invariant  set contained in the set E  =  {x  G R'^ : Dv(x)  =  0} D G. 
Proof.  Since  (f)(k,  XQ)  is  bounded  and  in  G,  it  follows  that  co(xo) 7^ 0,  CL)(XO)  C  G, 
and  (/)(/:, xo)  tends  to  a>(xo). Now  v{(j){k,  XQ))  is  nonincreasing  with  increasing  k  and 
bounded  from  below.  Therefore,  v(4>(k,  XQ))  ->  c.  If  y  G  CL)(XO), there  is  subsequence 
{ki}  of  the  sequence  {k}  such  that  (/>(/:/, xo) -^  y  and  therefore  v{(f)(ki, xo)) ->  v{y)  or 
v(y)  =  c. Therefore,  V{(X){XQ)) =  c [i.e., v(y)  =  c for all y  E  a;(xo)] or ^(xo)  C  v~^(c). 
Since v(6o(xo))  =  c and a;(xo) is positively invariant, it follows that Dv(o;(xo))  =  0 [i.e.. 
494 
Linear Systems 
Dv(y)  =  0 for all y  G co(xo)]. Therefore,  0(^," XQ) -^  (x)(xo)  C {x E  /?"" : Dv(x)  =  0} Pi "
G fl v^^c). Since co(xo) is positively invariant, it now follows  that a)(xo)  CM. 
• 
The  next  results,  which  are  direct  consequences  of  Theorems  10.2, 10.3, and 
10.4,  were  originally  established  by  Lyapunov. 
COROLLARY  10.1.  The equilibrium  x  =  0 of (10.3) is asymptotically  stable  if there 
exists a positive definite  function  v such that Dv is negative  definite. 
Proof.  Since Dv is negative definite  and v is positive definite, it follows  from  Theorem 
10.2  that  the equilibrium  x  =  0 is  stable.  From  the proof  of that  theorem  there  is an 
arbitrarily  small neighborhood  Go of the origin that is positively invariant. We can make 
Go so small that v(x) >  0 and v(x)  < 0 for all x G Go -  {0}. So, given  any xo G Go it 
follows  from  the invariance  principle  (Theorem  10.4) that  (pik, XQ) tends to the largest 
invariant  set in Go H {Dv(x)  =  0} =  {x  =  0} since Dv is negative  definite.  Therefore, 
the equilibrium  x  =  0 is asymptotically  stable. 
• 
COROLLARY  10.2.  The equilibrium  x  == 0 of (10.3)  is asymptotically  stable  in the 
large (or globally  asymptotically  stable)  if there exists a positive definite function  v that 
"is radially unbounded and if Dv is negative definite on R""""", i.e., Z)v(O)  =  0 and Z)v(x)  <  0 
for all X  7^ 0. 
• 
Proof,  From Theorem  10.3 all solutions  of system  (10.3)  are bounded. The proof  now 
• 
follows by modifying  the proof of Corollary  10.1 in the obvious way. 
EXAMPLE  10.6.  Consider the system described by the equations 
xi(k+  1)  = 
X2(k  +  1)  = 
ax2(k) 
1  +  xi(y^)2 
bxi(k) 
1 + X2(k)^' 
where it is assumed that a^ <  I and b^ <  I. We choose a Lyapunov function  v{x\, X2)  = 
x\  +  x\  that  is  positive  definite  and radially  unbounded.  Along  the  solutions  of  this 
system we compute the first forward  difference  as 
^ v t e , . . ) = ^^  + ^ ^ - ( x?  + 4) 
(1 + x\y 2\2 
1  Xo  + 
b^ 
1 
2\2 
(1 + 4> 
<  {a^ -\)xl  + (b^  -  l)x?. 
Since  by  assumption  a^ <  I  and Z?^ <  1, it follows  that  Dv(xi,  X2) <  0 for all x^  = 
(xi, X2) 7^ 0 and Dv(xi,  X2)  =  0 when x  =  0. It follows  from  Theorem  10.3 that all so 
lutions of the system are bounded, and from Corollary  10.2 it follows that the equilibrium 
• 
X =  0 of the system is globally  asymptotically  stable. 
EXAMPLE  10.7.  We reconsider the system given in Example  10.6 under the assump 
tion that a^ ^  I and Z?^ <  1, but a^ + b'^ 7^ 2. Without loss of generality we consider the 
case a^  <  1 and b^  =  1. As in Example  10.6, we again choose v(xi, X2)  =  x^ + x^, and 
from the computations in that example we see that 
Dv(xu  X2) <  (a^ -  \)x\  +  Q? - 
\)x\ 
=  {a^ -  \)x\  <  0, (xi, X2)^ G R^. 
It still follows  from  Theorem  10.3  that all solutions of the system are bounded. 
495 
CHAPTER 6* 
stabilitv 
Since Dv(xi, X2) is not negative definite, but negative semidefinite, we cannot apply 
Corollary 10.2 to establish the asymptotic stability of the equilibrium x  =  0. So let us try 
to use Theorems 10.2 and 10.4 to accomplish this. From the former we conclude that the 
equilibrium is stable. Using the notation of Theorem  10.4 we note that E  = {(xi, 0)^}, 
which is the xi-axis. Now g((xi, OY)  =  (0, bxiY  =  (0, xi)^  [where g(') is defined in 
(10.3)], and therefore, the only invariant subset of (E) is the set consisting of the origin. 
All conditions of Theorem  10.4 are satisfied  (with G  = R^), and we conclude that the 
• 
equilibrium x  =  0 of the system is globally asymptotically stable. 
THEOREM10.5.  Let Dv be positive definite and assume that in every neighborhood of 
the origin there is x such that v(x) >  0. Then the equilibrium x  =  0 of system (10.3) is 
unstable.  [Alternatively, let Dv be negative definite and assume that in every neighbor 
hood of the origin there is x such that v(x) <  0. Then the equilibrium x  =  0 of system 
(10.3) is unstable.] 
Proof, To set up a contradiction, assume that x  =  0 is stable. Choose e >  0 so small so 
that Dv{x) > 0 for all x G B{e) -  {0}, and choose 6 >  0 so small so that if  XQ G B(8) 
then 4>{k,  XQ) G B{e) for all ^ >  0. By hypothesis there is a point XQ G B{3) such that 
v(xo) > 0- Since  (j){k, XQ) is bounded  and remains  in 5(e),  the  solution  (f){k, XQ) will 
"tend to its Hmit set {x G /?"" : Dv{x)  =  0} Pi B{e)  = {0}. Since (/)(/:", XQ) -^  0, we have 
v((l)(k XQ)) -»  v(0)  =  0. But Dv((l)(k, xo)) >  0 and therefore v((/)(^, XQ)) >  0, and thus 
v(4>(k, Xo)) ^  v(cl)(k-l,  Xo)) >  ••• >  v(xo) >  0. We have thus arrived at a contradiction 
that proves the theorem. 
• 
EXAMPLE 10.8.  The system described by the equation 
x(k  +1)  =  2x(k) 
has an equilibrium  x  =  0. The function  v(x)  =  x^ is positive definite,  and along the 
solutions of this system we have Z)v(x)  =  4x^-x^  = 3x^, which is also positive definite. 
The conditions of Theorem 10.5 are satisfied and the equilibrium x  =  0 of the system is 
unstable. 
• 
C.  Linear  Systems 
In proving some of the results of this section, we require a result for system (10.2) that 
is analogous to Theorem  3.1  of Chapter  2. As in the proof  of that theorem,  we note 
that the linear combination of solutions of system (10.2) is also a solution of  system 
(10.2), and hence, the set of solutions {4>:  Z^  XR^  -^  R^} constitutes a vector space 
(over F  =  Ror  F  =  C).  The dimension  of this vector  space is n. To show this, we 
choose a set of linearly independent vectors  XQ, ...,  XQ  in the n-dimensional  x-space 
(R^  or  C^)  and  we  show, in  an identical  manner  as in the proof  of Theorem  3.1 of 
Chapter 2, that the set of solutions (/)(fc, XQ), i  =  1,...,  n, is linearly independent and 
spans the set of solutions of system (10.2). (We ask the reader in the Exercise section 
to provide the details of the proof of the above assertions.) This yields the  following 
result. 
THEOREM 10.6.  The set of solutions of system (10.2) over the time interval Z+ forms 
• 
an ^-dimensional vector space. 
Incidentally,  if  in  particular  we  choose  (/)(^, e^), i  =  I,..  .,n,  where  e\  i  = 
1,...,  n,  denotes  the  natural  basis  for  R^,  and  if  we  let  ^{k,  yto  =  0)  =  0(A;)  = 
[ct){k, e^),..., 
(pik," e"")]", then it is easily verified  that the n  X n matrix 0(A:)  satisfies 
496 
Linear Systems 
the matrix  equation 
ci>(k  +  1)  -  A^(k\ 
c|)(0)  = 
/ 
and that (5(fc)  =  A^,k^ 
0 [i.e., 3>(/:) is the state transition matrix for system (10.2)]. 
THEOREM  10.7.  The  equiHbrium  x  =  0 of  system  (10.2)  is  stable  if  and  only  if  the 
solutions of (10.2) are bounded. 
Proof.  Assume that the equilibrium x  =  0 of (10.2) is stable. Then for 6  =  1 there is a 
8  >0  such that \\cl)(k, xo)\\ <  1 for all  ^  >  0 and all ||jco|| <  6. In this  case 
U(k,  xo)\\  =  WA'xoW  = 
A^XQS 
m\\ 
M 
8 
<  8 
for  all  xo  7^ 0  and  all  k  >  0.  Using  the  definition  of  matrix  norm  [refer  to  (10.17)  of 
Chapter  1] it  follows  that  ||A^|| <  8~\  A:  >  0.  We have  proved  that  if  the  equilibrium 
X =  0 of (10.2) is stable, then the solutions of (10.2) are bounded. 
Conversely, suppose that all solutions (j6(/:, XQ)  =  A'^XQ are bounded. Let{^\  ...,"  ^""} "
denote the natural  basis  for  ^-space  and let  \\(p(k, e^)\\ <  jBj for  all  k  >  0. Then  for  any 
"vector  XQ =  S""=i  cty^^ we have that "
ll^(^,xo)|| 
^^aj(f)(k, 
7 =  1 
e^) 
Xk-|i8;^(max^,.)Xl^il 
7 =1 
^ 
7 =1 
c\\m 
0, 
for  some  constant  c. For given  6  >  0,  we choose  8  =  elc.  Then,  if  ||xo|| <  8,  we  have 
\^{k,  xo)|| <  c||xo|| <  6 for  all  /: >  0. We have proved  that if the  solutions  of (10.2)  are 
bounded, then the equilibrium  x  =  0 of (10.2) is stable. 
• 
THEOREM  10.8.  The following  statements  are  equivalent: 
(i)  The equilibrium  x  =  0 of (10.2) is asymptotically  stable. 
(ii)  The equilibrium  x  =  0 of (10.2) is asymptotically  stable in the large, 
(iii)  lim^^oo ||Ai  =  0. 
Froof  Assume that statement (i) is true. Then there is anry  >  0 such that when ||xo||  ^ 
17, then ^{k,  XQ) ->  0 as  /: -^  00. But then we have for any  XQ ^  0 that 
(^{k, xo)  =  A^xo 
Ikoll 
17x0 
Ikoll 
0  as  /: ^  00. 
It follows  that statement  (ii) is true. 
Next,  assume  that  statement  (ii)  is  true.  Then  for  any  e  >  0  there  must  exist  a 
K  =  K{e)  such  that  for  ?^k>  K  we have  that  \^{k,  xo)||  =  ||A^xo|| <  6.  To see this, 
let  {^^  ...,"  ^""} be  the  natural  basis  for  R^.  Thus",  for  a  fixed  constant  c  >  0,  if  XQ  = 
(a\,..., 
ji  -^  c. For eachy there 
is a Kj  -  Kj{e)  such that  \A^e^ 
K(€)  =  max {Kj(e)  : 
j  =  1,...,  n}. For ||xo| 
2:;.i«y^^'and2:;=iK 
<6/cfory^>  TTy. Define TT 
<  1 and  k  >  K  we  have that 
anf  andif ||xo|| ^ 
l,thenxo 
ll^'^oll  = 
7 =  1 
7 =  1 
By the definition  of matrix norm [see (10.17) of Chapter  1], this means that ||A^|| <  e  for 
k>  K.  Therefore,  statement  (iii) is true. 
Finally, assume that  statement  (iii) is true. Then  ||A^|| is bounded  for  all  /c >  0. By 
Theorem  10.7, the equilibrium  x  =  0 is stable. To prove asymptotic  stability, fix e  >  0. 
If  llxoll <  77 =  1, then  \\(t)(k,  xo)\\  <  \\A^\\  \\xo\\ ^  0 as  y^ ^ 
true. This completes the proof. 
00.  Therefore,  statement  (i) is 
497 
• 
CHAPTER  6: 
Stability 
To arrive  at the next result,  we  make  reference  to the results  of  Subsection  2.7E. 
Specifically,  by  inspecting  the  expressions  for  the  modes  of  system  (10.2)  given  in 
(7.50)  and  (7.51)  of  Chapter  2,  or by  utilizing  the  Jordan  canonical  form  of A  [refer 
to  (7.54)  and  (7.55)  of  Chapter  2], the  following  result  is  evident. 
THEOREM  10.9.  (i) The equilibrium  x  =  0 of system  (10.2) is asymptotically  stable 
if and only if all eigenvalues  of A are within the unit circle of the complex plane (i.e., if 
Ai,...,  A„ denote the eigenvalues  of A, then  \Xj\ <  I, j  =  1,...,  ^). In this case we say 
that the matrix  A  is Schur  stable,  or simply, the matrix  A  is  stable. 
(ii) The  equilibrium  x  =  0 of  system  (10.2)  is stable  if  and  only  if  \Xj\ <  1, j  = 
.,n,  and for each eigenvalue with  |Aj|  =  1 having multiplicity  rij  >  1, it is true that 
1,.. 
"}^^S^^^'-'^^""'^''-^^""^\='^ "
h...,nj- 
1. 
(iii) The equilibrium x  =  0 of system (10.2) is unstable  if and only if the conditions 
• 
in (ii) above are not true. 
Alternatively,  it is  evident  that  the  equilibrium  x  =  0  of  system  (10.2)  is  stable 
if  and  only  if  all  eigenvalues  of  A  are  within  or  on  the  unit  circle  of  the  complex 
plane,  and  every  eigenvalue  that  is  on  the  unit  circle  has  an  associated  Jordan  block 
of  order  1. 
EXAMPLE  10.9.  (i) For the system in Example  10.2 we have 
A  -
0  11 
-1 
0 
The eigenvalues of A are Ai, A2  =  ±  v  - 1-  According to Theorem  10.9, the equilibrium 
x  =  0 of the system is stable, and according to Theorem  10.7 the matrix A^ is bounded 
for all 
k^O. 
(ii) For system (10.2) let 
0 
-1 
The  eigenvalues  of A  are  Ai, A2  =  ±1/V2.  According  to  Theorem  10.9,  the  equilib 
rium  X =  0  of  the  system  is  asymptotically  stable,  and  according  to  Theorem  10.8, 
lim^^^ooA^  =  0. 
(iii) For system (10.2) let 
A 
The eigenvalues of A are Ai, A2  =  ±  V3/2. According to Theorem  10.9, the equilibrium 
X =  0 of the  system  is  unstable,  and  according  to Theorem  10.7, the  matrix  A^ is  not 
bounded  with increasing  k. 
(iv) For system  (10.2) let 
A  = 
1  1 
0  1 
The  matrix A is  a Jordan  block  of  order  2 for  the  eigenvalue  A =  1. Accordingly,  the 
equilibrium  x  =  0  of  the  system  is  unstable  (refer  to  the  remark  following  Theorem 
• 
10.9) and the matrix A^ is unbounded  with increasing k. 
498 
Linear Systems 
D.  The Schur-Cohn  Criterion 
In this section we present a method, called the Schur-Cohn  criterion,  that enables us 
to determine whether or not the roots of a polynomial with real coefficients  given by 
+  • • • + ^0, 
an > 0, 
(10.8) 
lie inside of the unit circle in the complex plane by examining the polynomial  coef 
ficients,  rather than  solving for the roots. This method provides us with an efficient 
means of studying the stability of the equilibrium x  =  0 of system (10.2) by apply 
ing it to the characteristic  polynomial of the matrix A. The Schur-Cohn  criterion is 
in the same spirit  [for discrete-time  systems  (10.2)] as the Routh-Hurwitz  criterion 
[for  continuous-time  systems  (L)]. In presenting  this  criterion,  we will  require the 
concept of inners of a square matrix A, defined  as the matrix itself, and all the ma 
trices obtained by omitting  successively the first and last rows and the first and last 
columns. In the following,  we depict the inners for a matrix A E R^^^ and a matrix 
A  G i?6x^: 
an 
an 
cin 
<2i4 
«21 
1  Cl22 
«23 
<324 
^25 
A  = 
^ 31 
1  ^32 
1 (233 
(234 
(241 
1 ^ 42 
(243 
CI44 
Cl5l 
«52 
«53 
^54 
<335 
(245 
ass. 
A  = 
(211 
<321 
(231 
(241 
asi 
(261 
an 
ail 
<332 
^ 42 
asi 
(262 
L 
ai3 
^23 
«33 
<^43 
<353 
^ 63 
ai4 
(224 
^ 34 
(244 
asA 
(264 
(215 
^25 
^35 
(245 
ciss 
aes 
(216 
^26 
<^36 
(246 
(256 
^66 
A  matrix is said to be positive  innerwise  if the determinants  of all of its inners 
are positive. 
THEOREM 10.10. (SCHUR-COHN CRITERION)  A neccssary and sufficient  condi 
tion that the polynomial (10.8) with real coefficients has all its roots inside the unit circle 
in the complex plane is that 
(i)  p(l) > 0 and (- 1)V(-1)  > 0, 
(ii)  the following (n —  I) X (n —  1) matrices are both positive innerwise: 
0 
Cln-l 
as 
(32 
as 
0 
0 
Cln~\ 
Cln. 
0 
(3o 
(31 
0 
(3o 
(31 
(10.9) 
0 
(30 
ai 
(3^n-l 
^ n -1 
We  will  not present  a proof  of Theorem  10.10. The interested  reader  should 
consult Jury  [91 cited in the reference  section for a proof of this result. 
EXAMPLE 10.10.  For the 2 X 2 matrix 
A = 
(311 
CI2I 
an 
ail. 
the characteristic polynomial is given by 
p(\)  =  A^  +  (3iA  +  (3o. 
We have p(l)  =  I + ai  + ao, p(-l)  =  1  -  ai  + ao, and Af  =  1  ± (^o  >  0. Therefore, 
the roots of p(X) he within the unit circle of the complex plane if and only if  |ao| <  1 
and |ai| <  1  + ao. 
• 
EXAMPLElO.il.  For the 3 X 3 matrix 
499 
CHAPTER  6: 
Stability 
an 
dii 
.asi 
the characteristic polynomial is given by 
an 
«22 
^32 
a i3 
<223 
<^33 
We have p(l)  =  1 + ^2 + ai  + <3o,  -p(-l) 
=  I -  a2  + ai  ao, and 
p(X)  =  A^  + (22 A^  + ai\  + ao. 
det{^^)  = 
1 
a2  ± ao  1 
-ao 
±ai 
> 0. 
Therefore, the roots of p(X) lie within the unit circle of the complex plane if and only if 
Wo  + a2\  < I + ai and \ai -  aoa2\  <  I -  al. 
• 
E.  The Matrix  Lyapunov  Equation 
In this subsection we apply the Lyapunov theorems of Subsection B to obtain another 
characterization of stable matrices. This gives rise to the Lyapunov matrix equation. 
Returning to system (10.2) we choose as a Lyapunov  function 
v(x)  =  x^Bx, 
B  =  B^, 
(10.10) 
and we evaluate the first forward  difference  of v along the solutions of (10.2) as 
v{x{k  +  1)) -  v{x{k))  =  x(k  +  lfBx(k 
+  1) - 
x(kfBx(k) 
=  x{kfA^BAx{k) 
- 
x{kfBx{k) 
=  x{kf{A^BA 
-  B)x(k\ 
and  therefore, 
Dv(x)  =  x^{A^BA 
-  B)x  =  x^Cx, 
where 
A^BA  -B  =  Q 
C^  =  C. 
(10.11) 
Invocation of Theorem  10.2, Corollary  10.2, and Theorem  10.5, readily leads to the 
following  results. 
THEOREM  10.11.  (i) The equilibrium x  =  0 of system (10.2) is stable if there exists 
a real, symmetric, and positive definite matrix B such that the matrix C given in (10.11) 
is negative semidefinite. 
(ii) The equilibrium x  =  0 of system (10.2) is asymptotically stable in the large 
if there exists a real, symmetric, and positive definite matrix B such that the matrix C 
given in (10.11) is negative definite. 
(iii) The equilibrium ;\f  =  0 of system (10.2) is unstable if there exists a real, sym 
metric matrix B that is either negative definite or indefinite such that the matrix C given 
in (10.11) is negative definite. 
• 
In applying Theorem  10.11, we start by choosing  (guessing)  a matrix B  having 
certain desired properties and we then solve for the matrix C, using equation (10.11). 
500 
Linear Systems 
If C possesses certain desired properties (i.e., it is negative definite) we can draw ap-
propriate conclusions by applying one of the results given in Theorem  10.11; if not, 
we need to choose another matrix B. This approach is not very satisfactory,  and in the 
following  we will derive results that will allow us (as in the case of  continuous-time 
systems)  to  construct  Lyapunov  functions  of  the  form  v{x)  =  x^Bx 
in  a  system 
atic  manner.  In  doing  so, we  first  choose  a matrix  C in  (10.11)  that  is either  nega 
tive  definite  or positive  definite,  and  then  we  solve  (10.11)  for  5.  Conclusions  are 
then made by applying Theorem  10.11. In applying this construction procedure, we 
need  to  know  conditions  under  which  (10.11)  possesses  a  (unique)  solution  B  for 
any  definite  (i.e., positive or negative definite)  matrix  C. We will address this issue 
next. 
We first show  that  if A is  stable, i.e.,  if  all eigenvalues  of  matrix A  [in  system 
(10.2)]  are  inside  the  unit  circle  of  the  complex  plane,  then  we  can  compute  B  in 
(10.11) explicitly. To show this, we assume that in  (10.11)  C is a given matrix  and 
that A  is stable. Then 
(A^)^+i5A^+i  -  {A^fBA^  = 
(A^fCA^ 
and summing from  ^  =  0 to / yields 
A^BA  -B  + {A^fBA^ 
-  A^BA  + 
B  = 
^{A^fCA^ 
/ 
or 
(A^y^^BA^^^ 
-B== 
Letting  / ^  oo^ we obtain 
k = 0 
I 
k = 0 
^(A^)^CA^. 
B  =  -^(A^)^CA\ 
k = 0 
(10.12) 
It is easy to verify  that (10.12) is a solution of (10.11). We have 
- A^  ^(A^)^CA^ 
A  +  ^(A^)^CA^ 
-  C 
k = 0 
k = 0 
-A^CA  +  C  -  (A^fCA^  +  A^CA  -  (A^fCA^  +  (A^fCA^ 
or 
Therefore  (10.12) is a solution of (10.11). Furthermore, if C is negative definite, then 
B is positive  definite. 
=  C. 
Combining the above with Theorem  lO.ll(ii)  we have the following  result: 
THEOREM  10.12.  If there is a positive definite  and symmetric matrix B and a neg 
ative definite  and symmetric matrix  C satisfying  (10.11), then the matrix A is stable. 
Conversely, if A is stable, then, given any symmetric matrix C, Eq. (10.11) has a unique 
solution, and if C is negative definite then B is positive definite. 
• 
Next, we determine conditions under which the system of equations (10.11) has 
a (unique) solution B  =  B^  E  R^^^  for a given matrix C  =  C^  E:  R^^^,  To accom 
plish this, we consider the more general  equation 
A1XA2-X  =  C, 
(10.13) 
"where A\  E  R""^^^^  A^  G  R""""^""""", and X  and  C are m X n matrices. 
"LEMMA 10.1.  Let Ai  G /^'^^^^ and A2 G /?""><^ ThenEq. (10.13) has a unique solution "
"X E R^^^  for a given C E  /^'^x"" if and only if no eigenvalue of A\  is a reciprocal of an "
eigenvalue of A2. 
Proof, We need to show that the condition on Ai and A2 is equivalent to the condition 
that A1XA2 =  X implies X  ^  0. Once we have proved that A1XA2 =  X has the unique 
solution X  =  0, then it can be shown that (10.13) has a unique solution for every C, 
since (10.13) is a linear equation. 
Assume first that the condition on Ai and A2 is satisfied. Now A1XA2 =  X implies 
that A\~^XA\~^  = X and 
501 
CHAPTER 6* 
Stability' 
A{X  =  A\XA\~^ 
for  y^ >  7  >  0. 
Now for a polynomial of degree k, 
k 
7 =0 
we define the polynomial of degree k, 
from which it follows that 
"/(A) = X^i^'""'' = ^'/^fT\ "
7 =0 
p{A,)X  =  A\Xp\A2l 
Now let (/)/(A) be the characteristic polynomial of A/, /  =  1, 2. Since (f)\ (A) and (/>2(A) are 
relatively prime, there are polynomials p{\)  and ^(A) such that 
p{\)cj>,{K) + q{k)cf>l{K)  = 1. 
Now  define  (j>{X)  =  q(X)(f)l(X)  and  note  that  (/)*(A)  =  ^*(A)(/)2(A).  It  follows  that 
(/)*(A2) =  0 and (p(Ai) = I. From this it follows that A1XA2 =  X impUes X  = 0. 
To prove the converse,  we assume  that  A  is  an eigenvalue  of  Ai  and  A~^ is an 
eigenvalue  of  A2  (and  hence,  is  also  an  eigenvalue  of  A^).  Let  Aix^  =  Xx^ and 
A^x^  =  X'^x^,  x^ ¥^  0, and  x^ 7^  0. Define X  =  {x\x\  xlx\  ...,  JC^X^). Then X 7^  0 
and A1XA2 =  X. 
• 
To construct v{x)  by using Lemma  10.1, we must still check the definiteness  of 
B.  To accomplish this, we utilize Theorem  10.11. 
1.  If all eigenvalues of A [for system (10.2)] are inside the unit circle of the complex 
plane, then no reciprocal of an eigenvalue of A is an eigenvalue, and Lemma  10.1 
gives  another  way  of  showing  that Eq.  (10.11)  has  a unique  solution B  for  each 
C if A is stable. If  C is negative  definite,  then B is positive definite.  This can be 
shown as was done for the case of linear ordinary differential  equations. 
2.  If  at  least  one  of  the  eigenvalues  of A is  outside  the  unit  circle  of  the  complex 
plane  and  if  no  reciprocal  of  an  eigenvalue  of A  is  an  eigenvalue,  and  if  C in 
(10.11) is negative definite, then B cannot be positive definite; otherwise we could 
apply  Theorem  lO.ll(iii)  to  come  up  with  a  contradiction.  If  in  particular,  all 
eigenvalues of A are outside the unit circle of the complex plane, then B must be 
negative definite.  [In this case the equilibrium  of (10.2) is completely  unstable.} 
Now  suppose  that  at  least  one  of  the  eigenvalues  of A  is  outside  of  the  unit 
circle in the complex plane and suppose that the conditions of Lemma  10.1 are vio 
lated (i.e., an eigenvalue of A is the reciprocal of an eigenvalue of A). Then we cannot 
502 
Linear Systems 
construct  v(x)  given  in  (10.10)  in the manner  described  above  (i.e., we  cannot  de 
termine B in the manner  described  above). To overcome this  difficulty,  we form  in 
this case the matrix 
Ao =  (1 + 
"lir""'A", 
(10.14) 
and  we  choose  |j8| arbitrarily  small  and  in  such  a manner  so that  AQ has  no  eigen 
values on the unit circle and has the same number of eigenvalues outside of the unit 
circle of the complex plane as matrix A.  Then  AQ satisfies  the conditions of Lemma 
10.1. For every given  C  =  C^  ^  R^^^  we can now  solve the equation 
AlBAo 
B  =  C 
(10.15) 
to  obtain  a  unique  matrix  B.  We  use  this  matrix  to  form  the  Lyapunov  function 
(10.10). Now since A  =  (1 + /3)^^^Ao, the first forward  difference  Dv(x)  of the Lya 
punov function  v(x)  =  x^Bx  along the solutions of (10.2)  yields 
Dv{x)  =  X'^IAIBAQ 
-  B  + 
[5AIBAO]X 
=  x^{C  +  I3AIBAO)X 
= 
x^Cx, 
(10.16) 
where  C is  given  in  (10.15). It now  follows  that  if  C is negative  definite  (positive 
definite),  then  we  can  choose  |jS| sufficiently  small  so that  C  will  also be  negative 
definite  (positive  definite). 
Summarizing  the above discussion, we have proved the following  result. 
THEOREM  10.13.  If all the eigenvalues of the matrix A are within the unit circle of 
the complex plane, or if at least one eigenvalue is outside the unit circle of the complex 
plane, then there exists a Lyapunov function  of the form v{x)  = x^Bx, B  = B^, whose 
first  forward  difference  along the solutions of system (10.2) is definite  (i.e., it is either 
negative definite or positive definite). 
• 
We conclude this subsection with some specific  examples. 
EXAMPLE 10.12.  (i) For system (10.2) let 
A = 
0  n 
•1  0 
Let B  = I, which is positive definite. From (10.11) we obtain 
C  = A^A  -  I 
ro 
1 
-11 
o| 
r  0  1 
[-1  0 
1  0 
0  1 
0  0 
0  0 
It follows  from  Theorem  lO.ll(i)  that the equilibrium  x  =  0 of this system is stable. 
This is the same conclusion that was made in Example 10.9. 
(ii) For system (10.2) let 
A = 
Choose 
which is positive definite. From (10.11) we obtain 
r  0 
[-1 
r^  01 
3 
^ 
0  ^ 
3  J 
L^ 
A^BA  -  B = 
-11 
oj 
0 
1 
2 
L 
n 
2 oJ 
"r^  0"" "
3 
^ 
0  ^ 
3-
L^ 
-1 
[  0 
"0"" "
- ij 
which is negative definite. It follows from Theorem 10.1 l(ii) that the equilibrium x  = 0 
of this system is asymptotically stable in the large. This is the same conclusion that was 
made in Example 10.9(ii). 
(iii) For system (10.2) let 
503 
CHAPTER  6: 
Stability 
Choose 
A = 
0 
-3 
-i 
0 
C  = 
-1 
0 
0 
-1 
which is negative definite. From (10.11) we obtain 
pll 
[b\2 
C  =  A^BA  -B  = 
bn'] 
Z722J 
[  0 
L-3 
n 
2 
0. 
bn 
bu 
bn 
b22. 
0 
1 
L  2 
-1 
0 
-3^ 
0^ 
0] 
' 
- ij 
m22-bn) 
[ 
\bn 
\bn 
{\bn  - b22). 
which yields 
B = 
-8 
0 
0 
-1 
which is also negative definite. It follows from Theorem 10.11 (iii) that the equilibrium 
X =  0 of this system is unstable. This conclusion is consistent with the conclusion made 
in Example 10.9(iii). 
(iv) For system (10.2) let 
I  1 
0  3 
The eigenvalues of A are Ai  =  |  and A2 =  3. According to Lemma 10.1, for a given C, 
Eq. (10.13) does not have a unique solution in this case since Ai  =  I/A2. For purposes 
of illustration we choose C  =  - /.  Then 
-I  =  A'^BA -  B 
[^11 
[bl2 
.1  3j 
bn] 
^22] 
H  1^ 
[0  3.  =  bn 
bn 
bn 
b22. 
1^11 
^bn 
1^11 
bn  + €>bi2  + 8^22. 
-1 
0 
0  -- 1. 
which shows that for C  =  - /,  Eq. (10.13) does not have any solution (for B) at all. 
R  Linearization 
In  this  subsection  we  determine  conditions  under  which  the  stability  properties  of 
the equilibrium  w  =  0 of the linear  system 
w(k+  1)  =  Aw(k) 
(10.17) 
determine the stability properties of the equilibrium  x  =  0 of the nonlinear  system 
under the assumption  that f(x)  =  o(\\x\\)  as ||x||  -^  0 (i.e., given  e  >  0 there  exists 
x(k  +  1)  =  Ax(k)  +  f(x(k)) 
(10.18) 
504 
Linear Systems 
S  >  0 such  that  \\f(x(k))\\  <  e\\x(k)\\  for a lU  >  0 and all \\x(k)\\  <  8).  [Refer  to the 
discussion  concerning  Eqs.  (10.2)  to (10.4)  in Subsection  A of this  section.] 
THEOREM  10.14.  Assumethat/  G C(R'',"  R"""") and thai f(x)  is o(\\x\\)sis\\x\\  -»  0. (i)If "
A is stable (i.e., all the eigenvalues of A are within the unit circle of the complex plane), 
then  the equilibrium  x  =  0 of  system  (10.18)  is asymptotically  stable,  (ii) If at least 
one eigenvalue of A is outside the unit circle of the complex plane, then the equilibrium 
X =  0 of system (10.18) is  unstable. 
Proof,  (i) Assume that A is stable. Then for any negative definite matrix C, the equation 
has a unique positive definite  solution B. Let 
A^BA 
-B  = C 
v(x)  —  x^Bx. 
Along the solutions of (10.18) we compute the first forward  difference  Dv(x) as 
Dv(x)  =  x^Cx  + 2x^A^Bf(x) 
+  v(/(x)). 
This allows us to estimate  [since f(x)  is 6>(||x||) as ||x|| -^  0] 
Dv(x)  <  AM(C)|WP  + 2||x|| ||A|| \\B\\ \\f(x)\\  +  v(/(x)) 
<  AM(C)||X|P  + 2||A|| \\B\\e\\xf  + AM(5)6^||X|P 
(10.19) 
=  [AM(C)  +  2||A|| \\B\\e  +  XM(B)e^\xf  =  y||x|p 
for  all X E  B(8) and for some 6 >  0, where  AM(C)  <  0, XM(B) > 0 denote the largest 
eigenvalues  of C and B, respectively.  We can make e  as small  as desired  by choosing 
8  sufficiently  small,  resulting  in y  <  0. Therefore,  Dv(x)  is negative  definite  and the 
equilibrium  x  =  0 of system (10.18) is asymptotically  stable. 
(ii) Assume that A has at least one eigenvalue outside the unit circle of the complex 
plane. Following the procedure given in proving Theorem  10.13 [refer to Eqs. (10.14) to 
(10.16)] we construct a Lyapunov function  v(x)  =  x^Bx  whose first forward  difference 
along the solutions of (10.17) is given by Dv(x)  =  x^Cx  [refer to (10.16)]. We choose 
C  to be negative  definite.  Then B is indefinite,  and in every  neighborhood  of the  origin 
there are x  G R^ such that v(x)  =  x^Bx  < 0. 
Next, we evaluate the first forward  difference  of v along the solutions of (10.18) to 
obtain  [identically  as in (10.19)], 
Dv(x)  <  [AM(C)  +  2||A|| \\B\\€  +  AM(B)6^]||X|P  =  y\\xf 
for  all X G B(8)  for  some  6  >  0, where  C is defined  by (10.14)  to (10.16). As in the 
proof  of part  (i), we can force  e  to be as  small  as desired  by choosing  8  sufficiently 
small,  resulting  again  in y  <  0. Therefore,  Dv(x)  is negative  definite.  It follows  from 
Theorem  10.5 that the equilibrium  x  =  0 of (10.18) is unstable. 
• 
Before  concluding  this  subsection,  we consider  some  specific  examples. 
EXAMPLE  10.13.  (i) Consider the system 
Xi(k+l)  =  -{X2(k)  + Xi(kf  +  X2(kf 
X2(k +  1)  =  -xi(k)  +  xi(kf  +  X2{kf. 
Using the notation of (10.18) we have 
A  = 
0 
-1 
-1 
0 
f{M,  X2) 
The linearization of (10.20) is given by 
w(k +  1) -  Aw(k). 
(10.21) 
From Example 10.9(ii) [and Example 10.12(ii)] it follows that the equilibrium w = 
0 of (10.21) is asymptotically stable. Furthermore, in the present case f(x)  =  o(\\x\\) as 
\\x\\ ->  0, Therefore, in view of Theorem 10.14, the equilibrium x  =  0 of system (10.20) 
is asymptotically stable. 
(ii) Consider the system 
505 
CHAPTER 6: 
Stability 
Xi(/:+  1)  =  -^X2(k)  + xi(kf  + X2(kf 
X2(k +  1)  =  -3x1 (y^) + xt(k)  -  X2{k)\ 
Using the notation of (10.17) and (10.18), we have in the present case 
A  = 
0 
3 
i 
2 
0. 
/ ( • ^b 
- ^ 2) 
"X-\  T""  X9 "
Since A is unstable [refer to Example 10.12(iii) and Example 10.9(iii)] and since f{x)  = 
o(\\x\\) as ||x|| ->  0, it follows from Theorem 10.14 that the equilibrium x  =  0 of system 
(10.22) is unstable. 
• 
G.  Input-Output  Stability 
We conclude  this chapter  by considering  the input-output  stability  of  discrete-time 
systems described by equations of the  form 
x(k  +  1)  -  Ax(k)  +  Bu(k) 
y(k)  -  Cx(kl 
(10.23) 
where  all matrices  and vectors  are defined  as in  (10.1). Throughout  this  subsection 
we will assume that  ^0  =  0.  -^(0)  =  0, and  ^ >  0. 
As  in  the  continuous-time  case,  we  say  that  system  (10.23)  is BIBO  stable  if 
there exists a constant  c  >  0 such that the conditions 
x(0)  =  0 
\\u(k)\\ <  1, 
k^O, 
imply that ||3;(^)||  <  c for all fc >  0. 
The results that we will present involve the impulse response matrix of  (10.23) 
given by 
H(k)  = 
fCA^-^B, 
[ 0, 
k>0, 
yk  <  0, 
and the transfer  function  matrix given by 
Recall that 
H(z)  =  C{zl-  AY^B. 
n 
y(n)  =  ^H(n- 
k)u{k). 
(10.24) 
(10.25) 
(10.26) 
506 
Linear Systems 
Associated with system (10.23) is the free dynamical system described by the equa-
^^^^ 
(10.27) 
THEOREM 10.15.  The system (10.23) is BIBO stable if and only if there exists a con 
stant L >  0 such that for all n >  0, 
p{k  +  1)  -  Ap{k), 
X  11^(^)11  ^L. 
(10.28) 
As in the continous-time case, the first part of the proof of Theorem  10.15 (suf 
ficiency)  is  straightforward.  Specifically,  if  ||w(fe)|| <  1 for  all  /: >  0 and if  (10.28) 
is true, then we have for all n  >  0, 
\\y{n)\\ =  \\^H(n 
-  k)u(k)\\  ^J^\\H(n 
-  kMk)\\ 
Therefore,  system  (10.23) is BIBO  stable. 
In proving  the  second  part  of  Theorem  10.15  (necessity),  we  simplify  matters 
by first considering  in (10.23) the single-variable  case (n  =  1) with the system de 
scription given by 
t 
y(t)  =  ^h(t- 
k = 0 
k)u{k), 
t  >  0. 
(10.29) 
For purposes of contradiction, we assume that the system is BIBO stable, but no finite 
L exists such that (10.28) is satisfied. Another way of expressing the last assumption 
is that for any finite L, there exists t  =  ki(L)  =  ki  such that 
^1 
^ 
k = 0 
\h(ki  ~  k)\ >  L. 
We now choose in particular the input u given by 
+ 1 
if  h(t- 
k)>0, 
u(k)  =  ^ 
0 
ifh(t-k) 
=  0, 
[-1 
ifh(t- 
k)<0, 
0  <  k  ^  ki.  Clearly,  \u(k)\  <  1 for  all  k  ^  0. The output  of the  system  ait  =^  ki 
due to the above input, however,  is 
y(ki)  =  ^  h(ki  -  k)u(k)  =  ^ 
\h(ki  -  k)\ >  L, 
which contradicts the assumption that the system is BIBO  stable. 
The above can now be extended to the multivariable case. In doing  so we apply 
the  single-variable  result  to  every  possible  pair  of  input  and  output  vector  compo 
nents, we make use of the fact that the sum of a finite number of bounded  sums will 
be bounded, and we note that a vector is bounded if and only if each of its components 
is bounded. We leave the details to the reader. 
Next, we establish  a connection between the asymptotic  stability  of the equilib 
rium p =  0 of system (10.27) and the BIBO stability of system (10.23). First, we note 
that the  asymptotic  stability  of the  equilibrium x  =  0 of  system  (10.27)  implies  the 
BIBO stability of system (10.23) since the sum 
507 
CHAPTER  6: 
Stability 
<l\\c\ 
k=l 
\k-l\ 
B 
is finite. 
The  main  task  in  proving  the  converse  to  the  above  statement  is  to  show  that 
controllability  and  observability  of  system  (10.23)  and  the  finiteness  of  the  sum 
"Er=i  IIC'A^""^^!! imply the finiteness of the  sum S^Li  ||^^~^ ||- ^^  ^^^ ^^ assume that "
the system (10.23) is BIBO stable. Then,  since 
\\yik)\ 
7=0 
we must have that the power  series 
k-l 
<  y  \\CA''-^J+^^B\\ 
I 
—  .^ 
II 
y 
X-u  II 
\\CA^-^B\\ 
II 
k=\ 
is finite (i.e., absolutely convergent), and this implies that 
"limCA^""^5 =  0. "
(10.30) 
From (10.30) we can conclude that 
lim CAA^-^B  =  lim CA^'^AB  =  lim CA^B = 0, 
and repeating, we arrive at 
lim{CA^)A^-\A'B) 
= 0, 
^,r  =  0 , 1 , . ..  , n-  1. 
We can write this as 
lim 
C 
CA 
CA n-\ 
A^-^[5,A5,--,A^-^5]=0. 
(10.31) 
If we now assume that (10.23) is controllable  (from-the-origin)  and observable, then 
we can select n linearly independent columns of the controllability matrix to form an 
invertible n x n matrix W and n linearly independent rows of the observability  matrix 
to form  an invertible n x n matrix M.  Using (10.31) we conclude that 
l i m M A ^ -V  =  0 
(10.32) 
508 
Linear Systems 
which  yields 
M-'[limMA^-^w]w-^ 
=  limA^-^  =  0. 
(10.33) 
From  (10.33)  we can conclude that the equilibrium  j:?  =  0 of (10.27)  is  asymptoti 
cally stable. To prove this assertion we assume to the contrary that j:?  =  0 of (10.27) 
is not asymptotically stable. This implies that A has an eigenvalue A with |A| >  1. We 
assume the case when A is real and leave the case when A is complex as an exercise 
for the reader. Let ry be an eigenvector associated with A (which must be real). Then 
A^T]  =  X^rj,k>  0. If  17 =  XQ denotes  an initial condition, then the  corresponding 
solution  of  (10.27)  is  given  by  x{k)  =  A^T]  =  X^TJ, fc >  0,  which  does  not  go  to 
zero as ^ —>  00, i.e., limy^_,oo A^~^  7^  0, which contradicts (10.33). {Note:  The above 
proof  solves Exercise 6.31 for the case where the eigenvalues  are real.) 
We have thus arrived at the following  result. 
THEOREM  10.16.  Assume that system (10.23) is controllable  and observable. Then 
system (10.23) is BIBO stable if and only if the equilibrium /? =  0 of system (10.27) is 
asymptotically stable. 
• 
Next,  we  recall  that  a  complex  number  Zp is  dipole  of  H(z)  =  [hjiz)] 
if  for 
some (/, j)  we have  \hij(zp)\  =  ^  (refer  to Section  3.5 for  the definition  of a pole). 
If each entry of H(z)  has only poles with modulus  (magnitude)  less than  1, then, as 
shown in Chapter  2, each entry of H(k)  =  [hij(k)]  consists of a sum of  converging 
terms. It follows  that under these conditions the  sum 
00 
k = 0 
is finite, and any realization of H(z)  will result in a system that is BIBO  stable. 
Conversely, if 
00 
k = 0 
is finite, then  the terms  in every  entry  of H(k)  must be convergent.  But then  every 
entry of ^(z) has poles whose modulus is within the unit circle of the complex plane. 
We have proved the final result of this  section. 
THEOREM 10.17.  The time-invariant system (10.23) is BIBO stable if and only if the 
poles of the transfer  function 
are within the unit circle of the complex plane. 
• 
H(z)  =  C(zI-A)-^B 
6.11 
SUMMARY 
In this chapter we first addressed the stability  of an equilibrium  of  continuous-time 
finite-dimensional  systems  (Part  1). In  doing  so, we first introduced  the concept of 
equilibrium and defined  several types of stability in the sense of Lyapunov  (Sections 
6.3  and 6.4). Next, we established  several  stability  conditions of an equilibrium  for 
509 
CHAPTER 6: 
Stability 
linear time-varying  systems  {LH)  in terms of the state transition matrix and for lin- 
ear  time-invariant  systems  L  in  terms  of  eigenvalues  (Section  6.5).  In  Section  6.6 
we  established  several  geometric  and  algebraic  stability  criteria  for  nth-order,  lin- 
ear,  time-invariant  systems  [including  the  Leonhard-Mikhailov  stability  criterion 
(Theorem  6.1),  the  gap  and  position  stability  criterion  (also  called  the  interlacing 
stability criterion)  (Theorem  6.2),  and the Routh-Hurwitz  criterion  (Theorem  6.4)]. 
Next,  we  established  various  stability  conditions  for  linear  time-invariant  systems 
that are phrased  in terms  of the Lyapunov  Matrix Equation  for  system  (L)  (Section 
6.7). In Section  6.8  we established  conditions  under  which  the asymptotic  stability 
and  the instability  of  an equilibrium  for  a nonlinear  time-invariant  system  (A)  can 
be deduced from  the linearization  of (A). 
Then in Part 2 we addressed the input-output stability of time-varying and time-
invariant linear, continuous-time,  and  finite-dimensional  systems  (Section  6.9). For 
such  systems  we  established  several  conditions  for  bounded  input  bounded  output 
stability  (BIBO  stability)  and we related  some of these to the stabiHty properties of 
an  equilbrium. 
The  chapter  concluded  with  Part  3  (Section  6.10),  where  we  addressed  the 
Lyapunov  stability  and  the  input-output  stability  of  (time-invariant)  systems.  For 
such  systems,  we  established  results  that  are  analogous  to  the  stability  results  of 
continuous-time  systems  considered  in Parts  1 and 2.  [Among other topics, we dis 
cussed  in  Subsection  6.10D  the  Schur-Cohn  criterion  (which  is  analogous  to  the 
Routh-Hurwitz  criterion  for  continuous-time  systems),  and  in  Subsection  6.10E 
we  established  stability  criteria  involving  the  Lyapunov  Matrix  Equation  for  the 
discrete-time  case.] 
6.12 
NOTES 
The initial contributions to stability theory that took place toward the end of the last 
century  are primarily  due to physicists  and mathematicians  (Lyapunov  [14]), while 
input-output stability is the brainchild of electrical engineers (Sandberg  [21] to [23], 
Zames  [26],  [27]).  Sources  with  extensive  coverage  of  Lyapunov  stability  theory 
include, e.g., Hahn [7], Khalil [11], LaSalle [12], LaSalle andLefschetz  [13], Michel 
and Miller [17], Michel and Wang [18], Miller and Michel [19], and Vidyasagar [25]. 
Input-output  stability  is addressed  in great detail in Desoer  and Vidyasagar  [5] and 
Vidyasagar  [25]. For  a  survey  that  traces  many  of  the  important  developments  of 
stability in feedback  control, refer  to Michel [15]. 
In  the  context  of  linear  systems,  nice  sources  on  both  Lyapunov  stability  and 
input-output  stability  can be found  in numerous texts, including Brockett  [2], Chen 
[3], DeCarlo  [4], Kailath  [10], and  Rugh  [20]. In  developing  our presentation,  we 
found  the  texts  by  Brockett  [2], Hahn  [7], LaSalle  [12], Miller  and  Michel  [19], 
and Rugh  [20] especially helpful. For a proof of the Schur-Cohn criterion, and other 
related results, refer  to the elegant book by Jury [9]. 
The background material summarized in the second section is developed in most 
standard linear algebra texts, including the classic books by Birkhoff  and  MacLane 
[1],  Gantmacher  [6], and  Halmos  [8]. For  more  recent  references  on  this  subject, 
refer,  e.g., to the books by Michel and Herget  [16] and Strang [24]. 
510 
Linear  Systems 
6.13 
R E F E R E N C ES 
1.  G.  Birkhoff  and  S.  MacLane,  A  Survey  of  Modern  Algebra,  Macmillan,  New  York, 
1965. 
2.  R. W. Brockett, Finite  Dimensional  Linear  Systems,  Wiley, New York,  1970. 
3.  C. T. Chen, Linear  System  Theory  and Design,  Holt, Rinehart  and Winston, New  York, 
1984. 
4.  R. A. DeCarlo, Linear  Systems,  Prentice-Hall, Englewood  Cliffs,  NJ,  1989. 
5.  C. A. Desoer and M. Vidyasagar, Feedback  Systems:  Input-Output  Properties,  Academic 
Press, New York,  1975. 
6.  F. R. Gantmacher,  Theory  of Matrices,  Vols. I, II, Chelsea, New York,  1959. 
7.  W  Hahn, Stability  of Motion,  Springer-Verlag, New York,  1967. 
8.  P. R. Halmos, Finite  Dimensional  Vector Spaces,  Van Nostrand, Princeton, NJ,  1958. 
9.  E. I. Jury, Inners  and Stability  of Dynamical  Systems,  Robert E. Krieger Publisher, Mal 
abar, PL,  1982. 
10.  T. Kailath, Linear  Systems,  Prentice-Hall, Englewood  Cliffs,  NJ,  1980. 
11.  H. K. KJialil, Nonlinear  Systems,  Macmillan, New  York,  1992. 
12.  J.  P. LaSalle,  The  Stability  and  Control  of  Discrete  Processes,  Springer-Verlag,  New 
York,  1986. 
13.  J. P. LaSalle  and  S. Lefschetz,  Stability  by Liapunov's  Direct  Method,  Academic  Press, 
New York, 1961. 
14.  M.  A.  Liapounoff,"  ""Probleme  generate  de  la  stabilite  de  mouvement","""  Ann.  Fac.  Sci. "
Toulouse,  Vol.  9,  1907,  pp.  203-474.  (Translation  of  a  paper  published  in  Comm. 
Soc.  Math.  Kharkow  1893,  reprinted  in  Ann.  Math.  Studies,  Vol.  17,  1949,  Prince 
ton, NJ.) 
15.  A. N. Michel," ""Stability: the common thread in the evolution of feedback  control","""  IEEE "
Control  Systems,  Vol.  16, 1996, pp. 50-60. 
16.  A. N. Michel  and C. J. Herget, Applied  Algebra  and  Functional  Analysis,  Dover,  New 
York, 1993. 
17.  A. N. Michel and R. K. Miller,  Qualitative  Analysis  of Large  Scale  Dynamical  Systems, 
Academic Press, New York,  1977. 
18.  A. N. Michel  and K. Wang,  Qualitative  Theory  of Dynamical  Systems,  Marcel  Dekker, 
New York,  1995. 
19.  R. K. Miller and A. N. Michel,  Ordinary  Differential  Equations,  Academic Press, New 
York,  1982. 
20.  W. J. Rugh, Linear  System  Theory, Second Edition, Prentice-Hall, Englewood CHffs, NJ, 
1996. 
21.  I. W. Sandberg," ""On the L2-boundedness of solutions of nonlinear functional  equations",""" "
BellSyst.  Tech. J., Vol. 43, 1964, pp.  1581-1599. 
22.  I. W.  Sandberg,"  ""A  frequency-domain  condition  for  stability  of feedback  systems  con "
taining  a  single  time-varying  nonlinear  element,"""  Bell  Syst.  Tech.  J.",  Vol.  44,  1974, 
pp.1601-1608. 
23.  I. W. Sandberg,"  ""Some results on the theory of physical  systems  governed  by  nonlinear "
functional  equations,""" Bell  Syst.  Tech. J.", Vol. 44,  1965, pp. 821-898. 
24.  G. Strang, Linear Algebra  and its Applications,  Harcourt, Brace, Jovanovich, San Diego, 
1988. 
25.  M. Vidyasagar, Nonlinear  Systems Analysis,  2d edition. Prentice Hall, Englewood  Cliffs, 
NJ,  1993. 
26.  G.  Zames,"  ""On  the  input-output  stability  of  time-varying  nonlinear  feedback  systems. "
Part I,""" IEEE  Transactions  on Automatic  Control",  Vol. 11, 1966, pp. 228-238. 
27.  G.  Zames,"  ""On  the  input-output  stability  of  time-varying  nonlinear  feedback  systems. "
Part II,""" IEEE  Transactions  on Automatic  Control",  Vol.  11, 1966, pp. 465-476. 
6.14 
E X E R C I S ES 
6.1.  Determine the set of equilibrium points  of a system  described by the differential  equa 
tions 
511 
CHAPTER 6: 
StabiHty 
Xi  =  Xi  -  X2  +  X3 
X2  =  2xi  +  3X2  +  -^3 
^3  =  3JCI  +  2X2  +  2X3. 
6.2.  Determine the set of equilibria of a system described by the differential  equations 
Xi  =  X2 
^2  =  S 
xi  sin  —  , 
when  xi  T^ 0, 
0, 
when  xi  =  0. 
6.3.  Determine the equilibrium points and their stability properties of a system described by 
the ordinary  differential  equation 
x  =  x(x-l) 
(14.1) 
by solving (14.1) and then applying the definitions  of stability, uniform  stability, asymp 
totic stability, etc. 
6.4.  Determine the set of equilibria and their stability properties of a system described by the 
ordinary differential  equation 
X =  (cost)x 
(14.2) 
by solving (14.2) and then applying the definitions  of stability, uniform  stability, asymp 
totic stability, etc. 
6.5.  Determine the set of equilibria and their stability properties of a system described by the 
ordinary  differential  equation 
X =  (4tsmt-2t)x 
(14.3) 
by solving (14.3) and then applying the definitions  of stability, uniform  stability, asymp 
totic stability, etc. 
6.6.  Determine the state transition matrix ^(t,  to) of the  system 
U\ 
[x2 
0  1 
-2t\ 
_{2t  -  t) 
X2_ 
Xi' 
-t 
Use  Theorems  5.1  to  5.4  to determine  the  stability  properties  of  the  trivial  solution  of 
this  system. 
6.7.  Show that the second-degree  polynomial 
f{s)  =  s^ + 2as  + b 
is  a  Hurwitz  polynomial  if  and  only  if  a>  0  and  Z?  >  0  by  (i)  solving  the  equation 
f{s)  =  0, and (ii) using the Routh-Hurwitz  criterion  (Theorem  6.4). 
6.8.  Determine whether the third-degree  polynomial 
f(s)  =  s^ + 3s^ + 3s  + 2 
512 
Linear Systems 
is  a  Hurwitz  polynomial  by  (i)  solving  the  equation  f(s)  =  0,  (ii)  applying  Theorem 
^•^'  ^^^^^ ^PP^yi^g Theorem  6.2, and (iv) applying Theorem  6.4. 
6.9.  Let A  G  C[/?+," /?""><""] and x  G 7?"" and  consider "
X =  A(t)x. 
(LH) 
Show  that  the  equilibrium  x^  =  0  of  (LH)  is  uniformly  stable  if  there  exists  a  2  G 
C^ [/?+," Z?^""""""] such that 2 (0  =  [Q(t)f  for all r and if there exist constants C2 >  ci  >  0 "
such that 
cil  <  2 (0  <  C2/, 
r G R, 
(14.4) 
and such that 
[A(0]^2(0  +  Q(t)A(t)  + m 
(14.5) 
where /  is the  fz X ^  identity  matrix. Hint:  The proof  of this  assertion  is  similar  to  the 
proof of Theorem 7.1. 
<  0, 
t^R, 
6.10.  Show that the equilibrium  Xg =  0 of {LH) is exponentially  stable  if there exists a 2  ^ 
C^/?^,^''''''] such that 2 (0  =  [2(01^  for alU and if there exist constants C2 >  ci  >  0 
and C3 >  0 such that (14.4) holds and such that 
[A(0]^2(0  +  Qit)A{t)  +  2 (0  ^  -C3I, 
t  G R. 
(14.6) 
Hint:  The proof  of this assertion  is similar to the proof  of Theorem  7.2. 
6.11.  Assume that the equilibrium Xg =  0 of {LH) is exponentially  stable and that there exists 
a constant a>  0 such that ||A(0||  ^  a for  all t  G R,  Show that the matrix given by 
2 (0  -^  j 
[a)(T,0]'^O(T,0^T 
(14.7) 
satisfies  the hypotheses  of the result  given  in Exercise  10. Hint:  The proof  of this as 
sertion is similar to the proof of Theorem 7.5. 
6.12.  For  {LH)  let  A^(0  and  AM(0  denote  the  smallest  and  largest  eigenvalues  of  A{t)  + 
[A{t)]^  at r G /?, respectively. Let (/)(^, ^o, XQ) denote the unique solution of {LH) for the 
initial  data  x{to)  =  XQ =  (^{t^, to, x).  Show  that  for  any  XQ  G  R^  and  any  ^o G  R,  the 
unique solution of {LH) satisfies  the estimate, 
||^(^^ ^^^ ^^^11 ^ 
11^^11^(1/2)1,; A„(.).x  ^ 
||^^||^o/2)(,; A,(.)..^ 
^ ^  ^^^ 
^j4 g^ 
//mL- Let v(r, ^0, XQ)  =  [4>{t, to, xo)V[(l){t, to, xo)]  =  \\(l){t, to, xo)p, evaluate v{t, to, xo), 
and then estabHsh (14.8). 
6.13.  Use Exercise  6.12  to show  that the equilibrium  Xg =  0 of  {LH) is  uniformly  stable  if 
there exists a constant c such that 
ft 
XM{T)dT^c 
(14.9) 
for  all  t, a  such  that  t  >  a,  where  AM(0  denotes  the  largest  eigenvalue  of  A{t)  + 
[A{t)Y,  t  G R. Hint:  Use (14.8) and the definition  of uniform  stabihty. 
6.14.  Use Exercise 6.12 to show that the equilibrium  Xg =  0 of (LH) is exponentially  stable 
if there exist constants e  >  0, a;  >  0 such that 
XM{T)dT  <  -a{t 
-  (7)  +  6 
(14.10) 
for all t, a  such that t  >  a.  Hint.  Use (14.8) and the definition  of exponential  stabihty. 
6.15.  Let V be a quadratic function  of the form 
513 
V(XJ)  =  x'^Q(t)x, 
(14.11) 
CHAPTER6: 
where xGR^'.Qe 
Evaluate the derivative of v with respect to t, along the solutions of {LH), to obtain 
C^[R," /?""><«]", Q(t)  =  [2(01^,  and  Q(t)  ^  kl,k> 
0, for  all t  e  R. 
Stability 
ViLH){x, t)  =  x^[[A(0]^G(0  +  Q(t)A(t)  +  Q(t)]x. 
(14.12) 
Assume  that  there is  a quadratic  form  w(x)  =  x^Wx  <  0, where  W'^  =  W  G 7?«x«, 
such that 
V(LH)(x,t)^  W(X) 
for  all (x, t)  G  G  X  R," where G is a closed and bounded  subset of /?"". Let "
E  =  { x E G:  w(jc)  =  0} 
(14.13) 
(14.14) 
and assume that for  (LH),  \\A(t)\\ is bounded  on R. Prove that any solution of (LH)  that 
"remains in G for all ^ >  fo —  0 approaches £"" as ^ ^  oo. "
6.16.  Consider the  system 
which by letting  xi  =  x  and X2 -  x  can be written as 
X  +  a(t)x  + X  =  0, 
Xi  =  X2 
X2  = 
-a(t)X2 
-  Xi. 
Assume  that  a  G  C[R, R^]  and  that  there  are  constants  ci, C2  such  that  0  <  ci  < 
a(t)  ^  C2 for all t  G R. Let v(x)  =  x\-\r  x\.  First, show that all solutions of this system 
are bounded.  Next,  use  the  results  of  Exercise  6.15  to  show  that  ^2it,  to, -^o) ->  0  as 
6.17.  Assume  that  for  system  {LH) there  exists  a  quadratic  function  of  the  form  v(jc, 0  = 
x^Q(t)x,  where  Q(t)  =  [Q(t)f  G  C^[R," 7?""''""]  and  Q(t)  >  cl  for  some  c>  0",  such 
that  V(LH)(x, t)  <  x^Wx,"  where  W  =  W'^  G  R""""^""""  is negative  definite.  Show that if v "
is  negative  for  some  {x, t),  then  the  equilibrium  Xg  =  0  of  system  {LH)  is  unstable. 
Hint.  The  proof  of  this  assertion  follows  along  similar  lines  as the proof  of  Theorem 
7.3. 
6.18.  It is shown that if the equilibrium  Xe =  0 of system {LH) is exponentially  stable, then 
there exists  a function  v that  satisfies  the requirements  of the result given  in  Exercise 
6.10, i.e., the present result is a converse  theorem  to the result given in Exercise  6.10. 
In  system  {LH),  let A  be  bounded  for  all  ^ G  /?, let  L  =  L^  G  C^[R," /?""><""] and "
assume that L is bounded for all t  G R.  Show that the integral 
Q{t)= 
f 
ma,t)VL{a)^{(T,t)da 
exists for all t  G R.  Show that the derivative of the  function 
v{xj)  =  x^Q{t)x 
(14.15) 
with respect to t along the solutions of {LH) is given by 
y(LH){xj)  = 
-X^L{t)x. 
Next,  show  that  if  L{t)  >  c^I,  C3  >  0,  for  all  t  G  R,  then  there  exist  constants  C2 ^ 
Cl  >  0 such that for all t  G  R, 
c i /<  Q{t)^  C2I, 
(14.16) 
"where /  G /?""^""  denotes the identity  matrix. "
514 
Linear  Systems 
Note  that  the  above  result  constitutes  a  generalization  to  Theorem  7.5  for  time-
invariant  systems (L). 
6.19.  Apply  Proposition  7.1  to  determine  the  definiteness  properties  of  the  matrix A  given 
by 
A  = 
1 
2 
1 
2 
5 
-1 
1 
-1 
10 
6.20.  Use Theorem 7.3 to prove that the trivial solution of the  system 
is unstable. 
3  4 
2  1 
6.21.  Determine the equilibrium points of a system described by the differential  equation 
X =  -X  + x^ 
and determine the stability properties of the equilibrium points, if applicable, by using 
Theorem  8.1 or  8.2. 
6.22.  The system described by the differential  equations 
Xi  =  X2 + Xi(xj  +  xl) 
Xi  +  X2{x\  +  x\) 
(14.17) 
has  an equilibrium  at the origin  x^  =  {x\,  X2) =  (0, 0). Show that the trivial  solution 
of  the  linearization  of  system  (14.17)  is  stable.  Prove  that  the  equilibrium  x  =  0 of 
system (14.17) is unstable. (This example shows that the assumptions on the matrix A 
in Theorems  8.1  and 8.2 are absolutely  essential.) 
6.23.  Prove that the system given by 
'xx' 
M. 
'yi 
J2J 
{It 
-1) 
\xi 
0] 
-2t\ 
+ 
cost 
sint 
sin^l 
cos^J 
U\ 
[X2_ 
-
uit) 
is BIBO  stable. 
6.24.  Use Theorem 9.3 to analyze the stability properties of the system given by 
i:  =  Ax  +  Bu 
y  =  Cx 
A 
1 
1 
0 
-1 
B  = 
1 
-1 
C  =  [0,  1]. 
6.25.  Determine  all equilibrium points for the discrete-time  systems given by 
(a) 
xi(k+  1)  -  X2(k) +  \xi(k)\ 
X2(k+  1)  =  -Xi(k)  + \x2(k)\ 
(b) 
Xi(k+ 
1)  =  Xi(k)X2(k) 
-  1 
X2(k  +  1)  =  2xi(^)jC2(^)  +  1. 
6.26.  Consider the discrete-time  system given by 
515 
CHAPTER  6: 
Stability 
where for 0  =  (Oi,...,"  OnV  e  /?""", sat6  =  [satOi,..., 
satdnV.  and 
x(k-{-  1)  -  sat[Ax(k)] 
(14.18) 
5<2^^/  = 
r  1, 
^/  >  1, 
- 1, 
Oi  <  1. 
"(a)  For A G /?""^"" arbitrary", use Theorem  10.1 to analyze system  (14.18). 
(b)  Imposing  various restrictions  on the locations  of the eigenvalues  of A in the com 
plex plane, use  as many  results  of this chapter  as you can  to analyze the  stability 
properties of the trivial solution of system  (14.18). 
6.27.  Determine  the  stability  properties  of  the  trivial  solution  of  the  discrete-time  system 
given by the  equations 
"'xx{k+  1)"" "
Mk  +1). 
cos 0 
- s i n^ 
sin ^ 1 
cosOj 
\xx{k) 
[x2{k) 
with 6  fixed. 
6.28.  Analyze  the  stability  of the equilibrium  x  =  0 of the  system  described  by the  scalar-
valued difference  equation 
x{k  +1)  =  sin[x(^)]. 
6.29  Analyze the stability of the equilibrium x  =  0 of the system described by the  difference 
equations 
Xx{k  +  1)  =  Xx{k)  +  X2{k){Xi{kf 
X2(k  +  1)  =  X2(k)  -  xi(k)[xi(kf 
-h  X2{kf^ 
+ 
X2(kfl 
6.30.  Determine  a basis of the solution space of the  system 
xi(k+  1) 
X2(k +  1)J 
0  1 
-6  5 
xi(k) 
[X2(k), 
Use your answer in analyzing the stability of the trivial  solution of this  system. 
"6.31.  Let A E  /?""^"". Prove that part (iii) of Theorem  10.8 is equivalent to the statement  that "
all eigenvalues  of A have modulus less than  1, i.e., 
lim ||Ai  =  0 
if and only if for any eigenvalue  A of A, it is true that  |A| <  1. 
6.32.  Use Theorem  10.7 to show that the equilibrium  x  =  0 of the  system 
x(k  +  1)  = 
1 
0 
0 
1 
1 
1 
1 
. 
. 
. 
. 
0 
0 
. 
. 
1 
1 
1 
x(k) 
is unstable. 
516 
6.33.  (a) Use Theorem  10.9 to determine the stability of the equilibrium x  =  0 of the system 
Linear  Systems 
"""1  1 "
x(k  -\-l)  =  0  1 
- 21 
3 
9 -1 
x(k). 
0 
(b) Use Theorem  10.9 to determine the stabiHty of the equilibrium x  =  0 of the system 
x(k+l)  =  \o 
ri  0 
1 
[o  9 
-21 
slxik). 
- ij 
6.34.  Apply the Schur-Cohn criterion (Theorem  10.10) in analyzing the stability of the trivial 
solution of the system given by the  equations 
xi(y^+l)] 
X2(k+  1)  = 
U3(/^+l)J 
r - 0 .5 
0.5 
I.  0 
0.5irxi(^) 
0 
0 
0 
\\x2(k) 
-0.5  0JU3W, 
"6.35.  Apply  Theorems  7.2  and  10.11  to  show  that  if  the  equilibrium  x  =  0  (x  E. /?"")  of "
the  system 
x(k  +1)  =  e^x(k) 
is asymptotically  stable, then the equilibrium  x  =  0 of the  system 
is also asymptotically  stable. 
X =  Ax 
6.36.  Apply Theorem  10.11 to show that the trivial solution of the system given by 
xi(k+  1) 
[X2(k +  1)J 
0  2  xi(k) 
[2  Oj [X2(k) 
is unstable. 
6.37.  Determine the stability of the equilibrium  x  =  0 of the scalar-valued  system given by 
6.38.  Analyze the stability properties of the discrete-time  system given by 
x(k+ 
I)  =  ^x(k)  +  f  sin jc(^). 
x(k+ 
I)  =  x(k)  +  ^u(k) 
y(k)  = 
'^x(k) 
where x, y, and u are scalar-valued variables. Is this system BIBO stable? Can Theorem 
10.16 be applied in the analysis of this  system? 
CHAPTER? 
Polynomial Matrix Descriptions 
and Matrix Fractional 
Descriptions of Systems 
In this chapter, representations of linear time-invariant systems based on polynomial 
matrices, called Polynomial  Matrix  Description  (PMD)  or Differential  (Difference) 
Operator  Representation  (DOR)  are  introduced.  Such  representations  arise  natu 
rally  when  differential  (or difference)  equations  of  order  higher  than  one  are  used 
to describe  the behavior  of  systems,  and  the  differential  (or difference)  operator  is 
introduced  to  represent  the  operation  of  differentiation  (or  of  time-shift).  Polyno 
mial  matrices  in place  of polynomials  are involved  since this  approach  is  typically 
used to describe MIMO  systems. Note that  state-space  system descriptions  involve 
only first-order differential  (or difference)  equations, and as such, PMDs include the 
state-space descriptions  as special cases. 
A rational function  matrix can be written as a ratio or fraction  of two polynomial 
matrices or of two rational matrices. If the transfer function  matrix of a system is ex 
pressed  as  a fraction  of two polynomial  or rational  matrices, this  leads  to a  Matrix 
Fraction(al)  Description  (MFD)  of the system. The MFDs that involve  polynomial 
matrices, called polynomial MFDs, can be viewed as representations of internal real 
izations of the transfer  function  matrix, i.e., as system PMDs of special form.  These 
polynomial  fractional  descriptions  (PMFD)  help establish  the relationship  between 
internal and external system representations in a clear and transparent manner. This 
can be used  to advantage,  for  example,  in the  study  of feedback  control  problems, 
leading to clearer understanding  of the phenomena  that occur when  systems  are in 
terconnected  in  feedback  configurations.  The  MFDs  that  involve  ratios  of  rational 
matrices, in particular, ratios of proper and stable rational matrices, offer  convenient 
characterizations  of transfer  functions  in feedback  control problems. 
517 
518 
Linear Systems 
MFDs that involve ratios of polynomial matrices and ratios of proper and stable 
rational matrices are essential in parameterizing  all stabilizing feedback  controllers. 
Appropriate  selection  of the parameters  guarantees  that a closed-loop  system is not 
only  stable but will also  satisfy  additional  control  criteria. This is precisely  the ap 
proach  taken  in  optimal  control  methods,  such  as  //°°-optimal  control.  Parameter-
izations  of  all  stabilizing  feedback  controllers  are  studied  extensively  in  Part  2 of 
this chapter. We note that extensions of MFDs are also useful  in linear  time-varying 
systems and in nonlinear  systems. These extensions  are not addressed here. 
In  addition  to  the  importance  of  MFDs  in  characterizing  all  stabilizing  con 
trollers, and in //°°-optimal control, PMFDs and PMDs have been used in other con 
trol design  methodologies  as well  (e.g.,  self-tuning  control). The use  of PMFDs  in 
feedback  control leads in a natural way to the polynomial Diophantine matrix equa 
tion that is central in control design when PMDs are used and that directly leads to the 
characterization  of  all  stabilizing  controllers. The  Diophantine  Equation  is  studied 
at length in Part  1 of this chapter. Finally, PMDs  are generalizations  of  state-space 
descriptions,  and  the  use  of  PMDs  to  characterize  the  behavior  of  systems  offers 
additional  insight  and  flexibility.  These  issues  are  also  explored  in  Part  1 of  this 
chapter. 
7.1 
INTRODUCTION 
In this chapter. Polynomial Matrix Descriptions  (PMDs) and Matrix Fractional De 
scriptions (MFDs) are used to study properties such as controllability,  observability, 
and stability, primarily  of interconnected  systems, and to conveniently  characterize 
all stabilizing feedback  controllers. These system descriptions are important in feed 
back control system analysis and design and are the key to developing control design 
theories such as H'^-opiimal  control. 
The  development  of  the  material  in  this  chapter  is  concerned  only  with 
continuous-time  systems;  however,  completely  analogous  results  are  valid  for 
discrete-time  systems and can easily be obtained by obvious  modifications. 
In the following,  PMDs and MFDs  are first introduced by an illustrative  exam 
ple. Next, the contents of the chapter  are briefly  described  and  some guidelines  for 
the reader are provided. 
An important comment on notation 
In this chapter we will be dealing with matrices with entries that are polynomials 
in s or q, denoted by, e.g., D(s)  or D(q).  For simplicity of notation we frequently  omit 
the argument 5* or ^ and we write D to denote the polynomial matrix on hand. When 
ambiguity  may  arise,  or  when  it  is  important  to  stress  the  fact  that  the  matrix  in 
question is a polynomial matrix, the argument will be  included. 
A.  A Brief  Introduction  to Polynomial  and Fractional  Descriptions 
The PMD and the MFD of a linear time-invariant system are introduced via a simple 
motivating  example. 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  1.1. 
by 
In the  ordinary  differential  equation  representation  of  a system  given 
519 
yi(t)  +  yi(t)  +  yiit)  =  uiit)  +  ui(t) 
yi(t)  + Ht)  + 2y2(t)  = U2(t) 
(1.1) 
yi(t\  yiit)  and ui(t),  U2(t) denote, respectively, outputs and inputs of interest. We assume 
that  appropriate  initial  conditions  for  the  w/(r), yi(t)  and  their  derivatives  at  r  =  0  are 
given. 
By  changing  variables,  one  can  express  (1.1)  by  an  equivalent  set  of  first-order 
ordinary  differential  equations,  in  the  sense  that  this  set  of  equations  will  generate  all 
solutions  of (1.1), using  appropriate  initial conditions  and the  same inputs. To this  end, 
let 
xi  =  yi  -  U2, 
X2  =  yi, 
X3 
yi  +  y i-  U2. 
Then  (1.1) can be written  as 
X =  Ax  +  Bu, 
y  =  Cx  +  Du, 
u{t)  = 
Ui(t) 
U2(t) 
y(t)  = 
yi(t) 
yiit). 
and 
B  = 
1 
0 
0 
-1 
1 
-2 
C  = 
1 
-1 
D  = 
lxi(t) 
X2(t) 
X3(t)\ 
-1 
0 
-2 
where x{t)  = 
A  = 
0  0 
1  0 
0  2 
with initial conditions  x(0)  calculated by using (1.2). 
More directly, however,  system (1.1) can be represented  by 
where 
P(q) 
P(q)z(t)  =  Q{q)u{t), 
Z{t) = 
zx{t) 
Z2(t)\ 
, U(t)  = 
y{t)  =  R{q)z{t)  +  W{q)u{t), 
Ui(t) 
uiit) 
y{t)  = 
and 
2 +  1 
1 
q 
q  + 2 
Q(q)-
q 
q 
R(q) 
W(q) 
yi(t) 
yiit). 
I 
0 
(1.2) 
(1.3) 
(1.4) 
with q  =  didt,  the differential  operator. The variables zi{t),  ziif)  are called/7(2r^/(2/ state 
variables,  z(t)  denotes iht  partial  state  of the system description  (1.4), and u{t) and  y{t) 
denote the input and output vectors, respectively. 
• 
Polynomial  matrix  descriptions  (PMD) 
Representation  (1.4), also  denoted  as {P{q),  Q{q),  R{q),  W{q)},  is  an  example  of 
a  PMD  of  a  system.  Note  that  the  state-space  description  (1.3)  is  a  special  case  of 
(1.4).  To  see  this, v^rite  (1.3)  as 
{ql  -  A)x{t)  =  Bu{t\ 
y(t)  =  Cx(t)  +  Du(t), 
(1.5) 
Clearly,  description  {ql  -  A,  B,  C, D]  given  in  (1.5)  is  a  special  case  of  the  general 
P MD  {P{q),  Q(q\  R(q\  W(q)}  with 
P(q)  =  ql-A, 
Q(q)  =  B, 
R{q)  =  C, 
^{q)  =  D. 
(1.6) 
The  above  example  points  to  the  fact  that  a  PMD  of  a  system  can  be  derived 
in  a  natural  way  from  differential  (or  difference)  equations  that  involve  variables 
that  are  directly  connected  to  physical  quantities.  By  this  approach,  it  is  frequently 
520 
Linear Systems 
possible  to  study  the  behavior  of  physical  variables  directly  without  having  to 
transform  the  system  to  a  state-space  description.  The  latter  may  involve  (state) 
variables  that are quite removed  from  the physical phenomena  they represent,  thus 
losing  physical  insight  when  studying  a  given  problem.  The  price  to  pay  for  this 
additional insight is that one has to deal with differential  (or difference)  equations of 
order greater than  1. This typically adds computational burdens. We note that certain 
special  forms  of PMDs, namely, the polynomial  MFD,  are easier  to deal with  than 
general  forms.  However,  a  change  of  variables  may  again  be  necessary  to  obtain 
such  forms. 
Consider a general PMD of a system given by 
P{q)z{t)  =  Q(q)u(t\ 
y(t)  =  R(q)z(t)  +  W(qMt) 
(1.7) 
withP(^)  G Rlgy^'K  Q(q)  G Riq]^'''^ and R(q)  G RlqV^'K  W(q)  G /?[^]^X'^, where 
Rlq^^^  denotes the set of /  X / matrices  with entries that are real polynomials  in  q. 
The transfer  function  matrix H(s)  of (1.7) can be determined  by taking the Laplace 
transform  of  both  sides  of  the  equation  assuming  zero  initial  conditions  (z(0)  = 
^(0)  =  ...  =  0," u(0)  =  u(0)  =  '""  =  0). Then "
H(s)  =  R(s)p-\s)Q(s) 
+  W(s). 
(1.8) 
For the special case of state-space representations, [see (1.6)]; H(s)  in (1.8) assumes 
the well-known expression H(s)  =  C(sl  — Ay^B  + D. For the study of the relation 
ship between external and internal descriptions, (1.8) is not particularly  convenient. 
Indeed,  it appears  that it is as difficult  to investigate the relationship  between  H{s) 
and PMDs as it was to study the relationship between H{s)  and state-space descrip 
tions. There are, however, special cases of (1.8) that are very convenient to use in this 
regard.  In particular,  as will be  shown  in  Section  7.3, if the  system  is  controllable, 
then there exists a representation  equivalent to (1.7) that is of the  form 
DM)Zcit)  =  u{t), 
yit)  =  NM)Zc{t\ 
(1.9) 
"where Ddq)  G R[qY''''^  and Nc{q)  G Riq^""^.  Representation  (1.9) is obtained by "
letting  Q{q)  =  I^  and  W(q)  =  0 in (1.7). It is common to use D and N  instead of  P 
and R, in view of 
H(s)  =  Nc(s)Dc(sr\ 
(1.10) 
where Nds)  and  Dds)  represent  the matrix  numerator  and  matrix  demonimator  of 
the transfer function, respectively. Similarly, if the system is observable, there exists 
a representation  equivalent to (1.7) that is of the  form 
Do(q)Zo(t)  =  No(q)u(t), 
y(t)  =  ZoU), 
(1.11) 
"where  Do{q)  G  R[q\P^P  and  A^^(^)  G  RiqY^""^.  Representation  (1.11)  is  obtained "
by letting R{q)  -  Ip and  W{q)  =  0 in (1.7) with P{q)  -  Do{q) and Q{q)  = No{q)-
Here, 
H{s)  =  D-\s)No{s\ 
(1.12) 
Note that  (1.10)  and  (1.12)  are generalizations  to the MIMO  case of the SISO sys 
tem  expression  H{s)  =  n(s)/d(s).  In the  same  manner  as H(s)  =  n(s)/d(s)  can  be 
derived  from  the  differential  equation  d(q)y(t)  =  n(q)u(t),  (1.12)  can  be  derived 
from  (1.11), usually written as i)o(^)};(0  =  No(q)u(t). 
Returning now to (1.3) in the example, notice that the system is observable (state 
observable from the output y). Therefore, the system in this case can be represented 
by a description of the form {Do, No, h,  0}. In fact  (1.4) is such a description,  where 
Do and No  are equal to P and  Q, respectively,  i.e., Do(q)  = 
q^+  1 
1 
q  + 2 
,  and 
No(q)  = 
H(s) 
1  q 
[O  q 
C{sl-  Ay^B  + D 
. The transfer function  matrix 
is, given by 
521 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
"""0 "
0 
1  Ol 
ij 
-1 
'  s 
0 
- 1 ^0 
0 
-2 
D-\s)No{s)  = 
1 
^3 +  2^2 +  2 
52 +  1 
5 
\s + 2 
[  -s 
"""0  0"" "
0  1 
+ 
-1  r 
"1  "" "
s + 1 
-1 
"1  "" "
5 +  2 
"""1 "
0 
0 
"""1 "
0 
-1 
1 
-2_ 
s 
s 
-1  1 
s^ +  ij 
ri  s 
[0  s 
= 
1 
S'  + 2^ 2 +  2 
-s 
s{s +  1) 
Matrix fractional  descriptions  (MFDs) of system transfer  matrices 
A given pXm  proper, rational transfer  function  matrix H{s)  of a system can be 
represented  as 
H{s)  =  NR(S)D^\S) 
= 
DI\S)NL(S), 
(1.13) 
E  R[sr'''^  mdNiis)  E  RlsV'^.DUs) 
whevQ NR(S)  E  Rlsy'^.DRis) 
RISVP. 
The pairs {NR(S),  DR(S)}  and {DL(S),  NL(S)}  are called Polynomial  Matrix  Fractional 
Descriptions  (PMFDs)  of the  system  transfer  matrix  with  {NR(S\  DR(S)} 
termed  a 
right Fractional  Description  and {DL(S),  NL(S)}  a left Fractional  Description.  Notice 
that in view of (1.10), the right Polynomial Matrix Fractional Description  (rPMFD) 
corresponds to the controllable PMD given in (1.9). That is, {DR,  Im, NR, 0}, or 
E 
DR(q)zR(t)  =  u(t), 
y(t)  =  NR(q)zR(t) 
(1.14) 
is a controllable PMD of the system with transfer function  H(s).  The subscript c was 
used in (1.9) and (1.10) to emphasize the fact that Nc, Dc originated from an internal 
description  that  was  controllable.  In  (1.13)  and  (1.14),  the  subscript  R  is  used  to 
emphasize that {NR,  DR} is a right fraction  representation of the external  description 
H(s). 
Similarly,  in view  of  (1.12), the left  Polynomial  Matrix Fractional  Description 
(IPMFD) corresponds to the observable PMD given in (1.11). That is, {DL,  NL, Ip, 0}, 
or 
DL(q)ZL(t)  =  NdqMt), 
y(t)  = ZLO) 
(1.15) 
is an observable PMD of the system with transfer  function  H(s).  Comments  analo 
gous to the ones made above concerning controllable and right fractional  descriptions 
(subscripts  c and R) can also be made here concerning the subscripts o and L. 
An MFD  of a transfer  function  may not consist necessarily  of ratios of polyno 
mial matrices. In particular, given a /? X m proper transfer  function  matrix H(s),  one 
522 
Linear Systems 
can  wnte 
H(s)  =  NR(S)D^\S) 
= 
DI\S)NL(S\ 
(1.16) 
where  NR, DR, DU NL  are proper  and  stable  rational  matrices.  To illustrate,  in  the 
example considered  above, H{s)  can be written  as 
H{s) 
1 
5  +  2 
s{s +  1) 
s^ +  2^2 +  2 
-s 
S{S^  - 5 + 1) 
'\{S  +  1)2 
[  0 
0 
s 
+  2 
-1 
?2 +  1 
1 
s + 2 
\s  +  1)2 
0 
0 
5  +  2 
52  +  1 
(5 +  1)2 
"5"" "
L  ^ + 2 
1 
1 
{S +  1)2 
(^  +  1)2 
{S +  1)2 
1 
0 
^ + 2  J 
= 
DI\S)NL{S). 
Note that Di{s)  and  A^L(^) are proper and stable rational matrices. 
Such representations of proper transfer  functions  offer  certain advantages  when 
designing  feedback  control  systems.  They  are  discussed  further  in  this  chapter  in 
Part 2, Subsection  7.4D. 
B.  Chapter  Description 
This chapter consists of two principal parts. In Part 1, the emphasis is on properties of 
systems described by PMDs. First, background  on polynomial matrices is provided 
in Section 7.2, and the Diophantine Equation is studied at length in Subsection 7.2E. 
Equivalence  of representations  and  system properties  are addressed  in Section 7.3. 
Properties  of  systems  consisting  of  subsystems  interconnected  in parallel, in  series 
(cascade),  and  in  feedback  configurations  are  investigated  in  Subsection  7.3C.  In 
Part  2,  Section  7.4,  feedback  control  systems  are  studied  with  emphasis  placed  on 
parameterizing  all stabilizing feedback  controllers. Further details  follow. 
In Section 7.2, polynomial matrices and their properties are studied, and  special 
forms  for  polynomial  matrices,  which  are  useful  in  subsequent  developments,  are 
introduced.  In particular,  polynomial  matrices  in  column  reduced,  triangular,  Her-
mite, and  Smith form  are defined,  and  algorithms  to obtain  such forms  by pre- and 
postmultiplication  by unimodular matrices are given in Subsections 7.2B  and 7.2C. 
Coprimeness of polynomial matrices is related to controllability and observability of 
PMDs  and is studied in Subsection 7.2D. The Diophantine Equation, which plays a 
central role in feedback  control, is studied at length in Subsection 7.2E, and methods 
for deriving particular  solutions are given. 
PMDs of systems are addressed throughout Section 7.3. Controllability, observ 
ability,  and  stability  are  revisited  in  Subsection  7.3B.  Also,  PMD  realizations  of 
transfer  function  matrices are studied and realization algorithms are developed. The 
relationships among different  PMDs and state-space descriptions of a system are ex 
plored  in  Subsection  7.3A,  using  equivalence  of representations.  The properties  of 
systems consisting of interconnected subsystems are best explored using PMDs, and 
this is accomplished  in Subsection  7.3C. 
Feedback control systems are studied in Section 7.4 using PMDs and MFDs with 
emphasis on stabilizing controllers. All stabilizing controllers are parameterized us 
ing  PMDs,  in  Subsection  7.4A,  and  proper  and  stable  MFDs  in  Subsection  7.4C. 
State feedback  controllers and state observers, important in the development involv 
ing MFDs, are discussed in Subsection 7.4B. The relationships  among all  feedback 
controller  parameterizations  discussed  herein  are  derived  and  fully  explained.  The 
complete  theory  of parameterizing  all stabilizing  feedback  controllers  is  developed 
in this  section. 
Two degrees  of freedom  controllers, their  stability properties, and their  param 
eterizations  are explored in Subsection 7.4D. Several implementations  of such con 
trollers  are  introduced  and  their  limitations  are  addressed.  Finally,  several  control 
problems  such  as the  model  matching  problem,  the  diagonal  decoupling  problem, 
and the static decoupling problem are formulated  and briefly  discussed. 
523 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
C.  Guidelines  for the  Reader 
As with every chapter of this book, this chapter can be approached at different  levels. 
If the characterization of all proper stabilizing feedback  controllers using proper and 
stable MFDs, which  arises in optimal control problems, is of primary  interest,  then 
the reader should focus on Subsection 7.4C. For better understanding of such MFDs 
of systems and of polynomial MFDs and their use in the study of systems, the reader 
at first reading  should  study  selected topics from  all sections  of this chapter.  In  the 
following,  the material that should be covered at first reading is described. 
The reader should first study coprimeness of polynomial matrices in Subsection 
7.2D  with  emphasis  on  the  tests  for  coprimeness  (Theorem  2.4).  To  determine  a 
greatest common divisor of polynomial matrices, one needs the algorithms given in 
Subsection  7.2D.  All  solutions  of  the  Diophantine  matrix  equation  are  derived  in 
Theorem 2.15 of Subsection 7.2E with particular solutions obtained in Lemma 2.14. 
The  study  of  equivalence  representations  in  Subsection  7.3A  leads  to  insight 
concerning  the relationships  between  different  PMDs  and  state-space  descriptions 
of a system. Tests for  controllability,  observability,  and  stability  are given in Theo 
rems 3.4,3.5, and 3.6 of Subsection 7.3B. Feedback configurations  of interconnected 
systems  are  studied  in  Subsection  7.3C.  Here the closed-loop  descriptions  are  also 
derived, which are then used in Section 7.4 to study the class of stabilizing  feedback 
controllers. 
All  stabilizing  controllers  are  expressed  in  terms  of  PMDs  in  Theorem  4.1  of 
Subsection 7.4A. Different  parameters  are introduced in Theorems 4.2 and 4.3, and 
Corollaries  4.5, 4.6,  and  4.9. To fully  understand  proper  and  stable  MFDs  of  sys 
tems,  one needs  to  study  state feedback  controllers  and  state  observers  in terms of 
PMDs. This is accomplished  in  Subsection  7.4B. All proper  stabilizing  controllers 
are parameterized  (using proper  and  stable MFDs)  in Theorem  4.13  given  in  Sub 
section 7.4C  and also in Theorem 4.16. The exact relationship between  such MFDs 
and internal descriptions is provided by Theorem 4.20. 
Two degrees of freedom  controllers that offer  advantages concerning  attainable 
system responses are studied in Subsection 7.4D. Theorem 4.21 is the principal  sta 
bility theorem with all stabilizing controllers being parameterized in Theorem 4.22. 
524 
Linear Systems 
Theorem 4.23 characterizes the response maps attainable via two degrees of freedom 
controllers under internal stability. Several control configurations are then examined. 
Finally, several control problems are formulated. 
PARTI 
ANALYSIS OF  SYSTEMS 
7.2 
BACKGROUND MATERIAL ON POLYNOMIAL MATRICES 
Let R[s]P^^ denote the set of p  X m matrices with entries that are polynomials in s 
with real coefficients.  If P(s) G R[sy^^,  then P(s) will be called a. p  X m polyno 
mial matrix. Frequently, it will be necessary to determine the rank of P(s), which is 
defined as the maximum number of linearly independent rows (or columns) of P(s) 
over the field of rational functions. The rank of a polynomial matrix is discussed in 
Subsection A. In Subsection B, unimodular matrices are introduced and transforma 
tions of polynomial matrices to column and row reduced form are discussed. Hermite 
and Smith canonical forms are addressed in Subsection C, and in Subsection D the 
important concept of coprimeness of polynomial matrices is studied. In Subsection 
E the linear Diophantine Equation is examined. 
A.  Rank and Linear Independence 
The linear independence of a set of vectors in a vector space, defined in Chapter 2, 
is recalled here for convenience. Let (V, F) denote a vector space V over the field F, 
and let v/ G K  /  == 1,...,  /c. The set of vectors {vi,..., Vyt} is F-linearly dependent, 
i. e., it is linearly dependent over the field F, if there exists a set {ai,..., a^^jof scalars 
in F with at T^ 0 for at least one /, such that 
a\v\  + fl2V2 +  • • • +  akVk  =  Oy. 
(2.1) 
The set of vectors {vi,..., v^^} is linearly independent over the field F if (2.1) implies 
that ai  = 0 for each /  =  1,...,  k. 
Linear dependence of p  X  1  polynomial vectors pi(s)  G R[sy  is defined  sim 
ilarly. This warrants  some explanation.  Let  R[s] be the ring  of polynomials  with 
coefficients  in R (see Subsection 7.2E) and let R(s) be the field of rational  fractions 
over R[s]  (called the field of rational functions), i.e., 
R(s)  = {t(s)\t(s) =  ^,  with n,dG  R[sl d ^  0}. 
d(s) 
Note that if p(s) G R[s], it can always be considered as being divided by 1, in which 
case p(s)/l  is a scalar in the field of rational fractions  over R[s].  Thus, a polyno 
mial vector pi(s) G R[S]P may be viewed as a special case of a rational vector, i.e., 
Pi(s) G R(sy,  whose elements are in the field of rational fractions. Now consider the 
polynomial vectors pi(s) G R[sy,  i  =  I,...,  k. The set of vectors {pi(s),...,  Pk(s)} 
is  said  to  be  R(s)-lmQ2ir\y  dependent,  (i.e.,  linearly  dependent  over  the field of 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
rational  functions),  if  there  exists  a  set  {ai(s),..., 
ai{s)  G  R{s),  i  =  I,.. 
.,k)  with  ai{s)  ¥'  0  for  at least  one  /,  such  that 
a^is)}  of  rational  functions,  (i.e., 
525 
ax{s)px{s)  +  •••  +  ak{s)p^{s) 
-  0  G  R{sy. 
(2.2) 
This  set  of  vectors  is  linearly  independent  over  R(s)  if  (2.2)  implies  that  aiis)  =  0 
for  each  /  =  1,..., 
k. 
EXAMPLE  2.1.  LQipiis)  =  r 
'^^\,P2(s) 
's + 3 
0 
s+  1 
0 
. Note that a 1(5') 
(s +  l)/(s  +  3), a2(s)  =  -I  satisfy  (2.2)  since 
ai(s)pi(s)  +  a2(s)p2(s) 
s+  1 
s + 3 
s + 3 
0 
+  (-1) 
's+  1 
0 
Therefore,  the set {p\(s),  P2(s)} is linearly dependent over the field of rational  functions. 
It is of interest to notice that {p\(s),  p2(s)} is linearly  independent  over the field of 
reals. In particular,  if ai,  a2 are restricted  to be reals then  (2.2) implies  that ai  =  a2  = 
0  (verify  this).  This  stresses  the  importance  of  the  particular  field  over  which  linear 
independence is considered  (refer  to Section 2.2 of Chapter 2). 
• 
It is not difficult  to see that if the set {pi  (s),...,  Pk(s)}  is linearly  dependent,  then 
(2.2)  is  also  satisfied  for  some  polynomials  ai(s).  To  see  this,  simply  multiply  both 
sides  of  (2.2) by  the least  common  multiple  of the denominators  of the rational  func 
"tions  ^1(5"")",..., ak(s).  This  implies  that  linear  dependence  over  R(s)  can  be  tested 
merely  by  searching  for  polynomials  ai(s)  E  R[s],  not  all  zero,  satisfying  (2.2).  To 
illustrate,  consider: 
EXAMPLE  2.2.  In  Example  2.1, {pi(s),  p2(s)}  is  linearly  dependent  over  R(s)  since 
( ^ + 1) 
s +  3' 
0 
+  (-(s  +  3)) 
's+  1 
0 
"DEFINITION  2.1.  The normal  rank of a polynomial  matrix  P(s)  G  /?[5]^^'"" is the max "
imum number of linearly independent rows (or columns) over the field of rational  func 
tions R(s). 
• 
EXAMPLE  2.3.  (i)  rankPi(s)  =  rank 
rank 
s 
1 
s + 1 
s+  1 
2. 
r^ +1  ^ + 31 
0 
0 
=  1,  and  (ii)  rankP2{s)  = 
It  can  be  shown  that  the  (normal)  rank  of  P{s)  is  also  equal  to  the  order  of  the 
largest  order  nonzero  minor  of  P{s). 
EXAMPLE  2.4.  (i) P\{s)  in Example 2.3 does not have a second-order  nonzero  minor, 
since det  P\{s)  =  0, and therefore  its rank is less than  2. The entries  are the  first-order 
minors and since nonzero entries exist,  rankPi(s)  =  1. 
(ii) P2(s) in Example 2.3 has a second-order nonzero minor since det  P2(s) 
^ 
c 2. 
1 ^ 0.  Therefore,  rank P(s)  =  2. 
Notice  that  if  ^  =  1 or  - 1, then  det  P2(l)  =  det  P2(-1) 
=  0.  This  is  true  be 
cause in this case, P2(l)  [or P2(-1)]  has only one linearly independent  column  (over 
the  field  of reals R)  and  rank  P ( l)  =  1. Since this loss of rank  (from  2 to  1)  occurred 
for  only  special  values  of s,  rank  P(s)  defined  above is referred  to as the normal  rank 
of  P(s),  instead  of just  the  rank  of  P(s),  when  there  is  ambiguity.  Note  that  unless 
otherwise  stated,  the  linear  dependence  of  rows  or  columns  of  a  matrix,  considered 
526 
Linear Systems 
for  rank  evaluation,  is taken  over the smallest  field  that  contains  the entries  of the 
matrix. 
B.  Unimodular  and Column  (Row) Reduced  Matrices 
is called  unimodular  (or /?[5-]-unimodular) if 
A polynomial  matrix  U(s) G R[sy^^ 
there exists a U(s) G  R[SY^P 
such that  U(s)U(s)  =  I p.  This is the same as saying 
that U~^(s)  =  U(s) exists and is a polynomial matrix. Equivalently, U(s) is unimod 
ular if det  U(s)  =  a  G  R,a7^0. 
It  can be  shown  that  every  unimodular  matrix  is a matrix  representation  of a 
finite number of successive elementary row and column operations. The  elementary 
row and column  operations  on any polynomial matrix P{s) E  R[sY^^  consist of the 
1.  interchange of any two rows (or columns) of P{s), 
2.  multiplication of any row (or column) of P{s) by a nonzero real a  G 7?, a: 7^ 0 (a 
unit in R[sY), 
3.  addition  to any row (or column)  of P{s) of a multiple by a nonzero  polynomial 
p{s)  of another row (or column). 
These elementary row (and column)  operations can be performed  by multiply 
ing  P{s) on the left  (right),  [i.e., by pre-(post-)  multiplying  P{s)\,  by  elementary 
unimodular  matrices.  These  elementary  unimodular  matrices  are obtained  by per 
forming  the elementary  operations  (1) to (3) on the identity matrix /. As mentioned 
above, it can be shown that every unimodular matrix may be represented as the prod 
uct of a finite number of elementary  unimodular  matrices. 
EXAMPLE  2.5.  The interchanging  of rows  1 and 3 in  a  specific  example  is  accom 
plished, e.g., as shown: 
UL{S)P{S)  = 
"""0 "
0 
_1 
0 
1 
0 
11 
0 
oj 
1 
s +  1 
0 
1 
0 
^ + 2 
0 
^ + 2 
s+  1 
1 
1 
0 
Also," addition to the second column of the third column multiplied by 5"" in a specific "
example is accomplished, e.g., as shown: 
s~\ 
0 
ij 
"ri  0  0"" "
0  1  0 
LO  s  1. 
P(S)UR(S)  = 
2s + 2 
s+  1 
5+ 1 
0 
1 
= 
1 
1 
1 
s + 2 
0 
0 
Let  the degree  of a polynomial  (row or  column)  vector  be the degree  of the 
highest  degree  entry  and let deg^. (P)  [deg^. (P)] denote  the degree  of the /th row 
(jth  column)  of  P(s).  Also  let  Cr(P)  [Cc(P)] be the highest  row degree  (column 
degree)  coefficient  matrix  of P(s), defined  as the real matrix with entries that are the 
coefficients  of the highest degree s terms in each row (column) of P(s). 
"We note that P(s) G RlsY^""^  can be written as "
P(s) 
diag  (s'^'i,  s'^'-2 ^ 
S--p)Cr(P)  +  Pr(s) 
Cc(P)diag(s'^ 
'^,S^'2, 
.. 
.,S^' 
) +  Pc(sl 
(2.3) 
wheredn  =  deg^. (P), i  =  1,...,  p,  anddcj 
Pc(s)  appropriate polynomial  matrices. 
deg^.  (P), j  =  1,..., m, with  Pr(s), 
EXAMPLE  2.6.  Let  P(s)  = 
's+l 
s 
3^2  +  21 
1 
.  The  row  degrees  are  deg^^ (P) 
[5^  +  3 
s^ + 5 , 
2,deg^2(P)  ^  1'  ^^^  ^^^r3 (^)  ^  ^'  while  the  column  degrees  are  deg^i(P)  =  2 
3] 
0 
1_ 
and J^^c2 (P)  ^  3- The highest row degree coefficient  matrix of P(s) is  Cr(P) 
ro 
1 
.0 
and the highest column  degree coefficient  matrix is CdP)  = 
We have 
0  0 
0  0 
1  1 
527 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
P(s) 
0 
0 
0 
0 
Sdr3 
0 
0 
Cr  +  Pr{s) 
0 
0 
s 
0 
0  ^3 
Cc  0 
+  Pc(s) 
0  0 
0  0 
1  1 
0 
0  3 
1  0 
0  1 
s +1 
s 
3 
s+l 
0 
2 
1 
s^  + 3  5 
+ 
3^2 +  1 
1 
5 
P(s)  is row  (column)  proper,  also  called  row  {column)  reduced,  if  Cr{P) 
[CdP)] 
has  full  rank. 
EXAMPLE  2.7.  P{s)  in Example  2.6 is row proper  since  rankCr  =  2 but not  column 
proper since rank Cp  =  I  <2. 
• 
"Consider  now  the  first  two  rows  of  ^(5"") in  Example  2.6  and  note  that "
det 
s  +1 
s 
3s^  +  2 
1 
= 
( - 3 )/ 
s+  1 
=  det 
0 
1 
3 
0 
^(dri +dr2)  _^  lower  degree  terms  . 
This  illustrates  the following  result  that can be  derived  from  (2.3): any  highest  order 
"minor  of  P{s)  E  7^ [5']^^'""  is  a polynomial  of  degree  equal  to  the  sum  of  the  degrees "
of  the  rows  {p  >  m)  or  of  the  columns  (;?  <  m),  with  leading  coefficient  equal  to 
the  corresponding  minor  of  Cr{P)  or  of  CdP), 
respectively.  For  the  case  when  P(s) 
is  square,  this  immediately  implies  that 
detP(s)  =  detCdP)s^^'^ 
+  lower  degree  terms 
=  detCdP)s^^'^ 
+  lower  degree  terms. 
(2.4) 
Clearly  then,  P{s)  G  R[sY^^^  is row  (column) proper if and only if ^i^^ {det  P{s))  ^ 
X  dr,{deg{det{P{s)) 
is  not  of 
full  rank  it  can  be  neither  a column  nor  a row  proper  matrix. 
=  Z  dcj).  (Show  this.)  Note  that  if  P{s)  G  R[S]P'''^ 
Equation  (2.3)  leads  to useful  polynomial  matrix  representations  given  by 
P{s)  =  diag  [s'^'i^Cr  +  block  diag 
[l,s,, 
•.s'^^i-^]Cr 
=  block  diag  [1, ^ , . . .,  s^'i]Pr 
and 
P{s)  =  Cc diag  [/^^  ]  +  Cc block  diag  [[1, s,,,,, 
s'^'j  ^ 
] 
= 
Pcblockdiag{[\,s,...,s'^'jfl 
(2.5a) 
(2.5b) 
528 
Linear Systems 
EXAMPLE 2.8.  In view of (2.5a), we have the representation 
r  1 
1 
2 1 
0 
s + 1 
"3s^ + 2"" "
P(s) 
s 
1 
= 
s^ + 3 
s^ +5  j 
s' 
0 
0 
0  01 
s  0 
0  ^^J 
"ro 3"" "
1  0 
LO  ij 
+ 
1  5  0  0  0 
0  0  10 
0 
0  0  0  1  5 
r 1 
1 
0 
21 
0 
3 
01 
0 
^'J 
0 
1 
3 
0 
[ 1 
5 
0 
0_ 
1 
0 
0 
2 
s 
s^ 
0  0 
0  0 
:  0  0 
:  1  s 
:  0  0 
0  0  0 
0  0  0 
1  s 
s' 
0 
0 
^'J 
0 
1 
1 
0 
3 
0 
1 N 
5 
0 
0 
1 _ 
Similarly, a representation in terms of column degrees can be obtained using (2.5b). 
• 
P{s) can also be expressed  as a matrix polynomial  of the  form 
"P{s)  =  Pks^  +  Pk-is""-'  +  ""'  + Pis  + Po", 
(2.6) 
where  Pi  G  RP^^,  A  square  polynomial  matrix  is  called  regular  if  rankP^  =  m. 
Note that if P(s)  is regular, then it is both row and column  proper. 
EXAMPLE 2.9.  P(5) of Example 2.8 can be written as P(5)  =  P3S^ + P2S^-\-Pis + Po = 
s+  1 
3^2 + 2 
1 
s^ + 3 
= 
ro 01 
0  0 
0  1 
^3  + 
"ro 3"" "
0  1 
1  0 
s^  + 
"ri 0"" "
1  0 
0  0 
s + 
ri 21 
0  1 
3  5 
Reduction to a row (column) proper polynomial  matrix 
Given P(s)  G Rlsy^'^  of full rank, there exists a unimodular matrix  UL(S)  such 
that  UL(S)P(S) 
is row proper. 
This is shown here by using a constructive proof. At each step of the  algorithm 
below, the degree of a row (the highest degree row) is reduced by at least one, using 
elementary  row operations. Since the matrix  is of full  rank, the algorithm will  stop 
after  a finite number of steps. 
Algorithm 
Let drf  =  degj.. (P), i  =  \,..., 
p. 
(i)  Ohi2im diag[s^^i]Cr{P). 
(ii)  Determine/? monomials pi{s)  such that 
{p,,,..,Pp)diag[s'^qCr{P) 
= Q. 
529 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Take  pk  =  I.  This  is  accomplished  by  dividing  all  monomials  by  the  lowest 
degree (nonzero) monomial, assumed here to be the  /cth one. 
(iii)  Premultiply  P(s)  by 
"""1 "
0 
•••  0 
••• 
0 
Ux(s)  =  Pi 
Pi 
Pp 
kih row. 
0 
0 
0 
1 
(iv)  Stop if  U\P  is row proper. Otherwise, set P  =  U\P\  repeat the steps. 
To determine the appropriate unimodular matrix  UL{S)  directly, so that  UL(S)P(S) 
is  row  proper,  one  may  decide  on  the  necessary  row  operations  based  on  P(s) 
(as  in  the  algorithm  above),  but  apply  these  to  [P(s\  Ip].  Then  UL(S)[P(S), 
Ip]  = 
[P(s),  UL(S)],  where P(s)  is the row proper matrix and  UL(S)  can be read off  directly 
from  the resulting  matrix. 
EXAMPLE  2.10.  Fov  P(s)  = 
's+ 1 
s 
s 
s^ + 2 
s + 2 
, the row degrees are dr^ =  I, dr^ = 2, 
dr,  -  1,  and  rankCr(P)  = rank 
=  1 <  2, and thus, P(s) is not row proper. 
The algorithm is now applied. We have 
0 
01 
's 
0 
s 
2 
0 
) ^J 
.0  C 
(i) diag  [s'^i][Cr(P)]  = 
"ri  1"" "
1  1 
Li  1. 
= 
'  s 
s^ 
_s 
s ' 
s^ 
s _ 
(nl(ni)Ui(s) 
= 
's  +  1 
(iw)UiP  = 
-s 
s 
"0"" "
1  0 
""" 10 "
-s 
. 0 0 1. 
' 
' 
s 
2 
s  +  2. 
, ai 
idCriUiP)  = 
'  1 
-1 
1 
11 
0  , 
ij 
which is of full rank. Thus, 
ULP.  where UL  U\, is row proper. 
• 
Note that a unimodular matrix  UL such that  ULP is row proper is not unique. In 
-1 
[I  0 
fact,  in Example  2.10,  another  choice  for  UL could  have  been  Ui  = 
since  U\P  = 
-2 
s^  + 2 
s + 2 
with  CriUiP)  = 
"""1 "
1 
1 
"- 2"" "
1 
1 
therefore,  Ui P is row proper. 
,  which  is  of  full  rank,  and 
It  is  possible  to  reduce  a  polynomial  matrix  to  a row  proper  polynomial  ma 
trix  using  elementary  column  operations  (in  place  of  elementary  row  operations). 
In  particular,  given  P(s)  G  R[sy^^  of  full  rank,  there  exists  a unimodular  matrix 
UR(S)  such that  P(S)UR(S) 
is row proper.  Such  a  UR(S)  is determined,  for  example, 
by  the  algorithm  described  in  Subsection  7.2C,  which  reduces  a matrix  to a  lower 
left  Hermite form.  Other algorithms to accomplish this can also be  derived. 
530 
Linear Systems 
EXAMPLE 2.11.  Consider P(s) of Example 2.10 and apply the algorithm of Subsection 
7.2C to reduce P(s) to lower left Hermite form. Take P(sY  and determine U^(s)  such 
that U^P^ is reduced to upper right Hermite form. Then 
-si 
s+l\ 
'  1 
-2 
. -2 
1.  = P(s) 
1  01 
Ij 
s^ + 2s + 2 
=  P(S)UR(S)  = 
n  —s 
P{s) 
.-1 
-I 
1 
0 
3s+  2 
which is row proper. 
Similar  results  for  reducing  a polynomial  matrix  to a  column  proper  polyno 
mial matrix  can easily  be derived.  Given  P(s)  E  R[sy^^  of full  rank,  there  exists 
a unimodular  matrix  UR(S)  such that  P(S)UR(S) 
is column  proper.  [Take P(sy  and 
apply  steps  (i) to (iii) of the above algorithm.]  Also, there exists  a unimodular ma 
trix  UL(S)  such that  UL(S)P(S) 
is column proper.  [Use the algorithm to reduce  P(s) 
to upper right Hermite  form  described  in Subsection  7.2C.]  Finally, we note that if 
P(s)  E  R[sy^^  has full  rank, there exist unimodular matrices  UL and UR such that 
ULPUR 
is both row and column proper. One such example is when  UL  and  UR  are 
chosen so that  ULPUR  is in Smith form  (see Subsection  7.2C). 
Proper rational  matrices 
Recall that a rational matrix H(s)  E  R(sy^^ 
is called proper  if 
limH(s)  =  D, 
5—»oo 
DGRP'''^ 
and if D  =  0, then H(s)  is called strictly proper  Frequently, H(s)  is expressed as 
H(s)  = 
N(s)D-\sl 
"where A^(^) and Z)(^) are polynomial matrices (A^(^) E  RlsV""^  Sind D(s)  E  Rls]""^""""""^)", 
The pair {N(s), D(s)} can be viewed as an rPMFD of a system described by a transfer 
function  matrix H{s). It is of interest to relate the propemess  of the rational  matrix 
H(s)  to the (column)  degrees  of N{s)  and D(s). Note that  when  N(s)  and D(s) are 
polynomials,  it is easily  seen  that  H(s)  is  strictly  proper  (is proper)  if  and only if 
degN(s)  < degD(s)  [if and only if degN(s)  <  degD(s)].  In the matrix case, sim 
ilar necessary  and sufficient  conditions, given in Lemma 2.2, exist only when  D(s) 
is  column  reduced.  Necessary  conditions  for propemess  are given  in Lemma 2.1. 
Completely  analogous  results to Lemmas  2.1 and 2.2 hold for left  factorizations  of 
H(s)  =  D-\s)N(s) 
as  well 
LEMMA 2.1.  Let H(s) be a proper (or strictly proper) rational matrix and let H(s)  = 
N(s)D(s)-\  Then  deg^.N(s)  <  deg^.D(s)  [or  deg^.N(s)  <  deg^.D(s)]  for  j  = 
1,.... m. 
Proof. N(s) =  //(5)D(^) and for the yth column of A^(^), 
m 
^O'W  =  ^Hik(s)dkj(s\ 
^=1 
i  =  I,. 
• A 
where nij(s) denotes the ith element in the jih  column of N(s).  Since every element 
Hik(s) of H(s) is strictly proper (or proper), all entries nij(s) must have degrees less than 
(or less than or equal to) the degree of the highest degree polynomial in the jih column 
• 
of D(s). 
The converse to the above result is not always true. For example, let 
N{s)  =  [l,s] 
and 
D(s)  = 
s^  +  \ 
s+l 
IJ 
where deg^^ Nis)  =  0 <  deg^^ D{s)  =  2 and deg^^ N(s)  =  1 =  deg^^ D(s). Here 
Nis)D-\s)  =  {\,s] 
1 
?  -  1  ^2 + 1 
-5 
1 
1 
-s 
2 
-s^  — s 
1  -^ 
1 
^  1  -^ 
which is not proper. Notice that D{s) is not column  reduced.  When D{s) is column 
reduced  (column  proper)  the conditions  of the above  lemma  are sufficient  as well, 
as the following  result shows. 
531 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
LEMMA 2.2.  Let H{s)  = N(s)D~\s)  with D(s) column reduced. Then H(s) is proper 
if and only if 
deg  N(s) <  deg,^  D(s), 
j= 
I 
., m. 
H(s) is strictly proper if and only if deg^. N(s) < deg^. D(s), j  =  1,..., m. 
Proof, Necessity  was shown in the previous lemma. To show sufficiency,  notice that 
by applying Cramer's rule for the inverse to solve H(s)D(s)  = N(s), we have hij(s) = 
[det D^J(sydet D(s)], where D^J(s) is the matrix obtained by replacing the jth row of D(^) 
by the /th row of N(s). In view of (2.3)," D(s) can be written as D(s) =  Cc(D) diag [s """"J ] + "
Dc(s), j  =  1,..., m, where dcj = deg^. D{s\ CdD) is the highest column degree coef 
ficient  matrix of D(sX and deg^. D^s)  < dc.. Similarly, D'^{s) = Cc(D'J) diag [A ] + 
&-^(s), where Cc(D^^) is the same as CdD), except for the 7th row, which may or may 
not be zero since each entry of the jth row of N(s) is of lower than or equal degree of the 
corresponding entry of the jih row of D(s). Since D(s) is column proper," det CdD) ¥"" 0", 
and in view of (2.4), degdetD(s)  = X%idj  while degdetD'ds)  <  YJ]=idj.  There 
fore,  hij{s) is  proper.  It  is  strictly  proper  when  deg^.  N(s) < deg^.  D(s) for  j  = 
1,..., m. 
• 
EXAMPLE  2.12.  H(s)  = 
N(s)D~\s),whQrQ 
\s + l 
-1 
D(s) = 
and 
A ^ ( ^ )= 
ais  +  aQ 
CiS  +  CQ 
d\S  -\r  do 
is proper for any values of the parameters since D(s) is column reduced and deg^. N(s) < 
deg^. D(s), j  =  1, 2. H(s) is strictly proper only when ai  = bi  = ci  = di  = 0. 
• 
Let  H{s)  =  D-\s)N(s),  where  D{s) G  R[syp 
"and N(s)  G  Rlsy""^.  Com "
pletely  analogous  results  to  Lemmas  2.1  and  2.2 hold  also  for  the  left  factoriza 
tion  matrices.  In particular,  if  H(s)  is  proper  (strictly  proper),  then  deg^. N(s)  < 
deg^. D(s)  [deg^.  N(s)  < deg^..  D(s)] for /  =  1,..., /? (see Lemma 2.1). When  D(s) 
is row reduced, then the conditions are necessary  and sufficient  (see Lemma 2.2). 
C.  Hermite  and Smith  Forms 
By elementary row and column operations, a polynomial matrix P(s) can be reduced 
to the Hermite form or the Smith form.  These special forms  are studied in this sub 
section, together with algorithms to reduce P(s) to such  forms. 
532 
Linear Systems 
Hermite  form 
Given P(s)  G R[sY^^  with p  >  m, there exists a unimodular matrix  UL(S)  such 
that  UL(S)P(S) 
is an upper (right) triangular matrix of the  form 
••  X 
••  X 
X 
X 
"""  X "
0 
UL(S)P(S) 
Pm(s) 
0 
0 
0 
0 
0 
0 
0 
X 
••  0 
•• 
0 
(2.7) 
r  =  rankP(s), 
where  Pm(s)  G  R[s]^^^.  When  p  >  m^ 
the  last  p  -  r rows  are 
identically zero. In column J, 1 <  j  <  r, the diagonal element is monic and of higher 
degree than any (nonzero) element  above it. If the diagonal element is one, then all 
elements  above it are zero. No particular  form  is assumed  by  the remaining  m  -  r 
columns in the top r rows. This is the (upper  triangular)  column  Hermite form.  Note 
that if  P(s)  is of full  rank,  then  UL(S)P(S) 
is column  proper.  By  postmultiplication 
by a unimodular matrix  UR(S),  it is possible to obtain the row Hermite form  of  P(s) 
when  p  <  m.  To  accomplish  this,  simply  determine  UL(S) in  such  a manner  that 
UL(S)P^(S) 
is  in  column  Hermite  form,  and  take  (UL(s)P^(s)y  =  P(s)Ul(s)  = 
P(S)UR(S),  which is in row Hermite  form. 
The following  algorithm reduces  P(s)  G R[sy^^,  p  >  m, to (upper  triangular) 
column  Hermite  form  by  elementary  row  operations  [premultiplication  by  UL(S)]. 
This algorithm can also be used to constructively prove our desired result, that there 
exists a unimodular matrix  UL(S)  such that  UL(S)P(S) 
(p  >  m) is in column Hermite 
form. 
The  algorithm  is  based  on  polynomial  division.  Given  any  two  polynomials 
a(s),  b(s),  b(s)  #  0,  there  exist  unique  polynomials  q(s), r(s)  such  that  a(s)  = 
q(s)b(s)  +  r(s)  [q(s) is the quotient and r(s) is the remainder], where either r(s)  =  0 
or deg r(s)  <  deg b{s). 
By row interchange, transfer  to the (1, 1) position the lowest degree element  in 
the  first  column  and  call  this  element  pn.  Every  other  element  pn  in  this  column 
can be expressed by polynomial division, as a multiple of pn  plus a remainder term 
of lower degree than pu,  i.e.. 
qnPn  +  ni, 
where deg rn  <  degp\\. 
(2.8) 
By elementary row operations, the appropriate multiple of j^n  can be subtracted  from 
each entry of column  1  leaving only remainders rn  of lower degree than pi\.  Repeat 
the above steps until all entries in the first column below  (1,  1) are zero and note that 
the (1, 1) entry can always be taken to be a monic polynomial. 
Consider next the second column and position (2, 2) while temporarily  ignoring 
the first row. Repeat the above procedure to make all the entries below the (2, 2) entry 
equal to zero. If the  (1, 2) entry does not have lower degree than the (2, 2) entry, use 
polynomial  division  and row  operations  to replace the  (1, 2) entry  by  a polynomial 
of lower degree than the (2, 2) entry. If the (2, 2) entry is a nonzero constant, use row 
operations to make the (1, 2) entry equal to zero. Continuing this procedure with the 
third, fourth,  and higher columns results in the desired Hermite  form. 
533 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  2.13. 
s(s  + 2) 
0 
s(s  + 2) 
0 
5 + 2 
5 +1 
P(s)  = 
0 
(s +  l)(s  + 2) 
0 
Ui 
(S+ 1)2 
5 + 1 
s(s + 1) 
0 
5 +2 
0 
(s+  1)2 
5 +1 
5(5 + 1) 
U2 
0 
(5 + 1)2 
5(5 + 2) 
0 
0 
S(S  + 1) 
5 + 2 
5 +1 
5 + 2 
0 
0 
0 
^4 
(5 + 1)2 
-s(s  + 1) 
s(s + 1) 
0 
0 
0 
5+  1 
(s + 1)2 
5+  1 
5+  1 
^5 
5 + 2 
0 
0 
0 
5 +1 
5 +1 
(5 + 1)2 
5+ 1 
U3 
t/6 
"""5 + 2 "
5 + 2 
0 
0 
0 
5 + r 
5+  1 
Uj 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
f  1 
5 -
0 
0 
ri 
0] 
0 
0 
0 
0 
ij 
[0 
5+  1 
-5 
= 
UL(S)P(S), 
0 
1 
0 
0 
- ( 5 + 1)  1 
0 
-1 
"0"" "
0 
0 
1 
' 1 0 00 
0  10 
- 10 
0 
10 
0  0  0  1 
S(S  + 1) 
5 
- (5  + 2) 
5 +1 
- (5  +  1)2 
- ( 5 + I) 
-1 
1 
-5 
0 
where 
L(5)  =  U,"U6'""Ui "
1 
0 
0 
0 
-1 
1 
0 
0 
Notice that P{s) has full  rank and  UL{S)P(S)  here is column proper. 
• 
Note  that  to  determine  UL(S) directly,  one may  decide  on  the  necessary  op 
erations  based  on  P(s),  but  apply  these  elementary  row  operations  to 
[P(s),Ip]. 
Then  UL(S)[P(S), 
Ip]  =  [Hp(s),  UL(S)],  where  Hp(s)  is the column  Hermite  form of 
P(s),  (p  >  m). Also,"  note  that  if the algorithm  is applied  to ^(5"") G  R[S]P^^",  where 
p  ^  m,  then 
UL(S)P(S) 
=  [Pi(s\P2(s)] 
= 
where  Pi (5)  G 
Ris^P. 
X  X 
0 
X 
0  0 
X 
X 
X 
X 
X 
X 
(2.9) 
Smith  form 
Given  P(s)  G  R[sy^^  with  rankP(s)  =  r,  there  exist  unimodular  matrices 
UL(S)  and UR(S) such  that 
UL(S)P(S)UR(S) 
=  Sp(s), 
(2.10) 
where 
Sp(s)  = 
K{s) 
0 
0 
0 
A(^)  = 
diag{ei{s),.,.,er{s)). 
534 
Linear Systems 
Each ei(s),  i  =  1,...,  r, is a unique monic polynomial satisfying  ei(s)  \ ei+i(s),  i  = 
1,...,  r  -  1, where P2(s)\pi(s)  means that there exists a polynomial P3(s) such that 
Pi(s)  =  P2(s)p3(s),  that is, €i(s)  divides ei+i(s).  Sp(s)  is the Smith form  ofP{s)  and 
the ei{s),  i  =  1,...,  r, are the invariant polynomials  of  P{s).  It can be shown that 
etis)  = 
Di(s) 
Di-i(sy 
1,  ...,r, 
(2.11) 
where  Di(s)  is  the monic  greatest  common  divisor  of  all  the nonzero  zth order mi 
nors of  P(s).  Note that Do(s)  =  1 and Di(s)  are the determinantal  divisors  of  P(s). 
The  Smith  form  Sp(s)  of  a matrix  P{s)  is unique,  however,  UL(S),  UR(S)  such  that 
UL(S)P(S)UR(S) 
=  5'p(5') are not unique. 
EXAMPLE  2.14.  P(s)  = 
s(s + 2) 
0 
0 
(s+  1)2 I 
I (s +  1)(^ + 2) 
^ + 1 
0 
s(s + 1)J 
with  rankP(s)  =  r  =  2. Here 
Do  =  hDi  =  hD2  =  (s  +  l)(s  +  2),  and 
(s +  l)(s  + 2). Therefore, the Smith form of P(s)  is 
ei  =  DI/DQ  =  1, €2  =  D2/D1  = 
1 
0 
0 
(s+  l)(s  + 2) 
Sp(s) 
AW 
0 
The  invariant  factors  6/  of  a  matrix  are  not  affected  by  row  and  column  ele 
mentary operations. This follows from the fact that the determinantal divisors Dt are 
not  affected  by  elementary  operations  (refer  to the Binet-Cauchy  formula  in  Exer 
cise 7.3). In view of this, the following  result  can now be easily  established:  given 
Pi(s)> Piis)  ^  R[s]P^^,  there exist unimodular matrices  Ui(s),  U2(s) such that 
U,(S)PI(S)U2(S) 
=  P2{S) 
if and only if Pi(s),  P2(s) have the same Smith  form. 
"The following  algorithm reduces P(s)  E  R[sy^""^  to its unique Smith form  Sp(s) "
=  Sp(s).  The algorithm  can 
and determines  UL(S),  UR(S)  such that  UL(S)P(S)UR(S) 
be used to constructively  prove that the Smith form of a matrix exists. 
Using row  and column elementary  operations, transfer  the element  of least de 
gree in the matrix P(s) to the (1,  1) position. By elementary row operations, make all 
entries  in the first column  below  (1, 1) equal  to zero  (refer  to the  algorithm  for  the 
column Hermite form). Next, by column operations, make all entries in the first row 
zero except  (1,  1). If nonzero entries have reappeared  in the first column, repeat the 
above steps until all entries in the first column and row are zero except for the  (1,  1) 
entry.  [Show  that  at each  iteration  the  degree  of the  (1, 1) element  is reduced,  and 
thus the algorithm is  finite.] 
If the  (1,  1) element does not divide every other entry in the matrix, use polyno 
mial  division  and row  and column  interchanges  to bring  a lower degree element to 
the (1,  1) position. Repeat the above steps until all other elements in the first column 
and row are zero and the  (1,  1) entry divides every other entry in the matrix, that is. 
535 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
0 
eiis) 
0 
Ei(s) 
0 
where 61(5') divides all entries ofEi(s).  Repeat the above steps on Ei(s)  and on other 
such terms, if necessary  to obtain the Smith form  of  P(s). 
Two  polynomial  matrices  Pi(s),  P2(s)  E  R[sy^^ 
there exist unimodular matrices  U\{s),  U2(s) such that 
are  said  to  be  equivalent  if 
Ui(s)Pi(s)U2(s)  =  P2(S\ 
(2.12) 
Recall that, as was mentioned earlier, (2.12) is satisfied if and only if Pi (s) and P2(s) 
have the same Smith  form. 
The Smith form of P{s) is a canonical form for the relation (2.12) on R[sy^^.  To 
see this, we first recall the definition of relation and equivalence relation: a relation  p 
in  a set X  is any  subset  of X  X X  and  p  is  an equivalence  relation  if  and only  if  it 
satisfies  the following  axioms: 
1.  xpx-reflexivity  (every  x  G X is equivalent to  itself). 
2.  {xpy)  =^ (3;px)-symmetry  {x is equivalent to y implies that y is equivalent to x). 
3.  {xpy)  and {ypz)  =^ (xpz)-transitivity  {x is equivalent to y and y is equivalent to 
z imply that x is equivalent to z). 
The  relation  p  described  by  U1P1U2  =  P2  in  (2.12),  (i.e.,  P1PP2),  satisfies 
the  above  axioms  (verify  this)  and  therefore  it  is  an  equivalence  relation.  The  p-
"equivalence  class  or  the  ""orbit""  of  a  fixed  P(s)  G  RlsY^'^  is  denoted  by  [P(s)]p. "
The Smith form Sp(s)  of P(s)  is a canonical form  for  p on  R[sY^^. 
D.  Coprimeness  and  Common  Divisors 
Coprimeness  of  polynomial  matrices  is  one  of  the  most  important  concepts  in  the 
polynomial matrix representation  of systems  since it is directly related to controlla 
bility and observability  (see Subsection  7.3B). 
A polynomial  g(s)  is a common  divisor  (cd) of polynomials  pi(sX  P2(s) if  and 
only if there exist polynomials  pi(s),  p2(s)  such that 
Pi(s)  =  pi(s)g(s), 
p2(s)  =  p2(s)g(s), 
(2.13) 
The highest degree cd of pi(^), P2(s), g'^is), is a greatest  common  divisor  (gcd) 
of  pi(s),  P2{s). It is unique  within  multiplication  by  a nonzero  real  number.  Alter 
natively,  g*(5') is  a gcd  of  pi{s),"  P2(s) if  and  only  if any  cd  ^(^5"") of pi(s)",  P2(s) is a 
divisor of g'^is) as well, that is. 
g^'is)  =  m(s)g(s) 
(2.14) 
with  m(s)  a polynomial.  The polynomials  pi(s),  P2{s) are coprime  (cp) if  and  only 
if a gcd g^'is) is a nonzero real. 
The above can be extended to matrices. In this case, both right divisors and  left 
divisors must be defined,  since in general, two polynomial matrices do not commute. 
Note that one may talk about right or left divisors of polynomial matrices only when 
the matrices have the same number of columns or rows, respectively. 
536 
Linear  Systems 
An  mx  m  matrix  GR{S) is a  common  right  divisor  (crd) of the pi  x  m  poly 
nomial  matrix  Pi{s) and the p2Xm  matrix  P2{s) if there  exist  polynomial  matrices 
PiR{s),P2R{s)sothsit 
PI{S)=PIR{S)GR{S), 
P2{S)=P2R{S)GR{S). 
(2.15) 
Similarly,  a.  p  x p  polynomial  matrix  GL{S) is a  common 
pxmi 
matrices  PIL{S)^P2L{S) 
SO that 
polynomial  matrix Pi {s) and the pxm2  matrix P2{s),  if there exist  polynomial 
left  divisor  (eld) of the 
Px{s)  =  GL{S)PIL{S), 
P2{S)  =  GL{s)P2ds). 
(2.16) 
Also  G^{s) is a greatest  common  right  divisor  (gcrd)  of Pi{s)  and P2{s) if and  only 
if  any crd GR{S) is an rd of G^(^).  Similarly,  G£(^) is a greatest  common 
left  divisor 
(geld)  of A [s) and P2{s) if and only if any eld GL{S) is an Id of G£(^). That is. 
GI{S)=M{S)GR{S), 
Gl{s)  = 
GL{S)N{S) 
(2.17) 
with  M{s)  and N{s)  polynomial  matrices  and GR{S) and Gi{s)  any crd and eld  of 
Pi {s), P2 ('^),  respectively. 
Alternatively,  it can  be shown  that  any crd G\{s)  of Pi{s)  and P2{s)  [or a  eld 
G£(^)  of A('^)  and P2{s)]  with  determinant  of the highest  degree  possible  is a  gcrd 
(geld)  of the matrices. It is unique  within  a premultiplication  (postmultiplication) by 
a  unimodular  matrix.  Here it is assumed  that  GR{S) is nonsingular.  Note  that if  rank 
: m [a (pi + P 2)  X mmatrix],  which  is a typical  case  in polynomial  matrix 
Piis) 
system  descriptions,  then  rank  GR{S) =  m, that  is, GR{S) is nonsingular.  Notice  also 
that if rank  GR{S) < m, then in view of Sylvester's  Rank Inequality,  rank 
\Piis)\ 
Piis) 
< m 
as  well. 
The  polynomial  matrices  Pi (s)  and P2 (s)  are right  coprime  (re) if and only  if a 
gcrd  G^{s) is a unimodular  matrix.  Similarly, Pi{s) and P2{s) are left  coprime  (Ic) if 
and  only if a geld  G2{s) is a unimodular  matrix. 
E X A M P LE  2.15.  Let Pi 
Two distinct crds are GR^  = 
5(5 +  2) 
0 
0 
0 
5 +1 
( 5 + 1 )2 
and  GR^ 
and  P2  = 
• ( 5 + l ) (5 +  2)  5 +1  • 
5 ( 5 + 1) 
0 
5 +  2 
0 
0 
( 5 + 1 )2 
GR. 
G/?2 
5 +2 
0 
5 +1 
5 ( 5 + 1) 
5 +  2  0 
1 
0 
GR^ 
1 
0 
0  5 +1 
GR^.  N O W, 
- » * —1 
0 
5 +1 
1 
5 
5 ( 5 + 2) 
0 
(5+l)(5 + 2) 
0 
5 +  2 
0 
5 +1 
0 
0 
5 +1 
where  Pf^  and P2j^  are re. Note  that  a geld  of Pi  and P2 is 
A  gcrd is  G^ 
s 
0 
5 +1 
0 
1 
5 
G; = 
0 
s+  1 
Both  G^  and  Gl  were  determined  using  an  algorithm  to  derive 
the Hermite form of 
as will be described later in this  section. 
It  can  be  shown  that  two  square  p  X  p  nonsingular  polynomial  matrices  with 
determinants that are prime polynomials  are both re and Ic. The converse of this is not 
true,  that  is, two re polynomial  matrices  do not necessarily  have  prime  determinant 
polynomials.  A  case  in point  is Example  2.15, where  P j^ and PJ^  are re;  however, 
detP\j^  =  detP2R  =  s(s  +  1). 
Left  and right  coprimeness  of  two polynomial  matrices  (provided  that  the ma 
trices  are  compatible)  are  quite  distinct  properties.  For  example,  two  matrices  can 
be  Ic but not re, and vice  versa  (refer  to the following  example). 
537 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  2.16.  Pi  =  |  ^ 
0 
.  J  and P2  =  I 
s+  1.  and P2 = 
(s + 1)(^ + 2)  1 
s 
^ 
0 
I are Ic but not 
re since a gcrd is G^ 
with detGl  = (s + 2). 
\s(s + 2) 
L  0 
's + 2  0 
1. 
0 
Finally,  we note  that  all the above  definitions  apply  also  to more  than  two  poly 
nomial  matrices. To see this, replace  in all definitions  P i, P2 by P i, P2, • . .,  P^. This 
is  not  surprising  in  view  of  the  fact  that  the  p\X  m  matrix  P\{s)  and  the  p2  X  m 
matrix  P2(s)  consist  of  pi  and p2  rows,  respectively,  each  of  which  can be  viewed 
as a  1 X m polynomial  matrix;  that is, instead  of,  e.g., the coprimeness  of Pi  and P2, 
one  could  speak  of the coprimeness  of the (pi  +  P2) rows  of Pi  and P2. 
How  to determine  a greatest  common  right  divisor  (gcrd) 
LEMMA  2.3.  Let Pi(s)  e  /?M^i><^ and P2(s) e  R[S]P^'''^  with pi  + P2 ^  m. Let the 
unimodular matrix  U(s) be such that 
U(s) 
Piis) 
0 
Then  G^(^) is a gcrd of Pi(^),  P2(s). 
Proof.  Let 
U  = 
X 
-Pi 
Y 
Pi 
(2.18) 
(2.19) 
"withX  G RisT""""^^", y  e  R[sT''P\  P2 G RWP\2indPi 
G PM^><^2, where^  =  (pi + 
P2)  -  m. Note  that  X, Y  and P2, Pi  are Ic pairs. If  they  were  not, then  det U  7^ a, 3. 
nonzero real number. Similarly, X, P2 and Y, Pi  are re pairs. Let 
[/-' 
\Pi 
-Y] 
vh  ^\' 
(2.20) 
"where  Pi  e  RW^'^""'","  P^  G RisY^^""""  are re  and X  G  R[s]P2'""i", Y  G RisV^'^''  are re. 
Equation  (2.18) implies  that 
Pi 
1P2  Gl, 
i.e., G^ is a crd of Pi, Pi- Equation  (2.18) implies  also that 
f/-' 
0 
XPi  +  YP2  =  G^. 
(2.21) 
(2.22) 
538 
Linear  Systems 
This  relationship  shows  that  any  crd  GR of  Pi, P2 will  also  be  an  rd  of  G\.  This  can 
be  seen directly by  expressing  (2.22)  as MGR  =  G*j^,  where Af is a polynomial  matrix. 
Thus,  G^  is  a crd of  Pi, P2 with the property  that  any  crd  GR of  Pi, P2 is an rd of  G^. 
This impHes that G^ is a gcrd of Pi, P2. 
• 
EXAMPLE  2.17.  Let  Pi  = 
Then 
's(s +  2) 
. 
0 
0 
(s + 1)^ 
,P2 
(s +  l)(s  +  2) 
0 
^ +  1  ' 
s(s  + 1) 
U  Pi 
X 
-Pi 
Y 
Pi} 
Pi 
IP2I 
-(s  +  2) 
s+  1 
-(s+lf 
-(s  +  1) 
-1 
1 
—s 
0 
s+  1 
-s 
0 
0 
s(s  +  1) 
0 
s 
-1 
Pi 
P2} 
s + 2 
0 
0 
s+  1 
G-
0 
0 
In view of Lemma 2.3, G^  = 
5 +  2 
0 
0 
s-hl 
is a gcrd (see also Example 2.15). 
Note that  to derive  (2.18)  and  thus  determine  a gcrd  G^  of  Pi  and  P2, one  could 
use  the  algorithm  that  was  developed  above,  in  Subsection  7.2C  (or  a  variation  of 
this  algorithm)  to  obtain  the  Hermite  form.  Finally,  note  also  that  if  the  Smith  form 
of  Pi 
Pi 
is known,  i.e.,  UL  PI 
PI 
, then  (diag  [e/], 0)t/^  ^ is 
UR  =  SP  = 
diaglEi] 
0 
a gcrd  of  Pi  and  P2  in view  of Lemma  2.3. When  rank 
=  m, which  is the  case 
0 
0 
Pi 
Pi 
of  interest  in  systems,  then  a  gcrd  of  Pi  and  P2  is  diag  [6/]L^^ ^. 
Criteria  for  coprimeness 
There  are  several  ways  of  testing  the  coprimeness  of  two  polynomial  matrices, 
as  shown  in  the  following  theorem. 
THEOREM  2.4.  Let  Pi  E  R[sV^'''^  and  P2  G  P[5]^2xm  with  pi  + p2  ^  m.  The  fol 
lowing  statements are  equivalent: 
(i)  Pi  and P2 are re. 
(ii)  A gcrd of Pi  and P2 is  unimodular. 
(iii)  There exist polynomial matrices X  G  R[S]'^^P^  and  Y  G  R[S]'^^P^  such that 
XPl  +  FP2  =  Im. 
(2.23) 
(iv)  The Smith form of 
(v)  rank  PliSi) 
PliSi). 
m for any complex number Si. 
constitutes m columns of a unimodular  matrix. 
539 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
Proof,  Statements (i) and (ii) are equivalent by definition.  Assume now that (iii) is true. 
Then  (2.23)  impUes that  any  crd  of  Pi  and  P2  must  be  an rd  of Im, which  is of  course 
a crd of Pi  and  P2. Therefore,  in view  of the definition  of a gcrd, Im is a gcrd  (see also 
proof  of Lemma  2.3)  and  so (ii) is true. To show that  (ii) also implies  (iii), determine  a 
gcrd  GJ  as in the Lenrnia 2.3 and note that  GJ  is unimodular.  Premultiplying  (2.22) by 
we obtain  (2.23). 
To show (iv), recall that a gcrd of Pi  and P2 can be determined from the Smith  form 
Px' 
P2 
as GJ  =  (diag [£/], 0)t/^ ^  (refer to the discussion following Example 2.17). It is 
of 
now clear that a gcrd will be unimodular if and only if the Smith form of 
IS 
(i.e.. 
r/1 
LOJ 
(iv) and (ii) are equivalent). To show  (v), consider  (2.18) and note that  rank 
\Pl(Si)]  ^ 
[Piisi)! 
rank GJ(5'/). The only Si that can reduce the rank are the zeros of the determinant of  GJ. 
Such  Si do not exist  if  and  only  if  detG]^  =  a,  a nonzero  real number,  i.e., if  and  only 
if G^ is unimodular. Therefore  (v) implies and is implied by (ii). Part (vi) was shown in 
• 
the proof of Lemma 2.3. 
EXAMPLE  2.18.  (i)  The  polynomial  matrices  Pi  = 
0 
^+  1 
P2  = 
s+  1 
0 
(see also Example  2.15)  are re in view  of the following  relations. To use  condition  (ii) 
of Theorem 2.4, let 
-(s  +  2) 
-1 
s+  1 
U  Pi 
Pil 
s+  1 
1 
-(s  +  If 
—s 
-(s  +  1) 
0 
s(s  +  1) 
\PI 
[Pl. 
= 
'  1 
0 
0 
0 
"0"" "
1 
0 
0 
= 
.  0  . 
Then  G^  =  h,  which is unimodular. Applying condition  (iii), XPi  +  FP2  = 
"""  (^ + 2)  -11 "
s+1 
l|  ^ 
"p +1  0"" "
I  -^ 
0 
/ 2. 
To use (iv), note that the invariant polynomials of 
areei  =  e2  =  1; the Smith 
Pi 
. To use  condition  (v), note that  presently,  the  only  complex  values st 
form  is  then 
h 
0 
that  may  reduce  the  rank  of 
~Pl(Si)] 
P2(Si)\ 
are  those  for  which  detP\{Si)  or  detP2(si)  =  0, 
i.e., ^1  =  0 and S2 =  - 1.  For these values we have  rank 
and  rank  'Pl(S2) 
Piisi). 
=  rank 
' -1 
0 
0 
0 
"0"" "
0 
1 
-1 
=  2, i.e., both are of full  rank. 
'PliSl) 
Piisi). 
=  rank 
0  0 
0  1 
1  1 
0  0 
=  2 
Note  that  if  the  criteria  for  coprimeness  given  in  Theorem  2.4  are  used  for  a 
pair  P i,  P2  that  is  not  re,  then  (ii)  will  provide  a  gcrd  G^  of  P i,  ^2- The  other  tests 
provide  only  partial  information  about  G^.  In  particular,  applying  (iv),  one  obtains 
the  Smith  form  of  G^  (show  this), while  (v)  will  give  information  about  the  zeros  of 
540 
Linear Systems 
"THEOREM 2.5.  Let Pi  G RlsV""""^ and P2 ^  RisV""^^ with mi + m2 >  p. The fol-"
lowing statements are equivalent: 
(i)  Pi and P2 are Ic. 
(ii)  A geld of Pi and P2 is unimodular. 
(iii)  There exist polynomial matrices X G R[S]'^I^P  and Y G R[S]'^^^P  such that 
PiX + P2Y = Ip. 
(2.24) 
(iv)  The Smith form of [Pi, P2] is [/, 0]. 
(v)  rank [Pife), P2(si)]  = p for any complex number si. 
(vi)  [Pi, P2] are p rows of a unimodular matrix. 
Proof. The proof is completely analogous to the proof of Theorem 2.4 and is omitted. 
E.  The Diophantine  Equation 
The linear Diophantine Equation of interest to us is of the  form 
X(s)D(s)  +  Y(s)N(s)  =  Q(sl 
(DIO) 
where D(s), N(s),  and Q(s) are given  polynomial  matrices  and X(s), Y(s) are to be 
determined.  This  equation  will  be  studied  in  detail  in  this  subsection.  First,  par 
ticular  solutions  of the Diophantine  Equation  are derived.  Next,  all  solutions  are 
conveniently  parameterized.  These parameterizations  are used  later in this  chapter 
(in Section 7.4) to characterize  all stabilizing  linear feedback  controllers of a linear 
time-invariant  system. This subsection is concluded  with some historical remarks. 
In  greater  detail,  solutions  of the polynomial  Diophantine  Equation  of low de 
gree are derived in Lemma 2.6, using the Division Theorem for polynomials, and in 
Lemma  2.8, using the Sylvester  Matrix  of two polynomials. Corresponding  results 
for the polynomial  matrix Diophantine Equation  are derived in Lemma  2.12, using 
the Division Theorem and in Lemma 2.14, using the Eliminant Matrix. All solutions 
of the Diophantine Equation are parameterized  in Theorem 2.15. 
The polynomial  case 
Given  coprime  polynomials  d{s)  and n(s), it was shown  in Theorem  2.4 that 
there exist polynomials  x{s) and y{s) such that 
x(s)d(s)  +  y(s)n(s)  =  1. 
(2.25) 
It can be shown that x(s) and y(s) are unique when certain restrictions  are imposed 
on their degrees. In particular, the following  result is true. 
LEMMA 2.6.  Let d(s) and n(s) be coprime polynomials. Then there exist unique poly 
nomials x(s) and 5^(^) that satisfy 
with 
deg y(s) < deg d(s) 
[or deg x(s) < deg n(s)]. 
x(s)d(s) + yisMs)  = 1 
(2.26) 
(2.27) 
Proof. In view of Theorem 2.4, d(s) and n(s) are coprime if and only if there exist poly 
nomials x(s) and y(s) such that x(s)d(s) + y(s)n(s)  =  1. The basic Division Theorem 
for polynomials can now be used to obtain polynomial solutions of lower degree. In par 
ticular, there exists a unique quotient polynomial q(s) and a unique remainder polynomial 
541 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
r{s) such that 
Now  define 
y(s)  =  q(s)d(s)  +  r(s) 
with deg r(s)  <  deg  d(s). 
y(s)  =  r(s)  =  y(s)  -  q(s)d(s), 
x(s)  =  x(s)  +  q(s)n(s), 
(2.28) 
+ 
where  degy(s)  <  degd{s).  Then  x{s)d{s)  +  y{s)n{s)  =  x(s)d(s)  +  y(s)n(s) 
[q(s)n(s)d(s)-q(s)d(s)n(s)] 
=  x(s)d(s)  + y(s)n(s)  =  I. Also  note that deg [x(s)d(s)]  = 
deg [I  -  y(s)n(s)]  <  deg[d(s)n(s)],  so  that  deg x(s)  <  degn(s).  To prove  uniqueness, 
suppose there exists another pair x(sX y(s)  that satisfies  the lemma.  Then 
[x{s)  -  x{s)]dis)  +  [>^(^) -  y(s)]n(s)  =  0, 
which imphes  that 
[ x W - x W]  = 
-[y(s) 
d{s) 
Since deg [y{s) -  y{s)\  <  deg d(s)  and the left-hand  side is a polynomial, this rela 
tion implies that d(s)  and n(s) must have a common factor that contradicts the assumption 
that d(s)  and n(s) are coprime. Therefore,  x(s)  and y(s)  are unique. Note that the proof of 
the lemma when in (2.27) deg x(s)  <  deg n(s) (for the part in parentheses) is completely 
analogous. In this case, let x(s)d(s)  +  y(s)n(s)  =  1 and divide x(s)  by  n(s). 
• 
Given  coprime polynomials  d(s)  and  n(s),  one way  of determining  x(s)  and  y(s) 
that  satisfy  the  above  lemma  is  to  follow  the  procedure  outlined  in  its proof.  In  par 
ticular,  x(s)  and  y(s)  that  satisfy  (2.25)  are  determined  first,  and  then  polynomial 
division  is  used  to reduce  their  degrees,  if  necessary. 
The  following  example  illustrates  this  procedure. 
EXAMPLE  2.19.  Let  d(s)  =  s(s  -  1)  and  n(s)  =  s 
x(s)d(s)  + y(s)n(s)  =  \s[s(s-l)]-l(s^ 
+ s + 2)[s-2]  = 
Us^  + s  + 2)  =  q(s)d(s)  +  r(s)  =  (-\)[s(s 
Then y{s)  • 
^ 
which we obtain 
k(s'-
2,  which  are  coprime.  Let 
=  1. 
-  1)] +  [-\{s  +  1)], from 
^)-Us^-s^-4) 
yi^s) =  r{s)  =  -\{s+ 
1)  and 
x{s)  =  x(s)  +  q(s)n(s)  =  ^s  + (-\)(s 
-  2)  =  ^ 
Note that  x(s)d(s)  +  y(s)n(s)  =  ^[s(s  -  1)] +  (-\(s  +  l))ls  -  2]  =  1 and degy(s)  = 
1  <  degd{s)  =  2 [degx(s)  =  0<  degn(s)  =  1]. 
The polynomials  x(s)  and  y(s)  can  also be  determined  using  the  Sylvester  Matrix 
of the polynomials d(s)  and n(s),  which in fact provides an alternative way of testing the 
coprimeness of d(s)  and n(s).  The Sylvester Matrix of d(s)  and n(s)  is now  introduced. 
Consider the polynomials, 
"d(s)  =  dnS""""  +  dn-lS''^^  +  '""  +  diS  +  do", 
n(s)  — riynS^  +  nyn-\s^~^  +  • • • +  n\s  -\-  n^, 
dn^O 
m <  n. 
(2.29) 
The Sylvester  Matrix  of the polynomials d{s), n(s)  is defined  as 
0 
0 
""" "
dl 
••  d2 
dn 
0 
do 
dx 
0 
do 
dn-2 
dn-l 
dn-l 
dn 
' 
••  0 
••  0 
S(d,  n)  = 
0 
^m 
0 
0 
rim-i 
^m 
0 
nm-2 
nm-\ 
""" "
0 
••  no 
•' 
nx 
' 
' 
dn 
0 
no 
dn-l 
0 
0 
dn-2 
0 
0 
' 
••  do 
••  0 
••  0 
(2.30) 
0 
0 
0 
0 
nm-i 
no 
542 
Linear  Systems 
where the block that contains the coefficients  of d(s)  has m rows and the one that contains 
the coefficients  of n(s)  has n rows. The coefficients  are arranged  so that there art  n + m 
c o l u m n s,  i.e.,  S(d,  n)  E  Rin+m)X{n+m)^ 
The determinant  of S{d, n) is known  as the Sylvester  Resultant  or Resultant  of  the 
polynomials  d{s)  and  n{s).  Note that the matrix  S{dy n)  is  sometimes^eferre4ta^s  the 
Eliminant  Matrix  of the polynomials d{s), n(s). 
• 
THEOREM2.7.  The polynomials d(s)  and n(s)  are coprime if and only if det S{d, n) 7^ 
0, that is, if and only if their resultant is nonzero. 
Proof,  (Necessity)  Suppose  that  d{s)  and  n{s)  are  coprime  but  their  resultant  is  zero. 
This implies that there exists a nonzero vector a,"  a^  G /?""""+"" such that aS{d",  n)  =  OOY 
such that 
^n+m-l 
^n+m-2 
aS{d,  n) 
=  a 
S 
1  J 
's'^-^disY 
sd(s) 
d(s) 
s^'-^nis) 
sn(s) 
.  n(s)  J 
= 
[ai(s),a2(s)] 
d(s) 
n(s)^ 
=  0, 
where 0:1(5)  =  ai 
anda2W  =  «2 
with [01,0:2]  =  a. Note that both oiC^y) 
and  0:2(5)  are  nonzero  since  otherwise  either  n(s)  or d(s)  would  be  zero  and  therefore 
n(s) and d(s)  would not be coprime. Write d(s)/n(s)  =  -a2(s)/ai(s).  Since deg02(5)  < 
degd(s)  and  degai(s)  <  degn(s),  it  follows  that  d(s)  and  n(s)  must  have  a  common 
factor.  Therefore,  d(s)  and  n(s)  are not coprime, which is a contradiction. Thus, S(d,  n) 
has full  rank, or detS(d,  n)  #  0. 
(Sufficiency)  Assume  that  detS{d,  n)  ^  0.  Take  a  =  [0,...,  0, l]S(d,  n)'^  and 
"let 0:1(5)  =  o:i[5'""~^ ...",  5, 1]^, 02(5)  =  02[5'^~^ .. .,5, 1]^, where  [ai, 02]  =  a.  Then 
0:1(5)^(5)  +  0:2(5)^^)  =  o:5(J,"^)[5""+^-i","5""+'^-2",  . . . , 5,  1]^  =  1,  which  implies,  in 
view of Theorem 2.4, that d(s)  and n(s)  are coprime. 
• 
Remarks 
(i)  Theorem  2.7  is  attributed  to  Sylvester  (1840). 
(ii)  A  useful  relation,  used  in  the proof  of  Theorem  2.7,  is 
s'^-^dis)] 
^n+m-\ 
^n+m—2 
S(d,  n) 
sd{s) 
d(s) 
sn(s) 
n(s) 
(2.31) 
where  d(s)  and  n(s)  are  given  in  (2.29)  and  S(d,  n)  is  defined  in  (2.30). 
(iii)  It is possible to arrange the coefficients  in S{d,  n) in several different  ways, 
recalling  that  elementary  row  and  column  operations  leave  the  rank  of 
S{d,  n) unchanged. For example, forn  =  3, m  =  2, 
(a) 
^3 
0 
«2 
0 
0 
di 
d3 
n\ 
«2 
0 
d\ 
d2 
no 
n\ 
ni 
"do  0"" "
d\ 
do 
0  0 
no 
0 
n\  no J 
, 
(b) 
d^  ^2 
0 
d3 
0  0 
n2 
0 
_n2 
ni 
dx 
d2 
n2 
ni 
no 
do 
d\ 
ni 
no 
0 
0 
do 
no 
0 
0 
543 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
(c) 
di 
do 
0 
do 
no  ni 
0 
no 
0  0 
"d3  0"" "
d2 
d2  d3 
di 
0 
0 
n2 
ni 
n2  0 
no  n 1  n2 
are all nonsingular  if and only if d(s)  and  n(s)  are coprime. The matrix in 
(a) is the Sylvester Matrix as defined  in (2.30). The matrices in (b) and (c) 
are variations of the Sylvester Matrix found  in the literature, 
(iv)  By adding zero coefficients  in n(s), it can always be assumed that the poly 
nomials d(s)  and n(s) have equal degrees (m  =  n) when using the test pro 
vided by Theorem 2.7. This leads yet to another variation of the  Sylvester 
Matrix of two polynomials  of dimension  2n  X  2n. 
Using  the  procedure  followed  in  the  sufficiency  proof  of  Theorem  2.7,  it  is 
straightforward  to  derive  the  unique  polynomials  x(s)  and  y(s)  that  satisfy  (2.26) 
and (2.27) of Lemma 2.6. This is illustrated in the next example. 
EXAMPLE2.20.  Lti d(s)  = s(s-l)  midn(s)  = ^-2, which are coprime as in Example 
2.19. In this  case the  Sylvester  Matrix  or the eliminant  of d(s)  and  n(s) in  (2.30) is 
-1 
-2 
01 
0  and the resultant  is detS{d, n)  =  2 T^ 0, as expected,  since 
n 
S(d, n)  =  \l 
LO 
1  - 2J 
d{s) and n{s) are coprime polynomials. In view of the sufficiency  proof of Theorem 2.7, 
let a  =  [ai,a2\  =  [0,0,l]S(d,  n)'^  =  [0,0,1] 
[i 
i,-ij.Then 
[4 
-2 
0 
x(s)  = ai(s)  =  ^,y(s)  = a2(s) 
determined in Example 2.19. 
- ^(5 +1), which also is the answer 
Using the Sylvester Matrix of coprime polynomials enables one in fact to deter 
mine solutions to the more general Diophantine  Equation 
x(s)d(s)  +  y(s)n(s) 
q(sl 
(2.32) 
as the following  lemma  shows. 
LEMMA  2.8.  Let  d(s)  and  n(s)  be  coprime  polynomials  with  degd{s)  =  n  and 
degn{s)  =  m ^  n  given  by  (2.29). Let  q(s) be  a polynomial  of  degree  n + m -  1. 
Then there exist unique polynomials x{s) and y{s) that satisfy 
with 
f x(s) < m 
and 
deg y(s) < n. 
x{s)d{s) + y{s)n{s) = q(s) 
(2.33) 
(2.34) 
544 
Linear  Systems 
Proof,  The  proof  is  constructive.  Let  x{s)  =  [x^-i,.  • •, xi,  xo][s'^  ^,..  .,s,l]^, 
"y(s)  =  [yn-h-""",yhyo][s''~K...,s,lV,2indwntQx(s)d(s) 
yn-h  . •., yo][s'^~^d(s),...,  sd(s),  d{s), s^'-^nis),..., 
yn-u  ...,  yo]S(d, n) [s-^^-\ 
where relation  (2.31) was used. This equality  is now satisfied  if and only if 
...,  ^, 1]^ =  q(s)  =  [qn^^-i,  •..,  ^i, q^Ms^^^'K  •. •, ^, 1 ]^ 
let 
+ y(s)n(s)  =  [ x ^ - i , . . ., XQ, 
sn{s), n{s)Y 
[Xm-h • • •, -^o, 
= 
[Xm-\, ...,XQ,yn-\,..., 
yQ\S{d, u)  -  [qn+m-\," - """,  q\,  <?o] 
(2.35) 
is satisfied.  Since S{d, n) is nonsingular, Eq. (2.35) has a unique solution that determines 
unique x{s)  and y{s) that satisfy  relations  (2.33) and (2.34). 
• 
EXAMPLE  2.21.  Consider  d{s)  =  s{s  -  1)  and  n{s)  =  s  -  2,  which  are  coprime 
as  in  Examples  2.19  and  2.20.  Let  q(s)  =  q2S^ +  qis  +  qo be  an  arbitrary  second-
degree  polynomial  (n  +  m  -  I  = 2 + 1 -1  =2).  Relation  (2.35)  yields  in  this 
"0"" "
0 
- 2. 
=  [q2, qi,  qo]^ from  which  we  obtain  [XQ, yi,yo]  = 
case  [xo,yi,yo] 
"""1 "
1 
.0 
-2 
'4 
2 -2 
.1 
-1 
-2 
1 
0' 
0 
- 1, 
\[q2,q\,qo\ 
=  [2q2 +  ^1 +  ^0,  -qi 
q\  -  hqo, -\qo\  and 
-1 
x{s)  =  XQ  =  2q2 +  q\ 
\qo 
y(s)  =  [yi, yo] 
=  (-\qo)  + {-qi 
-  q\- 
\qQ)s. 
For  q{s) 
+  2 ^ + 1, x{s)  =  |,  and y(s)  =  - \- 
Is. 
• 
COROLLARY  2.9.  Let  d(s)  and  n(s)  be  coprime  polynomials  with  degd(s)  =  n  and 
deg n(s)  <  n. Let q(s) be a polynomial with deg q(s)  <  2n- 
I. Then there exist unique 
polynomials  x(s)  and y(s)  that satisfy  the relation 
with 
deg x{s)  <  n 
and 
deg y{s)  <  n. 
x(s)d(s)  +  y(s)n(s)  =  q{s) 
(2.36) 
(2.37) 
Proof,  The  proof  is  similar  to  the  proof  of  Lemma  2.8,  where  in  place  of  S{d,  n)  E 
^(n+m)x(n+m)^  the  2n  X 2n  Sylvester  Matrix  S{d,"  n)  of  d{s)  =  dnS""""  +  • • • +  Ji^  +  JQ", 
(i„  7^ 0 and  n{s)  =  rinS^  +  ---  + nis  +  HQ  is used. Zero coefficients  are added in n(s)  if 
necessary.  Note  that  S(d,  n)  is  exactly  S(d,  n)  of  (2.30)  with  m  =  n.  This  leads  to  the 
relation 
{Xn-\,  ...,XQ,  yn-\,..., 
y()\S{d, n)  =  [qm-i,  • • •, ^b ^oL 
(2.38) 
which is the equation  corresponding  to (2.35). Since d{s)  and  n{s) are coprime, S{d,  n) 
• 
is nonsingular  and the x{s)  and y{s) that satisfy  (2.38) are unique. 
EXAMPLE  2.22.  As in Example  2.21, consider d{s)  =  s{s  — \)  =  s^  -  s and  n{s)  = 
2  =  O'S^  -\-s- 2, which are coprime. Then  (2.38) implies  that 
[xi,  xo, yi, yo] 
Ti 
0 
p 
0 
0 
-1 
-1 
1 
1 -2 
0 
1 
ol 
0 
0 
-2 
=  [qs, qi.  qi,  qol 
where ^(5-)  =  ^3^^ + ^2-y^ + ^i^ + ^o is a third-degree polynomial ( 2 ^ -1  =  2 . 2 -1  =  3). 
It  can  easily  be  seen  that  one  could  equivalently  solve  xi  =  qs  and  [XQ, yi,  yo] X 
"""1 "
-1 
=  [qi + q-iy qu  qo] (compare with Example 2.21), from  which we obtain 
01 
0 
-2 
545 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
x(s)  =  [xi, xo] 
=  qss +  [2(q2 +  ^3) +  ^1 + ^qo] 
y(s)  =  [yu yo] 
=  [-(qi  +  qs) -  qi- 
\qQ\s +  (-5^0). 
Note that for q^  =  0, this solution is precisely the solution of Example 2.21. 
• 
The  polynomial  matrix  case 
Similar  results  as in the preceding  can be  shown  for polynomial  matrices.  First 
the  Division  Theorem  for polynomial  matrices  is  established. 
"THEOREM  2.10.  Let D{s) E  R[sT^'^  be nonsingular.  Then  for  any A^(^) G RisY^""^ "
there exist unique polynomial matrices  Q{s), R(s) such that 
N(s)  =  Q(s)D(s)  +  R(s) 
(2.39) 
with  R(s)D(s)  ^ strictly  proper,  or with  deg^. R(s)  <  deg^. D(s), j  =  1,..., m,  when 
D(s)  is column  reduced. 
Proof.  Let H(s)  =  N(s)D~^(s)  be a rational matrix. By polynomial division in each en 
try, decompose this matrix uniquely into H(s)  =  Hsp(s) + P(s), where Hsp(s) is a strictly 
proper  rational  matrix  and  P(s)  is  a  polynomial  matrix.  Then  N(s)  =  H(s)D(s)  = 
P(s)D(s)  +  R(s), where R(s)  =  Hsp(s)D(s).  Then  R(s) is a polynomial  matrix  (since it 
is equal to N(s)  -  P(s)D(s)),  and by definition,  R(s)D~^(s)  =  Hsp(s) is strictly  proper. 
Note  that  when  D(s)  is  column  reduced,  then  in  view  of  Lemma  2.2,  R(s)D~^(s)  is 
strictly  proper  if  and  only  if  deg^. R(s)  < deg^. D(s),  j  =  1,...,  m.  We  shall  now 
verify  uniqueness  of  Q(s)  and  R(s)  directly;  it  also  follows  from  the  construction. 
Suppose  there  are  two  pairs  such  that  Q(s)D(s)  +  R(s)  =  Q(s)D(s)  +  R(s).  Then 
Q(s)  ~  Q(s)  =  [R(s) —  R(s)]D~^(s).  Since  the left-hand  side  is  a  polynomial  matrix 
and the right-hand  side is a strictly proper rational or zero matrix, this equality can hold 
only when both sides are zero, i.e., Q(s)  =  Q(s) and R(s)  =  R(s). 
• 
As  expected,  the following  result  also  holds. 
"THEOREM  2.11.  Let D(s)  G R[sY^P  be nonsingular.  Then  for  any N(s)  G RlsY^"""" "
there exist unique polynomial matrices  Q(s), R(s) such that 
N(s)  =  D(s)Q{s)  +  R(s) 
(2.40) 
with D~^(s)R(s)  strictly proper, or with deg^. R(s)  < deg^. D(s), i  =  1,...,  p, when D(s) 
is row reduced. 
Proof.  The proof of this result is completely  analogous to the proof of Theorem 2.10.  • 
Given  re  polynomial  matrices  D(s)  G  R[s]^^^ 
it  was 
shown  in  Theorem  2.4  that  there  exist  polynomial  matrices  X(s)  and  Y(s)  such 
that 
"and  A^(^) G  R[sy^""^ "
Let 
X(s)D(s)  +  Y(s)N(s)  =  Im. 
H(s)  =  N(s)D-\s) 
= 
D-\s)N(s) 
(2.41) 
(2.42) 
be proper,  where D(s)  G  R[sy^P  and N(s)  G  R[sy^^ 
Let  V be the highest  degree  of the polynomial  entries  in D(s)  and denote  this  as 
are Ic with D(s)  row reduced. 
p  = 
degD(s). 
(2.43) 
546 
Linear Systems 
We point  out that  it can be  shown  that  v  is the observabihty  index  of the  system 
His)  = N{s)D-\s)  =  D-\s)N{s). 
"LEMMA 2.12.  Given D{s) G RisT^""^ and N{s) E RisY^""^ that are coprime", there exist 
polynomial matrices X{s) and Y{s) that satisfy 
X{s)D{s) +  Y{s)N{s) 
(2.44) 
such that 
deg Y(s)  < V. 
Proof, This result can also be established by using the eliminant of N{s) and D{s) to be 
introduced in Lemma 2.14. In the present proof, use is made of the Division Theorem for 
polynomial matrices (Theorem 2.10). Let X{s) E Risf'''^  and Y{s) E  R[SY'''P  satisfy 
(2.41). There  exist unique polynomial  matrices  Q{s)  E  R[ST^P  and R{s) E RisT'^P 
such that  Y{s) =  Q{s)D{s)  + R{s) with R{s)D'^{s)  strictly proper, where b{s) is row 
reduced and satisfies  (2.42). Now define  Y{s) = R(s) = Y(s) -  Q(s)D(s) and X(s) = 
X(s) + Q(s)N(s). Then X(s)D(s) + Y(s)N(s)  = X{s)D(s) + Y(s)N(s) + [Q(s)N(s)D(s) -
Q(s)D(s)N(s)] =  X(s)D(s) +  Y(s)N(s)  =  /^. Note also that, in view of Lemma 2.1, 
if  R(s)D'^(s)  is strictly proper, then the column degrees of R(s) are less than  v, i.e., 
deg Y(s) <  V. In  addition,  note  that  from  X{s)D{s) = Im -  Y(s)N(s)  it  follows  that 
• 
deg,. (X(s)D(s)) = deg,. (/^ -  Y(s)N(s)) <v  + deg,. N(s\  j  =  l,...,m. 
Remarks 
(i)  When  D(s)  is  row  proper,  then  n  =  deg\D(s)\  =  sum  of  the  row de 
grees  of  D(s)  <  pp,  that  is,  v  ^  n/p.  If  D(s)  is  not  row  proper,  then 
n  =  deg \D(s)\  <  sum of the rows  degrees  of D(s)  and degD(s)  can be 
large. 
(ii)  In the polynomial  case  we have  that  v  =  n and Lemma  2.12 reduces to 
Lemma 2.6. 
(iii)  Using the Eliminant  Matrix of the re polynomial  matrices A^(^) and D(s), 
where D(s) is column proper, it will be shown (in Lemma 2.14) that (2.44) 
has a solution with both deg Y(s)  <  v and degX{s)  <  v. 
The Eliminant  Matrix 
"Consider  the polynomial  matrices  N{s)  E  R[sy^'^  and D{s) E  RisY""^""^ with "
D{s)  column  proper. Let deg^.N(s)  <  deg^.D(s)  =  dj, j  =  1,...,  m, and assume 
that dj  >  I, j  =  1,..., m. The Eliminant  Matrix  Me of N(s)  and D(s) is a general 
ization of the Sylvester Matrix, or of the Eliminant of two polynomials, introduced in 
(2.30), and is defined in an analogous manner (see also Remarks following  Theorem 
2.7). In particular, we write 
A^(^) 
sN(s) 
D(s) 
sD(s) 
e ^ -l  D(s) 
=  MekSek(s)  =  Mek  block  diag 
(2.45) 
^dj +  k-\ 
for  some integer k, where M^k G RKp+rn)x{j^dj+mk)^  ^^^^  ^^^^ f^^ ^ > 
will  have  as many  as or more  rows  than  columns.  Let ^ =  V be the least  integer k 
that minimizes  (^dj  + mk) — rank M^k, or equivalently  (as can be shown), let ^ = V 
denote the observability index of the system {DJ^N},  or of its equivalent  state-space 
description  (refer  to the discussion  on equivalence  of representations  in  Subsection 
7.3A). 
{ldj)/p,Mek 
The Eliminant  Matrix  of N{s)  and D{s) is defined  as the v{p + m)  x{n  + mv) 
matrix 
Me=Mev, 
547 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
where n = ^dj  = deg  det D{s), since D{s) is column proper. Note that the observ 
ability index v satisfies  v > n/p,  and therefore, Me has as many as or more rows than 
columns.  The following  result  is a generalization  of Theorem  2.7 (which  involved 
the Sylvester Matrix of two polynomials) to polynomial matrices. 
THEOREM 2.13.  The polynomial matrices N{s)  and D{s) given above are re if and 
only if their eliminant matrix M^ has full column rank, i.e., if and only if 
Proof, The proof is omitted. For a proof of this theorem, refer to Wolovich [36]. 
rank Me = n + mv. 
(2.46) 
• 
Remarks 
(i)  The Eliminant  Matrix  Me becomes  a  Sylvester  Matrix  when  applied  to 
-\-dis-\-do  and n{s) 
this is true where 
n{s) 
sn{s) 
polynomials.  In particular,  for d{s) 
n^s^ -\-n2S^ -\-nis-\-no^p  = m=  l,/i = 
n\ 
no 
0 
di 
do 
0 
"""no "
0 
0 
do 
0 
.0 
=  ^3^^  + d2S^ 
di=v  =  3, 
m 
ni 
n\ 
d3 
di 
di 
n2 
ni 
no 
di 
di 
do 
d{s) 
sd{s) 
s^d{s)\ 
•MeSeis) 
1 
0 
m 
ni 
0 
d3 
di 
"0"" "
0 
"""3 "
0 
0 
d3. 
See also Remarks following  Theorem 2.7. 
It can be shown that 
(ii) 
rankMek =  rankMey, 
^>  V, 
i.e.,  the  rank  of  Mek is  the  maximum  possible  when  k  is  equal  to the 
observability  index of the  system.  This is a consequence  of the  alternative 
definition  for v previously  given. 
The  Eliminant  Matrix  can be used  to  determine  solutions  of the  Diophantine 
Equation 
The Diophantine Equation is further  discussed later in this  subsection. 
X{s)D{s)^Y{s)N{s)  = Q{s). 
(2.47) 
LEMMA 2.14.  Consider the re polynomial matrices N(s)  e  R[S]P'''^,D(S)  e R[s]'^'''^. 
Let  D{s)  be  column  proper,  and assume  deg^.N{s) < deg^.D{s) = dj,dj  > lj  = 
1,...,"m [note that H{s) = N{s)D-^ (s) is proper]. Let Q{s) G Rls]^""""""^ with "
deg,.Q{s)<dj  + v-l, 
(2.48) 
548 
Linear  Systems 
where  v  is  the  observabiHty  index  of  the  system  {D, I, N, O}. Then  there  exist  X(s) 
R[s]qxm and  Y(s)  G R[s]^''P that satisfy  the equation 
X(s)D(s)  +  Y(s)N(s)  =  Q(s) 
(2.49) 
with 
degX(s)  <  v  ~  I, 
degY(s)  <  v  -  I, 
where degX(s)  denotes the highest polynomial  degree in the entries of  X(s). 
Proof.  The proof is by construction.  Let 
"X(s)  =  Xo+Xis  +  '-'+X^-is""""^ "
=  [Xo,Xu 
...,X,-i] 
and 
"Y(s)  =  Fo +  Fi5 +  • • • +  F.-i^""""^  =  [YQ", FI,  ...,  F,-i] 
In. 
Sim 
3 
Iffi 
sin 
S^'-^In 
(2.50) 
(2.51) 
Then  Y(s)N(s)  +  X(s)D(s)  =  [YQ,  F^ 
Yp-i,Xo,Xi,.. 
.,Xj,-\] 
N(s) 
sN(s) 
D(s) 
sD(s) 
[Fo,...,  F^-i, Zo,..., X^,-i]MeSe(s)  =  Q(s)  =  QSe(s),  in  view  of the  definition  of  the 
eliminant  matrix  Me  and  the  assumptions  on  the  column  degrees  of  Q(s)  in  (2.48). 
Therefore,  (2.49) is satisfied  with X(s)  and  Y(s)  given in (2.50) and (2.51) if and only if 
[Fo,...,F,_i,Xo,...,X,_i]M,  =  Q 
(2.52) 
is  satisfied,  where  M,"  G  R^(p+m)x(n+mv)  ^^^  Q  ^  j^qx(n+mv)  ^^^^  ^  ^  ^""J^i^j  = "
degdetD(s).  Since N(s)  and D(s)  are re, it follows  from  Theorem  2.13 that rank Me  = 
n  + mv,  i.e.,  Me  has  full  column  rank.  This  implies  that  a  solution  to  (2.52)  exists  for 
arbitrary  Q.  Therefore,  solutions  X(s)  and  Y{s)  of  (2.49)  with  degX(s)  ^  v  -  I  and 
• 
deg Y(s)  <  z^  -  1 always exist. 
Remark 
When  N(s)  and  D(s)  are  polynomials,  Lemma  2.14  reduces  to  Corollary  2.9 
(with  n(^)/(i(5*) proper).  In  this  case,  v  =  di  =  n  = 
deg(detD(s)). 
EXAMPLE  2.23.  The polynomial  matrices N(s)  = 
s+l 
1 
0 
1 
,D(s) 
0 
-s  + 1 
are  re  since  rank 
rA^(A) 
LD(A). 
2 for  A =  0 and A =  1, the  roots  of  detD(s).  D(s)  is  col-
umn proper  with deg^  D(s)  =  d\  =  2, deg  D(s)  =  di  =  \,  n  =  d\  -\-  d2  =  3, while 
deg^^ N(s)  =  1 <  Ji  =  2 and deg^^ N(s)  =  0  <  d2  =  I, p  =  m  =  2. To construct  the 
Eliminant  Matrix  of N(s)  and D(s),  we note that  n/p  =  |,  and therefore,  we let  A: =  2 
549 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
be an initial value. Then 
N(s) 
sN(s) 
D(s) 
sD{s) 
MelSe: 
1 
1 
0 
0 
0 
1 
1 
0 
1 
1 
0 
0 
0 
0 
1 
0 
1 
0 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
0 
1 
0 
0 
0 
0 
0 
1 
0 
-1 
0 
0 
0 
0 
0 
1 
0 
-1 
ri 
s 
\s^ 
r' 0 
0 
[o 
01 
0 
0 
0 
1 
s 
s^\ 
Note thai rank Me2  =  1  =  ^z + m^, which is full column rank. Therefore,  z^ =  2 and the 
EHminant Matrix of N(s)  and D(s)  is Me  =  Mei- The fact that rank Me  =  1 also  verifies 
that N{s)  and D{s)  are re. 
We consider the Diophantine Equation  (2.49)  next, 
(i)  First,  we let  Q{s)  =  [s^ +  1, s^], which  satisfies  (2.48), and we  write  Q(s)  = 
QSe(s)  =  [1, 0,  0,  1, 0,  0,  1] 
I 
s 
0  0 
s^ 
0 
s^  0  0  0 
0 
1  5  ^2 
.  Then  Eq.  (2.52) 
assumes the  form 
[Yo, Yi,Xo,Xi]Me  =  Q  =  [l  0,  0,  1, 0,  0,  1], 
which is an algebraic system of linear equations with 8 unknowns and 7 linearly 
independent  equations  that have more than  one solution.  One  such  solution  is 
given by [70,1^1,^0,^1]  =  [I  0 , - 1,  1,  1, 0,  1,  - 1 ], which, in view of (2.50) 
and (2.51), implies  that 
X(s)  =  Xo + Xis  =  [1, 0] +  [1,  -l]s  =  [s+l, 
-s] 
Y(s)  -  Fo +  Yis  =  [1, 0]  +  [ - 1,  1]^  =  [1 -  s,s] 
is  a  solution  to  the  Diophantine  Equation  with  degX(s)  =  I  =  v 
degY(s)  =  \  =  v - \. 
1  and 
(ii)  Next, we let Q(s)  =  ^ 
and we write Q{s)  =  QSeis)  = 
10 
0 
0 : 0 00 
0  0  0 
assumes the  form 
0 : 1 00 
s 
1 
0  0  0  0 
0  0 
1 
s 
Then  Eq.  (2.52) 
[Yo,YuXo,Xi]Me  =  Q  = 
10 
0  0  0  0  10 
0  0  0  0  0 
0 
A solution of this equation is [FQ,  FI,  XQ, Xi ]  = 
This implies  that 
1 0 - 10 
1 0 00 
1 0 - 1 0 00 
- 11 
X(s)  =  Xo+  Xis 
Y(s)  =  Yo +  Yis 
ro  0 
1 0] 
"-1  oJ""^Lo  0 "
r -1  0' 
1  0 
1  01 
1  + 
-1 
1  0 
0 
-1 
1  -s 
-1  +s 
0 
1 
is a solution of the Diophantine Equation with deg X(s)  =  0 < z ^ -l  =  1 and 
• 
degY(s)  =  \  =  v-\. 
550 
Linear  Systems 
In  the preceding  development,  it was shown  how to derive  particular  solutions 
of  the Diophantine  Equation,  given  coprime  polynomials  and polynomial  matrices. 
In  the following,  conditions  for existence  of solutions  are derived  and all  solutions 
of  the Diophantine  Equation  are conveniently  parameterized. 
"THEOREM  2.15.  Consider nonzero polynomial matrices D(s) G RlsY^^""^ and N(s) G "
R[s]P2Xm  with pi+  p2^  m, let GR(S) G /?[^]^^^  be a gcrd of D(s)  and A^(^), and let 
Q(s)  G R[sY'''^.  The Diophantine  Equation 
X(s)D(s)  +  Y(s)N(s)  = Q(s) 
(2.53) 
if and only if 
has  polynomial  matrix  solutions  X(s)  G R[SY^P^  and Y(s) G R[S]^^P^ 
GR(S)  is an rd of Q(s). If GR(S) is an rd of Q(s), then (2.53) has infinitely many polynomial 
matrix solutions. If X(^)  =  Xo(s) and Y(s)  =  FQ(5) is one such solution, then all solutions 
of (2.53) are given by 
X(s)  = Xo(s) -  K(s)Nds) 
Y(s)  =  Yo(s) +  K(s)Ddsl 
(2.54a) 
(2.54b) 
"where K(s) G Ris]^""""' and where NL(S) G RIS^^P^",  DL G RISY^'P^,  r  = (pi  + P2) -  m 
are Ic and  satisfy  NL(S)D(S)  +  DL(S)N(S)  =  0, i.e.,  [-NL(S),  DL(S)] 
is a minimal basis 
of the left  kernel of 
N(s), 
Proof,  If there  exist X  and Y that  satisfy  (2.53),  then  (XDR +  YNR)GR  =  Q, which 
implies that QG^ ^ must be a polynomial matrix. Thus, GR is an rd of Q that is a necessary 
condition for solutions  of (2.53) to exist. To show  that  this  also  constitutes  a  sufficient 
condition,  assume  that  GR is an rd of Q, i.e., Q =  QRGR  for some  polynomial  matrix 
QR,  and recall  that  there  exist  polynomial  matrices X  G RisY'^P^  Y G RISY'^P^ 
such 
that 
XD  +  YN 
(2.55) 
The proof of this result is constructive and is based on the algorithm to determine a gcrd of 
D and N, using the Euclidean algorithm. (Refer to Subsection 7.2D, where it is shown that 
U 
Y 
X 
-NL 
GR 
0 
,  where  [/ is a unimodular  matrix.)  Premultiplying 
(2.55) by  QR, we now obtain  (QRX)D  +  (QRY)N  =  QRGR 
a  or 
XQD  + YoN = Q, 
(2.56) 
i.e.,  GR  being  an rd of Q is also a sufficient  condition  for the existence  of solutions of 
(2.53). If (2.56) is satisfied,  then 
(Xo  -  KNL)D  +  (Fo +  KbL)N  =  XoD +  YoN  =  Q, 
and therefore, (2.53) has infinitely many solutions, among them the infinitely many given 
by  (2.54). It remains to be shown  that every  solution of (2.53) can be put into the form 
(2.54).  Suppose  that X and Y satisfy  (2.53).  Subtracting  (2.56)  from  (2.53), we obtain 
(X  -  Xo)D + (Y-  Yo)N  = 0, or 
[X -  Xo, F -  Fo] 
D 
0. 
LQiNi^RisY''^' 
and^L 
RlsY^'P^, r  = (pi 
m be relatively Ic and such that 
=  0. 
551 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
. (A discussion of polynomial 
Then [-NL,  DL] is a minimum basis of the left kernel of 
bases of vector spaces will be given shortly.) This implies that there exists some K E 
"Rls]^""""' so that "
which is (2.54). Thus, every solution of (2.53) can be written in the form of (2.54). 
• 
[X-Xo.Y-Yo] 
= 
K[-NL,DLI 
Remarks 
(i)  If Z)-i  exists, thenin the proof of Theorem2.15,(X-Xo)D + (F-7o)A^  = 0 
implies that Z - Zo  =  -(Y-Yo)ND-^ 
= -(F-Fo)^Z^^z.,  where A^L and 
DL  are Ic. Since X -  XQISSL  polynomial matrix, this implies that Y -  YQ = 
i'^DL for some iT, where X-Xo  =  -^A^L-Thus, when i)~^  exists, the above 
results can be derived without directly using the concept of minimum basis 
\D] 
of the left kernel of  A^ 
(ii)  In the theory of systems  and  control, the Diophantine  Equation  is of great 
use,  particularly  for  the case when D~^  exists  and ND~^  is a proper ratio 
nal matrix. In this case  solutions of the Diophantine Equation  with  special 
properties are of interest, particularly  solutions where X~^ exists  a n d Z ' ^F 
is a proper  rational  matrix  (see  Subsections  7.4A,  7.4B,  and  7.4C).  Such 
solutions, satisfying  particular properties, may also be determined via poly 
nomial matrix interpolation  (see the Appendix for theory and examples). It 
will be shown later in this chapter that the Diophantine Equation is central 
in the study of systems wherever feedback  is used. 
Rings, modules, and polynomial  bases of rational vector  spaces 
Now some useful concepts from algebra are briefly reviewed. In particular, rings 
of polynomials, of proper rational functions,  and of proper and  stable rational  func 
tions  are briefly  discussed,  together with modules  and polynomial bases of  rational 
vector spaces. 
Consider  the  set of polynomials  R[s] in s with  real  coefficients,  together  with 
the  usual  operations  of addition,  +, and  multiplication,  •, of polynomials.  Then 
(R[s], +, •) is a ring,  since  all the  axioms of a ring  are  satisfied.  These  axioms  are 
the same as the axioms of a field (see Section  1.10  of Chapter  1), except for  axiom 
(vii),  which  assumes  existence  of the  multiplicative  inverse  in a field. Indeed, if 
p(s)  G R[s] then  l/p(s)  ^  R[s], since in general  l/p(s)  is a rational function  but not 
a polynomial. Another  example of a ring is  the  set of integers, taken  together  with 
the usual operations of addition and multiplication  on integers. 
We note  that  R[s] is a Euclidean  ring,  i.e.,  (i) for  a{s), b(s)  G R[s]  such  that 
a(s)b(s)  7^ 0,deg[a(s)b(s)]  >  dega{s)\  and  (ii) for every  a{s),b{s)  G R[s^  with 
b{s)  ¥- 0, there exist ^(5-), r{s)  G R\s\  such that a(s)  = b(s)q(s)  + r(s),  where either 
r(s)  = 0 or deg r(s)  < deg b(s)  (polynomial division). If R{s) is the field of rational 
fractions  over R[s], called the field of rational functions  (see Subsection 1.2A),  then 
R[s] C R{s)  and  R{s) is also a Euclidean  ring. Note that the units of R{s] are those 
polynomials  p{s)  for  which  there exist a p\s)  G R[s]  such that  p(s)p'(s)  =  1, the 
unity element of R[s], i.e., the units of R[s] are the nonzero elements of  R. 
Another Euclidean ring of interest is the set of proper  rational functions,  taken 
together with the operations of addition and multiplication. A proper rational  function 
552 
Linear Systems 
t(s)  =  n(s)/d(s)  (d(s)  #  0) is  a unit  of this ring  if deg n(s)  =  deg d(s),  i.e.,  if  it is 
^ biproper  rational function.  The set  of proper  and  stable  rational functions  (with 
poles in the stable region of the ^--plane) is also a Euclidean ring. In this case, if  t{s) 
is a unit then t{s) and t~^{s) are proper and stable rational  functions. 
Polynomial  bases  of  rational  vector  spaces  are  discussed  next.  Recall  that  if 
Pi{s)  G  R[s],  then  it  may  always  be  viewed  as being  divided  by  1, in  which  case 
Pi{s)  =  Pi(s)/1  E  R(s),  the  field  of  rational  functions.  Thus,  a polynomial  vector 
p(s)  E  R[s]P may be viewed  as a special case of a rational vector p(s)  E  R(sy. 
is  also  a  basis  for 
Now let H(s)  E  R(sy^^,  assume that rankH(s)  =  m, and consider the rational 
vector  space spanned by the columns  hj(s)  E  R(sy,  j  =  1,...,  m, of H(s)  and de 
note this space by  Y(s).  Thus, the vectors in  Y(s)  are generated by H(s)a{s),  where 
a(s)  =  [ai(s),..., 
ap(s)]^,  cxj(s)  E  R(s).  The  matrix  H(s)  is  a basis for  Y(s)  and 
"if  T(s)  E  Ris)""^""""""^  and  rankT(s)  =  m",  then  H(s)  =  H(s)T(s) 
Y(s).  Consider a right polynomial MFD of H(sl  H(s)  =  B(s)A~\s),  where B(s)  E 
R[sy^^  and A(s)  E  R[s]^^^  are not necessarily coprime. Note that rankB(s)  =  m 
and  B(s)  is  a polynomial  basis  of the rational  vector  space  Y(s).  Consider  now  the 
set M  of all polynomial  vectors  h(s)  E  R[sy  that can be written  as linear  combina 
tions  over  the  ring  R[s]  of  the  columns  bj(s)  E  R[S]P,  j  =  1,...,  m,  of  B(s).  The 
set M  is  3. free  R[s]-module  and  5(^)  is  a basis  of M.  The  dimension  of M  is <i/m 
M  =  rankB(s)  =  m.  If  the p  rows  of  B(s)  are  re,  then  the  free  7?[5']-module M* 
generated  by  the  columns  of  B(s)  is  called  the  maximal  module  contained  in  Y{s) 
and  coincides  with  the  set  of  all polynomial  vectors  contained  in  the rational  vec 
tor space  Y{s)  [i.e., any polynomial vector in  Y{s) can be expressed  as B(s)p(s),  for 
some  p(s)  E  R[s]^].  Note  that  if  U(s)  E  R[s]^^^ 
is  any  unimodular  matrix,  then 
B{s)  =  B(s)U(s)  is  another  basis  for  M,  and  U(s)  can be  chosen  to reduce  B{s)  to 
a column proper  (reduced)  form,  if  so desired. A minimal  basis  of a rational  vector 
space  Y(s)  is  defined  as  a polynomial  basis  B(s)  of  Y(s)  with  all  its  rows  re,  i.e., 
if  B(s)  E  R[s]P^^  is  a minimal  basis  of  7(5*), then  any  polynomial  vector  in  Y(s) 
"can  be  expressed  as  B(s)p(s)  for  some polynomial  vector  p(s)  E  R[s]""^",  Note  that 
a minimal  basis  5(5*) is  sometimes  defined  in the literature  to be column  proper  as 
well. 
Summarizing,  given  H(s)  E  R(sy^^ 
and  rankH(s)  =  m  ^  p,  a  minimal 
polynomial  basis  for  the  rational  vector  space  spanned  by  the  columns  of  H(s) 
can  be  found  as  follows:  write  H(s)  =  B(s)A~^(s),  where  B(s)  E  R[S]P^^ 
and 
"A(s)  E  R[s]^^^  are not necessarily  coprime. Let  GR(S)  E  R[S]^^""^  be a gcrd of the "
p rows of 5(5') and write B(s)  =  B(S)GR(S).  Then B(s)  is a minimal basis. To reduce 
B(s)  to  column  proper  form,  consider  a  unimodular  matrix  U(s)  E  /^[^J'^^'^  such 
that 5(5')  =  5(5)6^(^) is column proper (see Subsection  7.2B.) 
Historical remarks on the Diophantine  Equation 
If  n, d  are two nonzero  integers  and  the integer  g is their  gcd,  then  there  exist 
integers  x, y  so that  xd  -\-  yn  =  g  (see also Lemma  2.3). This result was known to 
the fourth  century  B.C. Greek mathematician  Euclid. 
The Diophantine Equation xd-^yn  =  q given above, where d, n, and q are spec 
ified  and  solutions  x, y  are  to be  determined,  is  one  of  the  equations  in  more  than 
one indeterminants  introduced  by Diophantus  of Alexandria,  who lived  around  A.D. 
250. It is in fact  called  a linear Diophantine Equation  or a Diophantine Equation of 
first-order. Diophantus, who introduced letter symbols for quantities in mathematical 
553 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
problems, is considered to be one of the greatest mathematicians. His treatise on alge 
bra, considered to be the first ever," is called ""API0MHTIKA""  and consists of seven "
books, six of which have survived. Diophantus worked with equations involving in 
tegers. An example of a specific case of the Diophantine Equation is 3x-\-2y  =  4, the 
=  -1  +  3^ with k equal to any 
general solution of which is given byx  =  2-2k,y 
integer  (see Theorem  2.15).  In this  case,  the particular  solution  XQ =  2,  yo  = 
-I 
was used.  The parameterization  of  all  solutions  in this  convenient  form  appears  to 
be a later development,  the work of Hindu  mathematicians  in the fifth century  A.D., 
apparently  of  Aryabhata.  It  is  worth  mentioning  at  this  point  that  another  class  of 
famous  Diophantine  Equations  is  x^  + y^  =  z^,  where  x, y, z,  and  n  are  integers. 
When  n  =  2, then x  =  3,y  =  4, and z  == 5 is a solution since 3^ +  4^  =  5^. Solu 
tions for integer n greater than 2 do not appear to exist. In fact, the famous  Fermafs 
last  theorem  (c.  1637)  states that no solution  exists for  ^  >  3. Fermat  wrote on the 
margin  of  his  copy  of  the  works  of  Diophantus,  referring  to this  theorem,"  ""I  have "
"discovered  a truly  remarkable  proof  which  this  margin  is  too  small  to contain.""  In "
spite  of  attempts  over  the  next  centuries  by  mathematicians  like  Euler,  Legendre, 
and many others, this result has not yet been proved in its generality, although a re 
cent proof  (1994)  shows  great promise  of being  completely  correct. It is, however, 
known to be true for n up to tens of thousands, using computer methods. 
Diophantus worked with integers. However, integers and polynomials obey sim 
ilar rules (they are both rings), and therefore,  all results of interest on the linear Dio 
phantine  Equation,  xd  -\-  yn  =  q  that  were  developed  for  integers  can  readily  be 
written for polynomials, and this is what was done in Subsection 7.2E. These results 
for  the  polynomial  Diophantine  Equation  were  pointed  out  in  the  books  by  Gant-
macher  and McDuffee  (refer  to the bibliography  at the end of the chapter). In view 
of this, it is not  surprising  that  solutions  of linear Diophantine  Equations  involving 
elements other than integers or polynomials, but still members of rings, can be stud 
ied and expressed in a completely analogous manner. In fact, Diophantine Equations 
with elements that are polynomials in z~^ and (s -f- a)~^ were studied in the systems 
and  control literature  in the  1970s by  Kucera  and Pernebo, among  others. Later,  in 
1980, Desoer et al. clearly pointed this fact out in the systems and control literature, 
namely,  that  the  solutions  of  the  linear  Diophantine  Equation,  when  the  equation 
involves  elements  of rings  other than  integers  or polynomials,  are analogous  to the 
integer and polynomial cases. They also addressed conditions on system descriptions 
under which  such Diophantine Equations may  appear. 
It will be  shown in Subsection  7.3C  how the linear Diophantine Equation  is of 
fundamental  importance  in the  study  of  feedback  systems. It  should be noted  here 
that when  q  =  1, the Diophantine  Equation  is  sometimes referred  to as the  Bezout 
identity  (see, e.g., Kailath  [21]). For the role played by the Diophantine Equation in 
control, the reader  should also refer  to the survey paper by Kucera  [24]. For  further 
details, refer  to Sections 7.6 and 7.7, Notes and References,  respectively. 
7.3 
SYSTEMS  REPRESENTED  BY  POLYNOMIAL 
MATRIX  DESCRIPTIONS 
We consider system representations  of the  form 
P(q)z(t)  =  Q(q)u(tl 
yit)  =  R(q)z(t)  +  W(qMt) 
(3.1) 
554 
Linear Systems 
with  P{q)  G R[q]^''\  Q{q)  G R[qY'''^, R{q)  G R[q]P''K  and  W{q)  G R[q]P'''^, wliere 
R[qy^^  denotes tlie set of / x / matrices whose entries are polynomials in q with real 
coefficients  {q =  (d/dt) 
the differential  operator)  and we assume that  det P{q)  ^  0 
and  that  u{t)  is  sufficiently  differentiable.  We  also  assume  that  the  set  of  homo 
"geneous  differential  equations  P{q)z{t)  =  0 is  ""well  formed","""  that  is",  for  all  initial 
values  of  z(-)  and  its  derivatives  at  f =  0  the  solution  does  not  contain  impulsive 
behavior  at  f =  0.  (This  is  true  if  and  only  if  P~^{q)  is  a  proper  rational  matrix, 
which  is true  for  example  when  P{q)  is  column  or row reduced  (for  further  details 
refer,  e.g.,  to  Section  3.3  of  [9])).  Such  representations,  called  system  Polynomial 
Matrix  Descriptions  (PMD), were introduced in Section 7.1. 
In this  section,  equivalence  of  system  representations  is discussed first, in  Sub 
section  A.  This  notion  of  equivalence  establishes  relations  not  only  between  poly 
nomial  representations,  but  also  with  state-space  representations,  which  are in  fact 
a  special  case  of  PMDs  (see  Section  7.1).  Equivalence  of  PMDs  preserves  certain 
system  properties,  including  controllability,  observability,  and  stability,  that  are the 
topics of discussion in Subsection B, together with polynomial matrix realizations of 
transfer  function  matrices.  In  Subsection  C, Polynomial  Matrix Fractional  Descrip 
tions (PMFDs) are employed to study properties of interconnected  systems. 
A.  Equivalence of System Representations 
Consider the PMDs 
Pi{q)zi{t)  =  Qi{q)u{t), 
y{t)=Ri{q)zi{t)+Wi{q)u{t), 
1,2, 
(3.2) 
w\\QXQPi{q)eR[q]^'''^',Qi{q)eR[qy''''^,Ri{q)eR[q]P''^\ 
and W,-(^) G/^[^]^>^ 
DEFINITION  3.1.  The representations  {Pi, gi,/?i,\^i} and {P2,22,^2,^2} in (3.2) 
are called equivalent if there exist polynomial matrices M ^ R[q\^^^^^ ,N ^ R[q\^^^^^ ,X  ^ 
RW^K  and Y G P[^]^2xm ^^^^ ^^^^ 
'M 
X 
"0"" "
h. 
Pi 
- ^1 
Gi 
Wi 
Pi 
-R2 
Qi 
W2 
'N 
0 
-Y' 
^m 
with (M, P2) Ic and (Pi, A^) re. 
(3.3) 
• 
The  equivalence  of  the  representations  {P/,2/,/^/,W^},/  =  1,2,  or  of  the  corre 
sponding system  matrices  ^1,^2, where 
Pi  Qi 
-Ri  Wi 
€R[s]  {li+p)^{li+m) 
(3.4) 
is sometimes referred to as Fuhrmann's  System Equivalence  (FSE). This equivalence 
relation  will  be  denoted  by  pf,  or  simply  p.  It  can  be  shown  that  (3.3)  with  its 
associated conditions given in Definition  3.1 defines  an equivalence relation p  on the 
set of matrices S with p, m fixed, \P\  ^  0, and / any positive integer (see the discussion 
of  equivalence  relations  at  the  end  of  Subsection  7.2C).  The  polynomial  matrix  S 
defined  in (3.4) for  system  {P, g, P, W}  is called Rosenbrock's  System  Matrix  of the 
system Pz =  Qu^y =  Pz +  Wu. 
555 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  3.1.  Consider  the  representations  (1.3)  and  (1.4)  in  Section  7.1  and  let 
Pi  =  qI-A,Qi 
=  B,Ri  =  C,Wx  =  D given in (1.3), and let P2  =  P, Q2  =  Q> R2  = 
R^W2  =  W  given  in  (1.4).  If  A^  =  C  = 
[0 
0 
1 
-1 
,"M  =  1  q  0"" "
"0"" "
' 
1, 
0  0  q_ 
D 
andX  = 
0  0 
0 
1. 
1  ^  0  ^^  +  1 
are  Ic,  while  (Pi, N)  are  re,  as  can  be  verified  by  apply 
0  0^ 
ing,  for  example,  the  rank  test  for  coprimeness  of  Theorem  2.4(v)  to  (M, P2)  above 
then  (3.3)  is  satisfied  (verify  this). Note  that  (M, P2)  = 
0  0 
0  0 
1 
Q +  2 
q 
and  to 
0 
q 
-1 
0 
0 
0 
1 
-1 
1 
0 
' + 2  .  These  representations  satisfy  all  the  conditions  of 
0 
1 
Definition  3.1, and are therefore,  equivalent  (or Fuhrmann  system equivalent). 
• 
There is an alternative definition  of system equivalence,  sometimes referred  to as 
(RSE).  Subsequently, 
strict  system  equivalence  or Rosenbrock's  System  Equivalence 
PR will  denote  this  equivalence  relation.  It is  defined  as  follows. 
The  representations  given  in  (3.2)  are  called  strict  system  equivalent 
exist  unimodular  polynomial  matrices  M,N 
X  G  Riq^^, 
"Y  G  Riqf""^  with  m  =  deg  |P/|", k  >  max(ni,  ^2), such  that 
^  R[q\^^^ 
if  there 
and  polynomial  matrices 
M 
0 
Pi 
0 
0 
Gi 
Wi 
h-h 
0 
Pi 
0 
Q2 
N 
0 
-R2 
:  W2 
h, k>  h 
Relation  (3.5) is in general easier to use than (3.3), since the matrices M, A^, 
\N 
-Y 
and 
are  all  unimodular. 
(3.5) 
0 
M 
X 
The  following  theorem  establishes  that  the  preceding  two  definitions  of  system 
equivalence  [i.e., Fuhrmann's  (FSE)  (3.3) and Rosenbrock's  (RSE)  (3.5)]  are, in  fact 
equivalent.  Note  that it was  for  this reason  that  in Definition  3.1, which  is in fact  the 
definition  of  FSE,"  only  the  term  ""equivalent""  was  used. "
THEOREM  3.1.  Consider  the  representations  given  in  (3.2). If  they  are  Fuhrmann's 
System  Equivalent  (FSE)  [satisfying  (3.3)],  i.e.,  {Pi, Qi, Rx,  WI}PF{P2,  Qi, Ri, W2}, 
then 
i.e., 
{Ph  Qh  Rh  WI}PR{P2,  Q2,  Ri,  W2\  and vice versa. 
they  are  Rosenbrock's  System  Equivalent  (RSE) 
[satisfying 
(3.5)], 
556 
Linear Systems 
, where [-X,Y]  and 
Proof, If the representations  are FSE, then MPi  =  P2N and  -X 
Pi 
I  0 
were chosen so that the block matrices are unimodular. 
0 
/ 
This can always be done since (P2, M) are Ic and (Pi, N) are re. [See also the discussion 
on doubly coprime factorizations  of a transfer function in (4.18) of Subsection 7.4A.] It 
can now be seen that 
-N 
Pi 
Y 
M 
X 
Y 
-X 
P2 
Y 
M 
-R2 
X 
0 
Gi 
0 
0 
Pi 
~Ri 
0 
-X 
h. 
YPi 
N 
YQi 
Y 
0 
P2 
0 
-R2 
W2 
(3.6) 
Observe that  \ 
.0 
matrix in the left-hand side is unimodular. Therefore, FSE  ^  RSE of the representations. 
To show the converse, suppose that (3.5) is satisfied. Partitioning, we can write 
which implies that the second block 
xl ^J \-x 
U/, 
YPi 
N _ 
"""0 "
A 
W 
N. 
Mil 
Mu 
M21  M22 
0 
Pi 
0 
0 
Xi 
X2 
-Ri 
Wi 
(3.7) 
h-i, 
0 
0 
P2 
0 
Qi 
Nil 
N12 
N21  N22 
-Yi 
-Y2 
0 
- ^2 
W2  L  0 
where M22, N22  ^  ^[^l^^x^i. Then 
M22 
0 
Pi 
-Ri 
Qi 
Wi 
Pi 
-Ri 
Qi 
W2\ 
'N22 
0 
-Y2 
Im 
(3.8) 
It turns out that  (M22, P2) are Ic and  (Pi, N22)  are re. This can be shown  as follows. 
Consider the unimodular matrices M  = 
Mil 
1P2N21 
M12 
M22. 
andA^  = 
Nil 
N21 
MnPi 
N22  J 
where 
the relations M12P1 =  A^i2, M21 =  P2N21  from (3.7) were used. Now if (P2, M22) were 
not Ic, then  they  would have  a nonunimodular  common  left  divisor  that  would have 
caused M not to be unimodular. Therefore, they are Ic. Similarly, A^ is unimodular implies 
that (Pi, N22)  is re. This shows that (3.8) is indeed the defining  relation for FSE, and 
• 
therefore RSE => FSE of the representations. 
In the following  we enumerate  some of the important  properties  of FSE and 
RSE. 
THEOREM 3.2.  Assume that the representations (3.2) are equivalent, i.e., they are FSE 
or RSE. Then the following  are invariants of the equivalence relation  p  =  pF  = PR-
(i)  deg\Pi\  =  nj  =  1,2. 
(ii)  The nonunity  invariant polynomials  (in the Smith form)  of P/, [Pi, Qi\  Pi 
-Ri 
Si,  i  =  1, 2. 
(iii)  The transfer  function  matrix//,(^)  =  Ri(s)P;^(s)Qi(s)  + Wi(s),i  =  1,2. 
and 
Proof,  Recall  from  Section  7.2  that  two polynomial  matrices  Mi,  M2  E  R[qy^^  have 
the  same  Smith  form  if  and  only  if  there  exist  unimodular  matrices  Ui,  U2 such  that 
UiMi  =  M2U2. In this case Mi,  M2 are called equivalent polynomial matrices. To show 
557 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
(i),  note  from  (3.5)  that M 
0 
0 
Pi 
0 
Pi 
0 
N,  where  M, N  are  unimodular. 
Therefore,  Pi  and  P2  must  have  the  same  nonunity  invariant  polynomials  (note  that 
Pi, P2  may  have  different  dimensions),  which  implies  that  |Pi|  =  a\P2l  where  a  is 
some nonzero real number (show this). Clearly then, deg  \Pi \ =  deg  IP2I. 
To verify  (ii), note that in (3.5), 
fore,  the extended  system  matrices 
Se,  = 
h-ii 
0 
M 
X 
0 
^1 
0 
and 
are unimodular,  and there-
^€2 
~ 
lk-l2 
0 
0 
^2, 
with Si, i  =  1, 2, defined  in  (3.4), have the  same Smith  form.  Thus, ^1 and ^2 have  the 
same nonunity invariant polynomials. In a similar manner,  (3.5) implies  that 
M 
0 
0 
Pi 
0 
Qi 
0 
Pi 
0 
0 
Qi 
which  shows that  [Pi, Qi]  and  [P2, Q2]  have the same nonunity  invariant  polynomials. 
Similarly, 
and 
have the same nonunity  invariant  polynomials. 
Pi 
-Ri 
Pi 
-Ri 
Finally, to show (iii), we write, in view of  (3.5) 
Hi 
RiPi'Qi  + Wi  =  [0,  Pi] 
+  Wi 
= 
[0, R2W  +  X 
0 
Pi 
I 
0 
0  Pi 
+  Wi 
= 
[0,  P2 
0 
7 
0  P2 
-1 
M  + X 
+  Wi 
=  [0,  P2] 
M 
=  [0,  P2] 
7 
0 
0  P2 
/ 
0 
=  [0, P2] i 
0  P2 
+  Wi 
+ 
0 
GiJ 
7 
0 
0  P2 
+  [W2 +  [0P2]?] 
+  W2  =  RiP2^Qi  +  W2  =  H2. 
558 
Linear Systems 
In the above derivations the following relations, which can directly be seen  from 
(3.5), were used: 
M 
7 
0 
0  ^ 1. 
0 
Qi. 
M 
7 
"0"" "
0  P2_ 
^ 
N, 
I 
—  — 
0  P2_  f  + 
0 
"""0  ' "
.Q2_ 
I 
0 
0  Pi 
+  [0, -/?i]  =  [0,  -R2\N, 
+  Wi  =  -{Id,-R2\Y 
+W2. 
Now consider the representations  (3.2) and notice that they can be written as 
SM)  Ziit) 
-u(t) 
Piiq)  Qiiq) 
-Riiq)  Wiiq) 
Zi(t) 
-uit) 
0 
-y(0. 
(3.9) 
(3.10) 
(3.11) 
(3.12) 
(3.13) 
i  =  1, 2, where Si(q)  is Rosenbrock's  System Matrix  given in (3.4). If these repre 
sentations are equivalent, then the relation between the states zi  and Z2 can be found 
in the following  manner. 
we ob-
\  Px  Qx 
[~Rx  Wi 
'Nzi  +  Yu\' 
— u  J 
Pi 
Qi 
-R2  W2_ 
r 0' 
[-y. 
Postmultiplying both sides of (3.3) by  1 
"r  ""^1 "
Qi\ 
Ri  W2J 
[ —M 
M 
X 
\ ^A 
\_—u  \ 
-u'Y 
0 
lp\ 
0' 
-y. 
There-
'  Pi 
\—u 
tain 
M 
or 
= 
0 
T 
\  Pi 
Q2] 
[-R 2  W2J 
fore, 
Z2(t) =  N(q)zi(t)  + Y(q)u(t) 
(3.14) 
is  a possible  relation  between  the  partial  states. To obtain  the  inverse  relation,  we 
could express  z\  as a function  of Z2 by considering  (3.3) and  selecting X,  Y, X,  Y so 
that 
-x 
.Pi 
Y^ 
M\ 
\-N  X 
[Px  Y. 
"I  0"" "
/ 
0 
"""-A^  X] "
Pi 
Y\ 
\-X 
[Pl 
f 
M 
(3.15) 
are unimodular polynomial matrices. Note that this is always possible, since MP\  = 
P2N  with (M, P2) Ic and {Pi, N)  re (see also the proof of Theorem 3.1). Now in view 
of (3.15), Eq. (3.3) implies  that 
Px 
-Rx 
Qx] 
WiJ 
\X 
[0 
-E 
^m 
x  0] 
F  h\ 
Pl 
Qi 
-R2  W2 
(3.16) 
where £•  =  YQx-XYandF 
=  i?2^-XF. This relation was of course expected, due 
to the symmetry property of the equivalue relation pp.  Postmultiplying both sides of 
(3.16) by  [z\y -u^]^  and proceeding  similarly  as before,  we can now show that 
Zi(t)  =  X{q)z2(t)  ^  EiqMt). 
(3.17) 
Equations  (3.14)  and  (3.17)  determine  an invertible  mapping  that relates the  states 
of  the  equivalent  representations  (3.13).  It  can  be  shown  that  if  (3.14)  and  (3.17) 
hold for  some polynomial matrices A^,  Y X, E,  then the representations  in (3.13) are 
equivalent. 
559 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Polynomial Matrix Fractional Descriptions  (PMFDs) 
Next,  we  consider  the  right  Polynomial  Matrix  Fractional  Descriptions 
(rPMFDs)  given by 
Di{q)zi{t)  =  u{t), 
(3.18) 
THEOREM 3.3.  The rPMFDs given in (3.18) are equivalent if and only if there exists 
a unimodular matrix U such that 
y{t)  -  Ni{q)Zi{t\ 
i  =  1,2. 
Proof, Suppose that (3.19) is true. Rewrite it as 
U. 
D2 
-N2 
0 
0 
(3.19) 
(3.20) 
and note that this is a relation of the form (3.3). Therefore, the representations {Di, I, Ni}, 
{D2, /, N2} are equivalent. Conversely, suppose that (3.3) is true, i.e., 
M 
X 
01 
\ 
^' 
l-Ni 
Imi 
Im 
0_ 
D2 
-N2 
Im] 
\^ 
[0 
oj 
-Y' 
Im. 
with (M, 7)2) Ic and (Di, TV) rc. Then M  =  Im-D2Y  and MDi  = Z)2iV from which it fol 
lows that Di  = D2(N + YDi)  = D2U.A\so,XDi  -Ni  =  -N2NmdX  = A^2i'which 
imply that A^i  =  A^2(A^ +  YDi)  = N2U. From Di  = D2U and the fact that degDi  = 
degD2, it now follows that U is unimodular 
• 
The reader should verify  that in this case, the relations between the states (3.14) 
and (3.17) are given by Z2 =  Uzi  andzi  =  t/-iz2, i.e., A^ =  u,Y  =  0,X  =  U-\ 
mdE  = 0. 
A similar result is true for IPMFDs given by 
Di(q)zi(t)  =  NiiqMt), 
y(t)  =  Zi{t\ 
1,2. 
(3.21) 
Specifically,  the IPMFDs  given in (3.21) are equivalent  if and only if there exists a 
unimodular matrix  U such that 
[Di,Ni]  =  U[D2,N2l 
(3.22) 
The proof  of this result is completely  analogous to the proof  of Theorem  3.3  and is 
omitted. 
State-space  descriptions 
We now consider the state-space representations  given by 
Xiit)  =  AiXiit)  +  Biu{t), 
y(t)  =  CiXi +  Di{q)u{t), 
i  =  1, 2,  (3.23) 
and  we  assume  that these  are related  by  a similarity  transformation,  i.e., there is a 
g ^ ^ n x« 
|g|  ^ 0,  such that 
Q 
0 
0 
\qln  -  Ay 
In\ 
[ 
-Ci 
By 
Di(q)_ 
qln  -A2 
- C2 
B2 
\ 
D2{q)\ 
\Q  0 
[0 
/„ 
(3.24) 
Clearly,  this  is  a  relation  of  the  form  (3.3)  with  M  =  N  =  Q  2ind  X  =  Y  ^  0. 
Therefore,  {Ai, Bi,  Ci, Di(q)},  {A2, B2, C2, D2(q)}  are  equivalent  in  the  Fuhrmann 
or  Rosenbrock  sense.  The  converse  is  also  true.  In  particular,  if  two  state-space 
representations  are  equivalent  in  the  sense  of  Definition  3.1, then  they  are  related 
560 
Linear Systems 
via  a  similarity  transformation.  The  proof  of  this  result  is  not  presented  here.  We 
^^^  the  reader  to  verify  that  in  this  case  the  relations  between  the  states  (3.14), 
(3.17)  are  given  by  X2 =  Qxi  and  xi  =  Q~^X2, i.e.,  N  =  Q,Y  =  0,X  =  Q-\ 
and E  =  0. Note that the state-space representations  considered  in (3.23)  are more 
general  than the state representations  of previous  chapters,  since the term  D{q)u{t) 
may  contain  derivatives  of  the  input.  In  fact  it  can  be  shown  that  every  PMD 
{P{q), Q(q), R(q),  W(q)}  in  (3.1)  is  equivalent  to  a  state-space  description  of  the 
form  {A, B, C, D(q)}  (see, e.g..  Section 2.2 of  [30]). Note that a state-space  descrip 
tion of the form {A, B, C, D) that is equivalent to a given PMD as in (3.1) exists only 
when that PMD has a proper transfer  function  H{s). 
Now  recall  the  relation  between  a  state-space  realization  {Ac, Be, Cc, Dc]  in 
controller  form  of the transfer  function  matrix  H{s)  and the corresponding  rPMFD 
{DR,  I, NR}. Specifically,  (see Subsection  3.4D  of Chapter  3 and the Structure  The 
orem), we have 
H{s)  = 
NR(S)DR\S) 
with 
NR(S)  =  CcS(s)  +  DCDR(SI 
(SI  -  Ac)S(s)  =  BCDR(SI 
(3.25) 
s^^~^)^\  with dt, i  =  1,...,  m, 
where the n X m matrix S(s)  =  blockdiag  [(1, s,..., 
the controllability  indices of (Ac, Be) or the dimensions of the subblocks in the con 
troller form  (Ac, Be). 
The representations  DR(q)z(t)  =  u(t), y(t)  =  NR(q)z(t)  and  xdt)  =  Acx(t)  + 
Bcu{t),  y(t)  =  Ccx(t)  +  Dcu(t)  are equivalent  since 
Be 
Dc 
0 
Ip\ 
DRiq) 
y-NRiq) 
Im 
0 
ql  -  Ac 
-Cc 
Bc\ 
Dc\ 
\Siq) 
[  0 
0 
^m 
(3.26) 
with  (Be, ql  -  Ac)  Ic  and  (DR(q), S(q))  re  (show  that  this  is  true).  Verify  that  in 
this case the relation between the states given by Eq. (3.14) is ^^(0  =  S(q)z(t),  and 
determine the relation between the states given by Eq. (3.17) for this case. We note 
that (3.25) can be written  as 
NR(S)  =  CS(s)  +  DDR(S\ 
(SI  -  A)S(s)  =  BDR(SI 
(3.27) 
where  A  =  Q~^AcQ,B  =  Q~^Bc,C  =  CcQ,D  =  Dc  with  \Q\ ¥^ 0  and  S(s)  = 
Q~^S(s).  Equation  (3.27)  relates  NR(S)  and  DR(S) to  a  controllable  realization  of 
H(s)  that is not necessarily  in controller form. The matrix  2  is a similarity  transfor 
mation  matrix. 
Completely  analogous results exist for a state-space realization {Ao,  Bo, Co, Do} 
in observer form  and the corresponding  IPMFD {DL, NL, Ip}-
Finally,  note  that  the  above  results  involving  the  Structure  Theorem  are  also 
valid after the obvious modifications, when the state-space description is of the more 
general form {A, B, C, D(q)}. 
B.  Controllability,  Observability,  Stability, and  Realizations 
Consider now the PMD 
P(q)z(t)  =  Q(q)u(t), 
y(t)  =  R(q)z(t)  +  W(q)u(t\ 
(3.28) 
where P((^)  E  Riql^^'K Q(q)  G R[q]^'''^, R(q)  E  R[qy\ 
2indW(q)  G  /?[g]^x^.The 
561 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
important  system properties  of controllability,  observability,  and  asymptotic  stabil 
ity  can  be  developed  directly  in  a  manner  similar  to  that  in  earlier  chapters,  us 
ing state-space descriptions. However, instead of reintroducing these properties, we 
shall  concentrate  on  establishing  criteria  for  (3.28)  to be  controllable,  observable, 
and asymptotically  stable. 
Assume  that the PMD  given  in  (3.28)  is equivalent,  in the  sense  of  Definition 
3.1 and (3.3), to some state-space  representation 
x(t)  =  Ax(t)  +  Bu(t\ 
y(t)  =  Cx{t)  +  Du{t\ 
(3.29) 
where A  G /^'^x^ B  G  R'''''^,  C  G 7^^x^  and D  G T^^^^. That is, for the  discussion 
that follows, we restrict the PMD in (3.28), at least initially, to the class of PMD that 
is  equivalent  to  state-space  descriptions  {A, B, C, D] that  have been  studied  exten 
sively throughout this book. For the more general case of (3.28) being equivalent to 
state-space  descriptions  of the  form  {A, B, C, D(q)},  refer  to the remarks  following 
Theorem  3.6. 
Controllability 
Recall  from  Section  3.2  of  Chapter  3  that  {A, B, C, D}  is  controllable  if  and 
only if 
1.  rank [sil  -  A,B]  =  n for  any st complex  number. 
2.  The Smith form  of  [si  -  A, B] is  [/, 0]. 
Now  if {A, B, C, D} in  (3.29) is controllable, then  in the equivalent  description 
[P, Q, R, W} given in (3.28), the Smith form  of  [P, Q] will be  [/,  0] and  rank  [P(si\ 
Qisi)]  =  I for any complex number Sj, in view of Theorem 3.2(ii). Notice that these 
conditions  are  precisely  the  conditions  for  P, Q  to  be  Ic polynomial  matrices  (see 
Theorem  2.5 in Section 7.2). These observations  give rise to the following  concept 
and result. 
DEFINITION  3.2.  The representation  {P, Q, R, W} given in (3.28) is said to be con 
trollable if its equivalent state-space representation {A, B, C, D} given in (3.29) is state 
controllable. 
THEOREM 3.4.  The following statements are equivalent: 
(i)  {P, e, R, W} is controllable. 
(ii)  The Smith form of [P, Q] is [/, 0]. 
(iii)  rank [P(si), Q(si)] = I for any complex number Sf. 
(iv)  P, garelc. 
Proof, Parts (ii) and (iii) follow  from the fact that (A, B) is controllable if and only if 
the Smith form of  [ql -  A, B] is  [/, 0], or equivalendy,  rank [siI -  A, B]  =  n for any 
complex number (see Section 3.2 of Chapter 3), and from Theorem 3.2(ii) in this section. 
In particular the Smith form  of [P, Q]  in (ii) is [/, 0] if  and only if the Smith form of 
[ql — A, B] is [/, 0], in view of Theorem 3.2(ii). This in turn is true if and only if (A, B) 
is controllable, which is equivalent to (i) by definition. So (ii) is true if and only if (i) is 
tme. Similarly, one can show that (iii) is true if and only if (i) is true. Part (iv) follows 
• 
easily from (ii) or (iii), in view of Theorem 2.4 in Section 7.2. 
Remarks 
1.  From the above results it follows that (A, B) is controllable if and only if ^/  -  A 
and B are Ic polynomial  matrices. 
562 
Linear Systems 
2.  If P, Q are not Ic, then the Smith form of [P, Q] is [A, 0], where A  =  diag  [6/]  ¥= 
I.  It  can  easily  be  shown  that  if  GL is  a geld  of  [P, Q]  =  GL[P, Q],  then  the 
Smith form of  GL  is A. The roots of the invariant polynomials €( of [P, Q] or of 
GL  are the uncontrollable eigenvalues of the  system. 
3.  Similar tests as the eigenvalue/eigenvector  tests of Subsection 3.4B of Chapter 
3 can also be developed for the representation {P, Q, R,  W}. 
4.  The  rPMFD,  {DR,  Im, NR}, is  clearly  controllable  since  DR  and  /  are  Ic. This 
fact justifies  the  alternative  notation  {Dc, /, Nc} for  an rPMFD  when  the  con 
trollability  of the representation  is emphasized;  here Dc  =  DR and A^^  =  NR 
are  viewed  as  matrices  of  an  internal  system  representation.  Note  that  the 
term rPMFD stresses the relation to the transfer function  H(s)  = 
NR(S)D^^(S), 
where NR and DR  are intrepreted as the numerator and denominator of a transfer 
function,  respectively. 
Observability 
Observability can be introduced in a manner completely analogous to controlla 
bility. This leads to the following  concept and result. 
DEFINITION 3.3.  The representation {P, Q, P, W} given in (3.28) is said to be observ 
able if its equivalent state-space representation {A, B, C, D} given in (3.29) is state ob 
servable. 
• 
THEOREM3.5.  The following statements are equivalent: 
(i)  {P, 2, P, W} is observable. 
(ii)  the Smith form of 
=  / for any complex number st. 
\P(Si) 
(iii)  rank 
[R(Si)\ 
(iv)  P, R are re. 
Proof, The proofs of these results are completely analogous to the proof of Theorem 3.4 
and are therefore omitted. 
• 
Remarks 
.  From the above results it follows  that (A, C) is observable if and only if ql  -  A 
and  C are re polynomial matrices. 
2.  If P, R are not re, then the Smith form of 
IS 
, where A  =  diag  [e^]  T^ /. 
It  can  easily  be  shown  that  if  GR is  a gcrd  of 
GR,  then  the  Smith 
form  of GL is A. The roots of the invariant polynomials  6/ of 
or of  GR  are 
the unobservable eigenvalues of the  system. 
3.  Similar tests as the eigenvalue/eigenvector  tests of Subsection 3.4B of Chapter 
3 can also be developed for the representation {P, Q, R,  W}. 
4.  The  IPMFD,  {DL,  NL, Ip},  is  clearly  observable  since  DL  and  Ip  are  re.  This 
fact justifies  the  alternative  notation  {Do, No, Ip} for  an  IPMFD  when  the ob 
servability  of the representation  is emphasized;  here Do  =  DR and A^^  =  NR 
are  viewed  as  matrices  of  an  internal  system  representation.  Note  that  the 
term IPMFD stresses the relation to the transfer  function  H(s)  = 
DI^(S)NL(S), 
where NL and DL are interpreted as the numerator and denominator of a transfer 
function,  respectively. 
Stability 
DEFINITION 3.4.  The representation {P,Q,R,W}  given in (3.28) is said to be asymp 
totically stable if  for  its  equivalent  state-space  representation  {A,B,C,D}  given  in 
(3.29) the equihbrium x = 0 of the free system i  = Ax is asymptotically stable. 
• 
THEOREM 3.6.  The representation  {P,Q,R,W}  is asymptotically  stable if and only 
if Re  ?ii  <0,i  = 1,..., n,  where Xi,i=  1,..., n,  are the roots of det P{s)\  the Xi are the 
eigenvalues or poles of the system. 
Proof, In view of Theorem 3.2(ii), det {si — A) = a det P{s)  for some nonzero a  ^ R. 
563 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
At this point it is of interest to briefly  discuss  controllability,  observability,  and 
stability  for  the more general  case, when the PMD in (3.28) is equivalent to a state-
space representation of the fonnx{t)  =Ax{t)  +Bu{t)^y{t)  =  Cx{t) +D{q)u{t)  instead 
of  (3.29).  First,  note  that  the  concepts  of  state  controllability  and  observability  in 
state-space descriptions  of the form  {A,5,C,D(^)}  are completely  analogous to the 
{A,5,C,D}  case.  Furthermore,  the  criteria  for  controllability  and  observability  are 
exactly  the  same  for  the  above  cases,  and  they  depend  only  on  (A,5)  and  {A^C), 
respectively.  In yiow  of this, it can be  shovv^n that Definitions  3.2  and  3.3 and Theo 
rems  3.4  and  3.5  for  controllability  and  observability,  respectively,  are valid for  the 
more general PMD. For  similar reasons. Definition  3.4 and Theorem  3.6 on asymp 
totic  stability  are  valid  for  the  general  PMD  (3.28).  Hovv^ever,  care  should  be  exer 
cised  vv^hen discussing  input-output  stability  of  a  system  {A,5,C,D(^)}  or  of  their 
equivalent  descriptions  of the form  (3.28), but this topic vv^ill not be addressed here. 
For an extended  discussion  of controllability,  observability,  and  stability  of  systems 
described by a general PMD (3.28), refer to Chapter 3 of  [9] and Chapter 6 of [33]. 
It is of interest to note that equivalent representations  not only have exactly  the 
same  eigenvalues,  but  also  the  same  invariant  zeros,  decoupling  zeros,  and  trans 
mission  zeros  (see Section  3.5  of Chapter  3 for  the definitions  of  zeros  and  also the 
discussion belovv^). These assertions follovv^ directly from  Theorem  3.2. 
Poles and zeros 
In  the  follovv^ing,  wt  vv^ill  find  it  useful  to  first  recall  the  definitions  of  poles 
and  zeros  introduced  in  Section  3.5  of  Chapter  3  and  to  shovv^ how  these  apply  to 
PMDs. To this end, consider the representation in (3.28) vv^ith transfer function  matrix 
H{s)=R{s)p-\s)Q{s)+W{s). 
Let the Smith-McMillan form  of H{s)  be given by 
SMH{S)  = 
0 
0 
(3.30) 
v^here  A(^)  =  diag  — —,  • • •  , —— 
\l/r{s) 
1,  and  \i/i^i{s)  divides  \l/i{s)J • 
\\l/l{s) 
1,..., r — 1, and  1/A/+1 (s) divides  i/A/(^), / =  1,..., r —  1 [see (5.3) in Chapter  3]. Then 
the poles  ofH(s)  are the roots of the characteristic  or pole polynomial  PH{S)  ofH(s) 
defined  as 
,r  =  rank  H{s),ei{s)  divides  e/+i(^),/ 
(3.31) 
Note  that  PH{S)  is  the  monic  least  common  denominator  of  all  nonzero  minors  of 
H{s). 
=  XI/i{s)---XI/r{s). 
PH{s) 
564 
Linear Systems 
It is straightforward  to show that 
{poles oiH(s)}  C  {roots of  detP(s)}. 
(3.32) 
The  roots  of  det P  are the  eigenvalues  or  the poles  of  the  system  {P, Q, R, W}  and 
are equal to the eigenvalues  of A in any equivalent  state-space representation {A, B, 
C, D]. Relation  (3.32) becomes an equality when the system is controllable and ob 
servable, since in this case the poles of//are  exactly those eigenvalues of the system 
that are both controllable and  observable. 
Comidtr  iht  system matrix or RosenbrockMatrix  of \htvepr:QS&rA&iion{P,  Q, R,  W}, 
Sis)  = 
-Ris) 
Q(s) 
Wis) 
(3.33) 
and an equivalent state-space representation {A, B, C, D} given in (3.29). In view of 
(3.5), we have 
M 
X 
0 
I p^ 
h-i 
0 
0 
P 
0 
-R 
0 
Q 
w 
h-n 
0 
0 
si 
-A 
0 
-C 
:  o] 
\N 
:  B 
[0 
:  D\ 
-Y 
^m 
(3.34) 
where M,N  E. R[s^^^^  are unimodular  and  k  >  max {deg \P\, n) (see (3.5)). 
The zeros of {P, Q, R, W} can now be defined  in a manner completely  analogous 
to the way they were defined for state-space representations. Following the develop 
ment in Section 3.5, let fc =  nandr  =  rank 
\sl  -  A  B~ 
D 
-C 
, where n 
r  <  min(p + 
n,m-\-  n). Consider all those rth-order nonzero minors of Se{s)  = 
\h-i 
[  0 
0 
S{s) 
that 
are formed  by taking  the first n rows  and n columns  of Se{s). The zero  polynomial 
of the system  {P, Q, R, W}, Zs(s), is defined  as the monic gcd of all those minors. The 
roots  of  Zs(s) are  the zeros  of  the  system  {P, Q, R, W}.  The  reader  is  encouraged  to 
show that this definition  is consistent with the definitions  given in Section 3.5. 
The invariant  zeros  of the system  are the roots of the invariant zero  polynomial 
that is the product  of all the invariant factors  of S{s).  The 
input-decoupling/output-
decoupling  and  the  input-output  decoupling  zeros  of  {P, Q, R, W}  can  be  defined 
in  a manner  completely  analogous  to  the  state-space  case.  For  example,  the  roots 
of the product  of all invariant  factors  of  [P(s), Q(s)] are the input-decoupling  zeros 
of the system; they  are also the uncontrollable  eigenvalues  of the system. Note that 
the  input-decoupling  zeros  are  the  roots  of  detGiis),  where  GL{S) is  a  geld  of  all 
the columns of {P{s), Q{s)\  =  GL(S)[P(S),  Q(S)].  Similar results hold for the output-
decoupling zeros. 
The zeros  ofH(s),  also called the transmission  zeros  of the system,  are  defined 
as the roots of the zero polynomial  ofH(s), 
ZH(S)  = 
ei{s)...6r(s\ 
(3.35) 
where  the  6/  are  the  numerator  polynomials  in  the  Smith-McMillan  form  of  H(s) 
given  in  (3.30). When  {P, Q, R, W}  is  controllable  and  observable  the  zeros  of  the 
system, the invariant zeros, and the transmission  zeros coincide. 
565 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Consider  the  representation  DRZR  =  u,y  =  NRZR  with  DR  G  R[S]^^^ 
and 
and  notice  that  in  this  case  the  Rosenbrock  Matrix  (3.33)  can  be 
NR  E  R[sy^^ 
reduced via elementary  column operations to the  form 
0  /] 
r^R  oj 
\0 
[l  0 
r  / 
[-DR 
'  DR 
_-NR 
0] 
I\ 
I] 
0\ 
I 
"ro  /"" "
[/ 0 
7 
0 
0 
-NR 
In  view  of  the  fact  that  the  invariant  factors  of  S  do  not  change  under  elementary 
matrix operations, it is clear that the nonunity invariant factors  of S are the nonunity 
invariant factors of NR.  Therefore, the invariant zero polynomial  of the system  equals 
the  product  of  all  invariant  factors  of  NR  and  its  roots  are  the  invariant  zeros  of 
the  system.  Note  that  when  rankNR  =  p  ^  m,  the  invariant  zeros  of  the  system 
are the roots  of  detGi,  where  GL is  the  geld  of  all  the  columns  of NR,  i.e.,  NR  = 
GLNR.  When A^^^,  DR  are re, the system is controllable and observable. In this case it 
can be shown that the zeros  ofH  {=  NRD^^), 
also called the transmission  zeros of 
the system,  are equal to the  invariant  zeros  (and to the system  zeros  of  {DR,  I, NR}) 
and  can  be  determined  from  NR.  In  fact  the  zero  polynomial  of  the  system,  Zs(s), 
equals  ZH(S),  the zero polynomial  of H,  which  equals  ei(s)... 
er(s),  the product of 
the invariant factor  of NR, i.e.. 
The pole polynomial of H(s)  is 
Zs(s)  =  ZH(S) = 
ei(s)...er(s). 
PH(S)  = 
kdetDR(s), 
where  k  G  R. 
(3.36) 
(3.37) 
Realization theory and  algorithms 
A  representation  {P,  Q, R, W}  is  a realization  of  a rational  function  H{s)  if  the 
transfer  function  of {P, Q, R, W)  is H{s),  i.e., if 
R{s)p-\s)Q{s) 
+  Vi^(^)  =  H(s). 
(3.38) 
The realization  theory  for  PMDs  is analogous  to the theory  for  state-space  descrip 
tions, developed  in Chapter  5. Results  concerning  existence  and minimality  can  be 
developed  in  the  obvious  way,  using  the  results  on  equivalence  of  representations 
developed  in  Subsection  7.3A  and  the  above results  on controllability  and  observ 
ability.  The  following  theorems  provide  results  that  correspond  to  Theorems  3.9, 
3.10,  and  3.11  of  Section  5.3  of  Chapter  5.  The  reader  is  encouraged  to  give  full 
proofs  of these results. 
THEOREM  3.7.  A realization  {P, Q, R, W} of H(s)  of order  n  = deg |P| is minimal 
(irreducible, of least order) if and only if it is both controllable and observable. 
Proof  The proof is left as an exercise. 
THEOREM 3.8.  Let{P, Q, R, W}md{P_, Q, R, W} be realizations of//(^). If {P, Q, R, W} 
is a minimal realization, then {P, g, R, W} is also a minimal realization if and only if the 
two realizations are equivalent. 
Proof. The proof is left as an exercise. 
• 
THEOREM 3.9.  Let {P, Q, R, W} be a minimal realization of H(s). Then the character 
istic polynomial of H(s),  PH{S),  is equal to detP(s) within a multiplication by a nonzero 
real number, i.Q., PH(S)  =  kdet P(s). Therefore, the McMillan degree of//(^)  equals the 
order of any minimal realization. 
• 
566 
Linear Svstems 
Proof, To prove this result, refer to the proof of Theorem 3.11 in Chapter 5 and use the 
results on equivalence given in Subsection 7.3A. 
• 
Realization  algorithms 
It is rather straightforward  to derive a realization of H in PMD form. In fact real 
izations in right (left)  PMFD form were derived in Chapter 5 as a step toward deter 
mining a state-space realization in controller (observer) form  (see Subsections 5.4B 
and  5.4D).  However,  these  realizations,  of the  form  {DR,  Im, NR} and {DL,  Ni, Ip], 
are typically not of minimal order, i.e., they are not controllable and observable. This 
implies that the controllable realization {DR,  Im, NR}, for example, is not observable, 
i.e., DR, NR are not re. Similarly, the observable realization  {DL,  NL, Ip} is not con 
trollable, i.e., DL, NL are not Ic. To obtain a minimal realization, a gcrd must be ex 
tracted from  DR,  NR, and similarly, a geld must be extracted from  DL,  NL. This leads 
to the following  realization algorithm that results in a minimal realization {D, Im, N} 
ofH.  A minimal realization of the form {D, N, Ip} is obtained in an analogous  (dual) 
manner. 
Consider H(s)  =  [nij(s)/dij(s)],  i  =  I,...,  p, j  =  1,...,  m, and let lj(s) be the 
(monic)  least  common  denominator  of all entries  in the jth column  of H(s).  Note 
that lj(s) is the (monic) least degree polynomial divisible by all dij(s),  i  =  1,..., p. 
Then His) can be written as 
H{s)  =  NR(S)DR\S), 
(3.39) 
where  NR(S)  =  [nij(s)]  and DR(S)  =  diag(li(s),..., 
nij{s)ldij{s)  for /  =  I,...,  p, and all j  =  I,...,  m. Now 
lm(s)). Note  that  nij/lj(s)  = 
DR(q)ZR(t)  =  u(t), 
y(t)  = NR(q)zR(t) 
(3.40) 
is a controllable  realization  of H(s). If DR, NR are re, it is observable  as well, and 
therefore,  minimal. If DR and NR are not re, let GR be a gcrd and let D  =  DRG^^ 
andA^  =  NRG^\  Thm 
D(q)z(t)  -  u(t), 
y(t)  = N(q)z(t) 
(3.41) 
is  a controllable  and observable,  and therefore,  minimal  realization  of H(s)  since 
D, I and D, N are Ic and re polynomial matrix pairs, respectively. Note that ND~ ^ = 
(NRG^'XDRG^')-' 
=  NRD-^'  =  H. 
=  (NRG^'XGRD-^') 
There is a dual algorithm which extracts an IPMFD resulting in 
H{s)  =  DI\S)NL{S), 
(3.42) 
which corresponds to an observable realization of H{s),  given by 
DL(q)ZL(t)  = NL(qMt), 
(3.43) 
The details of this procedure  are completely  analogous to the procedure  that led to 
(3.39). If DL,  NL  are not Ic, let GL be a geld and let D  -  G^^DL  and N  =  G^^NL. 
Then  a controllable  and observable,  and therefore,  minimal,  realization  of H(s) is 
given by 
y(t)  = ZL(t\ 
D{q)z(t)  = N(qMt), 
(3.44) 
In  Subsection  5.4B,  a controllable  state-space  realization  that is equivalent to 
(3.40)  was obtained  first  using  the controllable  version  of the Structure  Theorem. 
Next, the unobservable part of this state-space realization  was separated and a con-
y(t)  = z(t\ 
trollable,  observable,  and  minimal  realization  was  extracted  (see  Example  4.3  in 
Subsection  5.4B).  This  minimal  state-space  realization  is of course  equivalent  to  the 
realization  (3.41),  which  is  in  PMFD  form.  It  is  possible  to  extract  an  equivalent 
minimal  state-space realization  directly  from  (3.41). However,  to use the  convenient 
Structure  Theorem,  typically  D  has  to be reduced  first  to  a column  proper  form,  i.e., 
(3.41)  must  be  reduced  to 
D{q)z{t)  =  u{t), 
y{t)  =  N(q)z(t\ 
(3.45) 
where  D  =  DU  is  column  proper,  N  =  NU,  and  f/  is  a unimodular  matrix.  Analo 
gous  results  are  valid  for  PMFD  and  realizations  (3.42)  through  (3.44). 
The  following  example  illustrates  the realization  algorithms. 
567 
CHAPTER 7: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  3.2.  We wish to derive  a minimal realization  for  H(s) 
s^  +  1  ^ +  1 
' 
s^ 
c3 
s 
Note that this is the same H(s)  as in Example 4.3 in Section 5.4B, where minimal  state 
space realizations were derived. The reader is encouraged to compare those results with 
the  realizations  derived  below.  We  shall  begin  with  a controllable  realization.  In  view 
of  (3.39) 
s^Ji 
and  H  =  NRD-J, 
[s^  +  1, ^  +  1] 
"s^  0""  ^ "
n 
c3 
.  Therefore, 
J^RZR  =  u  and  y  =  NRZR  constitute  a  controllable  realization.  This  realization  is  not 
observable  since  rank 
DR(S) 
NR(S), 
=  rank 
not re. 
ro 
0 
_i 
01 
0 
1. 
1  <  m  =  2, i.e.,  DR  and  NR  are 
Another way of determining that DR and NR are not re would have been to observe 
that deg det D(s)  =  5  =  order of the realization {DR,  /, NR}. NOW the McMillan  degree 
of i/, which is easily derived in the present case, is 3. Therefore, the order of any minimal 
realization  for  this  example  is  3. Since  {DR,  I, NR} is  of  order  5  and  is  controllable,  it 
cannot be observable, i.e., DR and NR cannot be re. 
We  shall  now  extract  a  gcrd  from  DR  and  NR,  using  the  procedure  described  in 
Subsection  7.2D. We have 
DR 
NR, 
0 
c3 
0 
S^  +  1 
5 +1 
S+  1 
c3 
S 
0 
Li 
1 
0 
0 
0 
c3 
5-
5 +  1. 
s+V 
s^ 
s^  J 
—> 
5 +1 
"""1 "
5^ 
.0 
0 
5^ 
"""1  5 +  r "
0 
.0 
s^ 
0  J 
Therefore,  GR  = 
1 
0 
5 +  1 
52 
NRG^^,  using  DR  = 
0 
_0 
5^ 
1 , 5+  1]  =  [5^ +  1,  - ( 5+  1)] 
is  a  gcrd.  We  now  determine  D  =  DRGJ^^  and  A^  = 
52 
0 
- (5  +  1) 
5 
1 
0 
5 +1 
s' 
=  DGR  and  NR  =  [s^ + 
1 
0 
S+\ 
s' 
NGR,  and we verify  that they are re. Then 
{DR,I,NR} 
= 
^ 
- ( ^ + 1) 
1  0 
0  1 
,[q^  + 
h-(q+\)] 
is a minimal realization  of  H(s). 
To  determine  a  minimal  state-space  realization  from  Dz  =  u  and  y  =  Nz  using 
equivalence  of  representations,  if  so  desired,  we  notice  that  D  is  already  in  column 
proper  form.  Using  the  Structure  Theorem,  and  the  notation  used  in  Examples  4.3 
568 
Linear  Systems 
and 4.5  in  Subsection  5.4B,  we  obtain  D(s) 
-(s  +  1) 
s 
=  DhA(s)  +  DiS(s)  = 
1 
0 
-1 
1 
s^  0 
0 
s 
+ 
0 
I u  u  — J  11 
0  0 
0 -1 
0 
.  Therefore,  B^  =  D,^  = 
1  1 
0  1 
and Am  = 
-Du'Di  = 
0  0  1 
0  0  0 
Also,  Dc  =  lim,^oc//W  =  [1,0]  and  A^(^)  =  [s^ +  1, -{s  + 
1)]  =  CcS(s)  +  DcD(s)  =  [1,0,0] 
+  [1,0] 
-(s+l) 
s 
Therefore,  a  mini-
1  0 
s  0 
0  1 
"""1  0^ "
s  0 
.0 
IJ 
mal state-space realization  of H(s)  is given by 
{Ac, Be, Cc, Dc}  = 
"""0  1  0"" "
, 
0  0  1 
.0  0  Oj 
"""0  0"" "
1  1 
.0  1_ 
, [ 1 , 0 , 0 ] , [ 1 , 0 ]^ 
Note that this realization  is precisely  the minimal realization  derived in Example 4.3 in 
Subsection  5.4B. This will not occur in general, as can be seen if for example a slightly 
different  GR is  used.  The  realization  {Ac, Be, Cc, Dc} determined  here  is  in  controller 
form,  since D^ was an upper triangular matrix with ones on the diagonal. In general, Dh 
will just  be nonsingular,  since  D(s)  will be column  proper,  and  therefore,  the  resulting 
controllable realization  will not be in controller form,  since Be will not be of the appro 
priate form. This point was also discussed in Subsection 5.4B and illustrated in Example 
4.5 in that  subsection. 
Alternatively,  given  //,  we  shall  first  derive  an  observable  realization.  In  view  of 
(3.42), 
H  =  DI^NL  =  (s^y^[s(s^  +  1),^  +  1]. 
Here  Di^(q) and  Niiq)  are  Ic  and  therefore  D(q)z(t)  =  N(q)u(t)  and  y(t)  =  z(t)  with 
D(q)  =  Di{q)  and A^(^)  =  Niiq)  is controllable and observable, and is therefore, a min 
imal realization. Note that the order of this realization is deg det DL{S)  =  3, which equals 
the McMillan degree ofH{s).  In Example 4.3 in Subsection  5.4B  a minimal  state-space 
realization  in observer form  was derived from  D{q)  and A^(^). 
• 
C.  Interconnected  Systems 
Interconnected  systems,  connected  in  parallel,  in  series,  and  in  feedback  configura 
tions,  are  studied  in  this  subsection.  Polynomial  matrix  and  transfer  function  matrix 
descriptions  of  interconnected  systems  are  derived,  and  controllability,  observabil 
ity, and  stability  questions  are addressed.  It is shown  that particular  interconnections 
may  introduce  uncontrollable,  unobservable,  or unstable  modes  into  a  system.  Feed 
back  configurations,  as  well  as  series  interconnections,  are  of  particular  importance 
in the  control  of  systems.  Feedback  control  systems  are  studied  at length  in  the  next 
section. 
Systems  connected  in  parallel 
Consider  systems  S\  and  ^2  connected  in  parallel  as  shown  in  Fig.  7.1  and  let 
Pi{q)ziit)  =  Qi(q)um 
yi(t)  =  Ri(q)zi(t) 
+  Wi(q)ui(t) 
(3.46) 
and 
P2(q)z2(t)  =  Q2(q)u2(t\ 
y2(t)  =  R2(q)z2it)  +  ^ 2 ( ^ ) ^ 2 (0 
(3.47) 
be  representations  (PMDs)  for  S]  and  ^2, respectively.  Since  u(t)  =  u\{t)  =  U2(t) 
569 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
FIGURE 7.1. 
Systems connected in parallel 
and y(t)  =  yi(t)  +  y2(t),  the overall system description is given by 
Pi(q) 
0 
0 
Piiq) 
Zi(q) 
Z2(q)\ 
Qi(q) 
Qiiq). 
u(t), 
y(t)  = 
[R,(q),R2(q)] 
zi(t) 
ziit) 
+  [WM)  + 
^2mu{t\ 
(3.48) 
If the systems ^i  and S2 are described by the state-space representations i/  =  Atxi  + 
BiUu yi  =  CiXi +  DiUu i  =  1, 2, then  the overall  system  state-space  description  is 
given by 
i i]  _ 
X2\ 
01  r^i 
\AI 
[ 0  A2J [^2. 
Bi 
Bi 
y  =  [Ci,  C2] 
+  [Di  -h  D2]u. 
(3.49) 
If Hi(s),  H2(s) are the transfer  function  matrices of 5i  and ^2, respectively, then the 
overall  transfer  function  can  be  found  from  y(s)  =  yi(s)  +  y2(s)  =  Hi(s)ui(s)  -h 
H2(s)u2(s)  =  [Hi(s)  +  H2(s)]u(s)toht 
H(s)  =  Hi(s)  +  H2(s\ 
(3.50) 
Now if both Hi(s)  and H2(s)  are proper, then H(s)  is also proper. 
The  stability,  controllability,  and  observability  of  the  overall  system  S  repre 
sented by Pz  =  Qu, y  =  Rz+  Wu  in (3.48) will now be examined briefly.  In view 
of  |P|  =  |Pi| IP2I it is clear that the overall  system is internally  stable if and only if 
each of the systems 5*1  and ^2 is internally  stable. Also, if both Si  and S2 are BIBO 
stable, i.e., all poles in Hi  and in H2 have strictly negative real parts, then the overall 
system is also BIBO stable. The converse is also true, i.e., if the overall system S is 
BIBO  stable, then  so are Si  and S2. This can be seen from  Fig. 7.1  since if,  say, ^i 
were  not BIBO  stable,  then  neither  would  S.  Next,  this  result  is  also  shown  using 
alternative  arguments. 
All uncontrollable  or unobservable  eigenvalues  of Si  and ^2 will be uncontrol 
lable or unobservable eigenvalues of the overall system S. To see this, consider 
Pi 
0 
0 
Qi 
P2  Q2 
and  let  Gi,  G2 be  gelds  of  [Pi,  Qi\  and  [P2, Q2],  respectively.  Then 
(3.51) 
0 
Gi 
0  G2  IS an 
570 
Linear Systems 
Id of the matrix (rows) in (3.51), i.e., the uncontrollable eigenvalues of 5i  and ^2 will 
be uncontrollable eigenvalues  of the overall system. Similarly, it can be shown  that 
the unobservable  eigenvalues  of Si  and 52 will be unobservable eigenvalues  of the 
overall  system.  Note  that  the  overall  system  S  may  have  additional  uncontrollable 
and  unobservable  eigenvalues,  as  is  now  shown.  It is  easier  to  show  this  when  5i 
and 52 are controllable and observable. Assume then that 
DMziit) 
=  uiit), 
yiit)  =  Ni(q)zi{t) 
and 
D2iq)Z2it)  = U2(t), 
yiit)  =  N2(q)Z2(t) 
(3.52) 
(3.53) 
are descriptions for 5i  and 52,  with//i (5)  =  Ni(s)D^^^(s)andH2(s)  =  N2(s)D2^(s). 
"mq]""""""""  and  Ni(q)","N2{q)  e  R[qV'"""".  The  overall  system  is "
Let  Diiq),D2iq) 
then described by 
Di(q) 
0 
0 
D2iq) 
zi(0 
Z2(t) 
uitx 
y{t) =  miqiN2m zi(t) 
Z2(t), 
(3.54) 
Note  that  0 
0 
£»2 
/ 
10 
[0 
0 
/ 
-D2 
0] 
0 
l\ 
Di 
0 
-D2 
0 
Now  if  for  some  com-
plex  value  A rank[Di(X),  -D2(A)]  <  m,  i.e.,  there  are  fewer  than  m  linearly  in 
<  2m, 
dependent  columns  in  [A (A),-D2(A)],  then  ran^t  P^^^^^ 
which  impHes  that  A is  an  uncontrollable  eigenvalue  of  the  overall  system.  If  G 
is  a  geld  of  [Di,  -D2],  then  A is  a  root  of  detG  and  it  is  an  eigenvalue  that  is 
common  in  both  systems  Si  and  S2.  Note  that  the  uncontrollable  eigenvalues  in 
NiD^^  +  A^2^2 ^  =  (^1  +  A^2^2 ^^O^F^  =  (A^i  + 
G  cancel mH  =  Hi+H2= 
Completely  analogous 
A^2^2 ^ i ) ^r 
results  can  be  shown  concerning  the  unobservable  eigenvalues  by  considering  the 
representations 
'  where  D^^Di  =  (GD2)~^GDi  =  D^'D 
-^2(A) 
/„ 
Di(q)zi(t)  =  Ni(q)ui(tl 
yi(t)  =  Zi(t) 
and 
D2(q)z2(t)  =  N2(q)u2(tl 
y2(t)  -  Z2(t) 
(3.55) 
(3.56) 
with Hi(s)  == D^^(s)Ni(s)  and H2(s)  =  D2^(s)N2(s),  The unobservable  eigenval 
ues cancel in Di(s)D2^(s)  (show this). 
In view  of the above it can be  seen that if all the poles of H  have negative real 
parts, then all the poles of both Hi  and H2  also have negative real parts, since possible 
additional  poles of Hi  and H2 are in the  same locations  as  some of the poles of  H. 
Therefore,  if S is BIBO stable so are both 5i  and  ^^2. 
Systems connected in series (or in cascade or in tandem) 
Consider  systems ^i  and  S2  connected in series, as shown in Fig. 7.2 and let 
Pi(q)zi(t)  =  Qi(q)ui(t), 
yi(t)  =  Ri(q)zi(t)  +  Wi(q)ui(t) 
(3.57) 
be a polynomial matrix representation for Si  and 
P2(q)z2(t)  -  22(^)^2(0. 
(3.58) 
be a representation for  ^2.  Here  U2(t)  =  yi(t).  To derive the overall system descrip 
tion,  consider  ^2^2  =  Q2U2 =  G2J1  =  62(^1^1  +  Wiui)  and  Pizi  =  Qiui  and 
also  y2  =  R2Z2 +  W2U2 =  R2Z2 +  W2yi  =  R2Z2 +  ^2(^1^1  +  WiwOand  ji  = 
yiit)  =  R2(q)z2(t)  +  ^2(^)^2(0 
571 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
^1 
Vi 
Si 
t/2 
^2 
1  ^^ 
FIGURE 7.2. 
Systems connected in series 
RiZ\  +  WiMl. Then 
Pi 
-QiRi 
0 
Pi 
yi  =  WtPx,  /?2] 
(3.59) 
If an external input r2 is introduced as in Fig. 7.3, that is, M2  =  Ji  + ''2» then P2^2  = 
22^2  =  Qi{y\  + ^2)  =  QiiRiZi  + Wi^O + 22^2 and y2  =  R2Z2 +  ^2^2  =  ^^2^2 + 
W2(yi  +  r2)  =  /^2Z2 +  ^2(^1^1  +  WiUi)  +  ^2^2. 
In this case a more complete description of the two systems in series with inputs 
wi, r2 and outputs y2, yi  is given by 
Pi 
0 
-22^1  P2 
\zi 
[Z2_ 
\  «2i 
[22^1 
\yi 
[y2. 
= 
Ri 
W2R1 
0] 
22 J 
0] 
Ril 
lui 
U2. 
\zi] 
U2J 
+ 
Wi 
0 
\W2WI  W2 
(3.60) 
If  the  systems  Si, S2 are described  by  the  state-space  representations  xt  =  Atxt  4-
CiUi, yi  =  CiXi + DiUi, i  =  1, 2, then it can be shown similarly that the overall sys 
tem state-space description is given by 
Xi 
hi 
J 2. 
= 
= 
B2C1 
Ci 
D2C1 
0] 
A2J 
0] 
C2J 
Ixi 
[X2_ 
Ixi 
[X2_ 
+ 
+ 
Bi 
B2D1 
'  D, 
P2D1 
0] 
Bil 
"0"" "
JO2J 
«il 
72 J 
\ui 
U2. 
(3.61) 
If Hi {s), H2(s) are the transfer function matrices of 5i and ^2, then the overall transfer 
function  };2(^)  =  H(s)ui(s)is 
His)  =  H2(s)Hi(s). 
(3.62) 
It can be  shown that if both Hi  and H2 are proper,  then H  is also proper. Note  that 
poles of Hi  and H2 may  cancel  in the product H2H1, and  any cancellation  implies 
FIGURE 7.3. 
Systems connected in series 
572 
Linear Systems 
that there are uncontrollable/unobservable  eigenvalues in the overall system internal 
description. This is discussed further  next. 
The stability, controllability, and observability of the overall system S described 
by  Pz  =  Qu,  y  =  Rz+  Wu,  and given in (3.60) will now be examined. In view of 
I P|  =  I Pi 11P21 it is clear that the overall system is internally stable if and only if each 
of the  subsystems  Si  and ^2 is stable. If both 5*1  and S2 are BIBO  stable, i.e., if  all 
poles in Hi  and H2 have  strictly negative real parts, then the overall  system is also 
BIBO stable. The converse is not necessarily true since cancellations may take place 
in the product H2H1, i.e., the unstable poles of Hi  and H2 may cancel in H2H1  =  H, 
thus leading to a BIBO stable system where Si  and/or ^2 might not be BIBO stable. 
Concerning  controllability  and observabiHty  of  (3.60), we make  several  obser 
vations: 
1.  All eigenvalues of Pi  are uncontrollable from  r2 and all eigenvalues  of P2 are 
unobservable from  yi.  This is of course as expected,  since Fig. 7.3 reveals that 
the input  r2 does  not  affect  system  5*1  at  all,  and  observation  of  the  output  yi 
will not reveal any information  about system 5*2. 
2.  All  uncontrollable  eigenvalues  of  ^i  and  5*2 are  uncontrollable  from  ui.  This 
is  true  because  any  geld  of  [Pi, Qi]  and  any  geld  of  [P2, Q2] are  elds  of 
~  Pi 
-Q2R1 
Finally,  all  unobservable  eigenvalues  of  Si  and  ^2  are  unobservable  from 
and  any  gcrd  of  P2  are  crds  of 
y2.  This  is  true  because  any  gcrd  of 
0 
Qi  ~ 
P2  Q2W1 
(show this). 
Pi 
^1 
Pl 
-Q2RI 
W2RI 
0 
P2 
R2 
(show this). 
It  should  be  noted  that  other  uncontrollable  and/or  unobservable  eigenvalues 
may exist. These correspond to poles of Hi  and Hj  cancelling in the product H2H1 
and can be found from representation (3.60) using, say, the eigenvalue tests for con 
trollability  and  observability.  It  is  of  interest  to determine  these  additional  uncon 
trollable  and  unobservable  eigenvalues  directly  from  the  PMFD  of  Si  and  52. To 
simplify  the  analysis,  we first assume  that  both Si  and  52 are controllable  and ob 
servable. Let 
Di(q)zi(t)  =  uiit), 
yiit)  =  Ni(q)zi(t) 
(3.63) 
be a description for 5i, with Hi{s)  =  Ni{s)D]^^{s),  and let 
D2(q)Z2it)  =  U2{t), 
y2(t)  =  N2iq)Z2(t) 
(3.64) 
be a description  for 52," with H2(s)  =  N2is)D2\s).  Let Di(q)  £  Riqr""""""",  Ni(q)  G 
"Rlqy'""""  and Diiq)  E  R[q]P''P", N2(q)  G RlqY^'P  and recall that yi  and  U2  have the 
same dimensions  (yi  =  U2).  In this case description  (3.60)  becomes 
0 
Di 
-A^i  D2 
I  0 
/ 
0 
0 
N2 
0 
(3.65) 
The uncontrollable  eigenvalues  from  ui  are the roots  of  a geld of 
0 
/ 
D2  0 
Using  elementary  column  operations  corresponding  to postmultiplication  by  a uni-
Di 
[-Ni 
modular  matrix, this matrix is reduced  to 
0 
-Ni 
3stmultip] 
0 
"/"" "
£>2  0 
, a geld of which is given 
by 
/ 
0 
0 
GL\ 
,  where  GL is  a geld  of  [-A/^i, Di]-  Thus,  all  the  uncontrollable  eigen-
values of the overall system are the roots of the determinant of a geld of [-iVi,  Di]. 
Note that these are poles of//2  cancelling in the product H2H\  =  N2D2^N\D^^, 
in 
D2^N\,  or equivalently, in  H2N\. 
The unobservable eigenvalues may be obtained  similarly, using the  representa 
tions 
and 
DM)zi{t)  =  Ni{q)ui(t), 
yxit)  =  zi(t) 
D2(q)Z2(t)  =  N2{q)u2{t), 
yiit)  =  ziit) 
(3.66) 
(3.67) 
573 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
with  Hi(s)  =  Dl\s)Ni(s) 
in this  case 
and  H2(s) 
D2 ^(s)N2(s)- Description  (3.60)  becomes 
Di 
-N2 
0 
Dil 
\zi 
U2. 
Ni 
N2 
Ol 
A^2j 
\ui 
V2_  ' 
y\ 
J2. 
/  Ol 
0 
l\ 
\z\ 
L^2 
(3.68) 
The  unobservable  eigenvalues  from  y2 are the roots  of  a gcrd of 
Dx 
-N2 
0 
0 
62 
/ 
. Us-
ing elementary row operations, corresponding  to premultiplication  by a unimodular 
matrix,  this  matrix  is reduced  to 
"Dx  0"" "
-N2  0 
0 
/ 
, a gcrd  of  which  is given  by 
GR 
0 
0 
/ 
where  GR  is a gcrd of  Dx 
-N2 
. Thus, the unobservable eigenvalues of the overall sys-
tem are the roots of the determinant of a gcrd of 
Dx 
-N2 
. Note that these are poles of 
Hx cancelling  in the product //2//1  =  D2^N2D\^Nx-> in N2D^^,  or equivalently,  in 
NiHx. 
Systems connected in feedback  configuration 
Consider  systems ^i  and ^2 connected  in a feedback  configuration  as shown in 
Fig. 7.4A,  or equivalently,  as in Fig. 7.4B. 
Let 
Pi(q)zi(t)  =  Qx(q)ux(t), 
yx(t)  =  Rx(q)zx(t)  +  Wx(q)ux(t) 
(3.69) 
and 
P2(q)z2(t)  =  62(^)^2(0, 
J2(0  =  R2(q)z2(t)  +  ^2(^)^2(0 
(3.70) 
be polynomial matrix representations  of 5*1  and ^2, respectively.  Since 
ui(t)  -  y2(t)  + rx(t), 
U2(t) =  yi(t)  + r2(tl 
(3.71) 
(3.72) 
where rx and r2 are external inputs, the dimensions of the vector inputs and outputs, 
ux and  j2  and  also  U2  and  j i,  must be the  same, i.e.,  ux, y2  ^  R^  and  U2, yx  ^  ^^• 
To derive the overall system description, we consider yx  =  i^iZi  +  WxUx =  ^iZi  + 
^1(3^2 +  n)  =  Rxzx  +  Wx(R2Z2  +  W2U2) +  Wxrx  =  RxZx +  WXR2Z2  +  WxW2(yx  + 
^2) +  Wxrx, from  which we obtain 
(/  -  WxW2)yx  =  R\zi^  WxR2Z2  +  Win  +  WxW2r2. 
(3.73) 
574 
Linear  Systems 
''^ 
• >! 
-^ 
^1 
Si 
yi 
S2 
.,  J 
L ( JH 
'^  FIGURE  7.4A 
Feedback  configuration 
^1 
'L.. -^0^ 
+ 
S2 
+ 
-^H(>- Sl 
yi 
FIGURE  7.4B 
Feedback  configuration 
Similarly,  we have  yi  =  R2Z2 +  W2U2  =  R2Z2 +  ^2(^1  +  ^2)  =  R2Z2 +  ^2(^1^1  + 
Wiui)  +  W2r2  =  R2Z2 +  W2RiZ\  +  ^2^1(3^2  +  n)  +  ^ 2 ^ 2.  from  which  we  obtain 
(/  -  W2Wi)y2  =  R2Z2  +  W2R1Z1  +  W2Wiri  +  W2r2. 
(3.74) 
LEMMA  3.10.  det(I  -  W1W2)  =  det(I  -  W2W1). 
=  det  1 
Proof,  det(I  -  W1W2)  =  det \ 
I 
.0 
=  det  1 
I 
-Wx 
0 
I-WxW2_ 
) 
r / 
01 
l\ 
r / 
=  det  { 
=  det 
-W2I 
I 
/  J 
0 
I  --W2WI 
0 
-W2 
\i 
W2I / J 
W2] 
IJ 
r  / 
[-Wi 
0' 
/. 
"0"" "
/. 
=  det(I 
-W2W1) 
Now  assume  that  det(I 
-  W1W2)  =  det(I 
-  W2W1)  ¥^  0.  If  Mi  =  (/ 
-
^ 1 ^ 2 ) '^  and  M2  =  {I  -  ^ 2 ^ 1 ) -^  then  (3.73)  and  (3.74)  imply  that  yi  = 
[MiRi,MiWiR2] 
[M2W2Wi,M2W2\ 
Z\ 
Z2 
r\ 
r2 
+ 
[MiWi,MiWiW2] 
a n d j2  =  [M21^2^!.  ^ 2 ^ 2] 
+ 
.  Now  Piz\  =  Q\ux  =  Qi(y2  +  n)  and  P2Z2  =  Q2U2  = 
62(^1  +  ^2), where  y\  and  j2  are  as  above.  Then  the  closed  loop  is  described  by 
Pi  -  Q1M2W2RX 
-Q1M2R2 
-Q2M1R1 
P2  -  Q2M1W1R2 
Q1M2 
Q2M1W1 
Q1M2W2 
Q2M1 
MiRi 
M2W2R1 
M1W1R2 
M2R2 
+  MxWi 
M2W2W1 
M1W1W2 
M2W2 
(3.75) 
"where  the  identity  /  +  (/  -  W i ^ 2 ) '^ V^i^2  =  (/  -  ^ 1 ^ 2 ) ""^  was  used "
At  this  point  it  is  of  interest  to  point  out  that  when  Wi  =  0,W2  =  0,  then  the 
575 
closed-loop  description  (3.75)  is  simplified  to  the  PMD 
^1 
- 6 2 ^1 
-QxRi] 
\ 
Pi 
Ui 
1.^2. 
Qi 
[o 
0 
Qil 
n 
['•2.  ^ 
y\ 
J 2. 
Ri 
[o 
0 
R2\ 
Ui 
[zi 
(3.76) 
Note  that  given  system  descriptions  (3.69)  and  (3.70), it is always  possible  to  obtain 
equivalent  representations  with  Wi  ^  0  and  W2  =  0.  Assuming  this  is  the  case, 
(3.76)  is  a  general  description  for  the  closed-loop  system,  and  the  condition  for  the 
closed-loop  system  to be  well  defined  is  that 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
del 
^1 
-Q2R1 
-Q1R2] 
Pi 
7^0. 
(3.77) 
If  this  condition  is  not  satisfied,  then  the  closed-loop  system  cannot  be  described  by 
the  polynomial  matrix  representations  discussed  in  this  chapter. 
If  the  systems  ^i  and  S2  are  described  by  the  state-space  representations  ki  = 
AiXi  +  BiUi,  yt  =  CfXi  +  DiUi,  i  =  1, 2, then  in  view  of  (3.75), the  closed-loop  sys 
tem  state-space  description  is 
Xi 
U2J 
Jl 
[3^2] 
^  Ai  +  B1M2D2C1 
B1M2C2 
B2M1C1 
A2  +  B2M1D1C2 
B1M2 
B2M1D1 
B1M2D2 
B2M1 
M i Ci 
M2D2C1 
M1D1C2 
M2C2 
+  M2D2D1 
M1D1D2 
M2D2 
(3.78) 
where  Mi  =  (I  -  DiD2)~^  and  M2  =  (I  -  D2DiyK 
D1D2)  =  det(I 
D2Di)y^0. 
- 
It  is  assumed  that  det(I 
-
It  is  not  difficult  to  see  that  in  the  case  of  state-space  representations,  the  con 
ditions  for  the  closed-loop  system  state-space  representation  to  be  well  defined  is 
det(I 
-  D1D2)  ^  0. When  Di  =  0  and  D2  =  0,  then  (3.78)  simplifies  to 
Xi 
= 
y\ 
J 2. 
Ai 
B2C1 
Ci 
0] 
0  C2J 
B1C2 
A2  _ 
Ui\ 
U2J 
+  Bi 
0 
[X2_ 
0] 
B2\ 
(3.79) 
EXAMPLE  3.3.  Let 5*1  and ^2 be described by zi  =  u\,y\  =  qz\  Sindqzi  ~  ^2,y2  = 
Z2, i.e., {Pi, Gi, Ru  Wi}  -  {1, 1, q, 0} and {P2, Q2, Ri,  W2} =  {q, 1, 1, 0}. These  systems 
have transfer  functions  H\{s)  =  s and H2{s)  =  l/s,  i.e.,  an ideal  inductance  Si  is con 
nected via feedback  to an ideal capacitance S2. Then  (3.76) assumes the  form 
'  1 
-q 
-1] 
q  \ 
\zi 
U2. 
"> i"" "
yi. 
01 
\ 
0 
ij 
q  01 
Ij 
P 
r^i 
U'2_ 
\z\ 
U2. 
0, this does not constitute a well-defined  closed-loop descrip 
Since det 
1 
-q 
-1 
q 
tion. It is  of interest  to note that Si  cannot  be  described  by  a state-space  description  of 
• 
the form {Ai,  Bi,  Ci, Di]  since its transfer  function  Hi{s)  =  sh  not proper. 
EXAMPLE  3.4.  Consider  systems  ^i  and  S2  connected  in  a  feedback  configuration 
with//i(^)  =  —-^-^  and//2(5')  = 
and consider the  realizations 
s  +  \ 
s + 2 
s  + 2 
s+  1 
576 
Linear  Systems 
[Pi,  Qh  R\,  Wx]  =  {q + Zq+1,1, 
(3.76)  becomes 
0} and {P2, Qi, Ri,  W2} =  {q+\,q+ 
2,1,  0}. Then 
q  + 2 
-(q  +  2) 
(q + 1)1 
\zi 
U2. 
\ 
q+  I 
"> i"" "
J2. 
0  1 
q + 2\ 
r^i 
L^2. 
'q+  1 
_  0 
"""1  01 "
ij 
0 
\zi~ 
U2. 
Since det 
q  + 2 
-(q  + 2) 
- ( ^ + 1 )1 
q+l 
\ 
=  0, the present example is not a well-defined  poly-
nomial matrix system description. It is of interest to note that here state-space realizations 
ofH\  and H2 exist. Let H\  = 
+  I, H2  = 
7 +  1, and consider the  state-space 
s + 2 
s  -\-  I 
realizations  {Ai, Bi,  Ci, Di}  =  {-2,  - 1, 1, 1} and {A2, B2, C2, D2}  =  {-1,  1, 1, 1}. Here 
I  -  D1D2  =  0,  and  therefore,  a  state-space  reahzation  of  the  closed-loop  system  does 
not exist, as expected. 
• 
EXAMPLE  3.5.  Consider  systems 5*1  and S2 in a feedback  configuration  with Hi(s)  = 
and//2(^)  =  1 and consider the realizations {Pi, Qi, Ri,  Wi}  =  {q+l,  q, 1, 0} and 
[Pi,  Qi, Ri,  W2} =  {1, 1, 1, 0}. Then  (3.76)  becomes 
q+  1 
-1 
-q\ 
1 J 
ki 
U2. 
> i' 
J2. 
q  01 
[0 
Ij 
"""1  01 "
ij 
[0 
In 
[ri 
\zi 
[z2 
Since det 
+  1 
-1 
-q 
1 
=  1 7^ 0, this is a well-defined  polynomial matrix  description 
for the closed-loop system. Note that the transfer  function  matrix of the closed-loop sys-
tem is  H(s) 
1  01 p  +  1 
0 
ijL  -1 
-s^ 
1J 
\s 
[0 
0]\s 
ij  ~  [^  ^ + 1 
s 
Hi  and H2 were both proper. 
, which is not proper whereas 
If  the  realizations  to  be  considered  are  {Pi, gi. Pi,  W\}  =  {q  +  1 , - 1,  1, 1} and 
{P2, Qi, Ri,  W2]  =  {1, 0, 0, 1}, then  1 -  WiTy2  =  1 -  1 • 1  =  0  and  no  representation 
of  the  form  (3.75)  can  be  derived.  This  stresses  the  point  that  the  conditions  for  the 
PMD of the closed-loop  system to be well defined  are given by  (3.77), since the condi 
tion det (I  -  W\W2)  y^ 0 may  lead  to erroneous  results. Note that det (I  -  W1W2)  =  0 
does not necessarily  imply  that a well-defined  polynomial  matrix representation  for  the 
closed-loop  system does not exist. 
Nowif  state-space realizations of ^i(>s)  = 
-  + lmidH2(s)  =  1  are considered, 
s + I 
namely,  {Ai, Pi, Ci, D^}  =  {-1,  1, - 1, 1} and  {A2, P2, C2, D2}  =  {0, 0, 0, 1}, then  1  -
D1D2  =  I  -  I  '  I  =  0, i.e., a state-space  description  of the closed-loop  does not  exist. 
This  is to be  expected  since the  closed-loop  transfer  function  is nonproper  and  as  such 
cannot be represented by a state-space realization {A, B, C, D}. 
• 
Next,  let  Hi(s)  and  H2(s)  be  the  transfer  function  matrices  of  S\  and  ^2,  i.e., 
=  7^2W^2W-In  view  of  wi  =  })2 +  n a n d w2  =  j^i  + 
yi{s)  =  Hi(s)iii(s)sindy2(s) 
r2,  we  have  yi  =  H\U\  =  H\{y2  +  n)  =  H1H2U2  +  / ^ in  =  H\H2y\  +  HiH2f2  + 
H\  f\,  or 
(I-HiH2)yi 
=  H,H2r2  +  H,n. 
(3.80) 
Also,  y2  =  H2U2  =  HziSi  +  h)  =  H2H1U1  + H2r2  =  H2Hiy2  + / ? 2 ^ in  +  ^2^2, 
or 
{I-H2Hx)y2 
= 
H2H,h+H2h. 
(3.81) 
Assume  that  det{I 
that  the  determinants  are equal  is completely  analogous  to the proof  of Lemma  3.10. 
Then 
-  H2H1)  ¥=  0.  Note  that  the  proof  of  the  fact 
-  H1H2)  =  det{I 
(/ 
-  //li/2)-'//l 
( /-
H2H\) 
tin  Hn 
H21 
^22 
H2H\ 
(/ 
(/ 
H\H2) 
-H2Hi)-'H2 
H1H2 
(3.82) 
577 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
The  significance  of  the  assumption  det(I 
-  H1H2)  #  0  can  be  seen  as  follows. 
Let  Dizi  =  Niu\y  y\  =  z\  and  D2Z2  =  ^2, 3^2  =  ^2Z2  be  representations  of  the 
systems  ^i  and  52.  As  will  be  shown,  the  closed-loop  system  description  in  this 
case  is  given  by  (D1D2  -  NiN2)Z2  =  A^i^i  +  5 i r2  and  yi  =  D2Z2  ~  ^2 and  y2  = 
N2Z2-  Now  note  that  /  -  H1H2  =  I  -  D\^NxN2D:^^  =  p\\DxD2 
NxN2)D:^\ 
which  implies  that det  (/  -  H1H2)  7^ 0 if  and  only  if det  {D1D2  -  N1N2)  ¥^ 0, i.e.,  if 
-  H\H2)  =  0,  then  the  closed-loop  system  cannot  be  described  by  the  poly 
det(l 
nomial  matrix  representations  discussed  in  this  chapter.  Thus,  the  assumption  that 
det  (I  -  H1H2)  7^ 0 is  essential  for  the  closed-loop  system  to be  well  defined. 
- 
EXAMPLE  3.6.  Consider Hi{s)  =  2 and H2(s)  =  1/s as in Example  3.3. Clearly,  1  -
H1H2  =  0,  which  implies  that the  closed-loop  system  is not well  defined.  This  agrees 
with the result of Example 3.3, where it was shown that a PMD of the closed-loop system 
does not exist. 
• 
EXAMPLE  3.7.  Consider  Hi(s)  = 
^,/i^2  = 
7  as  in  Example  3.4.  Here  1  -
H1H2  =  0 and the closed-loop system is not well defined,  which agrees with the results 
in Example 3.4. 
• 
5 +1 
5 +  2 
5 +  2 
5 +1 
EXAMPLE  3.8.  Consider  Hi(s)  = 
7 , ^ 2^  =  1  as  in  Example  3.5.  Here  1  -
5 +1 
H1H2  =  —-rr  ^  ^'  ^^^  therefore,  the  closed-loop  system  is  well  defined.  Relation 
(3.82) in this case assumes the  form 
5+  1 
'yi'  = 
5 
5 
5  1 
5 + lJ 
a nonproper transfer function that is the transfer function matrix H(s)  derived in Example 
3.5. 
• 
Now  consider  systems  Si  and  5*2 with  proper  transfer  function  matrices  Hi(s) 
=  1, 2, be their  state-space 
=  AiXi  + BiUuyi  =  CtXi^-DiUui 
SindH2(s),3ndlQtXi 
representations. 
LEMMA  3.11.  If  det(I  -  D1D2) 7^ 0,  then  det(I  -  Hi(s)H2(s))  7^ 0. Furthermore,  in 
this  case /  -  Hi(s)H2(s)  is biproper  [i.e., both /  -  H\{s)H2{s)  and  (/  -  Hi(s)H2(s))~^ 
are proper rational matrices]. 
Proof,  It is not difficult  to see that I -Hi  (5)7/2(5)  =  I-D1D2  + (strictly proper terms), 
which  implies  that  det (I  -  D1D2)  is  the  coefficient  of  the  highest  degree  5 term  in 
578 
Linear Systems 
the numerator of det{I  — Hi(s)H2(s)). Then if det(I  — D1D2)  7^ 0, we have det(I  -
Hi(s)H2(s)) ^  0. Furthermore, 
nm(/ -  Hi(s)H2(s)) = I-  D1D2, 
(3.83) 
which impHes that when det{I  -  D1D2) ^  0, then /  -  Hi(s)H2(s) is a biproper rational 
matrix, i.e., I -  H1H2 and (/ -  H\H2y^  are proper. 
• 
In  Lemma  3.11, we  have  used  the  fact  that  a  proper  rational  matrix  H{s) 
has  a proper  inverse,  e.g., H~^{s)  proper,  if  and only  if  detD  7^ 0,  where  D  = 
lim^^oo H(s). This result is based on Lemma 3.12 and Corollary 3.13. 
LEMMA 3.12.  Consider H(s) G R(S)P^P,  which can be expressed uniquely as H(s)  = 
H(s) + Q(s), using polynomial  division, where H(s) G R(sy^P  is strictly proper and 
Q(s) G R[sy^P. Then H~^(s) is proper if and only if Q~^(s) exists and is proper. 
• 
Proof, The proof is left to the reader as an exercise. 
COROLLARY 3.13.  If H(s) G R(s)P^P is proper, then H~\s)  is proper if and only if 
detD  #  0, where lim,_oo//(5)  =  D G RP^'P. 
Proof, D = Q(s) of the above lemma. 
• 
Note  that  det(I  -  Hi(s)H2(s))  7^ 0  does  not necessarily  imply  that  det(I 
-
D1D2) 7^ 0. To see this, recall that in Examples  3.5 and 3.8, Hi  =  ^  ^ ^, H2  = 1, 
1 
,  ¥=  0. However, in any state-space  realization 
and  1 -  H1H2  =  1  -
Di  =  l,D2  — 1, and  1 -  D1D2  =  0. In other  words,  when  Hi(s)  and H2(s) are 
proper,  the condition  det(I  -  D1D2)  =  det(I  -  D2D1)  ¥- 0 implies  that  det{l 
-
Hi(s)H2(s))  =  det(I  -  H2(s)Hi(s))  7^ 0,  or  that  a  closed-loop  representation  in 
state-space  form  exists. When  det(I  -  Hi(s)H2(s))  #  0, a polynomial  matrix  rep 
resentation for the closed-loop  system exists, but it is not necessarily in state-space 
form, i.e., det(I  — D1D2) is not necessarily nonzero. 
s+  1 
LEMMA 3.14.  Let//i(5), i/2W be proper with Di  =  \mis-^o,H\{s\D2 =  lim^-^ooi/aW 
and assume that (/ -  Hi{s)H2{s)y^  exists. Then Hn{s)  =  (/ -  Hi{s)H2{s)y'^Hi{s) is 
proper if and only if det (I -  D1D2)  7^ 0. 
Proof  If det (I -  D1D2)  7^ 0, then in view of Lemma 3.11, /  -  Hi(s)H2(s) is biproper 
and Hu(s) is then proper. If Hii(s) is proper, then Hu(s)H2(s) and /  + Hii(s)H2(s) are 
proptv.But(I-Hi(s)H2(s)y^  = I+ (I -  Hi(s)H2(s)y^Hi(s)H2(s)  =  I + Hn(s)H2(sX 
and therefore, (/ -  Hi(s)H2(s)y^  is proper or /  -  Hi(s)H2(s) is biproper. This implies, 
in view of Corollary 3.13, that det(I  -  D1D2)  7^ 0. 
• 
Similarly, it can be shown that all the rational matrices in (3.82), namely. 
In 
U2 
(/ -  HiH2y^HiH2] 
J 
(I-H2Hiy^H2 
Ul  -  HiH2y^Hi 
(I-H2Hi)H2Hi 
tin 
H22\ 
Hn 
H21 
\h 
U2. 
yi 
h. 
are proper if and only if det (I  —  D1D2) 7^ 0. This result can also be seen from the 
following  system  theoretic  argument:  The rational  matrices in (3.82)  exist  and are 
proper if and only if there exists a state-space representation of the closed-loop sys 
tem. This will happen if and only if det (/  -  D1D2) 7^ 0, in view of the  assumptions 
in (3.78). 
In the following  it is assumed that det {I -  Hi(s)H2(s))  #  0, that is, the closed-
loop system is well  defined. 
Controllability  and  observability 
Controllability  and  observability  of  closed-loop  systems  are  studied  next.  In 
view of the representation  (3.76), the following  is  evident: 
1.  If  GIL is  a geld  of  Pi,  Qi  and  G2L is  a  geld  of  P2, Q2, then 
\GiL 
0 
0 
G2L\ 
IS  a 
eld of 
Pi 
-Q1R2 
-Q2R1 
Pi 
Qi 
0 
0 
22 
Thus,  all uncontrollable  eigenvalues  of 
^1  in  Gil  are  uncontrollable  eigenvalues  of  the  closed-loop  system  from  ri, 
or r2, or 
. Also, all uncontrollable  eigenvalues  of 52 in  G2L  are  uncontrol 
lable eigenvalues of the closed-loop system from  ri  or r2, or 
. There may be 
additional uncontrollable eigenvalues  in the closed-loop  system,  and these  are 
studied below. 
2.  If  GiR  is  a gcrd  of  Pi,  Ri  and  G2R  is  a gcrd  of  P2, R2,  then 
\GiR 
0 
0 
G2R\ 
IS  a 
579 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
crd of 
Pi 
-Q2R1 
-Q1R2 
P2 
Ri 
0 
0 
R2 
That is, all unobservable eigenvalues of 
Si  in  GiR  are unobservable  eigenvalues  of the closed-loop  system from  j i,  or 
J2,  or 
yi 
LJ2 
. Also, all unobservable  eigenvalues  of ^2 in  G2R  are  unobservable 
eigenvalues  of  the  closed-loop  system  from  j i,  or  y2,  or 
.  There  may  be 
additional  unobservable  eigenvalues  in  the  closed-loop  system,  and  these  are 
studied below. 
Controllability  and  observabiHty  can  of  course  be  studied  directly  from 
the  PMDs  and  (3.76)  as  was  done  above.  However,  further  insight  is  gained  if 
the additional uncontrollable and unobservable eigenvalues are determined from  the 
PMFDs of ^i  and ^2. For simplicity, assume that both ^i  and ^2 are controllable and 
observable and consider the following  representations: 
For system 5i: 
(la) 
or (lb) 
Di(q)zi(t)  =  ui(t), 
yiit)  =  Ni(q)zi{t) 
Di(q)zi(t) 
-  Ni(q)ui(t), 
yi(t)  =  zi(t), 
where (Di(q),  Ni(q))  are re and 0i{q),  Ni(q))  are Ic. 
For system 5*2: 
(2a) 
or (2b) 
D2(q)z2(t)  =  U2(t), 
j2(0  =  N2(q)z2(t) 
D2(q)z2(t)  =  N2(q)u2(t\ 
J2(0  =  Ut\ 
where {D2{q), N2{q)) are re and (D2(q), N2{q)) are Ic. 
In view of the  connections 
(3.84) 
(3.85) 
(3.86) 
(3.87) 
uiit)  =  y2(t)  +  ri(t), 
(3.88) 
the closed-loop feedback  system of Fig. 7.4 can now be characterized as follows  [see 
also (3.76)]: 
U2(t)  =  yi(t)  +  r2(t) 
1.  Using descriptions  (la)  and (2a), Eqs. (3.84) and (3.86), we have 
Ol 
Nil 
/  Ol 
0 
/J 
-Ni] 
£>2j 
In 
Vl.  ' 
£>i 
Ni 
y\ 
yi. 
Ni 
0 
\z\ 
U2. 
n 
U2 
(3.89) 
580 
Linear  Systems 
2.  Using descriptions  (lb)  and (2b), we have 
A^il 
D2J 
\z\ 
[h. 
'Ni 
0 
ol 
A^2j 
['•1 
l.''2. ' 
yi 
y2. 
I  ol 
0 
i\ 
\zi 
U2. 
(3.90) 
3.  Using descriptions  (lb)  and (2a), we have 
\n 
"L'""2_ ' "
NxN2\ 
D2 
\ 
Ol 
l\ 
"""A^i "
0 
\zi 
U2. 
-I 
yi 
72. 
7  0] 
0  7V2J 
r^i 
[^2_ 
(3.91) 
Also,"_D2Z2  =  M2 =  >'i  +  r2  =  Dj  WiMi  +  r2  =  £)j Wi()'2  +  '""1)  +  r2  = "
"D~[^N\{N2Z2  +  n)  +  ^2 and yi  =  M2 — r2  =  D2Z2 """" ^2", from  which we obtain 
(D1D2 -  NiN2)z2  =  [Ni,Di] 
D2 
N2  Z2  + 
n 
(3.92) 
4.  Using descriptions  (la)  and (2b), we have 
Dx 
_-A^2A^i 
-11 
JO2J 
\z\ 
U2. 
= 
I 
0 
0 
A^2j V2. ' 
=  1  0 
[y2. 
Ol 
l\ 
\zi 
[Z2. 
(3.93) 
Also,^Z)izi  =  ui  =  y2  +  n  =  D2^N2U2  -^ n  =  ^2  ^^2(^1  +  ^2)  +  n  = 
"£^2^N2(NiZi  +  r2) +  n  and 3^2  =  ^1 """" n  =  Dizi  — n",  from  which we obtain 
{I )2£>l  - 
N2Ni)Zl  =  [ D2, A^2] 
nl 
/2J ' 
'Ni' 
Pi  zi  + 
= 
0 
/ 
Ol 
oj 
.3'2j 
(3.94) 
The preceding descriptions of the closed-loop system are of course equivalent.  This 
can be proved  directly, using the definition  of equivalent representations  discussed 
in Subsection 7.3A. Therefore,  these descriptions have the same uncontrollable  and 
unobservable  modes.  In  the  following  analysis  we  shall  carefully  select  different 
representations  to  study  different  properties  in  order  to  secure  additional  insight. 
The reader is encouraged to derive similar results, using different  representations. It 
is stressed  that in the following,  both S\  and  5*2 are assumed  to be controllable  and 
observable. The uncontrollability  and unobservability  discussed below is due to the 
feedback  interconnection  only.  As  was  previously  shown,  there  will  in  general  be 
additional  uncontrollable  and  unobservable  eigenvalues  in  a closed-loop  system  if 
S\  and S2 are uncontrollable and/or unobservable. 
To study controllability, consider the representation (3.89) in (1). It is clear  from 
the  matrices 
and 
that the eigenvalues  that  are  uncontrollable 
from  ri  will be the roots of the determinant  of  a geld  of[—Ni,D2\,  and the  eigen 
values that are uncontrollable  from  r2 will be the roots of a geld of  [D\,  -A^2]- The 
-N2 
D2 
closed-loop  system  is  controllable  from 
^2 
Clearly,  all possible  eigenvalues  that 
are uncontrollable from r\  are eigenvalues of ^2. These are the poles of//2  =^ ^2^2 ^ 
that  cancel  in the product  H2N1 or, as can be  shown,  they  are the poles  of H2 that 
581 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
cancel  in 
/ 
H2 
H\.  Similarly,  all possible  eigenvalues  that  are uncontrollable  from  r2 
are eigenvalues  ofS\.  These  are the poles  ofH\  =  NiD^^ 
that cancel  in the  product 
H1N2  or,  as  can  be  shown,  they  are  the  poles  of  Hi  that  cancel  in 
Hi 
I 
Ho 
To  study  observability,  consider  the  representation  (3.90)  in  (2).  It  is  clear 
from  the  matrices 
Di 
-Ni 
and 
that  the  eigenvalues  that  are  unobserv-
able  from  ^yi will  be  the  roots  of  the  determinant  of  a  gcrd  of 
,  and  the  eigen 
D2 
values  that  are unobservable  from  y2  will be the roots of the determinant  of a gcrd  of 
Di 
-N2 
. The  closed-loop  system  is  observable  from 
. Clearly,  all possible  eigen 
values  that  are  unobservable  from  yi  are  eigenvalues  of  S2.  These  are  the  poles  of 
H2  =  D2^N2  that cancel in the product N1H2,  or as can be  shown,  they  are the  poles 
of  H2  that  cancel  in Hi  [I, H2\-  Similarly,  all possible  eigenvalues  that  are  unobserv 
able  from  y2  are  eigenvalues  of  ^ i. These  are  the  poles  of  Hi  =  D^^Ni 
that  cancel 
in  the  product  N2H1,  or  as  can  be  shown,  they  are  the  poles  of  Hi  that  cancel  in 
H2[Hi,Il 
Summary,  The  poles  of  H2  that  cancel  in  H2N1  (or  in 
/ 
Hi 
Hi)  are  the  eigen 
values  that  are  uncontrollable  from  r i;  the  poles  of  H2  that  cancel  in  N1H2  (or  in 
HiU,  H2\)  are  the  eigenvalues  that  are  unobservable  from  yi.  The  poles  of  Hi  that 
cancel  in  H1N2  (or  in 
\Hi' 
H2)  are  the  eigenvalues  that  are  uncontrollable  from  r2\ 
the  poles  of  Hi  that  cancel  in  N2H1  (or  in  H2[Hi,  /])  are  the  eigenvalues  that  are 
unobservable  from  j 2' 
The  above  results  may  also  be  expressed  in  the  following  convenient  way, 
which,  however,  should  be  used  only  when  the  poles  of  Hi  are  distinct  from  the 
poles  of  H2,  to  avoid  confusion.  In  the  product  H2H1,  the  poles  of  H2  that  cancel 
are  the  eigenvalues  that  are  uncontrollable  from  r i;  the  poles  of  Hi  that  cancel  are 
the  eigenvalues  that  are  unobservable  from  ^2- In  the  product  H1H2  the  poles  of  ^i 
that  cancel  are  the  eigenvalues  that  are  uncontrollable  from  r2; the  poles  of  H2  that 
cancel  are the  eigenvalues  that  are  unobservable  from  yi. 
EXAMPLE  3.9.  Consider  systems  Si  and  S2 connected  in  the  feedback  configuration 
of Fig. 7.4  and let S\  and ^2 be described by the transfer  functions  Hi(s)  = 
^ +  1 
s  -  I 
-,  and 
Hiis)  = 
—,—. For the  closed  loop to be  well  defined,  we must have  1 -  H1H2  = 
s + b 
1  -
s +  I  ais  + ao 
s -  I 
s  + b 
(1 —  ai)s^  + (b  —  ai  —  ao —  l)s  —  (b  -\-  ao) 
7^ 0.  Note  that  for 
{s -  \){s  +  b) 
a\  =  l,ao  =  -l,andZ?  = 
values  are not allowed for the parameters  if the closed-loop  system is to be  represented 
by  a  PMD.  If  state-space  descriptions  are  to  be  used,  let  Di  =  \ims-^o=Hi(s)  =  1 
and  D2  =  lims^ooH2(s)  =  a\,  from  which  we  have  1 -  D1D2  =  1 -  ^1  7^ 0  for  the 
1 -1  = 0.  Therefore,  these 
^-^mdl-HiH2 
^ +  1 
l,//2 
582 
Linear  Systems 
closed-loop  system  to be  characterized  by  a  state-space  description  [and  also, in  view 
of  Lemma  3.14,  for  the  transfer  functions  in  (3.82)  to  be  proper]. Let  us  assume  that 
ai  7^ 1. 
The uncontrollable  and unobservable  eigenvalues  can be determined  from  a  PMD 
such as (3.92). Alternatively,  in view  of the discussion just preceding  this example,  we 
conclude the following,  (i) The eigenvalues that are uncontrollable from  ri  are the poles 
of H2 that cancel in H2N1  =  ais  +  ao 
s + b 
trollable from  r\  (at  - 1)  only when  b  =  \.  If this is the case,  -1  is also an  eigenvalue 
{s +  1), i.e., there is an eigenvalue that is uncon 
that is unobservable from y\.  (ii) The poles of Hi  that cancel in H\ N2  = 
are the eigenvalues that are uncontrollable from  r2, i.e., there is an eigenvalue that is un 
controllable  from  r2 (at  -1-1) only  when  ao/ai  =  - 1. If  this  is the  case,  -1-1 is  also  an 
eigenvalue that is unobservable from  j2- 
• 
r (ais  + UQ) 
^ +  1 
Stability 
The closed-loop feedback system is internally stable if and only if all its eigenval 
ues have strictly negative real parts. The closed-loop eigenvalues can be determined 
from  the  closed-loop  descriptions  derived  above.  If,  for  example,  (3.76)  is  con-
sidered, then the closed-loop eigenvalues  are the roots of  det 
\  Pi 
[-Q2R1 
-Q1R2 
Pi 
Since  any  uncontrollable  or  unobservable  eigenvalues  of  S\  and  ^'2  is  also  an 
uncontrollable  or  unobservable  eigenvalue  of  the  closed-loop  system,  it  is  clear 
that  for  internal  stability,  both  ^i  and  5*2  should  be  stabilizable  and  detectable, 
i.e., any uncontrollable  or unobservable  eigenvalues  of 5*1  and ^2 should have neg 
ative  real  parts.  This  is  a necessary  condition  for  stability.  We  shall  nov^  concen 
trate on the descriptions (3.87) to (3.94) in (1) through (4). First, recall the identities 
det 
A  D 
C  B 
=  det(A)det(B 
-  CA'^D)  =  det(B)det(A 
-  DB'^C), 
(3.95) 
v^here  in  the  first  expression  it  v^as  assumed  that  det {A)  ^  0  and  in  the  second 
expression  it  was  assumed  that  det(B)  7^ 0.  The  proof  of  this  result  is  imme-
diate  from  the  matrix  identities 
I 
-CA-^ 
0] 
\A  D 
[c  B  = 
l\ 
D 
B-CA-^D 
and 
[/ 
[0 
-Dfi-'l 
/  J 
\A  D 
[c  B 
A-DB-^C 
C 
0 
B 
Now consider the polynomial  matrices 
-N2 
D2 
-N2 
D2 
, (D1D2  -
N1N2),  and  {D2D1 -  N2N1)  from  the closed-loop  descriptions  in  (1),  (2), (3),  and 
(4). Then 
det 
£>! 
-Ni 
-N2 
£>2 
=  det(Di)  det{D2  -  NiD^^N2) 
-  Dx^N\N2) 
=  det(Di)det(D2 
=  det(Di)  det01^)  det0iD2 
=  aidet(DiD2 
-  N1N2), 
- N1N2) 
(3.96) 
583 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
where at  is a nonzero real number. Also 
det 
-N2 
D2  =  det(D2)  det(Di  -  7V2^2 ^M) 
=  det(D2)  det(Di  -  D2^N2Ni) 
=  det(D2)  det 02^)  det(D2Di  -  N2N1) 
=  a2 det 02^1 
-  N2N1I 
(3.97) 
where 0:2 is a nonzero real  number. 
Similarly, 
det 
-N2 
D2 
=  didet02Di 
-  N2Ni\ 
(3.98) 
where di  =  det(Di)  det(D^  ^) is a nonzero real number,  and 
det 
-N2 
Di 
=  d2det(DiD2 
-  N1N2I 
(3.99) 
"where ($2  ""=  det 02)  det(D2^)  is a nonzero real number.  These  computations  ver "
ify  that the equivalent  representations  given by  (1), (2), (3), and  (4) have  identical 
eigenvalues. 
The following  theorem presents conditions for the internal stability of the  feed 
back  system  of Fig. 7.4. These conditions  are useful  in a variety  of  circumstances. 
Assume that the systems Si  and 52 are controllable and observable and that they are 
described by (3.84) to (3.87) with transfer  function  matrices given by 
and 
Hi  =  NiDi^  =  Di^Ni 
H2  =  N2D2^  =  D2^N2 
(3.100) 
(3.101) 
where the {Nt, Di) are re and the {Nt, Di) are Ic for /  =  1,2. Let a 1 (s) and a2(s) be the 
pole (characteristic) polynomials ofHi(s)  and H2(s), respectively. Note that ai(s)  = 
i  =  1, 2, for  some nonzero real numbers  ki, ki.  Con 
kidet(Di(s))  =  kidet0i(s)), 
sider the feedback  system in Fig. 7.4. 
THEOREMS.15.  The following statements are equivalent: 
(i)  The closed-loop feedback system in Fig. 7.4 is internally stable, 
(ii)  The polynomial 
or 
-Ni' 
(a)  det 
(b)  det 
-N2 
Di. 
Di 
Ni 
bx 
Ni 
(c)  det0iD2 
(d)  det02Di 
is Hurwitz; i.e., its roots have strictly negative real parts, 
-NiN2),ov 
-N2N1) 
O2. 
or 
(iii)  The polynomial 
ai(s)a2(s)det(I  -  Hi(s)H2(s)) ==  ai(s)a2(s)det(I  -  H2(s)Hi(s)) 
(3.102) 
is a Hurwitz polynomial. 
584 
Linear  Systems 
iv)  T he  poles  of 
ill 
Ml. 
I 
-Hi 
-1 
-H2 
I 
^1 
72. 
{I-H2H1)-' 
Hi(I-H2Hir 
H2(I-HiH2r'] 
J 
{I-HIH2V 
\ri 
U2 
are  stable,  i.e.,  they  have  negative  real  parts. 
(v)  The  poles  of 
'y\ 
yi. 
'-H2 
.  I 
I 
-Hi_ 
"-1  ""0 "
L ^l 
H2] 
\ri 
L^2_ 
0 J 
(I-HiH2r'Hi 
{I-H2H1)-
'H2H1 
(I-HiH2r'HiH2] 
(/  -  H2H1)  H2  J 
\ri 
ih 
are  stable. 
(3.103) 
(3.104) 
Proof.  It  was  shown  previously  in  (3.96)  to  (3.98)  that  all  the  determinants  in  (ii)  are 
equal  within  some  nonzero  constants,  i.e.,  they  have  the  same  roots.  These  roots  are  the 
eigenvalues  of  the  closed-loop  feedback  system  [recall  that  the  representations  (3.89) 
to  (3.94)  are  all  equivalent].  The  feedback  system  is  internally  stable  if  and  only  if  its 
eigenvalues  have  negative  real  parts.  This  shows  that  (ii)  is  true  if  and  only  if  (i)  is  true. 
det(D^\DiD2-
and  a2(s)  = 
NiN2)D2^)  =  det(D^^) 
k2 det  (D2(s)),  where  ki,  k2 are  nonzero  real  numbers,  it follows  that,  ai(s)a2(s) 
det  (/  -
Hi(s)H2(s))  =  ki /c2 det(Dk),  which  is  a  polynomial,  the  roots  of  which  are  the  closed-
loop  eigenvalues.  Note  also  that  det  (I  -  H1H2)  =  det  (I  -  H2H1).  Since  the  roots  of 
(3.102)  are  exactly  the  closed-loop  eigenvalues,  (iii)  is  true  if  and  only  if  (i)  is  true. 
T o s h o w ( i i i ) , l e t D^  =  D1D2-  NiN2  2indwvitQ  det  (I  -  H1H2)  = 
det(Dk).  Since  ai(s)  =  kidet(Di(s)) 
det(D2^) 
To  show  (iv)  we  write 
/ 
-Hi 
H2 
I 
D2 
0 
Di 
-Ni 
"0"" "
6 1^ 
-1  r 
"-7^2"" "
Di_ 
-1 
62 
[ 
-Ni 
\Di 
"0"" "
-N2 
[0  D2_ 
D2_ 
(3.105) 
and  we  notice  that  these  are  coprime  polynomial  matrix  factorizations  (show  this).  The 
poles  of 
/ 
-Hi 
-H2 
I 
are the roots of J^H I 
Di 
-Ni 
-N2 
D2 
that are precisely  the  closed-
loop  eigenvalues.  Note  that the poles  are  also  equal  to the  roots  of det  [ | 
-N2 
Di 
0 
/ 
/  0 
So (iv) is true if and only if (i) is true  since the poles in (3.103)  are exactly  the  eigenvalues 
of  the  closed-loop  system. 
[see  (ii) above]  since 
0 
/ 
/  0 
Di 
-N2 
D2 
-Ni 
-N2 
Di 
-Ni 
D2 
-Ni 
D2 
bi 
N2 
-Ni 
D2 
det 
To  show  (v),  we  note  that 
of  (iv)  above  implies  that 
yi' 
y2_ 
= 
"""0  n  lui "
1^2. 
-
~riT  ,  which  in  view  of  the  proof 
'yi  = 
= 
/ 
-Hi 
0  nl 
I  ojl 
0 
/ir 
/  oj^ 
I 
-Hi 
/ 
-Hi 
-H2 
I 
-H2 
I 
-H2] 
I 
I 
0 
ro 
[HI 
0 
/ 
H2] 
0 
0' 
Di. 
"-1  ""0 "
.A^i 
A^2l 
0 J 
\r\ 
ih. 
/] 
"""0 "
/ 
oj 
/] 
"""0 "
_/ 
OJ 
/I 
"""0 "
J  oj 
D2 
-N2 
62 
-N2 
-1 
-1 
D2 
. 0 
"""0 "
Nx 
To  /] 
1/  OJ 
-A^if 
62J 
[  61 
L-A^2 
^\Ni 
01 
[0  7V2J 
- ^ il 
^2] 
Tn 
' 
ih 
-1 
\b. 
0] 
bi\ 
[0 
\r\ 
N2\ 
Vh. 
0  J 
[0  /] 
[/  oJ 
1
•
"-1  ""0 "
Ni 
Ni] 
0 J 
\r\ 
ih. 
(3.106) 
or 
'yi 
.h. 
"""  A "
, - / ! /2 
585 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
which is an Ic factorization. This of course is the expression for the transfer function that 
could have been derived directly from the internal description in (3.90). Similarly, from 
(3.89) it can be shown that 
yi 
0 
N2j 
Di 
-Ni 
0 
-1 
I 
-N2 
D2\ 
(3.107) 
which is an re factorization. Clearly, the poles of the transfer function matrix in (3.104) 
are precisely the closed-loop eigenvalues, which implies that 
that relates 
and 
(v) is true if and only if (i) is true. 
• 
Remarks 
1.  Parts  (iv)  and  (v) of Theorem  3.15  can  also be  shown  to be  true by  using  the 
following brief argument. It was shown that the feedback  system is controllable 
from 
and observable  from 
. Also, it can easily be shown that the system 
is observable  from 
. Therefore,  the poles of the transfer  function  from 
or 
to 
are precisely  the eigenvalues  of the closed-loop  system,  which 
must have negative real parts for internal  stability. 
2.  It is  important  to consider  all  four  entries  in  the  transfer  function  (3.104)  be 
tween 
and 
[or  in  (3.103)  between 
and 
]  when  considering  inter 
nal stability. Note that the eigenvalues that are uncontrollable from  r\  or r2 will 
not appear in the first or the second column of the transfer  matrix, respectively. 
Similarly, the eigenvalues  that are unobservable  from  y\  or j2  will not  appear 
in  the  first  or  the  second  row  of  the  transfer  matrix,  respectively.  Therefore, 
consideration  of  the  poles  of  some  of  the  entries  may  lead  only  to  erroneous 
results,  since possible  uncontrollable  or unobservable  modes  may  be  omitted 
from  consideration,  and these may lead to instabilities. 
3.  Write 
and 
If 
and 
(/  -  HiH2y^  =  D2(DiD2  -  NiN2y^Di 
( /- -H2Hi)-^  = 
DiiD2Di-N 
Dk  =  D1D2 -  N1N2 
Dk  =  D2D1 -  N2NU 
(3.108) 
(3.109) 
(3.110) 
(3.111) 
586 
Linear  Systems 
"then  (/  -  7/1//2)""'  =  D2D-'Du "
(I  -  H2H1) 
-- DiDl^D2, 
and 
D2Dl^Ni 
N2Dl^Nx 
NiDl^N2 
DiDl^N2 
NiD-^D2 
[N2D-^Ni 
NiDl^N2 
N2D^^Di\ 
(3.112) 
Note that the  first  column  above  can be  written  as 
D2 
N2 
D^^N\,  and possible  can 
cellations may  only occur between  D^  and A^i since  the  D2 
N2, 
are re. In view  of  the 
representation  (3.92),  these  are  precisely  the  eigenvalues  of  the  closed-loop  sys 
tem that are uncontrollable  from  ri.  Similar results  can be derived  by  considering 
the  second  column.  These  results  agree  with  the  comments  made  in  Remark  (2) 
above.  Similarly,  consider  the  first  row  NiDl^[D2,N2\. 
Since  the  [^2>  A^2]  are 
Ic,  possible  cancellations  may  occur  only  between  Ni  and  D^,  which  in  view  of 
representation  (3.94)  are precisely  the  eigenvalues  of the closed-loop  system  that 
are unobservable  from  y.  Analogous  results  can be established by  considering  the 
second  row  N2Dl^{N\,  D\\. 
Finally,  we  note  that 
N2D 
DiD 
^-1 
D2D-'Ni 
D^D 
l ^ r ^2 
D2D-'Di 
(3.113) 
from  which  similar results concerning  uncontrollable  and unobservable  eigenval 
ues  can  easily  be  derived. 
4.  The roots  of each  of the polynomials  in  (ii) of Theorem  3.15  are equal  to the  roots 
of  the  polynomials  in  (iii)  and  are  equal  to  the  poles  of  the  transfer  functions  in 
(iv)  and  in  (v). They  are  exactly  the  eigenvalues  of  the  closed-loop  system. 
5.  The  open-loop  characteristic  polynomial  of  the  feedback  system  is 
a\{s)a2{s). 
The  closed-loop  characteristic  polynomial  is  a  monic  polynomial,  aci{s),  with 
roots  the  closed-loop  eigenvalues,  i.e., it is equal  to  any  of the polynomials  in  (ii) 
within  a multiplication  by  a nonzero  real  number.  Then,  relation  (3.102)  implies, 
in view of (4), that the  determinant  of the  return  difference  matrix  [I—Hi 
(s)H2(s)] 
is the  ratio  of  the  closed-loop  characteristic  polynomial  over  the  open-loop 
char 
acteristic  polynomial  within  a  multiplication 
by  a  nonzero  real  number 
ais  + ao 
EXAMPLE  3.10.  Consider  the  feedback  configuration  of  Fig.  7.4  with  Hi  = 
s + 1 
s-  r 
the  transfer  functions  of  systems  Si  and  5*2, respectively.  Let  ai  7^ I 
Ho  = 
so that  the  loop is well  defined  in terms  of  state-space  representations  (and  all  transfer 
functions  are proper). (See Example  3.9.) 
s + b 
All  polynomials  in  (ii)  of  Theorem  3.15  are  equal  within  a  multiplication  by  a 
nonzero  real  number,  to  the  closed-loop  characteristic  polynomial  given  by  aci(s)  = 
9 
s  + 
.  ,  „ 
. This  polynomial  must  be  a Hurwitz  polynomial  for 
b —  ai  —  ao —  I 
s  - 
b + ao  ^,  . 
.  , 
^^ 
. 
, 
, 
, 
I  —  ai 
I  —  ai 
internal stability. If ai(^)  =  s —  I and a 2(5) =  s + bsiVt the pole polynomials of Hi  and 
H2, then the polynomial in (iii) is given by ai(s)a2(s)(l 
-  Hi(s)H2(s))  =  (1 -  ai)s^  + 
(b — ai  -  ao -  l)s  -  (b -\- ao)  =  (I  — ai)aci(s),  which implies that the return  difference 
1  -  Hi(s)H2(s) 
(s -  m  + b) 
ai(s)a2(a) 
(1  -  ai)aci(s),  and  the  transfer  function  matrix  in  (iv) of 
"-.  Note  that  (1  -  H1//2)"" "
(1  -  H2Hir 
with  a(s)  = 
(1  -  ai) 
a{s) 
587 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
Theorem  3.15 is given by 
(s -  l)(s  -\-  b) 
(s ~  l)(ais  +  ao) 
a(s) 
a(s) 
(s +  1)(^ +  b) 
(s -  l)(s  +  b) 
a{s) 
a{s) 
The polynomial  a{s)  has a factor  s  +  \  when  b  =  I.  Notice that 
when b  =  1. If this is the case (b  =  1), then 
a(-l) 
2-2b  =  0 
-s  -  I 
a(s) 
s+  1 
a(s) 
(s -  l)(ais  +  ao)-
a(s) 
s-  1 
a(s) 
where a(s)  =  (s + l)d(^). Notice that three out of four transfer  functions  do not contain 
the  pole  at  -1  in  d(s).  Recall  that  when  b  =  1,  -1  is  an  eigenvalue  that  is  uncon 
trollable from  ri,  and it cancels in certain transfer  functions,  as expected  (see  Example 
3.9). Similar results can be derived when ao/ai  =  -I.  This illustrates the necessity  for 
considering  all the transfer  functions  between  wi, W2  and  ri,  r2 when  studying  internal 
stability  of  the  feedback  system.  Similar  results  can  be  derived  when  considering  the 
transfer  functions  between  j i,  y2 and ri,  r2 in (v). 
• 
COROLLARY 3.16.  The closed-loop feedback  system in Fig. 7.4 is internally  stable if 
and only if 
(i)  Djf i[(/  -  H2Hi)-\  H2(I  -  HiH2)-^]  is stable, or 
(ii)  D2^[Hi(I  -  H2Hi)-\ 
is stable, or 
(I  -  HiH2y^] 
(iii) 
(iv) 
(I-H2H1)-' 
[Hi(I  -  H2H1)-' 
H2(I  -  H1H2)-' 
(I  -  H,H2)-' 
D2 ^ is stable, or 
D^ ^ is stable. 
Proof.  The  above  expressions  originate  from  rows  and  columns  of  the  transfer  func 
tion  matrix  between 
and 
.  In  view  of  (3.113),  expression  (i)  is  equal  to 
D\^DiDl^[D2,  N2\  =  D^^[D2, A^2], the poles of which are precisely the roots of  detDk, 
the closed-loop eigenvalues, since the pair (D2, N2) is Ic. Similar arguments hold for (ii), 
(iii) and (iv). 
• 
It  is  of  interest  to  point  out  that  expression  (i)  of  the  corollary  is  precisely  the 
transfer  function  between  the  partial  state  z\  and  the  input 
,  in  view  of  (3.103) 
and  Dizi  =  u\.  Expression  (ii)  corresponds  to the  transfer  function  between  zi  and 
. Notice  that  \ir\  = = 
= 
(i-H2Hir' 
(I-HiH2)-'Hi 
//2^2  + 
\l-H2Hi)-'H2 
{I-H,H2)-' 
Hxh 
from  (3.104).  Since  H2  =  ^2  ^^2  is  an  Ic  factorization,  the  transfer  function  from 
zi\ 
to  r2 is  stable  if  and  only  if  expression  (iii)  is  stable.  A  similar  argument  holds 
for  (iv). 
The  following  result  can  be  proved  in  a  completely  analogous  manner  to  the 
proof  of  the  above  corollary. 
588 
Linear  Systems 
COROLLARY  3.17.  The closed-loop feedback  system in Fig. 7.4 is internally stable if 
and only if 
(i)  DfH/  -  H2Hi)-^D2^ 
(ii)  D^^I 
-  HiH2T^b^^ 
is stable, or 
is stable. 
• 
Note  that  expression  (i) in  the  corollary  is  stable  if  and  only  if the  transfer  func 
tion between  z\  and 
is  stable. To  see this, note that  u\  =  (I  -  HjHi) 
^ n,  from 
"whichzi  =  Df^wi  =  [ Z ) j ~ H / - ^ 2 ^ i ) "" ^2 "
] ^ 2 n . N o w D 2 ri  =  D2U1 -  D2y2  = 
D2U1 -  N2U2  =  [D2, 
-N2\ 
,i.e.,£i  - 
[D-,\l-H2Hi)-'D^'W2,-N2} 
Since  the  pair  (62, N2)  is  Ic,  this  transfer  function  is  stable  if  and  only  if  expres 
sion  (i)  is  stable.  Similarly,  U2  =  (I  -  H\H2)~^r2^ 
from  which  £2  =  [^2  H^  ~ 
HiH2r'D^']Dir2 
=  [D^\I 
- 
HiH2r'D^'][-Ni,D,] 
,  which  is  stable  if 
and  only  if  expression  (ii)  is  stable,  since  (-A^i,  Di) 
matrices. 
is  an  Ic  pair  of  polynomial 
EXAMPLES.11.  Consider again the systems described by Hi (s)  = 
a\s  + ao 
, as in Example 3.10. The expressions in Corollary  3.16  are given by 
s+  1 
s-  1 
and 7/2 W  = 
s + b 
(i) 
1 
s-  1 
1 
(ii) 
s + b 
a(s) 
(s -  l)(s  +  b) 
{s -  \){s  + b) 
' 
(s +  l)(s  + b) 
a(s) 
(s- 
l)(ais  +  ao) 
a(s) 
(s- 
l)(s  +  b) 
a(s) 
1 
a(s) 
[s +  b, ais  + ^o], 
[s+hs- 
1], 
a(s) 
a(s) 
1 
(iii) 
(s +  l)(s  +  b) 
s + b 
s-  1 
s+  1 
1 
a(s)' 
a{s) 
(s -  l)(ais  +  ap) 
a{s) 
(iv) 
(s -  1)(^ +  b) 
a(s) 
1 
1 
ais  + ao 
I  s  + b  \  a(s) 
1 
Clearly, the monic pole polynomial  of each of the transfer  functions  in (i) to (iv) is 
9 
=  s  + 
(b -  ai  —  ao -  I) 
a(s) 
I  —  ai 
polynomial.  This  is  so even  when  Z? =  1 or aolai  =  -1  (see Example  3.9),  in  which 
case there are uncontrollable/unobservable  eigenvalues. Notice that s  + b and a\s  + ao 
are coprime by the definition  of  H2(s). 
=  cici(s), the closed-loop  characteristic 
(b + ao) 
\  —  a\ 
1 —  a\ 
s -  — 
,  ^ 
, 
Similarly, the expressions in Corollary  3.17  are given by 
(i) 
(ii) 
1 
(s -  l)(s  + b)  1 
s —  I 
a(s) 
s  + b 
1 
(s -  l)(s  + b)  1 
s + b 
as  expected. 
a(s) 
s-  1 
1 
a(s) 
1 
a(s)' 
589 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
PART 2 
SYNTHESIS OF CONTROL  SYSTEMS 
7.4 
FEEDBACK CONTROL SYSTEMS 
In this  section,  feedback  systems  are  studied  further  with  an emphasis  on  stabiHz-
ing feedback  controllers. In particular,  it is shown how  all the stabilizing  feedback 
controllers can be conveniently parameterized. These parameterizations are very im 
portant in control  since they  are fundamental  in methodologies  such  as the  optimal 
/7°°-approach to control design. Our development  of the subject  at hand builds upon 
the controllability,  observability, and particularly, the internal  stability results intro 
duced  in  Section  7.3, as well  as on the Diophantine  Equation  results  of  Subsection 
7.2E.  First,  in  Subsection  7.4A  all  stabilizing  feedback  controllers  are  parameter 
ized, using PMDs. A number of different  parameterizations  are introduced  and dis 
cussed  at length.  State  feedback  and  state estimation,  using  PMDs,  are  introduced 
in Subsection 7.4B and are then used in Subsection 7.4C, where all stabilizing  feed 
back controllers  are parameterized,  using proper  and  stable MFDs. Two degrees of 
freedom  feedback  controllers  offer  additional  capabilities  in control design  and  are 
discussed in Subsection 7.4D. Control problems are also described in this subsection. 
A.  Stabilizing  Feedback  Controllers 
Now consider  systems Si  and ^2 connected  in the feedback  configuration  shown in 
Fig. 7.4, or equivalently, in Fig. 7.5. Given S\,  it is shown in this section how to pa 
rameterize all systems ^2 so that the closed-loop feedback  system is internally stable. 
Thus, if 5*1, called the plant,  is a given system to be controlled, then ^2 is viewed as 
the feedback  controller  that is to be designed. Here we provide the parameterizations 
of all stabilizing feedback  controllers. 
^^O 
S^ 
yi 
3^2 
Or 
FIGURE 7.5A 
Feedback configuration 
'^ 
/-2 
+^ -N. 
^2  , Q^ 
>H Si 
yi 
FIGURE 7.5B 
Feedback configuration 
590 
Linear Systems 
Several parameters will be used to parameterize  all stabilizing  systems S2. The 
results  are  based  on  PMDs  of  the  systems  S\  and  5*2 and  of  the  closed-loop  sys 
tem, in particular, PMFDs. Parameterizations  are introduced, using first the polyno 
mial matrix parameters (1) D^, N^  and D^, Nk and then the stable rational parameter 
(2) K  =  NkDl^  =  D^^TV^. These parameters are very convenient in characterizing 
stability,  but  cumbersome  when  propemess  of  the  transfer  function  H2  of 5*2  is  to 
be  guaranteed.  The rational  proper  and  stable parameters  (3)  Qi  and  Q2 are intro 
duced  next. These  are very  convenient  when properness  of H2 is to be  guaranteed, 
but  cumbersome  when  characterizing  stability,  except  in  special  cases,  e.g.,  when 
Hi  is  stable.  The  stable  parameters  (4)  Su  and  521  that  are  the  comparison  sen 
sitivity  matrices  of the feedback  loop will  also be used.  These  can be employed  to 
conveniently parameterize all stabilizing H2 controllers only in special cases, for ex 
ample, when / /f  ^  exists. Parameters  (5) X2 and X2, which are closely related to Q2, 
will also be introduced  and discussed.  The results based  on X2 in the case of  SISO 
systems reduce to well-known  classical control results. Finally, rational  parameters 
(6) Li,  L2 are introduced  to help in providing  alternative proofs  for  the results  that 
involve the previously  introduced parameters. These results provide a link with pa 
rameterizations  of  all  stabilizing  controllers  using  proper  and  stable  factorizations. 
Such parameterizations  are addressed in Subsection  7.4C. 
The distinguishing characteristics of our approach of the parameterizations of all 
stabilizing feedback  systems S2 (of all stabilizing  controllers) is that they are based 
on internal representations, which were developed at length earlier in this book. This 
approach builds upon previous results and provides significant insight that allows the 
introduction  of  several  parameters  that  are  useful  in  different  circumstances.  This 
approach  also  makes  it possible  to easily  select  the  exact  locations  and  number  of 
the desired stable closed-loop eigenvalues. Utilizing the development of this section, 
a parameterization that uses proper and stable MFDs and involves a proper and stable 
parameter  K'  is introduced  in Subsection  7.4C. The parameter  K'  is closely  related 
to the stable rational parameter K used in the approach enumerated above. This type 
of parameterization  is useful  in certain control design methods  such as optimal //°°-
control  design. 
In  the  following,"  the  term  ""stable  system  5""  is  taken  to  mean  that  the  eigen "
values  of  the  internal  description  of  system  S  have  strictly  negative  real  parts  (in 
the continuous-time  case), i.e., the system S is internally  stable. Note that when  the 
transfer functions in (3.103) and (3.104) of the feedback  system S are proper, internal 
stability  of S implies  BIBO  stability  of the feedback  system,  since the poles  of  the 
various  transfer  functions  are  a  subset  of  the  closed-loop  eigenvalues  (see  Section 
7.3 and Chapter 6). 
Feedback  systems 
The feedback  system of Fig. 7.5 was studied at length in Subsection 7.3C. Recall 
that if 
Pi(q)Zi(t)  =  Qi(q)uiit) 
ytit)  =  Ri(q)Zi(t), 
i  =12, 
are polynomial matrix descriptions of Si and ^'2, then the closed-loop system is given 
by (3.76), i.e.. 
591 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
Pi 
-QiRi 
QIR2] 
P2 
J [Z2j 
= 
Qx 
0 
yi 
'J2_ 
= 
^1 
0 
0] 
U2_ 
ol 
R2\ 
\zi\ 
[Z2\ 
(4.2) 
where the relations 
Mi(0 =  nCO + nit), 
mit)  = yiit) +  nit) 
(4.3) 
have  been  used.  Based  on  this  description,  it  was  shown  that  for  the  closed-loop 
eigenvalues  to be  stable  (to have  strictly  negative  real parts), it is necessary  for  5i 
and  ^2 to be  stabilizable  and  detectable. This  is  so because  the uncontrollable  and 
unobservable  eigenvalues  of both  S\  and  ^2 will  also  be  uncontrollable  and  unob-
servable eigenvalues  of the closed-loop  system. 
Now  assume that S\  and  ^2 are controllable  and  observable,  and  let system  S\ 
be described by 
or 
(la) 
(lb) 
Dx{q)Zi{t)  =  ui(t),yiit)  =  Niiq)ziit) 
Di(q)zi(t)  =  Ni(q)ui(t),  yiit)  =  zi(t), 
(4.4) 
(4.5) 
where  the  pair  {D\{q), N\{q))  is  re  and  the  pair  (D\iq),  Ni{q))  is  Ic. Let  Hi{s)  = 
Ni{s)D^^{s)  =  D'[^(s)Niis)  be the transfer  function  matrix of S'l. Next, let  system 
52 be described  by 
or 
(2a) 
(2b) 
D2(q)z2{t)  =  U2(t), yiit)  =  N2iq)z2(t) 
D2(q)Z2{t)  =  N2(q)u2(t),  y2{t)  =  Mt), 
(4.6) 
(4.7) 
where  the  pair  {D2{q), N2{q))  is  re  and  the  pair  {D2{q), N2(q))  is  Ic. Let  H2is)  = 
N2(s)D^Hs)  D2 ^(s)N2(s) be the transfer  function  matrix of S2. Recall from  Sub 
section 7.3C [see (3.89) to (3.94)] that the closed-loop system descriptions are in this 
case as  follows: 
1.  Using descriptions  (la)  and (2a), we have 
Di 
A^2l 
D2\ 
\zi 
U2. 
7  ol 
0 
i\ 
\n 
U2 
\yi 
[y2. 
'Ni 
0 
0] 
/ ^2} 
\zi 
L^2. 
2.  Using descriptions  (lb)  and (2b), we obtain 
Ni] 
D2J 
\zi 
[Z2. 
-N2 
\yi 
y2. 
'Ni 
0 
7 
0 
ol 
A^2j 
"['""' "
[''2. 
-| 
[zi 
LZ2 
Ol 
/J 
(4.8) 
(4.9) 
592 
Linear Systems 
3.  Using descriptions  (lb)  and (2a), we have 
(D1D2 -  NiN2)Z2  =  [Ni,Di] 
D2 
N2  Z2  + 
4.  Using descriptions  (la)  and (2b), we obtain 
{D2D1 -  N2Nl)Zl  =  02,  N2] 
zi  + 
0  0 
-/  0 
(4.10) 
(4.11) 
These descriptions of the closed-loop system are all equivalent and the polynomials 
det 
-N2 
det 
-N2 
-Ni 
D2 
det{DiD2-NiN2), 
and 
det(D2Di  -  N2N1) 
are all equal within multiplication of nonzero scalars. Their roots are the closed-loop 
eigenvalues  (see Theorem  3.15). 
Parameterizations  of all stabilizing systems S2 
The six parameterizations of all stabilizing systems ^2 previously mentioned are 
now introduced  and discussed  at length. 
1.  Parameters  Dt,  N^  and  Dj^, N^.  Consider  now  the  closed-loop  description 
given in (4) above and let 
D2D1 -  N2N1  =  Dk 
(4.12) 
where  D^  is  some  desired  polynomial  matrix  so that  the roots  of  detD^  are  stable 
(have  negative  real  parts).  If  Z)i,  A^i, D^  are  assumed  to  be  given  and  D2,  -N2 
that satisfy  (4.12) are to be determined, then this equation is seen to be a polynomial 
matrix linear Diophantine equation. Such equations were studied in Subsection 7.2E. 
In  view  of  Theorem  2.15  of  Chapter  7,  Eq.  (4.12)  has  a  solution  for  any  Dj^ (of 
appropriate dimension) since the pair (Di, A^i) is re. All solutions of the Diophantine 
Equation  (4.12) can be parameterized  as follows  [see (2.54)]: 
D2  =  DkX,  -  N^N, 
-N2  =  DkYi  +  NkDi 
[D2,-N2]  =  [Dk,Nk] 
Xx 
(4.13a) 
(4.13b) 
(4.14) 
or 
where  X\,  Y\  satisfy  X\D\  -\-  Y\N\  =  /,  the  pair  {Ni,D\) 
is  Ic  and  is  such  that 
—N\D\  + D\N\  =  0,  and  N^  is  an  arbitrary  polynomial  matrix  of  appropriate  di-
mensions. Note that  {D^Xi,  D]J^\\ is a particular solution of  {D2,  -A^2] 
\Dx 
^1 
=  D,. 
For the  system  D2Z2 =  N2U2, J2  =  Z2  to be well  defined,  we must  have detD2  = 
det (Dj^Xi — NkNi)  7^ 0, i.e., Nk (and D^) must be such that this condition is  satisfied. 
Similar results can be derived using the closed-loop description given in (3). Let 
D1D2  -  N1N2  =  Dk, 
(4.15) 
where D^ is some desired polynomial matrix so that the roots of det D^ are stable. In 
view of Theorem 2.15, all solutions of the Diophantine Equation (4.15) are given by 
D2  =  XiDk  -  NiNk 
-N2  =  YiDk  +  DrNk 
N2 
D2_ 
Di 
Ni 
-Yi\ 
Xi\ 
\-Nk 
[Dk 
(4.16a) 
(4.16b) 
(4.17) 
or 
593 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
where  Xi,  Yi  satisfy  DiXi  +  A^i7i  =  /,  the  pair  (Ni,Di) 
is  re  and  is  such  that 
—DiN\  +  NiD\  =  0,  and Nk  is  an  arbitrary  polynomial  matrix  of  appropriate  di 
mensions.  Note  that  XiDk 
YiDk 
is  a particular  solution  of  [Di,  Ni]  D2 
-N2 
=  Dk.  For 
"the  system  D2Z2 =""  ^2",  j2  =  ^^2^2  to  be  well  defined,  we  must  have  detD2  = 
det{XiDk  -  NiNk)  7^ 0,  i.e.,  Nk  (and  Dk)  must  be  such  that  this  condition  is  sat 
isfied. 
The preceding two sets of parameterizations  for ^'2 are of course related. A con 
venient  way  of  presenting  the  above  results  in  a  unified  way  is  to  use  the  doubly 
coprime  factorizations  of  H\.  To this  end,  assume  that  the  descriptions  (4.4)  and 
(4.5) for  system Si  satisfy 
UU-'  = 
Fi 
Xi 
A^i  A  J 
£»! 
[A^I 
- I 'l 
^ i. 
/ 
0 
0 
/ 
(4.18) 
where  U  is  3.  unimodular  matrix  (i.e.,  det U  is  a.  nonzero  real  number)  and  the 
X\,  Yi,Xi,  Yi  are  appropriate  matrices.  Factorizations  of  Hi  =  NiD^^  =  D^^Ni 
that  satisfy  (4.18)  are  called  doubly  coprime factorizations  of  Hi.  Such  factoriza 
tions always exist (see, e.g.,  [21], [1]). In particular, in Theorem 2 of  [1] it is shown 
that if the relations XiDi  +  FiA^i  -  /, DiXi  + Nifi  =  I  and  -NiDi 
-f- DiNi  =  0 
are  satisfied,  then  (4.18)  is  satisfied  for  Di,  A^i, Di,  Ni,  Xi,  Yi  and  [Xi,  Yi]  = 
[Xi,  Yi]  -h ^[-A^i, Di], where  S  =  XiYi  -  YiXi,  i.e.,  any  Ic and  re  factorizations 
of Hi  with associated matrices can be adjusted  so that they are doubly  coprime. 
If Di,  Ni  and Di,  Ni  are doubly  coprime factorizations  and  satisfy  (4.18), then 
the solutions of the Diophantine Equations in (4.14) and (4.17) can be written as 
and 
from  which it follows  that 
and 
[D2.-N2]  =  [Dk,Nk\U 
N2 
D2 
=  U -1 
-Nk 
[Dk,Nk]  = 
[D2,-N2]U-' 
-Nk 
Dk 
= u\ 
N2 
D2 
(4.19) 
(4.20) 
(4.21) 
(4.22) 
594 
Xhe relation  between  D^,  N^  and  D^, N^  is  now  clear,  namely, 
Linear Systems 
-DuNk  +  NkDk  =  0. 
(4.23) 
THEOREM  4.1.  Assume  that  the  system  Si  is  controllable  and  observable  and  is  de 
scribed  by  the PMD  (or PMFD)  as  (i) DiZi  =  u\, y\  =  N\Z\  given  in  (4.4), or by  (ii) 
b\z\  =  N\u\y  y\  =  zi  given  in  (4.5).  Let  the  pair  (Di,Ni)  and  the  pair  (Di,Ni)  be 
"doubly coprime factorizations  of the transfer function  matrix//i (5)  =  MDj""^  =  D^^Ni "
[i.e.,  (4.18)  is  satisfied].  Then  all  the  controllable  and  observable  systems  S2 with  the 
property  that the closed-loop feedback  system eigenvalues  are stable (i.e., have  strictly 
negative real parts) are described  by 
(i) 
D2Z2  =  N2U2, 
(4.24) 
where  D2  =  DkXi  -  NkNi  and  N2  =  -{DkYi  +  A^^^i)  with  Xi,  Fi, A^i, 5i  given  in 
(4.18)  [see  also  (4.19)]  and  the  parameters  D^  and  Nk  are  selected  arbitrarily  under 
the conditions  that D^^  exists  and is stable, and the pair  {Dky Nk)  is Ic and is  such  that 
det(DkXi 
-NkNi)y^O. 
y2  =  Z2, 
Equivalently,  all stabilizing ^2 can be described  by 
(ii) 
D2Z2  =  W2, 
(4.25) 
where  D2  =  XiDk  -  NiNj,  and N2  =  -{Y\Dk  +  i^iA^^)  with Xu  ?i,  Nu  Di  given  in 
(4.18)  [see  also  (4.20)]  and  the  parameters  Dk  and  A^^^ are  selected  arbitrarily  under 
the conditions  that D^^  exists  and is  stable, and the pair  (Dk, Nk)  is re  and is  such  that 
det(XiDk-NiNk)7^0. 
yi  =  N2Z2> 
Furthermore,  the  closed-loop  eigenvalues  are  precisely  the  roots  of  detbk  or  of 
detDk.  In addition, the transfer  function  matrix of 5*2 is given by 
-0kX,-NkN,)-\DkY,+Nkb,) 
H2  = 
-  NiNk)-\ 
=  -{Y,Dk  +  DiNk)(X,Dk 
(4.26) 
Proof,  The  closed-loop  description  in  case  (i) is  given  by  (4.11)  in  method  (4)  above 
and  in  case  (ii) it is  given  by  (4.10) in method  (3). As  was  shown  in  Subsection  7.2E, 
(4.19)  and  (4.20)  are  parameterizations  of  all  solutions  of  the  Diophantine  Equa 
tions  b2Di  -  N2N1  =  Dk  [in  (4.10)]  and  D1D2  -  N1N2  =  Dk  [in  (4.11)],  respec 
tively.  The  fact  that  5^^  (or  D^^)  exists  and  is  stable  guarantees  that  the  closed 
loop  is  well  defined  and  all  of  its  eigenvalues,  which  are  the  poles  of  D^^  (or  of 
D^i),  will  be  stable.  The  condition  det(bkXi 
-  NkNi)  ¥^ 0  [or det{XiDk  -  NiNk) ¥^ 
0]  guarantees  that  detb2  7^ 0  [or  detD2  ¥^ 0],  and  therefore,  the  PMD  for  ^2  in 
is  Ic  if  and  only  if  the 
(4.10)  is  well  defined.  Finally,  note  that  the  pair  0k,Nk) 
pair  02,  N2)  is  Ic  as  can  be  seen  from  02,  -N2]  =  0k,NkW 
given  in  (4.19), 
where  U  is  unimodular.  This  then  implies  that  the  description  02,  N2> 1}  for  S2  is 
both  controllable  and  observable.  Similarly,  the  pair  (Dk,Nk) 
is  re  guarantees  that 
{D2,1, N2} with D2 and N2 given in (4.20) is also a controllable and observable descrip 
tion for 5*2. 
• 
2.  Parameter  K.  In place  of  the  polynomial  matrix  parameters  Dk,  N^  or Z)^, 
Nk,  it is possible  to use  a  single parameter,  a  stable  rational  matrix  K.  This  is  shown 
next  in  Theorem  4.2. 
THEOREM  4.2.  Assume  that  the  system  Si  is  controllable  and  observable  and  is de 
scribed by its transfer  function  matrix 
Hi  =  NiD^^  =  b^^Ni, 
(4.27) 
where  the  pairs  (A^i, Z)i), 0i,  Ni)  are  doubly  coprime  factorizations  satisfying  (4.18). 
Then  all the  controllable  and  observable  systems  S2 with  the  property  that  the  closed-
loop feedback  system eigenvalues  are stable (i.e., they have strictly negative real parts) 
are described by the transfer  function  matrix 
595 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
H2 = -(Xi  -  KNir\Y,  + KDi) 
=  -(Fi  + D,K)(Xi -  NiKr\ 
(4.28) 
where  the parameter  K is an arbitrary  rational  matrix  that  is stable  and is such  that 
det{X\  -  KN\) #  0 or det(Xi  — NiK) 7^ 0. Furthermore,  the poles  of ^  are precisely 
the closed-loop  eigenvalues. 
Proof,  This is in fact a corollary to Theorem 4.1. It is called a theorem here since it was 
historically one of the first results established in this area. The parameter K is called the 
Youla parameter  (see Section 7.6). 
In Theorem 4.1, descriptions for H2 were given in (4.26) in terms of the parameters 
Dk, Nk and Dk, Nk. Now, in view of -DuNk  + N^Dk  = 0, given in (4.23), we have 
D-,'Nk  = NkDl'  =  K, 
(4.29) 
a  stable  rational  matrix.  Since  the pair  (D^, N^) is Ic and the pair  {Nk, Dk) is re, they 
are  coprime  factorizations  for K.  Therefore,  H2 in (4.28)  can be written  as the H2  of 
(4.26) given in the previous theorem, from which the controllable and observable internal 
descriptions for S2 in (4.24) and (4.25) can immediately  be derived. Conversely,  (4.28) 
can immediately  be derived  from  (4.26), using  (4.29). Note that the poles of K are the 
roots of det Dk or det Dk that are the closed-loop eigenvalues. 
• 
EXAMPLE  4.1.  Consider//i  = 
. Here A^i  = A^i =  5 + 1 and Di  = Di = 5 - 1. 
These are doubly coprime factorizations  (a trivial case) since (4.18) is satisfied. We have 
s+  1 
s-  1 
uu-
Xi 
-Ni 
s + 
-{s  +1) 
Di 
-Yi 
Xi 
-s  + 
s -\ 
s -  1  -{-s  +  |) 
s+l 
s+  \ 
In view of (4.26) and (4.28), all stabilizing controllers H2 are then given by 
H2 
{-s+l)dk^{s-\)nk 
{s + \)dk  -{s+  \)nk 
_  _{-s+l) 
+ 
{s-l)K 
(5 + i) -  (5 + 1)K  ' 
where K = rik/dk, any stable rational  function. 
"EXAMPLE 4.2.  Consider//i(5"")  = ' "
[1,0] 
-(s  +  1) 
1 
=  NiD-, 1  _ 
1 
-1 
[1, s+l]  = Di Wi, which are coprime polynomial MFDs. Relation (4.18) is given by 
uu-^  =  Xi 
-Ni 
5i 
D, 
- Fi 
Xi 
1 
s+  1 
-s^  + l 
'2 
-(S  + 1) 
-(s  +  1) 
s'^ + s +  1 
0 
1 
-1 
~(s+l) 
0 
0 :1 
All stabilizing controllers may then be determined by applying  (4.26) or (4.28). 
596 
Linear Systems 
We  shall  now  express  the  transfer  functions  between 
yi 
J2. 
or 
U2 
and 
m 
/ 2_ 
terms of the parameters D^, N^  or D/., N^  or  K. 
Recall that  [see (3.103) and  (3.104)] 
\y\ 
Ui 
U2 
= 
= 
(I  - 
HIHJT' 
(I-H2Hi)-'H2Hi 
(I-HxH2r'HiH2 
(I-H2Hi)-'H2 
Hid 
-  H2Hir' 
H2(I 
HiH2r' 
and 
(4.30) 
(4.31) 
It is not difficult  to see, in view of (4.26) and (4.28)," that ( / - i ? i / / 2 ) ""'  =D2D^^Di  = "
(XiDk  -  NiNk)Dl^Di  =  (Xi  -  NiK)Du 
"and  (/  -  //z^/i)""^  =  £>i-D^'^2  = "
DiiXi  -  KNi).  Also, (/  -  HxH2)-^Hi  =  D2Dl^Nx  = 
Dxbl\bkXx-NkNx) 
(XiDk  -  NxNk)D7'Nx 
-  H2Hi)-^  =  NiDl^D2  = 
(Xi  -  NiK)Nx  =  Hiil 
-  NkNx)  =  NxiXx  -  KNx),  and  (/  -  H2Hx)-^H2  =  Z^ID^'JVJ  = 
NxDl\DkXi 
-DxiYx  + KDx)  =  H2(I  -  HxH2)-'  =  N2Dl'Dx  = 
-DxDl'{DkYx+NkDx) 
= 
-{YxDu  +  DxNk)Dl'Dx  = 
- ( fi  +  DxK)bx.  Note  that  (/  -  HiH2)-^HxH2  = 
Hx{I  -  H2Hxr^H2  =  Nxb 
+  A^^^i)  =  -A^i(Fi  +  KDx). 
To express  (/  -  HxH2)~^HxH2  in  terms  of  D^, N^  we  write  it  as  D2D^^NxH2  = 
-{XxDk-NxNk)Dl'Nx{YxDk 
+ 
DxK){Xi  —  NxK)~^,  which  is  not  as  simple  as  the  expression  given  in  terms  of 
bk,Nk. 
+ DxNu)0txDu-NxNkr^ 
,  'N2  =  -NxDl\DkYx 
=  -{Xx-NxK)Nx{Yx 
Similarly, (/-772^i)-iH2Hi  =  H2{I-HxH2)-^Hx  =  A^2£>^'A^i  =  -(?i£>*+ 
in  terms  of 
= -DxiYx  + 
//2ffi)~'^2^i 
-DxDl^{DkYx+Nkbx)NxD:^^ 
- ( Fi  +  DxK)Nx.  To  express  (/  - 
DxNk)Dl'Nx 
Di,jV<;,wewriteitasDiD^i7^2/^i  = 
KDx)NxDiK 
It is straightforward  to express the transfer  functions  (4.30) and (4.31) in  terms 
of the parameter ^,"  in view of A"" =  N^D^^  =  D^'iV^. In particular", we have 
= 
= 
J 2. 
U2 
(Xi 
-NiK)Ni 
- (f  1 +  DxK)Nx 
-(Xx  -  NxK)NxH2 
-{Yx  +  DxK)Dx 
(I-H2NxD^')-
(Xx 
-NxK)Nx 
-{Yx 
{Xx-
+  DxK)Dx 
-  NxK)Dx 
(4.32) 
(4.33) 
These  expressions  were  derived  from  the  previous  expressions  given  that  involve 
Dj^  and  N^.  The right  factorization  of H2 in  (4.28)  is to be  considered  in these  ex 
pressions.  Similarly, 
^ 
= 
U2 
NxiXx 
-KNx) 
-DxiYx  +  KDx)NxD7 
-NxiYx  +KDx) 
-DxiYx  +  KDx) 
DxiXx-KNx) 
NxiXx-KNx) 
-DxiYx  +  KDx) 
il  -  b^^NxH2)-^ 
(4.34) 
(4.35) 
which  were  derived  from  the  previous  expressions  involving  D^  and  N^.  The  left 
factorization  of  H2  in  (4.28)  is  to  be  considered  in  entry  (2,  2)  of  the 
to 
597 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
transfer  function.  These  expressions  for  the transfer  functions  in terms  of K  can of 
course be combined in order to use the most convenient  parameterizations. 
3.  Parameters  Q\  and  Q2.  Recall  from  Subsection  7.3C  the relations  (3.103) 
and (3.104) given by 
= 
= 
= 
and 
I 
-H2 
I 
-Hi 
(I-HiH2r'Hi 
"-1  ""0 "
til 
(I-H2H,r'H2H, 
H2] 
0  J  U2_ 
(I-H,H2r'H,H2] 
(I-H2H,r'H2 
In 
U2_ 
J 
-1 
-H2 
I 
I 
-til 
(I-H2H1)-' 
Hi{I-H2Hir' 
H2{I-HiH2r' 
(I-H,H2r' 
(4.36) 
(4.37) 
We shall now express the transfer  function  matrices in terms of some important  pa 
rameters. To this end,  define 
and note that 
Qi  =  / / i (/  -  H2Hi)-'  =  (/  -  H,H2)-'H, 
Q2  ^  H2Q  -  HxH2)-'  =  (/  -  H2H,)-'H2 
Hi  =  Qxil  +  //2Q1)-'  =  (/  +  QiH2)-'Qi 
H2  =  & (/  +  HiQ2)-'  ={I  +  Q2H,)-'Q2. 
(4.38) 
(4.39) 
(4.40) 
(4.41) 
It  is  not  difficult  to  see  that  QxH2  =  H1Q2  and  Q2H1  =  H2Q1  from  Q1H2  = 
(I  -  H\H2r^HxH2  =  Hi(I  -  H2Hi)-^H2  =  H1Q2, and  similarly  for  Q2HX.  Also 
note that 
"(/  -  //1//2)""'  =  /  +  HiQ2  =  /  +  QiH2 "
(I  -  H2Hx)-^  =  /  +  H2Q1  =  /  +  22^1, 
(4.42) 
(4.43) 
from  which  by  postmultiplying  the  first  relation  by  Hi  and  the  second  by  H2,  we 
obtain  Qi  =  (/  +  HiQ2)Hi  =  Hi(I  ^  Q2H1) and  62  =  (/  +  H2Qi)H2  =  H2(I  + 
Q1H2). In view of these relations, it is now straightforward  to write 
yi 
[y2_ 
=  Q\ 
H2Q1 
Q1H2 
(I  +  H2Qi)H2 
Ui 
U2 
I  + H2Q1 
(/  +  H2Qi)H2 
Qi 
1 +  Q1H2 
(4.44) 
(4.45) 
Note that (4.44) and  (4.45) are useful  when H2 is given, in which case they  depend 
only on the parameter g i.  In this case Hi  is given by (4.40). It is not difficult  to see 
that  Qi  is the transfer  function  matrix between  yi  or U2  and  ri.  Similarly, 
\yi 
[h. 
- ^ -
Ui 
^ U2  — 
Hi(I  + Q2Hi)  H1Q2 
QiHi 
Q2 
I  +  Q2H1 
Hi(I^Q2Hi) 
Q2 
I  + H1Q2 
(4.46) 
(4.47) 
598 
Linear Systems 
Expressions (4.46) and (4.47) are useful when H\  is given, in which case the transfer 
functions  depend only on the parameter  Q2. In this case H2 is given by (4.41). Q2 is 
the transfer  function  matrix between  J2 or wi and r2. 
If  the  given  transfer  function  H2  or  Hi  is  proper,  then  it  is  straightforward 
to  guarantee  properness  of  all  other  transfer  functions  by  appropriately  select 
ing  the  parameter  Qi  or  Q2.  In  particular,  given  that  Hi  is  proper,  let  a  proper 
Q2  be  such  that  (I  -\- HiQ2)~^  exists.  Then,  in  view  of  Lemma  3.14  in  Sub 
section  7.3C,  H2  =  Q2{J +  HiQ2)~^  given  in  (4.41)  is  proper  if  and  only  if 
det{I  +  (lim5^oo//i)(lim5^oo22))  ^  0.  If  this  is  true,  then  all  the  transfer  func 
tions in (4.46) and (4.47) will be proper. This implies that if the given Hi  is  strictly 
proper then any proper Q2 will guarantee that the above transfer  functions  exist and 
are  proper.  If  Hi  is  not  strictly  proper,  i.e.,  (lim^^oo//i  7^ 0),  then  care  should  be 
taken in the selection of a proper Q2; if in this case it is possible to select Q2 strictly 
proper,  then H2 will be  (strictly)  proper  for  any  g2- Similar results  are valid  when 
H2 is given and Qi  is  selected. 
In Theorem 4.3 we assume that Hi  is given and the parameter Q2 is to be chosen 
to guarantee internal  stability.  Such a situation  arises when Hi  represents  the given 
plant  and H2 is the  stabilizing  controller to be designed.  It should be noted that  (as 
was  shown  in  Subsection  7.3C),  if  the  given  system  ^i  is not  controllable  and  ob 
servable, all its uncontrollable  and unobservable  eigenvalues  will appear as uncon 
trollable  from 
and unobservable  from 
or 
eigenvalues in the closed-loop 
system.  Therefore,  for  stability  it is necessary  to assume that Si  is  stabilizable  and 
detectable.  Here,  working  with  Hi,  any  possible  uncontrollable  and  unobservable 
parts  of Si  are ignored.  Exactly  analogous  results  exist  for  the parameter  Qi  when 
H2 is given. 
Consider the feedback  system of Fig. 7.5 and assume that Si  is controllable and 
observable with transfer  function  matrix  Hi. 
THEOREM 4.3.  Given//i, let 
"H2 = G2(/ + //lG2)"" "
(4.48) 
where the rational matrix Q2 is such that (/  + HiQ2)~^  exists. Then the eigenvalues of 
the closed-loop feedback  system will be stable (i.e., they will have negative real parts) 
if and only if Q2 is selected so that 
(i)  the poles of Hi(I  + Q2H1), H1Q2, Q2H1, and Q2 are stable, or 
(ii)  the poles of Df^/  +  22^1, G2] are stable, or 
(iii)  the poles of 
\  2^  1 
b^ ^  are stable. 
Furthermore, the eigenvalues of the closed-loop system are precisely the poles in (i) 
or (ii) or (iii). In addition, if Hi is proper, then H2 and the transfer matrices in (4.36) and 
(4.37) are proper if and only if Q2 is proper and det (I + (lim^^oo //^(lim^^oo Q2))  ^  0. 
Proof, The expressions in (i) are precisely the entries of the transfer  matrix between 
and 
given in (4.46), the poles of which are the closed-loop eigenvalues (see 
Theorem 3.15 in Subsection 7.3C). The expressions in (ii) and (iii) come from Corollary 
3.16, where it  was  shown that the poles in these expressions  are exactly  the closed-
loop eigenvalues. The  statement  about properness  was proved  above, just  before  the 
• 
theorem. 
599 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Remarks 
1.  It is not difficult  to see that this theorem characterizes all H2 that lead to a feed 
back  system  with  stable  eigenvalues. When  Hi  is proper  it  also  characterizes 
all proper  stabilizing  H2. 
2.  The  eigenvalues  of the closed-loop  system  are the poles  of the expressions  in 
conditions  (i) or (ii) or (iii). These will be poles of  Q2, but also stable poles of 
H\,  depending  on the choice for Q2. 
3.  It is easy to select Q2 so that H2 in (4.48) is proper (when H\  is proper). Also, it 
is not difficult  to select Q2 so that the stability conditions are satisfied.  However, 
to conveniently  characterize  all Q2 that  satisfy  the stability  conditions  (i), (ii), 
or (iii) is not  straightforward,  unless  special conditions  apply. This is the  case 
for example when Hi  is stable, as in Corollary  4.4. 
4.  For further  discussion of the relation between propemess and stability in a sys 
tem described by a PMD, refer  to Chapter 6 of  [331 and also [9]. 
COROLLARY  4.4.  Given //i,  assume  that  its poles  are  stable. Let  H2 be  given by 
(4.48),  where  the  rational  matrix  Q2 is  such  that  (/  +  HiQ2)~^ exists.  The  eigen 
values  of  the  closed-loop  feedback  system  will  be  stable  (i.e.,  will  have  negative 
real  parts)  if  and  only  if  Q2 is  stable.  In  addition,  if  Hi  is  proper,  then  H2 and  all 
the transfer  matrices  in  (4.36)  and  (4.37)  are proper  if  and  only  if  Q2  is proper and 
det{I  + (lim,_oo//i)(lim,_oo Q2))  ^  0. 
Proof, When the poles of H\  are stable (i.e., have negative real parts), then the condi 
tions (i) or (ii) or (iii) of Theorem 4.3 are true if and only if the poles of Q2 are stable.  • 
Corollary  4.4 greatly  simplifies  the conditions  on Q2. However,  it is valid  only 
when Hi  has  stable poles. The result in this corollary  was pointed  out by Zames  in 
[38],  where  it was  used  to introduce  the  //°°-framework  of  optimal  control  system 
design. 
4.  Parameters  Sn  and 821-  At this point it is of interest to introduce the matri 
ces 
and 
S12  = (I-  HiH2r\ 
52i  = (I -  / / 2 ^ i ) '\ 
(4.49) 
which are of importance in control system design. They are the companion  sensitiv 
ity matrices  of  the feedback  loop.  Su  is  also  the transfer  function  between  U2  and 
r2,  while  ^21 is  the  transfer  function  between  ui  and  ri.  Note  that  Q2  =  H2{I  -
"HiH2r^  =  H2S12 =  S21H2  and  Qi  =  Hi(I  -  i/2//i)""^  =  H1S21 =  SnHi",  Also, 
H1Q2  =  S12 -  /, 22^1  =  ^21 -  /  and Q1H2 =  S12 -1,  H2Q1  =  S21  -  L  Now con 
sider Theorem 4.3 and note that 
H2  =  Q2S 12 
"^2""/22 "
(4.50) 
and  that  the conditions  (ii)  and  (iii)  can  be  written  as D.  ^[821, Q2] and  22 
^12 
DI 
which must be  stable in order to have  stable closed-loop  eigenvalues. This  implies 
that a necessary condition for stable closed-loop eigenvalues is that all unstable poles 
of Hi  must appear as zeros of 821  and of 812. 
In  general  it is not possible  to parameterize  all  stabilizing  controllers  in  terms 
of only 812 or 821, but this can be accomplished under certain assumptions on Hi.  In 
particular, we have the following  result. 
600 
Linear Systems 
COROLLARY  4.5.  Assume that detHx  7^  0. Let 
H2 = H[\Sn 
-  I)S^2  =  DdN{\Sn 
-  I)]Su' 
or 
H2 = 52-/(^21  -  I)H['  =  S2i'[(S2i  -  I)N{']Du 
(4-51) 
(4.52) 
where ^12 or ^21 are rational matrices such that S^2 ^^^ ^21^ exist. Then the eigenvalues 
of the closed-loop feedback  system will be stable if and only if 
(i)  S12 is such that the poles of H;\Sn-I) 
are stable, 
D^' 
^12 
(ii)  ^21 is such that the poles of Z)f^ [521, (52]-/)//f^]  =  [Dl^S2u  D^\S2i  - 
I)N;^Di] 
are stable. 
Proof.  The proof of this result follows  directly from  Theorem 4.3. 
• 
It is clear  from  (i) of Corollary  4.5 that  all the unstable  zeros  of ^i  must  cancel 
with  zeros  of  5*12  —  /,  which  is  the  transfer  function  between  yi  and  r2  [it  equals 
(/  -  H\H2)~^H\H2\.  Also  all the unstable poles of Hi  must  cancel  with  zeros 
ofSn. 
From  (ii) a similar  result  follows  for ^'21 -  /,  which  is the transfer  function  between 
j2  and ri  [it equals  (/  -  / / 2 ^ i ) ~ ^ ^ 2 ^ i]  and for 821 [see Exercise  7.23(c)  and (d)]. 
5.  Parameters  X2  and  X2'  Alternative  parameters,  closely  related  to  Q2, may 
be  used  in Theorem  4.3. To this  end, let 
X2  =  Di^Q2, 
and 
X2  =  Q2Di\ 
(4.53) 
COROLLARY  4.6.  Given//i, let 
H2  =  DiX2(I  + NiX2r^  =  [(/ + X2Ni)D^^]-^X2, 
(4.54) 
where  the rational  matrix  X2 is such  that  (/  + A^iX2)~^  exists. The eigenvalues  of the 
closed-loop  feedback  system  will  be  stable  (i.e.,  will  have  negative  real  parts)  if and 
only if X2 is selected  so that the poles of 
[iI  + X2N,)D^\X2] 
(4.55) 
are stable. Furthermore, these poles are precisely the eigenvalues of the closed-loop sys 
tem. In addition, if Hi  is proper, then H2 and all the transfer matrices in (4.36) and (4.37) 
are proper if and only if D1X2 is proper and det (I  +  (lim^-^oo Hi)(\ims^o,  D1X2)) 7^ 0. 
Proof.  Assume that the poles in (ii) of Theorem 4.3 are stable. Then, in view of Q2 = 
Z)iZ2,Dfi[/  +  G2^bG2]  =  Dl^lI  + DiX2NiD;\DiX2] 
X2Ni)D^\X2]^\so 
has stable poles. Conversely, if (4.55) has stable poles, then D]^^[I + Q2H1, Q2]  also has 
(the same) stable poles, where  Q2 was selected to be Q2 =  D1X2. The remainder of the 
corollary follows  easily in view of Theorem 4.3. 
=  [{I + 
Note  that X2 can be seen  to be the transfer  function  between  z\  and r2, since Q2 
is  the transfer  function  between  ui  =  Dizi  and r2 and Q2  =  D1X2.  Also  N1X2  = 
H1Q2  =  (I  -  HiH2Y^H\H2 
is  the transfer  function  matrix  between  y\  and  r2. It 
should  be  pointed  out  that  contrary  to  Corollary  4.4, the  result  in  Corollary  4.6 is 
valid  for Hi  unstable  as well  [7]. In a completely  analogous  manner,  it can easily  be 
shown  that  the following  result  is  true. 
COROLLARY  4.7.  Given//i, let 
H2  =  (1 + X2Ni)-^X2bi 
-  X2[b-,\I  + NxX2)r\ 
(4.56) 
where  the  rational  matrix  X2  is  such  that  (/  +  X2N\Y^  exists.  The  eigenvalues  of  the 
closed-loop  feedback  system  will  be  stable  (i.e.,  will  have  negative  real  parts)  if  and 
only if X2 is selected  so that the poles of 
X2 
D^\l  +  NiX2). 
(4.57) 
are stable. Furthermore, these poles are precisely the eigenvalues of the closed-loop sys 
tem. In addition, if Hi  is proper, then H2 and all the transfer matrices in (4.36) and (4.37) 
are proper if and only if ^2^1  is proper and det (/  + (lim^_>oo X2Di)(\ims^oo Hi))  7^ 0. 
601 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
EXAMPLE  4.3.  Consider  Hi  = 
s-h  1 
s-  1 
of  Example  4.1. In  view  of  Theorem  4.3,  all 
stabilizing  controllers  H2  are  given  by  i^2  =  G2  1 + 
s+  1 
where 
1 
1-H 
&^,a 
is  stable.  If  Q2  =  n/d, 
then 
—  stable  implies 
Id 
that  n 
{s -  \)n,  and d is stable. Also, 
1 
{s -  \)d  +  (5 -  \)n{s  + 1) 
d  + n{s+  1) 
^ -  1 
d{s-\) 
{s- 
\)d 
stable 
implies that d{\)  + n{\)2  =  0 and d is stable. Therefore,  for  stability  Q2  =  nid  with d 
stable, and  n  =  {s -  l)n,  d{l)  +  n{\)l  =  0. 
In view of Corollary 4.6, all stabilizing controllers H2 are given by H2  =  (^ -1)[1 + 
"^2(^+1)]""^^2",  where  1  +X2(S+  1)- 1 
,X2 
is stable. If X2  =  n/d,  then d is stable. 
and^(l) + /i(l)2  =  0 for internal stability. Note that ^2  =  n/d  =  D1X2  =  {s-l)X2  = 
(s -  l)nld. 
m 
1 
c2' 
"is""- "
-^+  ^ 
c2 
s-
EXAMPLE  4.4.  Consider  Hi(5) 
- r [ l ,5  +  l]  =  Dr^TVi, whichis  an 
Ic  polynomial  MFD.  In  view  of  Theorem  4.3, all  stabilizing  controllers  H2  are  given 
by  H2  =  Q2(l  + HiQ2)~\  where  the  poles  of 
5f  ^ are  stable.  If  Q2 
22 
1  +  ^^162 
, then  Q2D^^  stable implies that ni  =  s^fii,  ^2  =  s^h2 and d is stable. Now (1  + 
un^f^-\ 
HiQ2)Di 
- 
s^ + rii + {s +  l)n2  1 
^  = 
1 +  m  +  (^ +  l)/22 
-^ 
stable imposes additional 
^^ 
conditions on fii  and «2. 
EXAMPLE  4.5.  Consider  Hi  = 
lary  4.4  applies. All  stabilizing  controllers  H2 are given  by H2  =  ^2(1  +  ^ 1 6 2 )^  = 
n  ({s  +  \)d  + {s- 
d 
Furthermore,  if  Q2 is  proper  with  lim^-^oo Q2(^)  ^  - 1, then  H2  will  be  proper.  Note 
1 
-.  This  system  is  stable  and  therefore  Corol 
5 +  r 
Dllei 
n(s  +  1) 
-,  where  Q2 
{s+l)d  + 
(s+l)d 
\)n^~^ 
is  stable. 
{s-\)n 
n/d 
) 
that in view  of Theorem  4.3, the  closed-loop  eigenvalues  will be  the poles  of 
(5 +  1) +  (5 -  \)n  n 
'd\ 
-[(s+  l)d  + (s- 
(s+l)^d 
l)n,(s+ 
{s+\)d 
l)nl 
1 
1 
s+  1 
Relations  among  parameters.  It  is  now  straightforward  to  derive  relations 
among the parameters  Q2 and  Qi;  X2 and X2; D^,  N^,  and D^,  Nk', K\  and  also 512 
and 521- In particular, in view of (4.32) to (4.35), we have 
602 
Linear Systems 
(22  =  //2(/  -  HxH2r^  =  (/  -  H2Hiy^H2 
=  N2D^^Di  =  Dibl^N2 
=  -(YiDk  + D,Nk)Dl^bx 
=  - (f  1 +  DiK)bi  =  -£>i(Fi  +  KDi). 
=  ~Dxbl\bkYi 
+  NuDi) 
(4.58) 
Also, 
Qi  =  Hid  -  H2H1)-'  =  (/  -  H,H2r'Hi 
=  NiDl^b2  =  D2Dl^Ni 
=  Nibl\bkX, 
=  NiiXi  -KNi)  =  (Xi  -  NiK)Ni. 
-  N„Ni)  =  (XiDk  -  NiNk)D-k^Ni 
(4.59) 
The parameters  Q2 are used when the system Si  is assumed to be given. We have 
K  =  -D-[\Q2  +  Yrb,)bi' 
=  -D\\Q2 
+  D,Y{)b\\ 
(4.60) 
Next, we note that in view of (4.49) and (4.50), we have 
5i2  =  /  +  HxQ2  =  /  +  Nxbl^N2  =  /  -  Nibl\bkYx 
+ A^2^i) 
=  /  -  A^i(yi  +  Kbx) 
and 
521  =/  +  Q2H1  =  1 + N2D^^Ni  =  I-  (YiDk  +  DxNk)Dl^bi 
=  /  -  (fi  +  DxK)bx. 
(4.61) 
(4.62) 
From  (4.53)  it now  follows  that  Q2  =  D1X2  =  X2D1, from  which  the  parameters 
X2 and X2 can be expressed  as 
X2  =  - ( 7 1+  Kbi) 
and 
X2  =  - ( ?i  +  DiK). 
(4.63) 
The expressions  of  H2  in terms of the parameters  are now  summarized: 
H2  =  -0kXi 
-  NkNi)-\bkYi 
+ Nkbi)  =  - ( f , £ ),  +  DiNk)iXiDk 
-  T^XN^Y' 
=  -(Xi  -  KNxr\Yx 
+  Kbx)  =  - ( Fi  +  £>ii^)(^i  - 
= (/ + Q2Hxr'Q2  = [DfH/ + e2Hi)]-uor'Q2] 
=  Qiii + HxQi)-^ =  [e25r>][(/ + i?ie2)5ri]-' 
=  52-/22  =  [D-x'S2xr\D-x'Q2\  =  Q2Sx^  =  [Q2b-x'}[Sx2b~x'T' 
=  [(/  +  X2Nx)Dx^r'X2  =  MbxHl 
+ NiX2)r\ 
^xKT^ 
(4.64) 
6.  Parameters  Lx, La and  Lx,  L2.  Expressions (4.64) that describe H2  as a ratio 
of rational  matrices can also be derived  in an alternative way, using a theorem  that 
we establish  next. This result  also provides  a link between  the development  of this 
subsection  and the descriptions of all stabilizing controllers using proper and  stable 
factorizations  given in Subsection  7.4C. 
Consider the feedback  system of Fig.  7.5 and assume that 5i  is controllable and 
observable. The following  constitutes one of the principal results of this  section. 
THEOREM 4.8.  Let the transfer  function  matrix of the system Si  be Hi  with Hi  = 
NiD^^iHi  =  D^^Ni)  being  a coprime polynomial  matrix  factorization.  If  H2  is the 
transfer function of ^2,  then the eigenvalues of the  closed-loop feedback system are sta 
ble if and only if H2  can be written as 
//2  =  L^^U 
(H2  =  L1L2 ^), 
(4.65) 
603 
where the L2, L\  (Li, L2) are stable rational matrices with detL2  #  0 {detLi  #  0), which 
satisfy 
L2D1 -LiNi  =  I 
01L2  -NiLi  =  I). 
(4.66) 
Furthermore, if 
[L2,Li]  =  D-,'[D2,N2] 
DZ 
(4.67) 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
are coprime polynomial  matrix factorizations,  then  the closed-loop  description  is  given 
by 
DkZ  =  02,  N2] 
D,z  =  [Ni,  bi] 
' 
72. 
In 
yi 
J 2. 
y\ 
z + 
0 
01 
.-/  oj 
Pi. 
D2 
N2_ 
z + 
0 
-/I 
.0  0  J 
In 
1^2. 
(4.68) 
Proof,  The proof of the parts in parentheses will not be shown since it follows the proof 
given  below  in  a completely  analogous  manner.  Let  [Li, L2] be  stable  with  detL2  9^  0 
and  satisfying  (4.65)  and  (4.66)  and  write  an  Ic polynomial  matrix  factorization  as  in 
(4.67).  Then  D2D1  -  N2N1  =  D^,  where  D^^  exists  and  is  stable.  Furthermore,  the 
pair  02,  N2)  is  Ic  [since  any  eld  of  the  pair  (D2, A^2) would  be  an  Id  of  Dk]  and  ^2 ^ 
exists. Therefore," the closed-loop system with//2  =  ^ 2 ^ ^!  ""^ 62^/^2is well defined. Its "
internal description is given in (4.68)  [see also (4.11)], and the closed-loop  eigenvalues 
are the stable roots of  detbk. 
Now let H2  =  62^  N2 be an Ic polynomial factorization and note that the closed-loop 
system is given by (4.68), where Dk  =  D2D1 -  N2N.  Assume that D^^  is stable. Define 
[L2, Li]  =  bl^02,  N2] and note the D^  and 02,  A^2]  are Ic since the pair 02,  N2) is  Ic 
Then H2  =  ^2 ^^1 where L2 and Li  are stable with L2D1 
LiNi  =  /. 
In  view  of  the  above  theorem,  all  stabilizing  H2  are  given  by  (4.65),  v^here  the 
stable  rational  matrices  L2, Li  (Li, L2)  span  all  solutions  of  the  Diophantine  Equa 
tion  given  in  (4.66).  There  are  different  ways  of  parameterizing  all  stable  solutions 
L2, Li  (L2," Li)  of  (4.66)  with det  L2  7^ 0  (det  L2  ¥"" 0)", each  one leading  to a  different 
parameterization  of  all  stabilizing  H^.  In  fact,  in  this  way  one  may  generate  the  pa-
rameterizations  developed  above, thus providing  alternative  proofs  for  those  results. 
This  is  shown  in  the  next  corollary. 
COROLLARY  4.9.  All Stabilizing H2 are given in the  following. 
(i) 
^2  ~  ^2  ^1 
{H2  =  L1L2'), 
(4.69) 
where the L2, Li  (Li, L2) are stable with detL2  7^ 0 (detL2  7^ 0) and L2D1 -  L\N\  =  / 
0\L2  — N\Li  =  /). The closed-loop eigenvalues  are the poles of  [L2, ^i]  (L 
VLMJ 
(ii)  H2  =  -(Xi 
-  KNir'iYi 
+  KDO 
[H2 =  -(Yi  +  DiK)(Xi 
- 
NiKy'l 
(4.70) 
where i^ is any stable matrix such that J^r(Zi  -  i^A^i)  #  0[det(Xi-NiK) 
Fi,Xi,Fi  satisfy  t/t/  -1  _  r  ^i 
[-Af, 
[7  01 
0 
/. 
pi 
[iV, 
- ^I 
Xlj 
Yx\ 
61J 
¥^  0].TheZi, 
, where f/  is a unimodular 
604 
Linear  Systems 
matrix. The closed-loop eigenvalues  are the poles of 
[Xi  -  KNi,  Yi  +  KDi] 
Xi  -  NiK 
or equivalently, the poles of  K. 
(iii) 
H2  =  [D-,\I  +  Q2H,)r'[D-,'Q2] 
=  (/  +  QiH^r'Qi 
where  Q2 is such that 
[D-,\I  +  Q2H,),D-,'Q2] 
Qib'x' 
{I  +  H,Q2)b-, 
(4.71) 
(4.72) 
(4.73) 
is stable and det{I  +  Q2H1) 7^ 0 (det(I  + H1Q2) ^  0). The closed-loop eigenvalues  are 
the poles of (4.73). 
(iv) 
H2  =  [D^'S2i]-'[D^'Q2] 
(H2  = 
[Q2b^'][Si2b^']-'), 
(4.74) 
where 5*21  (Su)  and  Q2 are such that 
[D^'S2uD^'Q2] 
Qib-,' 
W 
VSnb-,\ 
(4.75) 
is  stable  with  ^^^5*21 7^ 0  (detSu  ^  0)  and ^'21 
closed-loop eigenvalues  are the poles of (4.75). 
Q2H2  =  HSn-HiQ2 
=  /).  The 
(V)  H2  =  [(I  + 
X2Ni)D^'r'X2 
(H2  =  X2[b-,\I  +  N,X2)r'), 
(4.76) 
where X2 (X2) is such that 
[(I  +  X2Ni)D^\X2] 
X2 
b^\l  +  NiX2)\ 
(4.77) 
is stable and det(I  +  ^ 2 ^)  7^ 0 (det(I  + N1X2) 7^  0). The closed-loop eigenvalues  are 
the poles of (4.77). 
Proof.  The  proof  is  straightforward  in  view  of  Theorem  4.8. Part  (i)  follows  directly 
from  Theorem 4.8. To show  (ii), note that  [Xi  -  KNi]Di  -  [-(Fi  +  KDiWi  =  I  for 
any  K  (compare  with  Theorem  4.2).  To  show  (iii),  note  that  [Z)f ^7  +  Q2Hi)]Di 
-
[D^^Q2]Ni  =  /  for  any  Q2  (compare  with  Theorem  4.3).  To  show  (iv),  note  that 
[D^^S2i]Di  -  [D^^Q2]Ni  =  /  if  and  only  if  S21 -  Q2H1  =  1. To show  (v), note  that 
[(/  +  X2Ni)Dl^^]Di  -  [X2\Ni  =  I  for  any X2  (compare  with  Corollaries  4.6  and 4.7). 
What has not been  shown  yet is that  all stabilizing H2 can be expressed  by, say,  (4.70) 
in (ii). This can be accomplished  in a manner  analogous to the proof  of the theorem. In 
particular,  any  stabilizing  H2  =  02^N2,  where  the  pair  (D2,iV2)  is  Ic,  that  gives  rise 
to  a  closed-loop  description  (4.68)  implies  that  bl^[D2,  -N2]  =  [Xi  -  KNi,  - ( Fi  + 
KDi)]  =  [I,K] 
Xi 
Yi] 
-Ni  D ij 
=  [/,  K]U,  where  U  is  a.  unimodular  matrix.  Therefore, 
from  [/,  K]  =  b}^^ 02,  —N2W  ^ it follows  that a stable K can be determined  uniquely. 
Similarly, in (iii), the relation D ' ^ ^ i,  A^2] =  D^^[I  + Q2H1, Q2] =  D^^[I, Q] 
I 
Hi 
determines  uniquely  a stable  Q2  =  Dibj^^N2'  The details  are left  to the reader.  These 
results were of course also shown in Theorems 4.2 and 4.3, using alternative approaches. 
Remarks 
In Theorem 4.8  and Corollary  4.9, H\  may or may not be proper. Also, the  sta 
bilizing  H2 may  or may  not be proper. Thus, the above results  characterize  all  sta 
bilizing H2, both proper  and not proper. It is frequently  desirable to restrict H\  and 
H2 to be proper  rational  matrices.  The  problem  of  interest  then  is  to determine  all 
proper  stabilizing  H2, given  a proper  Hi.  Note  that  this  problem  has  already  been 
addressed previously in this section using the parameter Q2, and it will be studied at 
length in Subsection  7.4C. 
We conclude  by  summarizing  the relations  among  the parameters  used  in  this 
subsection. Note that the relations for all parameters, except Li, L2 and L2, L\,  were 
derived in (4.58) to (4.64). The relations to L2, Li  can easily be obtained in view of 
Corollary 4.9. These relations  are summarized  as: 
605 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
L2 
u 
and 
Also, 
Xi-KNi 
=  D\\l  + Q2Hx)  = 
D^'S2i  =(I  +  X2Ni)D^' 
-{Y,+KD,) 
=  D-,'Q2  =  X2. 
(4.78) 
L2 
Xi  -  NyK  =  (1 + HiQ2)Di' 
-  SnDi'  =  D^^I  +  N1X2) 
and 
Li  =  -(Y,^D,K) 
=  Q2D-,'  =X2. 
(4.79) 
EXAMPLE 4.6.  Consider//i  =  s+  1  In view of Corollary 4.9, all stabilizing control 
lers are given by H2 = L2^L\, where the L2, L\ are stable and satisfy L2D1 -L\N\  =  /. 
Now  in  view  of  (4.78)  and  (4.79), L2  =  (/  + X2Ni)D\^  and  Lx  = X2. All ap 
propriate  X2, however,  were  characterized  in  Example  4.3  to  be  X2  =  hid  with d 
stable  and  d{l)  +  n{l)2  =  0.  Therefore,  all  appropriate  L2, L\  are  given  by  L2 = 
d  +  h(s  +  I) 
; 
d 
l)(i, i.e.,/2(1)  =  -^d(l). 
=  -7, ^1  =  -:, where d is stable and n is such that d + n{s + \)  = 
• 
d  ~ 
d 
s -  I 
^1 
d 
(s- 
1  , 
i ~. 
~^ 
,1 
,. 
I 
, 
B.  State Feedback  and  State  Estimation 
State feedback  and  state estimation  are studied  in this  subsection,  using PMFDs of 
systems.  Our  current  development,  which  offers  additional  insight,  parallels  that 
given  in  Chapter  4,  where  state-space  descriptions  were  used.  The  study  of  state 
feedback  and  state  estimation,  using  PMFDs,  however,  is  important  in  its  own 
right. An additional reason for  discussing  state feedback  and  state observers  at this 
point  is  to provide  the  necessary  background  needed  to  connect  the  parameteriza-
tions  of  all  stabilizing  controllers  using  proper  and  stable  factorizations  with  the 
internal  descriptions  (PMDs  or PMFDs)  of  systems. This  is  accomplished  in  Sub 
section  7.4C. 
State  feedback 
State feedback  control laws are closely related to the state-space  representations 
of systems. Recall from  Chapter 4 that  given 
X =  Ax  +  Bu, 
y  =  Cx  -^ Du 
(4.80) 
606 
Linear Systems 
"with  A  G  /^""><^ B  G  /^""><^", C  G  iR^x^  and  D  G  7?^><^, the  hnear  state  feedback 
control law is defined  by 
u  =  Fx  +  Gr, 
(4.81) 
where F  G /^^^^  and G  G i^'^x^  with  G nonsingular. Frequently,  G  -  /.  Then  the 
closed-loop system description is given by 
i:  =  (A  +  BF)x  +  BGr, 
y  =  {C  + DF)x  +  DGr 
(4.82) 
and the closed-loop eigenvalues are the zeros of det [ql  -  (A +  BF)].  In view of the 
relation 
ql  -A-BF 
BG 
- (C  +  £>7^)  DG 
^/ -  ^  5l 
\ 
^ 
-c 
[-F  G 
D\ 
^ 
(4.83) 
it is not difficult  to  see that  any  geld  of  [ql  -  A, B\  will be  an Id of  ^/  -  A -  BF 
for any F. This implies that for complete eigenvalue assignment, ql  — A  and B must 
be left  coprime, i.e., (A, B) must be completely  controllable, which is a well-known 
result (see Chapter 4). Also, for stability, (A, 5) must be a stabilizable pair. Note that 
any geld of  \_ql  -  A, 5]  will be an Id of  \ql  -  A-  BF,  BG]  for  any F and  G.  Since 
here G is taken to be nonsingular,  [ql  -  A, B] and [ql -  A-  BF,  BG] have the same 
geld, i.e., the open- and closed-loop systems have precisely the same uncontrollable 
eigenvalues. When G is singular, the closed-loop system may have additional uncon 
trollable modes (show this). Although F does not affect  the uncontrollable modes of 
the  system, it may  alter its unobservable  modes. For example,  in an  SISO  control 
lable and observable system, it is possible to select F so that some of the closed-loop 
eigenvalues  are at the same location  as the finite zeros, and therefore,  they  become 
unobservable. This corresponds to pole/zero cancellations in the closed-loop  transfer 
function.  The  closed-loop  unobservable  eigenvalues  can  also be  studied  by  means 
of relation  (4.83) and the gcrd of the pair (ql  -  A-  BF,-C 
-  DF), 
The  effects  of  state  feedback  control  laws  can  conveniently  be  studied  using 
polynomial matrix descriptions. In particular,  assume that the state-space  represen 
tation  (4.80) is controllable  and in controller  form  [A^  Be, Cc, Dc)  (see Chapter  3). 
An equivalent PMFD is then given by 
Dc(q)Zc(t)  =  u(t), 
y(t)  =  Nc(q)Zc(t) 
(4.84) 
with Dciq)  G R[q]'^'''^  and A^^(^) G R[q]P'''^, where 
Be 
Dc 
0 
^PA 
Dciq) 
-NAq) 
Im 
0. 
ql  -  Ac 
-Cc 
Be] 
Del 
\Sciq) 
[  0 
(4.85) 
with the pair (B^  ql  -  Ac) being Ic and the pair (Ddq),  Sdq))  being re  [see (3.26)]. 
The matrix Sdq)  =  blockdiag[(1,  q,...,  ^^'~^)^]  is an  n  X m matrix  with J/,  /  = 
1,...,  m, the controllability indices of {A^, Be, Ce, Dc). Note that the above relations 
can be written as 
{ql  -  Ac)Se{q)  =  BcDc(q), 
Ndq)  =  CcSdq)  +  DcDdq), 
(4.86) 
which  were  derived  via  the  Structure  Theorem  in  Subsection  3.4D.  Note  that  the 
states are related by xdt)  =  Sc(q)Zc(t). When the state feedback  control law 
u(t)  =  FcXeit)  +  Gr{t)  =  FeSe(q)Zc(t)  +  Gr(t)  -  Fe(q)Zc(t)  +  Gr(t) 
(4.87) 
607 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
is  applied,  the  closed-loop  system  state-space  representation  is  {Ac  +  BcFc, BcG, 
Cc +  DcFc, DcG} and the polynomial matrix description is 
Dp{q)Zc{t)  = 
Gr(t\ 
y(t)  =  NF(q)zM 
(4.88) 
where Dj.(^)  ^  Ddq)  -  Fdq)  = 
resentations  are equivalent  since 
:  Dciq)  -  FcSc(q) and Npiq)  =  Ndql  These rep-
Be 
Dc 
0 
Ip\ 
\Dc(q)  -  FcSciq)  G 
0_ 
[ 
-Nc(q) 
ql  -  Ac-  BcFc 
^c 
J-^c^ c 
BcG] 
DCG\ 
\Sc(q) 
[  0 
0 
(4.89) 
where the pair (Be, ql  — Ac  -  BcFc) is Ic and the pair (Ddq)  -  FcSdq),  Sdq))  is re 
(see Subsection 7.3 A). Note that (ql  -Ac-  BcFc)Sc(q)  =  Bc[Dc(q) -  FcSc(q)] and 
NF(q)  =  (Cc + DcFc)Sc(q) + Dc[Dc(q)-FcSc(q)]  =  CcSc(q) +DcDc(q)  =  Nc(q\ 
i.e., the numerator Nc(q)  is invariant under state feedback.  Note that Nc(q)  contains 
the zeros of the system (see Subsection  7.3B). 
Now  assume  that  the  state-space  representation  in  (4.80)  is  controllable  but 
not  necessarily  in  controller  form,  and  let  A  =  Q~^AcQ,  B  =  Q~^Bc,  C  =  CcQ, 
D  =  Dc  with  Q  a  similarity  transformation  matrix.  Relations  (4.86)  then  assume 
the  form 
(ql  -  A)S(q)  =  BDc(q), 
Nc(q)  =  CS(q)  +  DDc(q\ 
(4.90) 
where  S(q)  =  Q-^Sc(q).  Then 
Dc(q)Zc(t)  =  u(t\ 
y(t)  =  Nc(q)Zc(t) 
(4.91) 
is an equivalent polynomial matrix description  and now x(t)  =  S(q)zc(t).  Note that 
deg^. S(q)  =  deg^. Sc(q)  =  di, i  =  1,...,  m, which are the controllability indices of 
the system. The linear state feedback  control law is then given by 
u(t)  =  Fx(t)  +  Gr(t)  =  FS(q)zc(t)  +  Gr(t)  =  Fc(q)Zc(t)  +  Gr(tl 
(4.92) 
W e n o w h a v e ( ^ / - A - 5 F ) S ( ^)  -  B[Dc(q)-FS(q)\dindNc(q) 
D[Dc(q)  -  FS(q)]  =  CS(q)  +  DDc(q\ 
=  (C + DF)S(q)  + 
In view of the above, it can be seen that linear state feedback can be equivalently 
defined  for the case of (controllable) polynomial matrix right fractional  descriptions 
as shown in the following.  Given 
D(q)z(t)  -  u(t), 
y(t)  =  N(q)z(tl 
(4.93) 
where D(q)  is column reduced, define  the linear state-feedback  control law by 
u(t)  =  F(q)z(t)  +  Gr(t), 
(4.94) 
where  deg^. F(q)  <  deg^. D(q)  with  F(q) 
closed-loop system is then described by 
/^M^x^,  G  E  7?^x^, detG  7^ 0.  The 
DF(q)z(t)  =  Gr(t\ 
y(t)  =  NF(q)z(t), 
(4.95) 
where  DF(q)  =  D(q)  -  F(q),  NF(q)  =  N(q).  The  F(q)  =  FcSc(q)  can be  chosen 
to  arbitrarily  assign  the polynomial  entries  of  D(q),  up  to  and  including  the  terms 
of  degrees  J/  -  1 in  the  /th  column  of  D(q),  i  ^  1,...,  m.  In  fact,  recall  from 
the development in Chapter 3 (Theorem 4.10—the  Structure Theorem) that D(q)  — 
=  B^^[diag[q^q-
F(q)  =  D(q)-FcSc(q)  =  B'^ldiagiq^q-AmSc(q)]-FcSc(q) 
608 
Linear Systems 
(Afn +  BmFc)Sc{q)]. It was shown  in Chapter  4 how to appropriately  select  Fc to 
arbitrarily  assign all the closed-loop eigenvalues, i.e., the roots of det (D(q)  -  F{q)). 
Now  consider  the closed-loop  state-space  representation  (4.82).  As was dis 
cussed in Chapter 4, the closed-loop transfer  function  can be written as 
HF,G{^)  =  [(C + DF)[sI  -  (A + BF)]-^B  + D]G 
=  [C(sl -  A)-^B  + D][F[sI  -  (A + BF)Y^B  + /]G 
=  H(s)He(s). 
(4.96) 
Here H(s) is the open-loop transfer  function,  and He(s) represents the transfer  func 
tion of a system that, if connected  in series  with the given  system,  will  apparently 
produce the same overall transfer  function  as the feedback  system. Recall that  this 
issue  was addressed  at length  in Chapter  4. If the PMD (4.93)  is used,  then the 
closed-loop transfer  function  is given by 
HF,G(S)  =  NF(S)DF\S)G 
=  N(s)D^\s)G 
=  [N(s)D-\s)][D(s)D^\s)]G 
= H(s)He(s). 
(4.97) 
It is not difficult  to verify  that  the system  {Dpiq),  Im, D{q), 0} is equivalent  to the 
system {A + BF,  B, F, Im}, both of which have the same transfer function He(s)  (show 
this). 
Relation  (4.97) also impHes that 
H(s)  =  N(s)D'\s) 
= 
HF,G(S)H;\S) 
=  [N(s)D^\s)G][D(s)D^\s)G]-\ 
(4.98) 
Note that both HF,G and He are proper and stable (H(s) is proper). Furthermore, H~^ 
is also proper. Thus, HF,G  and He are proper and stable factors in the MFD 
H(s)  =  HF,G(S)H;\S). 
(4.99) 
This  is further  discussed  in the next  subsection,  where  it is shown  how all proper 
and stable right MFDs can be generated by means of state feedback.  The left  proper 
and stable MFDs can be generated from  observers of the partial  state. Observers of 
the state are examined  next. 
State  observers 
State observers were discussed at length in Chapter 4. Here we wish to present 
additional material concerning  observers in terms of PMDs. 
Consider the plant S and the observer  Sob of Fig. 7.6 and let the plant S be de 
scribed by (4.93)," where D(q) G R[qr'''^  and N(q)  G Rlq^""^",  As was discussed 
above, when D(q) is column  reduced,  the linear  state feedback  control law can be 
defined by u(t)  = F(q)z(t)  -h r(t), where deg^. F < deg^. D,i  =  1,...,  m. Then the 
^ 
J 
+ 
u  1 
*• 
o 
1 
y 
H  ^ob r 
' 
' 
w 
FIGURE 7.6 
Plant and observer 
609 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
closed-loop system is represented  by 
[D{q) -  F{q)Ut)  =  r(t\ 
y(t)  ==  N(q)z(t). 
(4.100) 
When the state is not readily available, then a state observer for Fz  may be used. Let 
the observer Sob be described by 
Q(q)Zob(t)=^ 
[K(qlH(q)] 
u{t) 
W(0  =  Zob(t), 
(4.101) 
"where  Q{q)  E  R[qT'''^.  K(q)  G  Riq^'""'^",  and H(q)  G  R[qr''P.  Note that in Fig. 
7.6 u(t)  == w(t) + r(t). Assume now that the observer polynomial matrices Q, K, and 
H satisfy  the relation 
K(q)D(q)  +  H(q)N(q)  =  Q(q)F(q), 
(4.102) 
Recall  that Q~^ 
where  Q'^  and  Q~^[K," H]  are proper  and  stable  (F  G  Rlq^'""'^). "
"proper is needed  for  Q(q)Zob(t)  =  0 to be a ""well-formed""  set of differential  equa "
tions so as to avoid impulsive behavior at ^ =  0. Note that if Q is, say, row or column 
proper, then  Q~^ is proper. The rational function  Q~^[K, H]  is the transfer  function 
of the observer. Then  w  =  Zob =  Q~^[Ku  +  Hy]  =  Q~^[KD  +  HN]z  =  Fz,  i.e., 
Zob is a candidate for estimating a function  F(q)z(t)  of the partial state z(t).  To show 
this, consider the closed-loop internal  description 
D(q) 
-Im 
-Q(q)F(q)  Q(q) 
\  z(t) 
• 
[Zob(t). 
Um 
[0_ r(t) 
),0] 
y(t)  =  [N(qlO] 
_Zol 
(4.103) 
derived  by  using  u  =  Dz  =  w  +  r  =  Zob  -^ ^  and Qzob 
HN)z  =  QFz,  and consider the unimodular  transformation 
Ku  + Hy  =  (KD  + 
Im 
[-F(q) 
z(t) 
Zob(t). 
0 
z(t) 
Zob  -  F(q)z(t) 
Z(t) 
e(t) 
. Then the closed-loop  system description  becomes 
D(q)-Fiq) 
0 
-I 
Q(q)\ 
Z(t) 
e(t) 
r(t) 
y(t)  =  [N(q\0] 
zit) 
e{t)_ 
(4.104) 
First,  note  that  the  closed-loop  eigenvalues  are  the  roots  of  detiP 
-  F)detQ, 
and  therefore,  the  closed-loop  system  is  stable  if  and  only  if  all  the  roots  of  both 
detiP  -  F)  and  detQ  have  negative  real  parts.  The  roots  of  det{D  -  F)  are  of 
course the closed-loop eigenvalues  under  state feedback  when there is no  observer, 
while  the  roots  of  det Q  are  the  observer  eigenvalues  that  are  taken  to  be  stable. 
Note  that  in  view  of  Q(q)e(t)  =  0,  where  Q~^(q)  is  proper  and  stable,  the  error 
"^(0  =""  ZobO)  -  F(q)z(t)  =  w(t)  -  F(q)z(t)  will go to zero as t goes to infinity",  and 
therefore, the output w(t) of the observer will asymptotically approach the function of 
the state F(q)z(t).  This will happen independently of r(t). Note that the roots of det Q 
are uncontrollable  from  r  as can  easily  be  seen, using,  e.g.,  the  eigenvalue  test  for 
610 
Linear Systems 
controllability.  As  expected,  these  uncontrollable  eigenvalues  cancel  in  the  closed-
loop transfer  function  matrix given by 
ms),o] 
D(s)-F{s) 
0 
-1 
--N{s)[D{s)-F{s)]-
(4.105) 
In  other  words,  after  the  transients  caused  by  initial  conditions  have  died  out  (see 
Chapter 4), the system behaves to the outside world as though  an observer were not 
present. The observer in (4.101) was introduced in Wolovich [36]. 
For  an  observer  (4.101)  to  exist,  K,H,  and  Q  must  satisfy  the  Diophantine 
Equation  KD + HN  =  QF  given  in  (4.102),  where  QT^  and  Q~^[K^H]  are  proper 
and  stable  to  ensure  causality.  Note  that  if  Dp  =  D — F,  then  F  =  D — Df  and 
KD + HN  =  Q{D-DF), 
or {Q-K)D  + {-H)N  =  QDp,  which implies that 
[Q-\Q-K)][DD-p']  + 
[-Q-'H][ND-p']=L 
(4.106) 
The pair (g  ^{Q — K)^—Q  ^H) is a proper and stable solution of the equation XD  + 
YN  = /,  where  D = DD^^  and N  = ND^^  are  proper  and  stable.  This  equation  is 
important in the parameterization  of  all  stabilizing  feedback  controllers  when  using 
the ring of proper and stable rational functions,  discussed in the next  subsection. 
It is possible to implement the observer discussed above in an alternative manner. 
In particular, u = w^r  = Q~^Ku^Q~^Hy  + r impUes that ( /-  Q~^K)u  = QT^Hy  + 
r,oxu  =  {I-Q-^K)-\Q-^Hy 
+  r),ox 
u =  {Q-K)-^Q{Q-^Hy 
+ r). 
(4.107) 
This corresponds to the configuration  in Fig. 7.7. 
o 
{Q-K)-^Q 
Q-'H 
FIGURE 7.7 
Observer-based controller implementation 
Note  that  the  feedback  path  controller  Q~^H  is  always  stable,  while  the  con 
troller  in  the  feedforward  path  is  biproper  (i.e.,  it  along  with  its  inverse  is  proper) 
but not necessarily  stable. If the external input r is of no interest, then take r =  0, in 
which case we have 
, 
u={Q-K)-^Hy. 
(4.108) 
This corresponds to the configuration  depicted in Fig. 7.8. 
c i 
^ 
J i 
""" "
S 
y 
ff^ 
(f ^  — T\j 
IX\ -1  U 
r 7 
FIGURE 7.8 
Observer-based controller implementation when r --
It is of interest  to compare these results  with  the corresponding  state-space  re 
sults in Chapter 4. In particular, consider the state-space plant representation  (4.80) 
and assume that it is controllable and observable. Now comparing Fig. 7.7 with Fig. 
4.7 of Chapter 4, we obtain, in view of (4.25) and  (4.24) of Chapter 4, the relations 
(Q(s)-K(s))-'Q(s) 
+ 
-  KD)  -h /,  Q-\s)H{s)  =  Gy(s)  =  F[sl  -  (A -  KC)]-^K  and 
BF  -  KDF)r\B 
Q-\s)K(s)  =  Guis)  =  F[sI-(A-KC)]-\B-KDXA\so,(Q(s)-K{s)r^H(s) 
= 
(/ -  Gu(s))~^Gy(s)  =  F[sl  -{A-KC-\-BF- 
(see Fig. 7.8). It is there 
fore  clear  that  the  two  degrees  of  freedom  controller  in  Fig.  4.7  of  Chapter  4  is  a 
special case (of order n) of the controller in Fig. 7.7. 
=  (I  -  Gu(s))-'  =  F[sI-{A-KC 
=  (I  -  Q-\s)K(s)r' 
KDF)T^K 
611 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
EXAMPLE 4.7.  Consider ^(5*) 
given in Example 4.2 of Chapter 4. In 
view of the above, it is not difficult  to see that the results developed in Example 4.2 can 
also be derived if we let 2(5)  =  s^ + d\s + d{),F{s) = (2-ai)s  + (2-ao)  = 
[^ao-l,2-
2] 
=  FS(sl  K(s) 
ai 
s(2 -  ai)  -  do(^ao -  1), and  H{s)  =  s{{do  -  2)(^ao  -
di)(ao -  2) + (do  -  2)(s -  ai)X which satisfy (4.102). 
1) + (di -  2)(2 -  ai)) + ((do 
• 
Verify this. 
Finally,  it remains  to  be  shown  that  polynomial  matrices  K,  H,  and  Q,  which 
"satisfy  (4.102)  with  Q~^  and  g "" ^ [ ^ ", / /]  proper  and  stable,  exist.  Here  deg^.F  < 
deg^. D, where D is assumed to be column reduced  and the N,  D are assumed to be 
re. The system S is assumed to be controllable and observable. That such K, H, and Q 
exist will not be shown here. This is shown in Wolovich  [36], where an algorithm is 
given that is based on the Eliminant Matrix ofD  and N  (see Subsection 7.2E, Theo 
rem 2.13, and Lemma 2.14) to select an appropriate row reduced Q and to determine 
K and H. Note that (4.102) can also be solved by using other methodologies, such as 
polynomial matrix interpolation  (see the Appendix). 
C.  Stabilizing  Feedback  Controllers  Using Proper  and  Stable  MFDs 
Now  consider  systems  ^i  and  ^2  connected  in  a feedback  configuration  as  shown 
in Fig. 7.5. Let  system ^i  be controllable  and observable  and let it be described  by 
its  transfer  function  matrix  Hi.  In  Subsection  7.4A,  all  systems  ^2  that  internally 
stabilize the closed-loop feedback  system were parametrically characterized. In that 
development  Hi  was  not  necessarily  proper,  and  the  stabilizing  H2  as  well  as  the 
closed-loop  system transfer  function  were not necessarily  proper either. Recall  that 
a system is said to be internally  stable when all its eigenvalues, which  are the roots 
of its characteristic polynomial, have strictly negative real parts. Polynomial  matrix 
descriptions  that  can  easily  handle  the  case  of  nonproper  transfer  functions  were 
used to derive the results in Subsection 7.4A, and the case of proper Hi  and H2 was 
handled by restricting the parameters used to characterize all stabilizing controllers. 
Here  we  concentrate  exclusively  on  the  case  of  proper  Hi  and  parametrically 
characterize  all proper H2 that internally  stabilize the closed-loop  system. For this, 
proper and stable MFDs of Hi  and H2 are used. These are now  described. 
Consider  H(s)  G  R(sy^^ 
to  be  proper,  i.e.,  \ims-^ooH(s)  <  00, and  write  the 
MFD as 
H(s)  =  N'(s)D'(sy 
(4.109) 
612 
Linear Systems 
where the N'(s)  andD'(s)  are proper and stable rational matrices that we denote here as 
"A^'(^)  ^  RH^^'^mdD'is)  G /?H^>^""'; that is", they are matrices with elements in/?^oo, 
the set of all proper and stable rational functions  with real coefficients.  For instance, 
if  H(s) 
s-  1 
(s -  2)(s  +  1) 
then  H(s) 
s-  1 
(s +  2)(s  +  3) 
(s -  2)(s  +  1) 
(s +  2)(s  +  3) 
"""  5-  1  1 "
_(S+  1)2 J 
Is-2' 
[s + l_ 
1 
are examples of proper and stable MFDs. 
A pair (N\  D')  G RHo, is called  right coprime  (re)  in RHoo if there exists a pair 
(X',  Y')  G RHoo  such that 
X'D'  +  Y'N'  =  L 
(4.110) 
This is a Diophantine  Equation  over the ring of proper and stable rational  functions. 
It is also called a Bezout  identity. 
Let H  =  N'D'-^  and  write  (4.110)  as X'  +  Y'H  -  WK  Since the  left-hand 
side is proper,  D'~^  is  also proper,  i.e.,  in the MFD  given  by  H  =  N'D'~^,  where 
the pair (N',  D')  is re, D'  is biproper  (D'  and D'~^  are both proper). 
Note that X'~^,  where X'  satisfies  (4.110), does not necessarily  exist.  If,  how 
ever, H is strictly proper [lim^^oo H{s)  =  0], then lim^^oo X'{s)  =  lim5_>oo D'{sy^ 
a nonzero real matrix, and in this case X'~^  exists and is proper, i.e., in this case  X' 
is biproper. 
is 
When  the  Diophantine  Equation  (4.110)  is used  to  characterize  all  stabilizing 
controllers, it is often  desirable to have solutions {X',  Y'),  where X'  is biproper. This 
is always possible. Clearly,  when H  is  strictly  proper,  this is automatically  true,  as 
was shown. When H is not strictly proper, however, care should be exercised in the 
selection of the solutions of (4.110). 
LEMMA 4.10.  luoXH  =  N[D'\^  =  A^2^'2^ be rc factorizations. Then 
U', 
(4.111) 
where  U',U' 
RHoo 
Proof, Given the two re factorizations, let  f/'  =  D\  D2 and note that A'^2 = ^^'2  ^ 
N[D\^D'2  = N[U'.NowX!^D'2 + Y!^N^  = (X!^D[  + Y!^N[)U'  = /, from which f/'-^  = 
X^D;  +  r^A^j,  i.e.,  U'-^  E  RHoo. Similarly,  X[D[  +  Y[N[  =  I 
U' E RHoo. 
implies  that 
m 
Remarks 
1.  A  matrix  U\  as  given  above,  with  U'  and  f/'~^  G  RHoo  is  a unit  in  the  ring 
RHoo  (refer  to the discussion on rings and modules in Subsection  7.2E). 
2.  If//  is also  stable, i.e., if  H  E  RHoo,  then H  =  HI~^  is an re factorization.  If 
now  H  =  N'D'~^  in  any  re proper  and  stable  MFD,  then  in  view  of  Lemma 
4.11, /  -  D'U\  i.e., D'  and D'-^  G  RHoo. 
EXAMPLE  4.8.  Let  7/ 
1 
1 
(s-2)(s-\-  1)  Us+  1)2/U+  1 
=  A^'D'-^HereA^' 
and D'  are re since X'D'  +  Y'N'  =  5  +  1 /\5  +  1 
+ (9) 
s-  1 
(S +  1)2 
1. In view of 
613 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Lemma 4.10, all 
U' 
•• 
s-1 
s-\ 
t/',  where t/',t/'-i  G/?//oo are also re 
factorizations  of//.  Here,  U\s)  = a{s)/b{s),  where a{s) and b{s) are prime Hurwitz 
polynomials of the same degree n and n can be arbitrarily large, but 
• 
finite. 
The above example illustrates that when N' ^D' ^  RHoo  dire re in RHoo,  they  may 
have common factors  that include common poles and zeros; however, these possible 
common poles and zeros have to be stable. Note that any common right divisor G^ of 
an re pair N^,D^ G RHoo  must  satisfy  G^ G^~^  G RHoo.  Contrast this with the case of 
two re polynomial matrices. 
Analogous  results  hold  for  Ic  proper  and  stable  MFDs  of  H  = b'~^N'  with 
b'^N'  ^  RHoo, where the Diophantine  Equation 
b'X'+N'f 
= 1 
(4.112) 
is satisfied for some X, F G RHoo. In this case the result corresponding to Lemma 4.10 
becomes  [52,^/^1 
Ic MFDs. 
U'[b\,N[]  with tJ', tJ'-^  GRHoo whenH - -&-^ Ni=b'-^Nl 
are 
As in  the polynomial  case,  doubly  coprime  factorizations  in RHoo  of  a  transfer 
function  matrix  Hi  = N[D'-^  = b'-^N[,  where  D[,N[  G RHoo  and  b[,N[  G RHoo 
are important in obtaining  parametric  characterizations  of all stabilizing  controllers. 
Assume therefore  that 
u'u'-
X[  Y[  D\ 
N[ 
I 
0 
0 
/ 
(4.113) 
-n 
XI 
where U^ is unimodular in RHoo, i.Q.,U'^U'~^ G RHoo. Also, assume that X[^X[  have 
been selected  so that det X[ ^  0 and det X[ ^  0. 
To see how such relations can be derived [compare with the discussion  following 
(4.18) in Subsection  7.4A], assume that some X'^^Y^  and Y^^X'^ have been found  that 
satisfy  X^D;  XN[ 
: /  and b[X'^  -N[n- I. Note then that 
0 
/ 
D[ 
D'S',-?;, 
N'  N'Sl  -K 
-N[  D' 
I 
0 
(4.114) 
whereS',  4  x'X-YX- 
Fj)  to obtain (4.113). It can be shown that matrices are indeed  unimodular. 
Let  {X[,Y[)  =  {X',X)  and (Z(,-?/)  =  {NS'.+X'.^iys',  -
Internal  stability 
Consider now the feedback  system in Fig. 7.5  and let Hi  and H2 be the  transfer 
function  matrices of Si  and ^2, respectively, that are assumed to be controllable  and 
observable.  Internal  stability  of  a  system  can  be  defined  in  a  variety  of  equivalent 
ways in terms of the internal description  of the  system. For example in this  chapter, 
polynomial matrix internal descriptions were used, and the system was considered as 
internally  stable when its eigenvalues were stable, i.e., they had strictly negative real 
parts. In Theorem 3.15 in Subsection 7.3C, it is shown that the closed-loop  feedback 
system is internally stable if and only if the  transfer  function  between 
and 
614 
Linear  Systems 
or 
and 
n 
have  stable  poles, i.e., if and only  if the poles of 
/ 
-Hi 
-H2 
I 
I 
or 
-1-1 
/ 
-Hi 
0 
Hi 
Hi 
0 
I 
, respectively,  are stable. 
In  this  subsection  we  shall  regard  the feedback  system  to  be  internally  stable 
when 
/ 
-Hi 
1-1 
-H2 
I 
^RH^, 
(4.115) 
i.e.,  when  all the transfer  function  matrices  in  (4.115)  are proper  and stable.  In  this 
way, internal  stability can be checked without necessarily  involving internal  descrip 
tions of 5i  and ^2. This  approach  to stability has advantages  since it can be  extended 
to  systems  other  than  linear  time-invariant  systems. 
THEOREM  4.11.  Leti/i  =  A^;Z)V^  =  D'i^N[  mdH2  =  D'^^N^  =  N^D'^^  be dou 
bly coprime MFDs in RHoo. Then the closed-loop feedback  system is internally  stable if 
and only if 
or if and only if 
D ^ D;  -N2N[  =  U' 
D[D2-N{Ni 
=  U', 
(4.116) 
(4.117) 
where  U', U'~^ G RHa. and U', U''^  G RHo.. 
Proof,  Consider//i  =  N[D'^\H2 
have/  =  D'2^N2N[D\^  +  6 2 ^ ^ '^ T^  which implies  that 
=  D'2 ^^2 ^nd assume that (4.116) is satisfied. We 
/ 
-Hi 
-H2 
I 
/ 
-Hi 
-H2 
I 
and 
D'2U' 
-D'^'N^ 
-N[D'-,' 
D'l 
u'-^b'2^ 
U'-^D'2^N': 
0 
(4.118) 
which is proper and stable, since both factors in the right-hand side are proper and stable. 
Therefore,  if  (4.116)  is  satisfied,  the closed-loop  feedback  system  is internally  stable. 
Similarly, it can be shown that if Hi  =  b'\^N[,  H2  =  Nl^D'^^  and (4.117) is  satisfied, 
then the closed-loop feedback  system is internally  stable. 
The  converse  will  now be  established,  namely,  if  the feedback  system  is  inter 
nally  stable,  then  (4.116)  is satisfied.  The proof  that  (4.117)  is also  true  is  completely 
analogous.  Let Hi  =  N[D']^^  be re  and H2  =  ^^'2 ^A^2 ^^ ^^ MFDs  in  RHo., and let 
D ^ D;  -  N^N[  =  U' with  U' some matrix in RH^. Recalling  (3.103) or (4.37), we have 
I 
-Hi 
'-' 
-H2 
I 
r  (I-H2H1)-' 
~ 
[Hi(I-H2Hir 
I  + 
{I'H2Hi)-'H2 
Hi(I-HiH2r^H: 2j 
(4.119) 
"where the identities (/-^1/^2)""^  =  I + (I ~ HiH2)-^HiH2and(I "
-  HiH2r^HiH2  = 
Hi{I  -  H2Hi)~^H2  were used. It is not difficult  to see [compare also with (3.113)] that 
/ 
-Hi 
-1 
-H2 
I 
= 
'D[U' -'D'2 
N[U'-^D'2 
"""0  0"" "
0 
/.  + 
[N[\ 
"D[U""^N^ "
I  +  N[U'-^N2. 
U'-'[D'2,N^l 
(4.120) 
615 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Assume now that the system is internally  stable, i.e., 
/ 
-H2 
I 
e  RHoo.  Then, 
since  D[, N[  are  re  and  D2, N2  are  Ic,  (7  Ms  in  RHo,. To  see  this,  premultiply 
U'~^[D2,N2l  which  is  in  RHa., by  [D^,-A^^]  G RH^,  and  postmultiply 
by  I -N: 
e  RHo..  These  operations 
leave  the  matrix  in  RHoo. Therefore, 
RH^ 
COROLLARY 4.12.  Let//i  = N{D'l^  =  D'f^TVJ  be doubly coprime MFDs in/?//oo, 
i.e., (4.113) is satisfied. Then the closed-loop feedback system is internally stable if and 
only if H2 has an Ic MFD in RHa,, H2 = D'2^N'2, such that 
or if and only if H2 has an re MFD in RHoo, H2 =  A/^2^'2 ^' ^^^^ that 
D'2D[  -N'2N[  = /, 
D[D'2-N[N2  = I. 
(4.121) 
(4.122) 
Proof. The proof is straightforward, in view of Theorem 4.11 and Lemma 4.10. 
• 
Parameterizations of all stabilizing  controllers 
Several  parameterizations  of  all  proper  stabilizing  controllers  are  now con-
sidered. 
Parameter  K' 
THEOREM 4.13.  Let//i  = N[D'\^  =  D'f ^A^j be doubly coprime MFDs in/?//oo that 
satisfy (4.113). Then all H2 that internally stabilize the closed-loop feedback system are 
given by 
H2 = -(X[  -  K'N[)~\Y[  + K'D[) =  - ( ?; + D[K')(X[ -  N[K')-\ 
(4.123) 
where K' G RHoo is such that {X[  -  K'N[)~^  [or (Xi -  N[K')~^] exists and is proper. 
Proof. It can be shown that all solutions of 62^1 ~ ^2A^i  =  I are given by 
[D'2,  -N^]  U.K'] 
x[  rr 
-N[  D[\ 
(4.124) 
where K' E RHoo.  The proof of this result is similar to the proof of the corresponding 
result for the polynomial matrix Diophantine Equation in Subsection 7.2E and is omitted 
(see also Subsection 7.4A). Similarly, all solutions of D[D2 -  N[N2 =  /  are given by 
(4.125) 
where K' E RHoo. The result then follows directly from Corollary 4.12. 
The above theorem is a generalization of the Youla parameterization of Theorem 
4.2 over the ring of proper and stable rational functions. Generalizations of the Youla 
parameterization over rings other than the polynomial ring were introduced in Desoer 
et al. [11]; for a detailed treatment see also Vidyasagar [34]. 
It is interesting to note that in view^ of (4.113), H2 in (4.123) can be written as 
follows. Assume that X^^  and Xf^  exist. Then 
616 
Linear  Systems 
H2  =  -(Y[  +  X'^\l 
-  Y[N[)K')(Xi 
-  N[K')-^ 
=  -[Y[X\\X[ 
-  N[K')  +  X\^K'](Xi 
-  N[KT^ 
=  -Y[X\' 
-  X'i'K'iXi 
-  N{K'r' 
=  H20 +  H2a, 
(4.126) 
i.e.,  any  stabilizing  controller  H2  can  be  viewed  as  the  sum  of  an  initial  stabiliz 
ing  controller  H20  =  -Y[X'^^ 
and an additional  controller  H2a that  depends  on  ^ '. 
When  K'  =  0, then  H2a is  zero. 
In  view  of  (4.120),  the  poles  of 
/ 
-Hi 
1-1 
-H2\ 
I 
,  which  are  the  closed-loop 
eigenvalues,  are the poles of 
/ 
H2 
I 
D[ 
-1 
U'~\D2,  N2I  Similarly,  since 
I  + N^U 
= 
I  0 
0  0 
+ 
U'-\N[,D[l 
(4.127) 
"where Hi  =  D ' f ' ^i  i^ ^^ ^""'l ^2  =  A^2^'2  '  is re", and both  are MFDs  in RHo. with 
U'  and  U',"  f/'""'  G  /?//„",  it  follows  that  the  eigenvalues  of  the 
D[D'^  -  N[NL, 
closed-loop  feedback  system  are the poles of 
forward  to prove  the following  result. 
N'2 
D' 
U'~^[N[,  D[].  It is now  straight-
LEMMA4.15.  Given//i  = N[D\^  =  5 'f  ^ ^ j,  doubly  coprime MFDs in 7?//oo, if ^2 
is given by (4.123), the closed-loop eigenvalues  are the poles of 
[/, K'] 
x:  Y[ 
-N[  D[\[0 
0 
-I 
[X[ -  Y[]  -
K'[N[,D[] 
(4.128) 
or of 
-K' 
I 
[N[,D[] 
[N[,D[]-
x: 
K'[N[,D[l 
(4.129) 
Proof.  Note  that D'2D[-N^N[  =  (X[-K'N[)D[+(Y[+K'D[)Ni 
I  =  U', which in view of the above discussion, directly  implies the lemma. 
=  X[D[+Y[Ni  = 
• 
Therefore,  in  view  of  Lemma  4.15,  when  the parameterization  for H2  of  The 
m  , of 
orem  4.13 is  used,  the closed-loop  eigenvalues  are in  general  the poles  of 
[-N[  D[ 
,  andof/i:'. 
EXAMPLE  4.9.  Let Hi  = 
1 
fs-l\-i 
1 
i-l-  lVs+  1 
NID'J' = 
I r'  1 
s + a/ 
D\  N[ with a  >  0, which are doubly coprime factorizations. Note that 
X'l  Y[ 
-N[  D[  N'l 
-Y[ 
x: 
s-\-3 
s +  2 
1 
s -\- a 
^ + 5-1 
^ + 2 
^-  1 
s -\-  a-^ 
s-  1 
s+  1 
1 
s+  1 
(s + 5)(s + a) 
(s +  1)(^ + 2) 
(s +  3)(^ +  a) 
(s +  l)(s  + 2) 
s + a 
1  0 
0  1 
If all stabilizing  H2 are parametrically  characterized  by means of (4.123), then in view 
of Lemma 4.15, the closed-loop eigenvalues  are in general the poles of 
that are at 
-1, the poles of 
X[  Y[ 
-N[  D[ 
that are at -2  and -a,  and the poles of K'.  Also, H2 in this 
617 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
case is given by 
H2  = 
where K'  G  RHoo. 
.  +  5 ^ ^ , . -l 
s_±2 
s + 3 
s + 2 
K'\ 
1 
s + a 
s + al  _ 
1 1^' 
(s +  5)(s  +  1) 
(5 +  1)(^ +  2)  V^  +  1 
{s +  3)(5 +  a) 
{s +  1)(5 +  2)  V5  + ITK 
Note  that  it  is  possible  to  select  -m 
1 
^ iJ 
so  that  the  poles  of  X[  and  Y[  are 
those of  -  A^{ and D[.  In the above example, this is the case when  a  =  2. This  is  also 
the  case  when  these  quantities  are  expressed  in  terms  of  a  state-space  realization  of 
Hi,  as  is  shown  later  in  this  subsection. 
It  is  always  possible  of  course  to  select  K'  so  as  to  minimize  the  number  of 
the  closed-loop  eigenvalues.  This  corresponds  to  minimizing  the  McMillan  degree 
(number  of  poles)  of//2-  This  follows  from  the  fact  that  any  proper  stabilizing  con 
troller  can  be  expressed  as  (4.123)  for  appropriate  K'.  If  for  example  H\  can  be 
stabilized  by  means  of  a  real  static  H2,  then  a  ^'  E  RHo,  exists  for  this  to  happen. 
In  this  case  the  number  of  closed-loop  eigenvalues  is  equal  to  the  number  of  poles 
of  Hi.  It  is  not  easy,  however,  to  find  such  K'  unless  for  example  X[  =  I  and  Y[  is 
real,  in  which  case  ^'  =  0 a n d H2  =  ^ j-
In  view  of  Lemma  4.15,  it  is  recommended  that  the  number  of  poles  in  ^1 
and  in  [-A^{, D['\  be  taken  to  be  the  minimum  possible,  which  is  the  number  of 
poles  in Hi.  Also,  the  number  of poles  in  [X[,  Y[]  should  be  taken  to be  low.  This  is 
accomplished  in  a  systematic  way  in  the  following,  using  state-space  descriptions. 
If  the  desired  stabilizing  H2  is  known,  then  the  appropriate  K'  that  will  modify 
yield  the  desired  H2,  can  be  calculated  from  (4.122)  as 
the initial  //20  ^  X''[^Y[,io 
K'  = 
-{Y[+X[H2){D[-N[H2r\ 
(4.130) 
EXAMPLE  4.10.  In the  above example 7/2  = 
stabilizing H2. Then for a  =  1, we have 
-(/? +  1), Z?  >  0 characterizes  all  static 
K'  = 
s+5 
s + 2 
5 +3 
s + 2 
( ^ + 1) 
-bs-
3/7 +  2 
8 + 2 
s + b 
s+  1 
5 -1 
5+  1 
1 
b+l 
(s +  l)(bs  +  3/7-2) 
' 
(s +  2)(s  +  b) 
which will yield the desired H2  = 
at  -b,  as can easily be  verified. 
-{b  -\-  1). The closed-loop eigenvalue is in this case 
Parameters  Q2, X'2 
Parameters  other  than  K'  can  also  be  used  to  parametrically  characterize  all 
stabilizing  H2.  These  parameters  were  introduced  in  Subsection  7.4A,  and  in  the 
following  these  results  are  modified  to  accommodate  the  MFDs  in RHoo. 
THEOREM  4.16.  Let  Hi  =  N[D\  =  D':[^N[  be  doubly  coprime  MFDs  in  RHoo  that 
satisfy  (4.113). Then all H2 that internally  stabihze the closed-loop system are given by 
(i) 
7/2  =  (/  +  Q2Hi)-'Q2  =  [D'-,\I  +  Q2Hi)r'[D'-,'Q2-\ 
=  [{I +  X'2N'i)D'-,']-'X'^, 
(4.131) 
618 
Linear  Systems 
where Q2 is such that U\^\l  + 22^1,  G2] ^  ^^00 and (/ + QiHiY^  exists and is proper; 
or where Z2 is such that  [(/  + X'^N'^~^U\^,  X'^  E  RHo.  and (/  +  X'jN'^~^  exists and is 
proper. Or by 
(ii) 
//2  =  Qiil^H^QiY' 
=  [Q2D'-,'W  +  H,Q2)D'-,'r 
X'2[D'-,\l  +  N[X'2)r' 
(4.132) 
where Q2 is such that 
where X2 is such that 
Qi 
1  + H1Q2 
X', 
VD'-,\I  + N[X'2) 
"D'l^  E  RHoo and (/  + Hi ^2)""^  exists and is proper; or "
E  RHo, and {I  + N[X'2)~^ exists and is proper. 
Proof,  First, notice the similarity of the results in this theorem and in Theorem 4.3  and 
Corollary  4.6  in  Subsection  7.4A.  To verify  (i)  directly,  note  that  if  H2  =  ^'2  ^^2'  ^^ 
solutions of b2D[  -  A^2^|  =  /  are given by 
[b'2, N!2\ =  [(/  +  X!2N[)D'i\  X^]  E  RH^ 
(4.133) 
where X2  E  RHoo is a parameter that we set equal to N2- Then in view of Corollary 4.12, 
the result in (i) that involves X2 follows  directly. Notice that (/  + X2N[)D']^^ is biproper, 
and therefore, H2 in (4.131) is proper. Now if Q2  =  D[X2, then the results involving Q2 
also follow. Note that Q2 E  RHo,. Part (ii) can be verified  in an analogous manner.  Here 
Qi  =  X'2D[. 
• 
In  view  of  Lemma  4.15  and  the  discussion  preceding  it,  the  next  result  follows 
readily. 
LEMMA  4.17.  Let  Hi  =  N[D'\^  =  D'l^N[  be  doubly  coprime.  If  H2  is  given  by 
(4.131), then the closed-loop eigenvalues  are the poles of 
[D'i\l  +  Q2Hi\D'i'Q2] 
U  + QiHu  Qi] 
[(I  + X^N[)D'i\X^l 
(4.134) 
If ^2  is given by (4.132), then the closed-loop eigenvalues  are the poles of 
Qib'^' 
[Nib[]  = 
Qi 
1 + H1Q2 
[Hi, I] 
X'2 
D'-,\I-VN[X'2). 
[N[,b[l 
(4.135) 
Proof,  The proof  of this result is  straightforward,  in view  of Lemma  4.15  and the dis 
cussion preceding it. 
• 
An  interesting  case  is  when  Hi  is  stable,  as  the  following  corollary  shows. 
COROLLARY  4.18.  Let  ^1  E  RHo.. Then  all H2 that  internally  stabilize  the  closed-
loop feedback  system are given by 
H2  =  (I  -  K'HiY^K'  =  K'(I  -  HiK')-\ 
(4.136) 
where K'  E  RH^  such that (/  -  K'Hi)  ^ [or (/  -  H^K')  ^] exists and is proper. Further 
more, the closed-loop eigenvalues  are the poles of 
\[IK'] 
0 
I 
-Hi 
(4.137) 
619 
CHAPTER 7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Proof, Note that in this case (4.113) can be written as 
/ 
-H, 
01 
l\ 
\I 
[HX 
0' 
/. 
I  0' 
0 
/. 
for 
the doubly coprime MFD/fi  =  Hil'^  = /-^//i. Then (4.123) of Theorem 4.13 reduces 
to expression (4.136) for H2. The closed-loop eigenvalues are then given by the poles of 
(4.137), in view of Lemma 4.15. 
• 
Compare  this  corollary  with  Theorem  4.16, where H2 is expressed  in terms of 
Q2. In this case it is clear that K'  =  -Q2.  Note that K'  E  RH00 suffices  to guarantee 
stability. 
MFDs and internal  representations 
"Consider^  =  N'D'~^  =  D'""^A^'", a doubly coprime factorization  in i^ii/oo, i.e., 
(4.113) is satisfied.  It is possible to express all proper and stable matrices in (4.113) 
in terms of the matrices  of a state-space  realization  of the transfer  function  matrix 
H{s).  In particular, we have the following  result. 
LEMMA 4.19. Let {A, 5, CyD}  be a stabilizable  and detectable  realization  of H{s), 
i.e., H{s)  =  C{sl -  A)-^B + D, which is also denoted by H(s) = 
and with 
C  D 
(A, B) stabilizable and (A, C) detectable. Let F be a state feedback gain matrix such that 
all the eigenvalues of A -f- BF have negative real parts, and let K be an observer gain 
matrix such that all the eigenvalues of A -  A'C have negative real parts. Define 
U' 
X' 
y 
-N'  b' 
and 
U' = 
D' 
N' 
-r 
X' 
A-KC 
B-  KD  K 
-F 
-C 
-D 
A + BF 
B  K 
F 
C + DF 
/ 
D 
(4.138) 
(4.139) 
/ - I/ 
"Then (4.113) holds and// =  N'D'-'^  = /)'""iA^'are coprime factorizations  of/^. "
Proof. Relation  (4.113) can be shown to be true by direct computation  and is left to 
the reader to verify.  Clearly,  U\ U' G RHoo.  That A^', D'  and D', N'  are coprime is a 
direct  consequence  of (4.113). That N'D' 
computation and is left to the reader. 
=  D'  ^N' = H can be shown by direct 
In view of Lemma 4.19, U' and U' 
E  RHoo in (4.113) can be expressed as 
U'  = 
Y' 
-F 
-C 
[si  -  (A -  KC)Y'[B 
-  KD, K] +  -D 
/  Ol 
I\ 
andt/' 
= 
D' 
N' 
-r 
X' 
F 
C  ^DF 
- Ir 
[sI-(A-^BF)r'[B,K] 
+ 
(4.140) 
(4.141) 
620 
Linear Systems 
These  formulas  can  be  used  as  follows.  A  stabilizable  and  detectable  realization 
{A, B, C, D] of H{s)  is first determined,  and  appropriate  F  and  K  are found  so that 
"A + BF  and A-KC  have eigenvalues with negative real parts. Then U^ and t/'""^  are "
calculated from (4.140) and (4.141). Note that appropriate state feedback gain matri 
ces F and observer gain matrices K can be determined, using the methods  discussed 
in  Chapter  4.  The  matrices  F  and  K  may  be  determined  for  example  by  solving 
appropriate  optimal  linear quadratic  control  and  filtering  problems.  All proper  sta 
bilizing controllers//2  =  A^2^'2^  ^  D'2 ^^2 ^f theplant/i/i  are then  characterized 
as in Theorem 4.13. 
It can now be shown, in view of Lemma 4.19, that all stabilizing controllers  are 
described by 
k  =  {A + BF  -  K(C  +  DF))x  -V  Ky  + {B -  KD)ri 
u  =  Fx  + ri,r2  =  y-{C  + DF)x  -  Dri,  n  =  K'{q)r2, 
(4.142) 
which can be rewritten  as 
k  =  Ax  + Bu  + K(y  -  (Cx  +  Du)) 
u  =  Fx  + K'{q){y  -  {Cx  +  Du)\ 
(4.143) 
Thus, every  stabilizing  controller is a combination  of an asymptotic  (full-state/full-
order) estimator or observer and a stabilizing state feedback,  plus K'(q)r2  with r2 = 
y -  (Cx  +  Du),"  the output ""error"" (see Fig. 7.9). "
Let 
be coprime factorizations  in RHoo, where N',  D', N',  D'  G RHoo. Also, let 
H  =  N'D'-^  =  D'~^N' 
H  =  ND-^  =  D-^N 
(4.144) 
(4.145) 
be polynomial matrix coprime factorizations. The relation of proper and stable MFDs 
of H(s)  to internal PMDs of the system is established in the next result. 
FIGURE 7.9 
A state-space representation of all stabilizing controllers 
THEOREM 4.20.  (i) The pair  {N',D')  e RHoo  defines  an re factorization  of H{s)  as 
in (4.144) if  and only if there exists a rational matrix n  with n,  n~^  stable and DYl 
biproper such that 
Furthermore, if only n  is stable and DYl is proper, then (N^D^) is a right  factorization 
but it is not necessarily coprime. 
n. 
(4.146) 
(ii) Similarly, the pair  (N^,&)  G RHoo  defines  an Ic factorization  of H(s)  in RHoo 
621 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
as in (4.144) if and only if there exists a rational matrix fl  with fl, fl~^  stable and YID 
biproper such that 
(4.147) 
Furthermore, if only n  is stable and YID is proper, then  {N\&)  is a left  factorization 
but it is not necessarily coprime. 
[N',D']  =U[N,D]. 
Proof, The proof of this result can be found in Antsaklis  [4] and will not be repeated 
• 
here. 
An interesting  implication  of Theorem  4.20 is the following:  let H  =  ND~^  be 
a right  PMFD  and  let D be  column  proper;  Dz  =  u,y  = Nz  is  di controllable  PMD. 
Following the development in Subsection 7.4B, define the linear state feedback  con 
trol law by (4.94), as w =  F{q)z  +  Gr, det G 7^ 0, where deg^.F{q)  < dQg^.D{q).  The 
closed-loop  system  is  then  Dpz  =  Gr^y = Nz  given  in  (4.95),  where  Dp  = D — F. 
Now in view of Theorem 4.20, the relation 
D^'G 
(4.148) 
defines  re proper  and  stable factorizations  of H,  when  {DJ^N} 
is detectable.  If the 
pair  (N^D)  is  re,  then  Yl =  D^^G.  In  fact,  it  is  shown  in  Antsaklis  [4]  that  all  re 
factorizations  in  RHoo  may  be  obtained  by  means  of  (4.148),  i.e.,  by  using  linear 
state  feedback  on  controllable  and  detectable  realizations  of  H.  It  is  interesting  to 
note that if  {A,5,C,D}  is an equivalent  state-space representation  to  {DJ^N}  with 
(F, G) the corresponding  state feedback  gain matrices. 
F 
C + DF 
[sI-{A-
BF)]-^BG 
G.  This  expression  is  the  same  as  (4.141),  when  G =  1.  Simi 
lar  results  can  be  derived  for  the  Ic  factorizations  {N^,&)  that  are  related  to  state 
observers. 
As  an  application  of  (4.148),  consider  Theorem  4.8  and  Corollary  4.12,  where 
it is  shown that if the given plant Hi  =  NiD^^  =  N[D'^^  where Ni^Di  are re poly 
nomial  matrices  and A^(, D\  are proper  and  stable matrices,  then H2 is  a  stabilizing 
controller  if  and  only  if  it  can  be  written  as  H2 =  L^^Li,  where  L2D1 — LiNi  = 
/  (Theorem 4.8),"  or  if  and  only  if  H2  can  be  written  as  H2  =  ^2""^^/^'  where "
A^(A^( =  /  (Corollary 4.12). Assuming that Di  is column proper, then in view 
D^,D[ 
/, 
of  (4.148),  the  last  relation  can  be  written  as  [(D^^G)5^]Di  -  [{Dp^G)N^]Ni 
and therefore, the relation between L2,Li  and D21N2 ^^ gi^^i^ by 
G-^DF 
\L2\ 
\LI\ 
(4.149) 
622 
Linear Systems 
^ 
^ -1 
^.. 
TV =  A^^ 
^^  2)(5 + 1) 
, where N  =  s -  I  md  D  = 
\ , ,,  then A^' = NU, D'  = DU,  and X'D'  +  Y'N'  =  ^-^  ^-^  + 
EXAMPLE  4.11.  Let H(s)  =  1-^^^. 
. 
.. 
(s -  2)(^ + 1). 
(i)  If n  =  , 
s-  1 
(s + 1> 
®  If  n  =  , 
o(^ + 3) 
(^ + 2) 
Notice that in both (i) and (ii), 11," H""^ are stable and DU is biproper as required by "
• 
(s -  1)(^ + 2)  ^ 
(^ +  1)2(^ + 3) 
j^  '  ^^  ^  ^j  • ^ ^ ^ ^^  + 
, ,,  then  X'D'  +  FW  = 
(5 +  1)2(5' +  3) 
Theorem 4.20. 
(5 +  1)(^ +  3) 
(5 +  1)(^ +  2) 
; t; 
L 
The  X-approach 
Given the transfer  function  H(s),  instead of obtaining proper and  stable  factor 
izations  to  characterize  all  proper  stabilizing  controllers  via  a  Diophantine  Equa 
tion  over  the  ring  of  proper  and  stable  rational  functions,  the  transformation  A  = 
l/(s  -\-  a),a>  0,  may  be  used.  Then  one  works  with  a Diophantine  Equation  that 
involves  polynomial  matrices  in  A.  This  transformation  maps  the  stable  region 
"in  the  s-plane  into  a  ""stable""  region  in  the  A-plane  and  the  point  ^  =  oo to  the "
point  A  =  0  (see  Pernebo  [29]  for  a  detailed  discussion).  This  approach  corre 
sponds  to  working  with  proper  and  stable  factorizations  of  H,N',  and  D'  with  all 
the  poles  of  A^' and  D'  at  -a  and  requires  only  polynomial  matrix  manipulations 
"[here  H  =  (l/(^  +  a)"")/  in  Theorem  4.20].  Recall  that  a  rational  R(s)  is  proper "
(there  are  no  poles  at s  =  ^)  if  and  only  if  R[(l  -  Xa)/X] has  no  pole  at  A == 0. 
Therefore,  for  proper  stabilizing  controllers,  solutions  of  appropriate  polynomial 
Diophantine  Equations  are  sought  where  the  denominator  Z)2(A) of  the  stabilizing 
controller  H2  has  no  A factors  in  det  D2W, 
i.e.,  ^2^'^)  has  no  poles  at  A == 0. 
Note that in this case, all the poles of the solutions of the corresponding proper  and 
stable Diophantine Equation will also be at  -a,  and stabilizing controllers  obtained 
by  this  method  tend  to  assign  multiple  closed-loop  eigenvalues  at  -a.  As  an  il 
lustration,  consider  H(s)  =  (s  -  l)/[(s  -  2){s  + 1 )]  (see  the  example  above)  and 
let A - 
l/(^  +  1). Then H(X)  =  (I  -  2A)A/(1 -  3A). The polynomial  Diophantine 
Equation in A is solved to obtain ZD +  M  =  (-6A  +  1)(1 -  3A) + 9(1 -  2A)A  =  1. 
The  corresponding  (proper  and  stable)  Diophantine  Equation  is  obtained  if  we  let 
A =  l/(^  +  1) in X, A  Y, N.  Then the Z', D',  Y', N'  of case (i) of the above example 
are derived. If the controller u  =  Cy  + r with C{s)  =  -9(s  + l)/(s  -  5) is used, all 
"three closed-loop eigenvalues  will be at  - 1. [C(s)  =  C(A)  =  -X'^Y""^  with A = "
l/(s  +  1).] 
D.  Two Degrees  of Freedom  Controllers 
Consider the two degrees of freedom  controller Sc  in the feedback  configuration  of 
Fig.  7.10.  Here  SH represents  the  system  to  be  controlled  and  is  described  by  its 
transfer  function  matrix H(s)  so that 
y(s)  =  H(s)u(s), 
(4.150) 
623 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and  Matrix 
Fractional 
Descriptions 
of  Systems 
The two degrees  of freedom  controller 5c  is described  by  its transfer  function  matrix 
C(s)  in 
u(s)  =  C(s) m 
r(s). 
[Cy(s\  Cr(s)] 
(4.151) 
Since  the  controller  Sc  generates  the  input  u  to  SH  by  processing  independently  y, 
the  output  of  SH,  and  r,  the  external  input,  it  is  called  a  two  degrees  of  freedom 
controller. 
In  the  following,  we  shall  assume  that  //  is  a proper  transfer  function  and  shall 
determine proper controller transfer  functions  C that internally  stabilize the  feedback 
system  in Fig.  7.10.  The  restriction  that H  and  C  are proper  may  easily  be  removed, 
if  so  desired.  Note  that  in  the  development  in  Subsection  7.4C  we  assumed  proper 
transfer  functions  in  the  feedback  loop,  while  the  development  in  Subsection  7.4A 
applies  to  nonproper  transfer  functions  as  well. 
r 
Sc 
u 
SH 
y 
* 
FIGURE  7.10 
Two degrees of freedom  controller  Sc 
Internal  stability 
THEOREM  4.21.  Given is the proper  transfer  function  H  of  SH, and the proper  trans 
fer  function  C of  Sc  in  (4.151),  where  det(I  -  CyH)  T^ 0.  The  closed-loop  system  in 
Fig. 7.10 is internally  stable if and only if 
(i)  u  =  Cyy  internally  stabilizes the system  y  =  Hit, 
(ii)  Cr is such that the rational  matrix 
M  =  {I 
-CyHY^Cr 
(4.152) 
(w  =  Mr)  satisfies  D  ^M  =  X, a stable rational matrix, where Cy satisfies  (i) and H 
ND~^  is a right coprime polynomial matrix  factorization. 
Proof,  Consider controllable  and observable PMDs for SH, given by 
and for Sc,  given by 
Dz  =  u, 
y  =  Nz, 
DcZc =  [Ny,Nr] 
U  =  Zc. 
(4.153) 
(4.154) 
where the N, D  are re and the Dc, [Ny, Nr] are Ic polynomial  matrices. The  closed-loop 
system is then described by 
{bcD  -  NyN)z  =  Nrr, y  =  Nz 
(4.155) 
and  is  internally  stable  if  the  roots  of  det Do,  where  Do  =  DcD  -  NyN,  have  strictly 
negative real parts. 
(Necessity)  Assume  that  the  closed-loop  system  is  internally  stable,  i.e.,  D~^  is 
stable.  Since  Cy  =  D~^Ny  is  not  necessarily  an  Ic  polynomial  factorization,  write 
[Dc,Ny]  =  GdDcy,Ncy],'^^^reGLis2igcldofthQpaiY0c,Ny).ThenDcyD-NcyN 
= 
Gl^Do  =  bk,  where  D^  is  a polynomial  matrix  with  D^^  stable; note also that  G^^  is 
stable. Hence,  u  =  Cyy  =  D'^^Ncyy  internally  stabiUzes  y  =  Hu  =  ND'^u, 
i.e., part 
(i)  of  the  theorem  is  true.  To  show  that  (ii)  is  true,  we  write  M  =  (I  -  CyH)~^Cr  = 
624 
Linear Systems 
Dbl^Dcy0-^Nr)  = Db^^Gl^Nr  = DX, where X  = D'^Nr  is a stable rational ma-
^^^- ^^^^ shows that (ii) is also necessary. 
(Sufficiency) Let C satisfy  (i) and (ii) of the theorem. If C  = D~^[Ny, Nf] is an Ic 
polynomial MFD and GL is a geld of the pair (5c, Ny) then [Dc, Ny] = GiVDcy, Ncy] is 
true for some Ic matrices Dcy  and Ncy(Cy = D^^Ncy)- Because (i) is satisfied, DcyD  -
NcyN  =  D;t, where D^Ms stable. Premultiplying by GL we obtain Dc/)-A^^A/^ =  GLDJ,. 
Now if G^^ is stable, then 5~^ where Do = DcD -  NyN  = GiDk, will be stable since 
6^1 is stable. To show this, write D'^M  = D-\l 
-  CyUy^Cr  = D^^Dcy0~^Nr)  = 
b^^Gl^Nr  and note that this is stable, in view of (ii). Observe now that the GL, Nr are 
Ic; if they were not, then C  = b~^[Ny, Nr] would not be a coprime factorization. In this 
case no unstable cancellations take place in D^^G^^Nr 0^^  is stable), and therefore, if 
D~^M is stable, then {GLDkY^ = b~^  is stable or the closed-loop system is internally 
stable. 
• 
Remarks 
(1)  It is  straightforward  to  show  the  same results, using  proper  and  stable  factor 
izations of H given by 
H  =  N'D'-\ 
where the pair (N',  D')  G RHoo  and (A^', D')  is re, and of 
C  =  &;'[N;,N^I 
(4.156) 
(4.157) 
where the pair 0'^,  [N!^,  N;.])  G  RHOO and (D^, [A^^, TV/]) is Ic. The proof is com 
pletely  analogous and is left to the reader. The only change in the theorem will 
be in part (ii) which will now read: 
(ii)  Cr  is  such  that  the  rational  matrix  M  =  (I  -  CyH)~^Cr  satisfies 
is an re MFD in 
D'-^M  =  X'  G RH^,  where Cy satisfies  (i) and H  =  N'D'-^ 
RHoo. 
(2)  Theorem 4.21 separates the role of Cy, the feedback  part of C, from  the role of 
Cr, in achieving internal stability. Clearly, if only feedback action is considered, 
then only part (i) of the theorem is of interest; and if open-loop control is desired, 
then  Cy  =  0  and  (i)  implies  that  for  internal  stability  H  must  be  stable  and 
Cr  =  M must satisfy  part (ii). In (ii) the parameter M  =  DX appears naturally 
and in (i) the way is open to use any desired feedback  parameterizations. 
In view of Theorem 4.21, it is straightforward  to parametrically  character 
ize all internally stabilizing controllers C  In the theorem it is clearly stated [Part 
(i)] that  Cy must be a stabilizing  controller. Therefore,  any parametric  charac 
terization of the ones developed in the previous subsections can be used for  Cy. 
Also, 
Cr is expressed in terms of D~^M  =  X  (or D'  M  ^  X'). 
"THEOREM 4.22.  Given that }) =  //w is proper with//  =  ND~^  = D""^A^ doubly co-"
prime polynomial MFDs, all internally stabilizing proper controllers C in w  =  CK  are 
given by: 
(i) 
C  = (1 + QHr^[Q,M]  =  [(/ + LN)D-^]-^[L,Xl 
(4.158) 
where Q =  DL and M  =  DX are proper with L, X and D'^I  + QH)  =  (/  + LN)D-^ 
stable, so that (/  + QH)~^ exists and is proper; or 
(ii) 
C  =  (Xi  -  KN)-\-{X2  + Kb),  XI 
(4.159) 
where K and X  are stable  so that  {X\  — KN\)  ^ exists and C is proper. Also, X\  and X2 
625 
are determined  from  UU 
'  Xi 
-N 
X2\ 
D\ 
ID 
[N 
-X2 
^ 1. 
"I  0"" "
/ 
0 
with U unimodular. 
lfH=  N'D'-^  = D'-^N'  are doubly  coprime  MFDs  in RHoo,  then  all stabilizing 
proper C are given by 
(iii) 
C = {X[-K'N')-\-{X!^ 
+ K'D'),X% 
(4.160) 
CHAPTER 7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
where  K',X'  e  RH^o  so  that  {X[ -K'N')'^ 
exists  and is  proper.  Also,  U'U'-^  = 
X',] 
& 
D' 
N' 
\  ^1 
-N' 
(iv) 
-xn 
K 
7 
0 
"0"" "
/ 
with  U'U'-^  eRK 
c = (/+e//)-i[e,M]:  [(/  +  L W ) Z ) ' - l ] - l [ L ^ r] 
(4.161) 
where  Q = D'L'.M  = D'X'  e  RH^o  with L^X'  and D'-^{I  + QH) 
RHoo  so that  {I + QH)~^  or {I + LlN')-^  exists and is proper. 
{I +  L'N')D'- e 
Proof,  In view of part (i) in Theorem  4.21,  Cy of C =  [Cy,  Q]  can be expressed in terms 
of any parameterization of all stabilizing feedback  controllers developed in  Subsections 
7.4A and 7.4C. Cr can then be expressed as Cr = {I — CyH)M  with Cy  given from  above 
and M = DX with X  any stable rational matrix. 
If  Cy =  {I + QH)-^Q  with  D-^[I + QH,Q]  stable  (see Theorem  4.3) or  Cy = 
[{I + LN)D-^]-^L  with  [{I + LN)D-\L] 
stable  (see Corollary  4.6), part  (i) of the 
theorem  follows.  Notice  that  Cr = (I-  CyH)M  =  (/ + QH)-^M  =  [{I +  LN)D-^]-^X 
since Q = DL and M = DX. Similarly, if Cy  = -{Xi-  KN)'^  {X2 + KD)  with K stable 
(see Theorem 4.2), then C, =  {Xi -  KNy^D'^M  = {Xi -  KN)-^X  and part (ii) of the 
theorem  follows. 
For part  (iii), express  Cy in terms of K'  G RHoo,  as in Theorem  4.13, and use X' G 
RHoo  in part  (ii) of Theorem  4.21, as in remarks  following  (4.157).  Part  (iv) follows 
from  Theorem 4.16 of Subsection 7.4C. 
• 
Response  maps 
It is straightforward  to express  the maps  between  signals  of interest  of Fig. 7.10 
in  terms  of the  parameters  in Theorem  4.22.  For instance  u = C 
- [C-y,C^ 
CyHu+Crr, 
from  which  we have u = {I — CyH)~^Crr  = Mr.  (In the following  we  will 
use the symbols  u^y^  r, etc., instead of w, j, r, etc., for convenience.)  If expressions  (iv) 
of  Theorem  4.22  are used,  then 
and 
y = Hu=N'D'-^D'X'r 
u = D'X'r, 
= N'X'r, 
(4.162) 
in  view  of {I — CyH)~^  =  D'{I+  L'N')D'~^.  Similar  results  can be derived  using the 
other  parameterizations  in Theorem  4.22.  To determine  expressions  for other  maps 
of  interest  in control  systems,  consider  Fig.  7.11,  where  du and dy are assumed  to 
be  disturbances  at the input  and output  of the  plant  H,  respectively,  and 77  denotes 
measurement  noise.  Then,  u  =  [C3;,Cr] 
\y + dy +  vi\ 
du, 
from  which  we  have 
{I-CyH)-^[Crr 
+ Cydy+Cy^+du] 
diXidy = Hu  = H{l-CyU)-^[Crr 
+ Cydy 
CyVi+du]. 
Then, in view  of (4.161)  in Theorem  4.22, we obtain 
u = D'X'r  + D'Lldy  +  D'L'I]  +D\I  +  L'N')D'-^du 
=  Mr + Qdy +  Qri+Sidu 
(4.163) 
626 
Linear Systems 
o^ 
FIGURE7.il 
Two degrees of freedom control configuration 
and 
y  =  N'X'r  +  N'L'dy  +  N'L'r]  +  A^'(/ +  L'N')D'~^du 
=  Tr  + (So -  I)dy  +  HQT] +  HSidu. 
(4.164) 
Notice that  Q  =  (I  -  CyHy^Cy  =  D'L'  is the transfer  function  between  u and dy 
or 7]. Also, 
Si  =  (I  -  CyHY^  =  D'(I  +  L'N')D / -I 
I  + QH 
(4.165) 
is the transfer  function  between u and du. The matrix St is called the input  compari 
son sensitivity  matrix.  Notice also that yo  =  y -^ dy  =  Tr-\-  Sody + HQrf  +  HSidu\ 
i.e., 
So  =  {I-  HCy)  -1  _  I^HQ 
(4.166) 
is the transfer function between yo and dy. The matrix So is called the output  compar 
ison sensitivity  matrix.  The  sensitivity  matrices  St and So are important  quantities 
in control design. Now 
HQ  =  So-  N'L'  =  I 
(4.167) 
.yL±) 
HCyil-HCy)-^ 
L±^yyL 
±±^yj 
since//g  =  H(I-CyH)-^Cy 
=  -J  + So. 
^y 
where So and HQ  are the transfer functions  from  yo to dy and T;, respectively. Equa 
tion  (4.167)  states  that  disturbance  attenuation  (or  sensitivity  reduction)  and  noise 
attenuation  cannot  occur over the same frequency  range  (show  this). This is a  fun 
damental limitation of the feedback  loop and occurs also in two degrees of  freedom 
control  systems. Similarly, we note that 
=  -I  + il-HCyT^ 
We now summarize  some of the relations discussed  above: 
Si  -QH  =  I. 
(4.168) 
-CyHy^Cr  DX, 
=  DL, 
T  =  H(I  -  CyHY'Cr  =  HM  =  NX, 
M  =  (I 
Q  =  (I-CyHy^Cy 
So  =  {I-HCyY^ 
=  I  +  HQ, 
Si  =  (I-  CyHy^  =  I  +  QH, 
{y  =  Tr) 
(u  =  Mr) 
(u  =  Qdy) 
{yo  =  Sody) 
(u  =  Sidu). 
The input-output maps attainable from  r, using an internally  stable two degrees 
of  freedom  configuration,  can  be  characterized  directly.  In  particular  consider  the 
two maps described  by 
(4.169) 
i.e., the command/output map T and the command/input map M. Let H  =  ND  ^ be 
an re polynomial MFD. 
THEOREM 4.23.  The Stable rational function matrices T and M are realizable with in 
ternal stability by means of a two degrees of freedom control configuration  [that satisfies 
(4.169)] if and only if there exists stable X so that 
X 
(4.170) 
Proof, (Necessity) Assume that T and M in (4.169) are realizable with internal stability 
Then in view of Theorem 4.20," X  = Z)""^M is stable. Also", 3; = Hu  = (ND'^)(Mr)  = 
NXr. 
627 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
(Sufficiency) Let (4.170) be satisfied. If X is stable then T and M are stable. Also, 
note that T  =  HM.  We now show that in this case a controller configuration  exists to 
implement these maps (see Fig. 7.12). Note that  u  = Mr  +  Cy(fr  -\-  y)  =  [Cy, M  + 
CyT] 
, from which we obtain 
r-y] 
\_r\ 
u  = (I + CyH)-\M  + Cyf)r. 
(4.171) 
HM  this relation implies that u = 
Now if M  =  M and T  =  T, then in view of T 
(I  + CyH)-\l  +  CyH)Mr  = Mr  and y  =  Hu 
HMr  =  Tr.  Furthermore,  Cy is a 
stabilizing feedback  controller, and the system is internally  stable since t  and M  are 
stable. 
• 
m.\  A  1 
1  M^M 
r 
L 
o-C^  ;o 
u 
1 
1 
y 
FIGURE 7.12 
Feedback realization of (T, M) 
Note that other internally stable controller configurations to attain these maps are 
possible. (The realization of both response maps T and M, instead of only T as in the 
case of the Model Matching  Problem,  makes the convenient  formation  in  Theorem 
4.24 possible. The realization  of both  T and M  is sometimes referred  to as the Total 
Synthesis  Problem;  see [7], [8] and the references  therein.) 
The  results  of  Theorem  4.23  can  be  expressed  in  terms  of  H  =  N'D'~^,  re 
MFDs in RHoo. In particular, we have the following  result. 
THEOREM4.24.  T,M  EL  RHOO are realizable with internal stability by means of a two 
degrees of freedom control configuration  [that satisfies (4.169)] if and only if there exists 
628 
Linear  Systems 
X'  E  RH^  so that 
\X'. 
(4.172) 
Proof.  The proof is completely analogous to the proof of Theorem 4.23 and is omitted. 
It  is  now  clear  that  given  any  desirable  response  maps 
r  such  that 
N' 
D' 
X\  where  X'  G  RHo^, the  pair  (T,  M)  can  be  realized  with  internal  sta 
bility  by  using  for  instance  a  controller  (4.161),  C  =  [(/  + 
L'N')D'-T^[L',X% 
where  [(/  +  L'N')D'~^,  L']  G  RH^^  and  X'  is  given  above,  as  can  easily  be  veri 
fied.  It  is  clear  that  there  are  many  C  that  realize  such  T  and  M  and  they  are  all 
parameterized  via  the  parameter  L'  E  RHoo that,  for  internal  stability,  must  satisfy 
the condition  (/  + L'N')D'~^  E  RHoo. Other parameterizations  such  as K'  can also  be 
used.  In  other  words,  the  maps  T,  M  can  be  realized  by  a  variety  of  configurations, 
each  with  different  feedback  properties. 
Remark 
In  a  two  degrees  of  freedom  feedback  control  configuration,  all  admissible  re 
sponses  from  r  under  condition  of internal  stability  are  characterized  in  terms  of  the 
parameters  X  (or  M),  while  all  response  maps  from  disturbance  and  noise  inputs 
that  describe  feedback  properties  of  the  system  can  be  characterized  in  terms  of  pa 
rameters  such  as  ^  or  2  or  L.  This  is  the  fundamental  property  of  two  degrees  of 
freedom  control  systems:  it  is  possible  to  attain  the  response  maps  from  r  indepen 
dently  from  feedback  properties  such  as  response  to  disturbances  and  sensitivity  to 
plant  parameter  variations. 
EXAMPLE  4.12.  We  consider  H(s)  =  (s -  m  + 2) 
proper  and stable transfer  functions  T(s)  that can be realized by means  of some  control 
and  wish  to  characterize  all 
(s -  2)2 
configuration  with  internal  stability.  Let  H(s)  = 
1  (s -  2f 
{s + 2)2 
s +  2\ 
"N'D""^  be  an "
re  MFD  in  RH 
s + 2 
1 
Then  in  view  of  Theorem  4.24,  all  such  T  must  satisfy  N' 
'T  = 
T  ^  X'  G  RHoo.  Therefore,  any proper  T with  a zero at  +1  can be realized  via 
a two degrees of freedom  feedback  controller with internal  stability. 
Now  if  a single  degree  of freedom  controller  must be used,  the class  of  realizable 
T(s)  under internal stability is restricted. In particular, if the unity feedback  configuration 
{/; Gff,  1} in  Fig.  7.15  is  used,  then  all  proper  and  stable  T  that  are  realizable  under 
internal  stability  are  again  given  by  T 
N'X' 
[s  -  I' 
s + 2 
X\  where  X'  =  L'  E  RH^ 
[see (4.184)] and in addition  (/  +  X W ) ^' 
1 +r  s-  1 
, ^  • ^^  , 
\5  +  2 
(s +  2)2 
(s -  2)2 
X'  =  Hx/dx is proper and stable and should also satisfy  (s+2)dx  + (s 
for  some polynomial  p(s). 
E  RHoo, i.e., 
^  (s-2fp(s) 
This illustrates the restrictions imposed by the unity feedback controller, as opposed 
to a two  degrees  of freedom  controller.  Notice that these  additional  restrictions  are im 
posed because the given plant has unstable poles. 
• 
It is  not  difficult  to prove  the  following  result. 
THEOREM4.25.  T,M,SG 
RHOO are realizable with internal stability by a two degrees 
of freedom  control configuration  that satisfies  (4.169) and (4.167)  [S  =  S^  see Fig. 7.11 
and (4.163), (4.164)] if and only if there exist X',  L  G RH^  so that 
r ri 
M 
_S _ 
= 
[N' 
D' 
.0 
0] 
0 
A^'J 
\X''  + 
ro] 
0 
./_ 
(4.173) 
where  (/  +  L'N')D'-^  G  RHoo,  Similarly,  T, M, Q 
there exist X',L'  G RHo, so that 
RHoo  are realizable  if  and  only  if 
629 
CHAPTER 7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
T' 
M 
Q\ 
= 
[N' 
D' 
.0 
0 
0 
D' 
(4.174) 
where  (/  +  L'N')D'-^  G  RH^o. 
Proof,  The proof  is straightforward  in view  of Theorem  4.24. Note that S ox Q are se 
lected  in  such  a  manner  that  the  feedback  loop  has  desirable  feedback  characteristics 
that are expressed  in terms of these maps. 
• 
Controller  implementations 
The  controller  C  =  [Cy, Cr] may  be  implemented,  for  example,  as  a  system 
Sc as  shown  in  Fig.  7.10  and  described  by  (4.154),  or  as  shown  in  Fig.  7.12  with 
C  =  [Cy, M  + CyT],  where  Cy stabilizes H  and  T, M  are desired  stable maps  that 
relate  r  to j  and  r  to u, i.e.,  y  =  Tr  and  u  =  Mr,  There  are  also  alternative  ways 
of  implementing  a  stabilizing  controller  C.  In  the  following,  the  common  control 
configuration  of Fig. 7.13 is briefly  discussed. It will be denoted by {R; Gff,  Gf^}. 
The {R\ Gff,  Gfb}  Configuration 
Note that  since 
U  =  [Cy, Cr] 
-  [GffGfb,  GffRIl 
(4.175) 
{R; Gff,  Gfb)  is  a  two  degrees  of  freedom  control  configuration  that  is  as  general 
as the ones  discussed 
as the ones discussed before. To see this, let C  =  [Cy, Cr\  =  D'c ^i^r  ^rl  be an Ic 
MFD in 7^7^00 and let 
R  =  N;.,  Gff  =  D 
Gft  =  N;. 
(4.176) 
Note that R  and  G/^  are always  stable; also, G^j  exists  and is stable. Assume now 
that C was chosen so that 
D'D'  -  N'N'  =  U', 
(4.177) 
R  PC 
J , 
+ 
• >! 
r 
1 
I 
1 
1 
1 
1 
1 
1 
L 
u  H 
y 
Gff 
Gfb 
FIGURE 7.13 
Iwo degrees or Ireedom 
controller {R; Off,  Gfb} 
630 
Linear Systems 
where  U',  U' 
in (4.176) is internally  stable, as is shown in the  following. 
E  RHa,. Then  the  system in Fig. 7.13  with  R, Gff,  and  Gft  given 
G  RHoo.  It  can  be  shown  that  (4.177)  implies  (i).  Note  that 
internally  stabilizes  H,  and  (ii)  X'  =  D'-^M  =  D'-\l 
In view of Theorem 4.21, the feedback  system is stable if and only if  (i)  Cy  = 
-
GffGfb  =  D'c'^Ny 
GffGfbHy^GffR 
any  possible  cancellation  in  the product  GffGft>,  between  D'c~^  and  Ny,  will  in 
volve  only  stable  poles;  this  can  easily  be  shown,  using  (4.177).  The  cancelled 
stable  poles  will  be  uncontrollable  or  unobservable  eigenvalues  in  the  closed-
loop  system.  In  addition  X'  =  D'-\l 
-
N!^N'y^D'c]£>'c^N;.  =  U'^N'r  E  RHoo.  Therefore, 
the  control  configuration 
{R;Gff,  Gfb}  =  {Nl\D'-^,N'y}  with  (4.177)  satisfied  is  internally  stable.  In  view 
of this result and Theorem 4.22, Gff,  Gft,,  and R may  also be selected as 
-  GffGfbHy^GffR 
=  D'-^[D'(D'^D' 
R  =  X\  Gff  =  [(/  +  L'N')D'-^] 1-1-1 
Ub 
L' 
(4.178) 
WiihX',  L,{I  + L'N')D'-^  E  J?//oo and J^r(/  + L W)  ^  0, w h e r er  =  D'-^Mand 
L'  =  D'-^Q,  Now if X'  and L'  satisfy  (4.173)  or (4.174) of Theorem 4.25, desired 
command  responses  T, M  and disturbance responses  S ox Q are achieved  under  in 
ternal stability. Note that Gff,  Gfb,  and R may also be selected  as 
R  =  X',  Gff  =  (X[  -  K'N'y 
-1 
, Gfb  =  -(X^  +  K'N'), 
(4.179) 
where X',K'  G  RHoo. 
We  shall  now  briefly  discuss  some  special  cases  of  the  {R; Gff,  Gfb}  control 
configuration,  which are quite common in practice. Note that the configurations  be 
low are simpler; however, they restrict the choices of attainable response maps  and 
so the flexibility offered  to the control designer is reduced when using these  config 
urations. 
/.  The {/;  Gff,  Gfb}  controller.  In this case u  =  [Cy, Cr] 
[GffGfb,  Gff] 
, that is. 
In view of (4.161) given in Theorem 4.22, this implies  that 
Cv  CrG 
r^fb-
L'  =  X'G fb> 
(4.180) 
(4.181) 
or that the choice for the parameters L' and X'  is not completely independent as in the 
{R; Gff,  Gfb} case. The L' and X'  must of course satisfy  L', X'  and (/ + L'N')D'-^  E 
RHa,. In  addition  in this case L'  and X'  must be  such that  a proper  solution  Gfb  of 
(4.181) exists and no unstable poles cancel in X'Gfb.  Note that these poles will can 
cel in the product  Gff  Gfb  and will lead to an unstable  system.  Since L'  and X'  are 
o 
FIGURE 7.14 
The {/; Off,  Gfb} controller 
both  stable, we will require  that  (4.181)  have  a solution  Gfb  ^  RHoo.  This  implies 
that  if  for  example  X'~^  exists,  then  X'  and  L'  must  be  such  that  X'~^L'  G  RHoo, 
i.e.," X'  and  L'  have  the  same unstable  zeros  and  L'  is  ""more proper""  than X'.  This "
provides  some guidelines  about the conditions that X'  and L'  must satisfy.  Also, 
Gff  =  [(I  -hL'N')D'-T 
X'. 
(4.182) 
It  should  be  noted  that  the  state  feedback  law  implemented  by  a dynamic  ob 
server  can be represented  as an {/; Gff,  Gfb}  controller  (see  Subsection  7.4B, Fig. 
7.8). 
631 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
2.  The {/; Gff,  1} controller,  A  special case of (i) is the unity feedback  control 
configuration.  Here  u  =  [Cy, Cr] 
; I.e., 
(4.183) 
^ 
J L 
Gff 
'  u 
H 
y 
FIGURE 7.15 
The {/; G//, /} controller 
which in view of (4.161) implies  that 
X'  =  L'. 
(4.184) 
In  this  case  the  responses  between  y  or  u  and  r  (characterized  by  X')  cannot  be 
designed independently  of feedback  properties such as sensitivity  (characterized  by 
L').  This  is  a  single  degree  of  freedom  controller  and  is  used  primarily  to  attain 
feedback  control  specifications. 
3,  The {R\Gff,I} 
controller.  Here  w -  [C^;, C,] 
[Gff,  GffR] 
; I.e., 
In view of (4.161) given in Theorem 4.22, this implies  that 
Cr  — CyR. 
X'  =  L'R. 
(4.185) 
(4.186) 
The L'  and X'  must satisfy  L', X',  (I  +  L'N')D'-^  e  RHoo. In addition they must be 
such that (4.186) has a solution R  G RHoo. Note that R stable is necessary for internal 
R  ^ 
Gff 
u 
H 
y 
FIGURE 7.16 
The {R; Off,  1} controller 
632 
Linear Systems 
stability. The reader  should refer  to the discussion  in (1) above for the  implications 
of such assumptions on X'  and L'.  Also, 
Off  =  [{I + 
L'N')D'-^Y^L'. 
(4.187) 
4,  The {R\ I,  Gft,} controller.  In this case 
U =  [Cy, Cr]  =  [Gfb,R] 
(4.188) 
1 
^ 
H 
y 
r 
R 
tr^ •?  % 
FIGURE 7.17 
The {R; /, Gft} controller 
For internal  stability, R  must be  stable. In  view  of  (4.161)  given  in  Theorem  4.22, 
this implies the requirement  [(/ + VN')D'~^]~'^X'  G RHoo, in addition to L', X',  (I  + 
L'N')D~^  E  RHoo, which imposes  significant  additional restrictions  on L'. Here 
[Gfb,R]  =  [(I + 
L'N')D'-T'[L\X'l 
(4.189) 
5.  The  {1,1, Gfh}  controller.  This  is  a  special  case  of  (4),  a  single  degree  of 
freedom  case, where R  =  I.  Here R  =  I  implies  that 
or that X'  and L'  must satisfy  additionally the relation 
X'  =  (/  +  L'N')D'-\ 
D'X'  -  L'N'  =  I, 
(4.190) 
(4.191) 
a (skew) Diophantine Equation. This is in addition to the condition that L', X',  (I  + 
L'N')D-^  G  RHoo. 
1  U 
H 
y 
~\ 
J i 
G* 
FIGURE 7.18 
The {/; /, G/b} controller 
Control  problems 
In control problems, design specifications  typically include requirements for in 
ternal  stability  or  pole  placement,  low  sensitivity  to  parameter  variations,  distur 
bance attenuation, and noise reduction. Also, requirements such as model matching, 
diagonal decoupling,  static decoupling, regulation,  and tracking  are included  in the 
specifications. 
633 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
Internal  stability  has  of  course  been  a central  theme  throughout  the book,  and 
in  this  section  all  stabilizing  controllers  were  parameterized.  Pole  placement  was 
studied in Chapter 4, using  state feedback,  and output feedback  via the  Diophantine 
Equation was addressed earlier in Chapter 7. Sensitivity and disturbance/noise reduc 
tion are treated by appropriately  selecting the feedback  controller Cy. Methodologies 
to  accomplish  these  control  goals,  frequently  in  an  optimal  way,  are  developed  in 
many control books. It should be noted that many important design approaches  such 
as the Hoo-optimal  control  design  method,  are based  on the parameterizations  of  all 
feedback  stabilizing controllers discussed earlier. In particular an appropriate or opti 
mal controller is selected by restricting the parameters used, so that additional control 
goals are accomplished  optimally, while guaranteeing internal  stability in the loop. 
Our development of the theory of two degrees of freedom controllers can be used 
directly to study model matching and decoupling, and a brief outline of this approach 
is now given. Note that this does not, by any means, constitute a complete  treatment 
of these important  control problems, but rather,  an illustration  of the  methodologies 
introduced in this  section. 
In the model matching  problem, the transfer  function  of the plant H{s){y  =  Hu) 
and  a  desired  transfer  function  T{s){y  =  Tr)  are  given  and  a  transfer  function 
M{s)(u  =  Mr)  is sought so that 
T{s)=H{s)M{s). 
(4.192) 
Typically, H{s)  is proper, and the proper and stable T{s)  is to be obtained from  H{s) 
using  a  controller  under  the  condition  of  internal  stability.  Therefore,  M{s)  can  in 
general  not be implemented  as an open-loop  controller,  but rather,  as a two  degrees 
of freedom  controller. In view of Theorem 4.24 (or Theorem 4.23), if H  = N'D'~^  is 
an re MFD in RHoo, then the pair  {T,M)  can be realized with internal  stability if and 
only  if  there  exists X^ G RHoo  so  that 
X\  Note  that  an M  that  satisfies 
(4.192)  must first be  selected  (there may  be  an infinite  number  of  solutions  M).  In 
the case when det H{s)  7^ 0,  T can be realized with internal  stability by means  of a 
two degrees of freedom  control configuration  if and only if N^~^T  =X'  ^  RHoo  (see 
Example 4.12). In this case M  =  D'X'.  Now if the model matching is to be achieved 
by  a more  restricted  control  configuration,  then  additional  conditions  are  imposed 
on T  for this to happen,  which are expressed  in terms of X'  (see for instance Exam 
ple 4.12 for the case of the unity feedback  configuration  and Exercises 7.23, 7.26). 
In the problem of diagonal  decoupling,  T{s)  in (4.192) is not completely  speci 
fied, but is required to be diagonal, proper, and  stable. In this problem the first input 
affects  only the first output,  the  second input affects  only the  second  output,  and  so 
forth.  \f  H{s)~^  exists,  then  diagonal  decoupling  under  internal  stability  via  a two 
degrees of freedom  control configuration  is possible if and only if 
•ni_ 
di 
N'-^T  =N'-^ 
X'  G RHo. 
(4.193) 
Clyn J 
where  H  =  N'D'-^ 
l,...,m. 
It  is  clear  that  if  H{s)  has  only  stable  zeros, 
is  an  re  MFD  in  RH^.  and  T{s)  =  diag  [ni{s)/di{s)],i  = 
then  no  additional 
634 
Linear Systems 
restrictions  are imposed  on  T{s).  Relation  (4.193)  implies  restrictions  on the  zeros 
^^ ^i^^) when H{s)  has unstable zeros. 
It is  straightforward  to show that if  diagonal  decoupling  is to be  accomplished 
by means  of more restricted  control configurations,  then  additional restrictions  will 
be imposed on T{s)  via X'.  (See Exercise 7.25  and Exercise 4.17, 4.20 of Chapter 4 
for the case of diagonal decoupling via linear state  feedback.) 
The problem of diagonal decoupling has a long and interesting history and a very 
rich  literature.  The  original  solution  of  the problem  involved  linear  state  feedback 
and state-space descriptions  and is due to Falb and Wolovich  [12]. For an  approach 
involving PMDs  and the transfer  function  matrix,  see Williams  and Antsaklis  [35]. 
Other types of decoupling, such as block, dynamic, and static, are also treated there. 
A problem closely related to diagonal decoupling  is that of the inverse  of  H{s). 
In  this  case,  T{s)  =  I.  There  is  also  a very  rich  literature  on this  problem  and  the 
interested  reader  is encouraged  to find out more  about it. A  starting point  could  be 
Williams  and Antsaklis  [35]. (See also Exercises 4.17, 4.18 in Chapter  4.) 
In  the  problem  of  static  decoupling,  T(s)  E  RHa,  is  square  and  also  satis 
fies  r(0)  =  A,  a  real  nonsingular  diagonal  matrix.  An  example  of  such  T(s) 
r ^2  +1 
[s(s +  2) 
s(s^  + 2)  ] 
s^  ^3s+ 
I 
d{s) 
where  d{s)  is  a  Hurwitz  polynomial. 
Note  that  if  T(0)  =  A,  then  a  step  change  in  the  first  input  r  will  affect  only 
the  first  output  in  y  at  steady-state,  and  so  forth.  Here  y  =  Tr  =  T(l/s)  and 
lims^osT(l/s)  =  T(0)  =  A, which is diagonal and nonsingular. For this to happen, 
with internal  stability  when H(s)  is nonsingular  (see Theorem 4.24), we must  have 
N'  T  =  X'  G  RHoo,  from  which  can  be  seen  that  static  decoupling  is possible  if 
and only if H{s) does not have zeros at 5* =  0. If this is the case and if in addition  H{s) 
is  stable,  static  decoupling  can  be  achieved  with just  a precompensation  by  a real 
gain matrix  G, where  G  =  H-\Qi)K.  In this case  T{s)  =  H{s)G  =  H{s)H~\0)A, 
from  which  T(0)  =  A. 
7.5 
SUMMARY 
In this chapter  alternatives  to state-space  descriptions  were introduced  and used  to 
further  study  the  behavior  of  linear  time-invariant  systems  and  to  study  in  depth 
structural properties of feedback  control systems. 
In Part 1, the properties of systems described by Polynomial Matrix Descriptions 
(PMDs)  were explored  in Section  7.3  and background  on polynomial  matrices  was 
provided  in  Section  7.2. The Diophantine  Equation,  which  plays  an important  role 
in feedback  systems, was studied  at length in Subsection  7.2E. 
An in-depth study of the theory of parameterizations of all stabilizing controllers 
with emphasis on PMDs was undertaken in Part 2, Subsection 7.4A, and the param 
eterizations of all proper stabilizing controllers in terms of proper and stable Matrix 
Fraction Descriptions  (MFDs) were derived in Subsection 7.4C. State feedback  and 
state estimation  using PMDs were studied in Subsection  7.4B. Finally, control sys 
tems  with  two  degrees  of  freedom  controllers  were  explored  in  Subsection  7.4D, 
with  an  emphasis  on  stability,  parameterizations  of  all  stabilizing  controllers,  and 
attainable response maps. 
635 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of Systems 
7.6 
NOTES 
Two  books  that  are  original  sources  on  the  use  of  polynomial  matrix  descriptions 
in systems and control are Rosenbrock  [30] and Wolovich  [36]. In the former,  what 
is now called Rosenbrock's Matrix is employed and relations to state-space descrip 
tions are emphasized. In the latter, what are now called Polynomial Matrix Fractional 
Descriptions  (PMFDs)  are  emphasized,  and  the  relation  to  state  space  is  accom 
plished primarily  by using  controller  forms  and the Structure  Theorem,  which  was 
presented in Chapter 3. Good general  sources for the polynomial matrix  description 
approach  also include the books by Vardulakis  [33], Kailath  [21], and Chen [10]. 
Basic  references  for  the  material  on polynomial  matrices  discussed  in  Section 
7.2  are  the  books  by  MacDuffee  [25]  and  Gantmacher  [14]. These  books  also  in 
clude  material  on  the  Diophantine  Equation  discussed  in  Subsection  7.2E.  Addi 
tional sources for the properties of polynomial matrices that we found useful  include 
Wolovich  [36], Vardulakis  [33], and Kailath [21]. 
A key  concept  in our  development  of polynomial  descriptions  for  the  study  of 
systems  is  the  notion  of  equivalence  of  representations,  discussed  in  Subsection 
7.3A,  since  it  establishes  not  only  relations  between  polynomial  descriptions  but 
also between  polynomial  and  state-space  representations.  Original  sources  for  this 
include  Rosenbrock  [30]  and  Fuhrmann  [13]. See  also  Pernebo  [28]  and  the  com 
ments by Rosenbrock in [31 ] and [32], noting that the definition of equivalence given 
by Wolovich [36] was shown by Pernebo in [28] to be the same as strict system equiv 
alence. Additional material on this topic can be found in Kailath [21], Wolovich [36], 
and Vardulakis  [33]. A good source for the study of feedback  systems using  PMDs 
and MFDs is the book by Callier and Desoer [9]. 
The development of the properties of interconnected systems, addressed in Sub 
section 7.3C, which include controllability, observability, and stability of systems in 
parallel, in series, and in feedback  configurations  is based primarily on the approach 
taken in Antsaklis  and  Sain  [8], Antsaklis  [2] and  [3], and Gonzalez  and  Antsaklis 
[18]. 
Parameterizations  of  all  stabilizing  controllers  are  of  course  very  important  in 
control theory today. Historically, their development  appears to have evolved in the 
following  manner  (see  also  the  historical  remarks  on  the  Diophantine  Equation  in 
Subsection 7.2E): Youla et al. [37] introduced the K parameterization (as in Theorem 
4.2) in  1976 and used it in the Wiener-Hopf  design of optimal controllers. This work 
is considered to be the seminal contribution in this area. The proofs of the results on 
the parameterizations in Youla et al. [37] involve transfer functions  and their charac 
teristic polynomials. Neither the Diophantine Equation nor PMDs of the system are 
used  (explicitly). It should be recalled  that in the middle  1970s most of the  control 
results in the literature concerning MIMO systems involved state-space descriptions 
and  a few  employed  transfer  function  matrices. The  PMD  descriptions  of  systems 
presented  in  the  books  by  Rosenbrock  [30]  and  Wolovich  [36]  were  only  begin 
ning  to make  some impact.  A version  of the linear  Diophantine  Equation,  namely, 
AX  ^-YB  =  C polynomial in z~^ was used in control design by Kucera in work re 
ported in 1974 and  1975. In that work, parameterizations of all stabilizing controllers 
were  implicit,  in  the  sense  that  the  stabilizing  controllers  were  expressed  in  terms 
of the general  solution of the Diophantine Equation, which in turn can be  described 
parametrically. Explicit parameterizations were reported in Kucera [23]. In Antsaklis 
636 
Linear Systems 
[1] the doubly coprime MFDs were used with the polynomial Diophantine Equation, 
working over the ring of polynomials, to derive the results by Youla in an alternative 
way. In Desoer et al. [11] parameterizations K'  of all stabilizing controllers using co-
prime MFDs  in rings other than polynomial rings  (including  the ring of proper  and 
stable rational functions)  were derived. It should also be noted that proper and stable 
MFDs  had  apparently  been  used  earlier  by  Vidyasagar.  In  Zames  [38], a parame 
terization  Q of all  stabilizing  controllers, but only for  stable plants, was  introduced 
and  used  in  //oo-optimal  control  design.  (Similar  parameterizations  were  also  used 
elsewhere, but apparently not to characterize all stabilizing controllers; for example, 
they were used in the design of the closed-loop transfer  function  in control  systems 
and  in  sensitivity  studies  in  the  50s  and  60s,"  and  also  in  the  ""internal  model  con "
"trol""  studies  in  chemical  process  control  in  the  80s.)  A  parameterization  X  of  all "
stabilizing  controllers  (where  X  is  closely  related  to  the  attainable  response  in  an 
error feedback  control  system), valid for unstable plants  as well, was introduced  in 
Antsaklis  and  Sain  [7]. Parameterizations  involving  proper  and  stable MFDs  were 
further  developed  in the  80s in connection  with  optimal  control  design  methodolo 
gies,  such  as ii/oo-optimal  control,  and  connections  to  state-space  approaches  were 
derived.  Two degrees  of freedom  controllers  were  also  studied,  and  the  limitations 
of the different  control configurations  became better understood. By now, MFDs and 
PMDs have become important system representations  and their study is essential, if 
optimal control design methodologies  are to be well  understood. 
In Subsection 7.4A, the discussion of parameters N^,  D^,  and K  (Theorems  4.1 
and 4.2) follows Antsaklis  [1]. The material for the parameter X2 (Corollary 4.6) fol 
lows Antsaklis  and  Sain  [7], where X2 was introduced  in connection  with the  error 
feedback control configuration.  Q2 was used in Zames [38] for stable systems (Corol 
lary 4.4); however. Theorem 4.3 is valid for unstable systems as well. The discussion 
of the parameters  Sn  and  Li, L2 follows  Antsaklis  and  Sain  [8], and Antsaklis  [3]. 
Subsection 7.4B is based on Wolovich  [36] and Antsaklis  [2] and [3]. 
The results on proper and  stable MFDs in Subsection  7.4C  and their use in pa 
rameterizing  all proper  stabilizing  controllers  are due to Desoer  et al.  [11]. The de 
velopment  in  Subsection  7.4C  was based  on Vidyasagar  [34], Antsaklis  [3], Green 
and Limebeer [20], and Maciejowski  [26]. The development of the relations between 
MFDs in RHoo and PMDs of a system follows  AntsakHs  [4], and Nett et al. [27]; see 
also Khargonekar  and Sontag  [22]. The A-approach was developed in Pernebo [29]. 
The material on two degrees of freedom  controllers in Subsection 7.4D is based 
on Antsaklis [3], Antsaklis and Gonzalez [6], and Gonzalez and Antsaklis [16], [17], 
[18],  [19]; a good  source  for  this  topic  is  also  Vidyasagar  [34]. Note that  the  main 
stability  theorem  (Theorem  4.21)  first  appeared  in Antsaklis  [3] and Antsaklis  and 
Gonzalez  [6]. For  additional  material  on  model  matching  and  decoupling,  consult 
Chen  [10], Kailath  [21], Falb and Wolovich  [12], Williams  and AntsakUs  [35], and 
the extensive list of references  therein. 
7.7 
REFERENCES 
1.  P. J. Antsaklis," ""Some Relations Satisfied by Prime Polynomial Matrices and Their Role "
in Linear Multivariable System Theory,""" IEEE Trans",  on Autom. Control,  Vol. AC-24, 
No. 4, pp. 611-616, August 1979. 
2.  P. J. Antsaklis, Notes  on: Polynomial  Matrix  Representation  of Linear  Control  Systems, 
637 
3. 
4. 
Pub. No. 80/17, Dept. of Elec. Engr., Imperial College, London,  1980. 
P. J. Antsaklis,  Lecture Notes  of the graduate  course. Feedback  Systems,  University  of 
Notre Dame, Spring  1985. 
P.  J.  Antsaklis,"  ""Proper",  Stable  Transfer  Matrix  Factorizations  and  Internal  System 
Descriptions,""" IEEE  Trans",  on Autom.  Control,  Vol. AC-31,  No. 7,  pp. 634-638,  July 
1986. 
5.  P. J. Antsaklis," ""On the Order of the Compensator  and the Closed-Loop Eigenvalues in "
the Fractional Approach to Design,""" Int.  J. Control",  Vol. 49, No. 3, pp. 929-936,  1989. 
6.  P.  J.  Antsaklis  and  O.  R.  Gonzalez,"  ""Stability  Parameterizations  and  Stable  Hidden "
Modes in Two Degrees of Freedom Control Design,""" Proc.  of the 25th Annual  Allerton "
Conference  on  Communication,  Control  and  Computing,  pp. 546-555, Monticello, IL, 
Sept. 30-Oct.  2, 1987. 
7.  P. J.  Antsaklis  and  M.  K.  Sain,"  ""Unity  Feedback  Compensation  of  Unstable  Plants",""" "
Proc.  of  the  20th  IEEE  Conf.  on  Decision  and  Control,  pp.  305-308,  San  Diego, 
December 1981. 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
10 
11 
12. 
13. 
14. 
15. 
16. 
9. 
8.  P. J. Antsaklis  and M. K.  Sain,"  ""Feedback  Controller Parameterizations:  Finite  Hidden "
Modes and Causality,""" in Multivariable  Control: New  Concepts  and Tools", S. G. Tzafes-
tas, ed., D. Reidel Pub., Dordrecht,  Holland,  1984. 
F. M. Callier and C. A. Desoer, Multivariable  Feedback  Systems,  Springer-Verlag,  New 
York,  1982. 
C. T. Chen, Linear  System  Theory  and Design,  Holt, Rinehart  and Winston, New York, 
1984. 
C.  A.  Desoer,  R.  W.  Liu,  J.  Murray,  and  R.  Saeks,"  ""Feedback  System  Design:  The "
Fractional  Approach  to  Analysis  and  Synthesis,"""  IEEE  Trans",  on  Autom.  Control, 
Vol. AC-25, pp. 399-412, June  1980. 
P.  L.  Falb  and  W.  A.  Wolovich,"  ""Decoupling  in  the  Design  of  Multivariable  Control "
Systems,""" IEEE  Trans", on Autom.  Control,  Vol. AC-12, pp. 651-659,  1967. 
P. A. Fuhrmann," ""On Strict System Equivalence and Similarity",""" Int. J. Control", Vol. 25, 
pp. 5-10,  1977. 
F. R. Gantmacher,  The Theory  of Matrices,  Vol.  1 and 2, Chelsea, New York,  1959. 
Z.  Gao  and  P. J.  Antsakhs,"  ""On  Stable  Solutions  of  the  One  and  Two  Sided  Model "
Matching  Problems,"""  IEEE  Trans",  on Autom.  Control,  Vol.  34,  No.  9,  pp.  978-982, 
September  1989. 
O.  R.  Gonzalez  and  P.  J.  Antsaklis,"  ""Implementations  of  Two  Degrees  of  Freedom "
Controllers,""" Proc.  of the 1989 American  Control  Conference",  pp. 269-273, Pittsburgh, 
PA, June 21-23,  1989. 
O. R.  Gonzalez  and P. J. Antsaklis,"  ""Sensitivity  Considerations  in the  Control  of  Gen-"
erahzed  Plants,""" IEEE  Trans",  on Autom.  Control,  Vol. 34, No.  8, pp. 885-888,  August 
1989. 
O. R.  Gonzalez  and P. J. Antsaklis,"  ""Hidden  Modes  of  Two Degrees  of  Freedom  Sys "
tems in Control Design,""" IEEE  Trans", on Autom.  Control,  Vol. 35, No. 4, pp. 502-506, 
April  1990. 
O.  R.  Gonzalez  and  P. J.  Antsaklis,"  ""Internal  Models  in  Regulation",  Stabilization  and 
Tracking,""" Int.  J. of Control",  Vol. 53, No. 2, pp. 411-430, 1991. 
M.  Green  and  D.  J.  N.  Limebeer,  Linear  Robust  Control,  Prentice  Hall,  Englewood 
Cliffs,  NJ,  1995. 
17 
18 
19 
20. 
21.  T. Kailath, Linear  Systems,  Prentice-Hall, Englewood  Cliffs,  NJ,  1980. 
22.  P. Khargonekar  and  E.  D.  Sontag,"  ""On  the  Relation  Between  Stable  Matrix  Fraction "
Factorizations  and Regulable Realizations of Linear Systems Over Rings,""" IEEE  Trans", 
on Autom.  Control,  Vol. AC-27, pp. 627-638, June  1982. 
23.  V  Kucera, Discrete  Linear  Control, Wiley, New York,  1979. 
638 
Lh^^Systems 
24.  V. Kucera,"  ""Diophantine  Equations  in  Control—A  Survey","""  Automatica",  Vol. 29, pp. 
1361-1375, 1993. 
25.  C. C. MacDuffee,  The Theory  of Matrices,  Chelsea, New York, 1946. 
26.  J.  M.  Maciejowski,  Multivariable  Feedback  Design,  Addison-Wesley,  Reading,  MA, 
1989. 
27.  C. N. Nett,  C. A. Jacobson,  and M. J. Balas,"  ""A Connection  Between  State-Space and "
Doubly Coprime Fractional Representations,""" IEEE  Trans", on Autom.  Control, Vol. AC-
29,  pp. 831-832, September 1984. 
28.  L. Pernebo," ""Notes on Strict System Equivalence",""" Int. J. of Control", Vol. 25, pp. 21-38, 
1977. 
29.  L. Pernebo," ""An Algebraic Theory for the Design of Controllers for Linear Multivariable "
Systems,""" IEEE  Trans", on Autom.  Control,  Vol.  AC-26, pp. 171-194, February 1981. 
30.  H. H. Rosenbrock,  State-Space  and Multivariable  Theory, Nelson, London, 1970. 
31.  H. H. Rosenbrock,"  ""A Comment  on Three Papers",""" Int. J. of Control",  Vol. 25, pp. 1-3, 
1977. 
32.  H. H. Rosenbrock,"  ""The Transformation  of Strict  System Equivalence",""" Int. J.  Control", 
Vol. 25, pp. 11-19, 1977. 
33.  A. L G. Vardulakis, Linear  Multivariable  Control,  Wiley, New York, 1991. 
34.  M. Vidyasagar,  Control  System  Synthesis.  A Factorization  Approach,  MIT Press, Cam 
bridge, MA,  1985. 
35.  T. Williams  and P. J.  Antsaklis,"  ""Decoupling","""  The  Control  Handbook",  Chap.  50, pp. 
745-804, CRC Press and IEEE Press, Boca Raton, FL, 1996. 
36.  W. A. Wolovich, Linear  Multivariable  Systems,  Springer-Verlag, New York, 1974. 
37.  D. C. Youla, H. A. Jabr, and J. J. Bongiorno, Jr.," ""Modern Wiener-Hopf Design of Optimal "
Controllers—Part  II:  The Multivariable Case,""" IEEE  Trans", on Autom.  Control, Vol. AC-
21,  pp. 319-338, June 1976. 
38.  G. Zames," ""Feedback and Optimal Sensitivity: Model Reference  Transformations",  Mul 
tiplicative Seminorms, and Approximate Inverses,""" IEEE  Trans", on Autom.  Control, Vol. 
26,  pp. 301-320, 1981. 
7.8 
EXERCISES 
7.1.  Given  a polynomial  matrix  P{s) G R[sY^^  with  rankP(s)  =  mm(p,  m), write a com 
puter program to reduce P(s) to a row proper (row reduced) matrix via row elementary 
operations and to derive the corresponding unimodular matrix  UL(S).  Use your computer 
algorithm to verify  the results of Example 2.10. Hint:  Apply the algorithm to [P(s), Ip] 
so that in  UL(S)[P(S), 
Ip]  =  [P(s),  UL(S)],  P(S) is in row proper  form  and  UL(S) is the 
appropriate unimodular  matrix. 
"7.2.  Given  a polynomial  matrix  P(s)  G RlsV^""^ with p  >  m", write a computer program to 
reduce P(s) to column Hermite form and to derive the corresponding unimodular matrix 
UL(S).  Use your computer algorithm to verify  the results of Example 2.13. Hint:  Apply 
the algorithm to [P(s), Ip] so that in  UL(S)[P{S), 
Ip]  =  [P(s),  UL(S)1  P(S) is in Hermite 
form  and  UL(S)  is the appropriate unimodular  matrix. 
"7.3.  Consider  A  G R^^^  and let  IAI//'""'!^  ", be the r  X r  minor  formed  by selecting  r rows 
I 
\{ki,...,kr} 
-^ 
^ 
denoted by {ii,..., 
ir},  and r columns of A, denoted by {^i,... Z:^}, where r <  min(m, n). 
Let B G  R'^^P  and consider the minors of the product AB. These can be determined using 
\An\iH'-M 
^  ^ 
I .  |{'l.-.^r}  |^|{/i,...,/r} 
639 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
formula. 
where  {/i,..., Ir}  denotes  all possible  sets  of  r integers  among  the  n columns  of  A 
and  n rows  of 5,  with  r < mm{m,n,p).  This  formula  for  the  minors  of  the  product 
of matrices is known as the Binet-Cauchy 
(a)  \iA^R^^^,B^R^^^, 
with m<n,  determine  an expression for  detAB. 
(b)  Show that if A and B are both square, then det AB  = det A  det B = det  BA. 
(c)  Suppose that Pi {s)  and Piis),  polynomial  matrices  of the  same dimensions,  are 
related  by  P\{s)  =  U{s)P2{s)V{s),  where  U{s)  and  V{s)  are  also  polynomial 
matrices.  Show that the  (monic)  gcd of  all j  x j  minors of P2('^), i-e., the  deter-
minantal divisor Dj{s)  of P2{s), divides the gcd of all j  x j  minors of Pi (5),  i.e., 
the corresponding  determinantal  divisor of Pi {s). 
(d)  \iU{s)  and y  (5)  (in (c)) are unimodular,  show that all the determinantal  divisors 
Dj{s),  and  therefore,  all  the  invariant  factors  ej{s)  of  P\{s)  and  Piis),  are  the 
same.  That  is,  the  invariant  factors  of  a  matrix  are  not  affected  by  row  and 
column  elementary  operations.  This  also  shows  that  if  Pi (5)  =  U(s)P2(s)V(s) 
with  U{s)  and  V{s)  unimodular,  then  Pi{s)  and  P2{s) have  precisely  the  same 
Smith  form.  It  is  straightforward  to  also  show  the  opposite,  i.e.,  if  Pi (s)  and 
P2{s) have the same Smith form,  then there exist unimodular  matrices  U{s)  and 
V{s)  such that Pi (s)  =  U{s)P2{s)V{s)  (see Subsection  7.2C). 
7.4. 
Given  a polynomial  matrix  P{s)  e  R[S]P^^  with  p  > m,  write  a computer  program 
to  determine  a  gcrd  G^{s)  of  all  the  rows  of  P{s)  and  to  derive  the  corresponding 
unimodular matrix U{s).  Use your computer program to determine a gcrd and a geld 
of  the  matrices  Pi{s)  and  P2{s)  of  Example  2.15.  Hint:  Determine  a  unimodular 
matrix  U{s)  such  that  U{s)P{s) 
.  Apply  your  algorithm  to  [P(s),  Ip] so 
0 
that  U{s)[P{s),Ip 
G%{s) 
0 
U{s) 
7.5.  Consider the polynomial matrices P{s) -
s^  + s 
- . 2 -1 
R{s)-
s 
-s-l 
(a)  Are they re? If they  are not, find a greatest common right divisor (gcrd). 
(b)  Are they Ic? If they are not, find a geld. 
7.6.  (a)  Show that two square and nonsingular polynomial matrices, the determinants of 
which  are coprime  polynomials,  are both re  and Ic. Hint:  Assume  they  are  not, 
say, re and then use the determinants of their gcrd to arrive at a contradiction, 
(b)  Show  that  the  opposite  is not  true,  i.e.,  two re  (Ic) polynomial  matrices  do  not 
necessarily  have determinants that are coprime  polynomials. 
7.7.  (a)  Show  that  if  (the nonsingular)  G^^ (s)  and  G^^ (s)  are both  gcrds  of  Pi  and P2, 
then there exists a unimodular  matrix  UR{S)  such that G^  (s)  =  UR{S)G^ 
(S). 
(b)  Similarly,  show  that  if  the  nonsingular  G^  (s)  and  G|^ (s)  are  both  gelds  of 
Pi  and  P2,  then  there  exists  a  unimodular  matrix  UL{S) such  that  G£  (5)  = 
GI,{S)UL{S). 
7.8.  Show that v  defined  in (2.43) is indeed the observability  index of the  system. 
"7.9.  Let P{s)  =  P„5""  + P„_i5""-i  +  • • • +Po  be a matrix polynomial with Pi  e  P""><"" and let "
"A  G P""><"". Show  that "
"(a)  P{s)  =  Qr{s){sl-A)  +Rr  withRr  = P„A"" + P„_iA""-i  +  • "
(b)  P{s)  =  {sI-A)Qi{s)+Ri 
"withRi  =A""P„+A""-ip„_i  + • "
•+Po, 
•+Po. 
"Hint:  Qr{s)  = PnS^'^ +  (P„A +  P„_i)5""-^ +  • • • +  {PnA^'^  +  • • • + P i ). "
640 
Linear  Systems 
7.10. Let P(s) be a polynomial matrix of full  column rank and let y(s) be a given  polynomial 
vector. Show that the equation  P(s)x(s)  = y(s) will have a polynomial  solution x(s) for 
any y(s) if and only if the columns of P(s)  are Ic, or equivalently, if and only if P(A) has 
full  column rank for any complex number A. 
"7.11.  Let P(s)  =  PdS^ + Pd-is""^'^  + • • • + Po ^  R[s]P'''^ and let Pe(s)  =  block  diag "
(I^,..., 
Imy P(s)) with d blocks  on the diagonal. It can be shown  that by means  of elementary 
row and column operations, Pe(s) can be transformed  to a (linear) matrix pencil  sE -  A. 
In  particular, 
Pe(s)  =  U(s)(sE  -  A)V(s), 
where E and A are real matrices  given by 
E  = block  diag(Pd,  Im, •  •> Im) 
A  =  • 
-Pd-i 
/ 
0 
"•"" "
••• 
-Pi 
0 
-Po 
0 
••• 
/ 
0 
and  U(s) and V(s) are unimodular  matrices given by 
I 
si 
s^-'l 
y(s) 
U(s)  = 
si 
I 
0 
Bi(s) 
-I 
Bd-i(s) 
with  Bi+i(s)  =  sBi(s)  +  Prf-o+i), /  -  1,..., J  -  2, and Bi(s)  =  sPd +  Pd-i-  Note 
that  P(s)  and sE  -  A  have  the  same  nonunity  invariant  polynomials.  Let  P(s)  = 
s^  -\- s  —s 
1 
and obtain the equivalent matrix pencil sE -  A. 
7.12. Let {DR, I, NR} and {DL, NL, I] be minimal realizations of H(s),  where H(s)  •-
^  NRDI'  = 
DI^NL 
X 
NL 
with 
Fl 
DL\ 
{NR,PR) 
-Y 
X 
and 
/  where  U is unimodular,  i.e., they  are doubly co-
prime factorizations  of H(s).  Show that these realizations are equivalent representations. 
Hint: 
re 
I  0 
0 
related  by 
\DR 
[NR 
(PL,NL) 
and 
Ic 
NL  0 
0 
/ 
Y  0 
X 
I 
DR 
-NR 
I 
0 
DL 
-I 
NL 
0 
DL 
I 
NL 
0 
DR 
-NR 
/ 
0 
NR  0 
/ 
0 
-X 
/ 
Y 
0 
and also, 
7.13.  Consider  P{q)z{t)  =  Q{q)u{t)  and y{t)  =  R(q)z(t)  +  W(q)u(t),  where 
P{q)  = 
R(q)  = 
q  -
0 
\q  -q 
[-q-2 
\2q^  + q + 2 
-q-2 
Q(q)  = 
W(q)  = 
q -  1 
-2q  + 2 
1 
3q 
1  3q + 4 
1 
-3q 
Iq 
0 
with q  =  d/dt. 
(a)  Is this system representation  controllable? Is it observable? 
(b)  Find the transfer  function  matrix//(>y)(y(5')  =  H(s)u(s)). 
(c)  Determine  an equivalent  state-space  representation  x  =  Ax  + Bu,  y  =  Cx  +  Du 
641 
and repeat (a) and (b) for this  representation. 
"7.14. Use system theoretic arguments to show that two polynomials d{s)  =  s""^  + dn-is""""'^  + "
"\-dis  -\-do and n(s)  =  n„_i5'""~^ +  nn-2S^~^ + "
\- nis  -\- no art coprime if and only 
if 
Cc 
rank 
=  n, 
where Ar  = 
0 
0 
1 
0 
0 
1 
0 
-do 
0 
-di 
0 
-d2 
CcAT' 
0 
0 
1 
-dn-\ 
a n dQ  =  [no, n\,..., 
nn-\\. 
CHAPTER?: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
7.15. Consider the transfer function  H{s) 
s 
s+  1 
Determine a minimal real 
ization in 
(a)  Polynomial Matrix Fractional Description  (PMFD)  form, 
(b)  State-Space Description  (SSD)  form. 
7.16. In the following,  assume that a PMD, [P, Q, R, W}, realizes an invertible mXm 
transfer 
function  matrix  H. 
(a)  Show that the system matrix for H~^  is given by 
P  Q 
-R  W 
0 
Im 
0 
0 
Hint:  Note thaiSdz^, 
-w^,  - / ]^  =  [0,0, -u'^f  when Pz  =  Qu,y  =  Rz  +  Wu. 
(b)  Show that the following  system matrix can also be used to characterize  / / ~\ 
R 
P 
-W 
Q 
SM  — 
0 
0 
(c)  Let  detW  ^  0.  Show  that  H'^  =  RP'^Q  -H W,  where  W  =  W'K  Q  =  QW'K 
R  =  -W-^R,  mdP  =  P  +  QW-^R. 
7.17. Consider the system Dz  =  u, y  =  Nz,  where D  = 
0 
0 
andA^  =  [s^ -ls+ 
1]. 
(a)  Determine an equivalent  state-space  representation. 
(b)  Is  the  system  controllable?  Is  it  observable?  Determine  all  uncontrollable  and/or 
unobservable eigenvalues, if any. 
(c)  Determine the invariant  and the transmission  zeros of the  system. 
642 
Linear Systems 
7.18. Consider the series connection depicted in Fig. 7.2 and the PMFDs for ^i and ^2, given 
in (3.63), (3.64) and (3.66), (3.67). 
(a)  Show that the system S is controllable if and only if 
(i)  (A^i, D2) is Ic, or 
(ii)  (5iZ)2,M)islc, or 
(iii)  (N2Ni,D2)is\c, 
(b)  Determine similar conditions [as in (a)] for S to be observable. 
7.19. Consider the parallel connection depicted in Fig. 7.1 and the PMFDs for ^i and S2 given 
in (3.52), (3,53) and (3.55), (3.66), Derive conditions for controllability and observabil 
ity of S analogous to the ones derived for the series connection in Exercise 7.18. 
7.20. Consider the double integrator//i  = l/s'^. 
(a)  Characterize all stabilizing controllers H2 for Hi using all the methods developed 
in Subsections 7.4A and 7.4C. 
(b)  Characterize all proper stabilizing controllers H2 for Hi of order 1. 
7.21. Consider the double integrator//i  =  l/s^. 
(a)  Derive a minimal state-space realization for Hi and use Lemma 4.19 to derive dou 
bly coprime factorizations in RHoo. 
(b)  Use the polynomial Diophantine Equations (4.102) and (4.106) to derive factoriza 
tions in RHoo. 
7.22. Consider// 
s^ + I 
s+1 
(a)  Derive a minimal state-space realization {A, B, C, D} and use Lemma 4.19 and The 
orem 4.13 to parameterize all stabilizing controllers H2. 
(b)  Derive a stabilizing controller H2 of order 3 by appropriately  selecting K'.  What 
are the closed-loop eigenvalues in this case? Comment on your results. 
Hint: A minimal state-space realization was derived in Example 3.2. The eigenval 
ues of A + BF and A -  KC  are stable, but otherwise arbitrary. Note that some of 
these eigenvalues become closed-loop eigenvalues. 
7.23. Consider the unity feedback (error feedback) control system depicted in Fig. 7.19, where 
H and C are the transfer function matrices of the plant and controller, respectively. 
r 
+  ^^ 
e 
a 
FIGURE 7.19 
Assume that (/  + HC)  ^  exists, 
(a)  Verify the relations 
y = {1 + HCy^HCr  + {I + HCT^d  ^  Tr-\-Sd 
u  = (1 + CHY^Cr  -  (/  + CHY^Cd  = Mr  -  Md. 
Compare  these  with  relations  (4.163)  to  (4.168)  for  the  two  degrees  of  freedom 
controller  u  =  Cyy  +  G r.  Note  here  that  u  =  -Cy  +  Cr,  and  therefore,  Cy  = 
-C  and  Cr  =  C.  Hence, for  the  error  feedback  system  of Fig. 7.19, the  relations 
following  (4.168) assume the  forms 
M  =  (/  +  CHY^C  =  DX  =  -Q  = 
T  =  H(I  + CHY^C  =  (/  +  HCY^HC  =  HM  =  NX 
So  =^  (1 + HCY^  =  I  + HQ  =  I-  HM  =- 
Si  =  (/  +  CHY^  =  I  + QH  =  I  -  MH. 
-DL 
I-T 
643 
CHAPTER  7: 
Polynomial 
Matrix 
Descriptions 
and Matrix 
Fractional 
Descriptions 
of  Systems 
(b) 
(i)  Let  H  =  ND~^  be  an  re  polynomial  factorization.  Show  that  all  stabilizing 
controllers are given by 
C  =  [(/ -  XN)D-^T^X, 
where [{I-XN)D~^,  X] is stable and (I-XNY^ 
4.22 to the error feedback  case, 
exists. Hint:  Apply Theorem 
(ii)  If  H  is  proper  and  H  =  N'D' 
is  an re  MFD  in  RH^,  show  that  all  proper 
stabilizing controllers are given by 
C =  [(/ - X'N')D' \'X\ 
where  [(/  -  X'N')D' 
Hint:  Apply Theorem 4.22 to the error feedback  case. 
\  X']  G  RH^  and  (/  -  X'N'Y^  exists  and  it is  proper. 
v -l 
(c)  Assume  that  H  is  proper  and  H~^  exists,  i.e.,  H  is  square  and  nonsingular.  Let 
H  =  ND~^  be  an  re  polynomial  MFD.  If  T  is  the  closed-loop  transfer  function 
between y  and r, show that the system will be internally  stable if and only if 
[N-\I-T)H,N~^T] 
is stable. Assume that T  ^  I  for the loop to be well defined. Note that if T is proper, 
then 
C  =  H-^T(I-TY^ 
is proper if and only if H~^T  is proper and I  -  T  is biproper. 
(d)  Assume that in  (c) H  and  T are  SISO transfer  functions.  Let H  =  n/d.  Show  that 
the closed-loop  system will be stable if and only if 
(1 -  T)d  -1  _  Sd-
and 
Tn-
are stable, i.e., if and only if the sensitivity matrix has as zeros all the unstable poles 
of the plant and the closed-loop transfer  function  has as zeros all the unstable zeros 
of the plant. 
(e)  Given  His)  = 
Remark:  Note that this is a result known in the classical control literature  (refer 
to J. R. Ragazzini and G. F. Franklin, Sampled  Data  Control Systems,  McGraw-Hill, 
1958). It is derived here by specializing the more general MIMO case results to the 
SISO case. 
5 -1 
^rrz  —,  characterize  all  scalar  proper  transfer  functions  T 
that can be realized  via the error feedback  configuration  shown in Fig. 7.19, under 
internal  stability. For comparison  purposes,  characterize  all  T that  can be  realized 
via a two degrees of freedom  controller and comment on your results. In both cases, 
comment  on  the  location  and  number  of  the  closed-loop  eigenvalues.  Hint:  Use 
Theorems 4.22 and 4.24. 
644 
Linear  Systems 
7.24. Consider/^W 
(s -  l)(s  +  2) 
(s  -  2)2 
and  characterize  all proper  and  stable  transfer  func-
tions  T(s)  that  can  be realized  via  linear  state  feedback  under  internal  stability.  Hint: 
From Subsection  7.4B, note that T 
NDp^G  and consider Theorem 4.23. 
7.25.  Consider//  = 
1 
s+  1 
1 
5  +  3 
1 
L^H-  1 
5  +  l-J 
(a)  Derive an re MFD in  RHo.,  H  =  N'D'~ 
(b)  Let  T 
r ^l 
^1 
0 
0 1 
ni 
^2-i 
and characterize  all diagonal  T that  can be realized  under  in 
ternal stability via a two degrees of freedom  control  configuration, 
(c)  Repeat  (b) for a unity feedback  configuration  {/; G//,  /} (see Fig. 7.15). 
7.26. In the model matching problem, the transfer function  matrices H  E  RP^^{S)  of the plant 
and  T  G  RP'^'^is) of the model  must be found  so that  T  =  HM  [see (4.192)]. M  is to 
be  realized  via  a  feedback  control  configuration  under  internal  stability.  Here  we  are 
interested  in the model  matching  problem  via  linear  state feedback.  For this, let H  = 
ND~^  an re polynomial factorization  with D column reduced. Then Dz  =  u, y  =  Nz  is 
a minimal realization of H.  Let the state-feedback  control law be defined  by  u  =  Fz  + 
Gr,"  where  F  G  Rlsr""""""^",  G  G  /?^><^ with  detG  y^O and deg^. F  <  deg^.  D.  To  allow 
additional  flexibility,  let r  =  Kv,"K  ^  R""^""""^. Note that (see Subsection 7.4C)  HF",GK  = 
NDp^GK  =  (ND-^)(DDp^GK)  =  {ND-^){D{G-^DF)-^K] 
=  HM. 
In view of the above, solve the model matching problem via linear state  feedback, 
determine F, G, and K,  and comment on your results  when 
(a)  H 
(b)  H 
(c)  H  = 
{s +  \){s  +  2) 
2^2 -  3^ +  2  ' 
T 
5+  1 
s + 2 
^ 
0 
s 
1 
s 
s + 2 
s+  1 
1 
L5+  1 
-^ + 2 
s 
S  +  3-] 
s + 2 
0 
T  =  h 
s+  1 
5 +  4 
-2 
.(5 +  2)(5 +  4)J 
//mr.'  The  model  matching  problem  via  linear  state  feedback  is  not  difficult  to  solve  when 
p  =  mmdrankH 
=  m," in view of (G-^D^)""^/^  =  D'^M  =  D'^H-^T  =  N'^T. "
APPENDIX 
Numerical  Considerations 
A.l 
INTRODUCTION 
To compute the rank of the controllabiHty matrix [B, AB,...,  A^~^B\  or the eigen 
values of A, or the zeros of the system {A, B, C, D], typically requires use of a digital 
computer. When this is the case, one must deal with selection of an algorithm and 
interpret numerical results. In doing so, two issues arise that play important roles in 
numerical computations using a computer, namely, the numerical stability or insta 
bility of the computational method used, and how well or ill conditioned iht problem 
is numerically. 
An example of a problem that can be ill conditioned is the problem of calculat 
ing the roots of a polynomial, given its coefficients.  This is so because for certain 
polynomials, small variations in the values of the coefficients,  introduced, say, via 
round-off  errors, can lead to great changes in the roots of the polynomial. That is 
to say, the roots of a polynomial can be very sensitive to changes in its  coefficients. 
Note that ill conditioning is a property of the problem to be solved and depends on 
neither the floating-point system used in the computer nor on the particular algorithm 
being implemented. 
A computational method is numerically stable if it yields a solution that is near 
the true solution of a problem with slightly changed data. An example of a numer 
ically unstable method to compute the roots of ax^ + Ibx  +  c  =  0 is the formula 
{-b  ±  JQP-  — ac))la that for certain parameters a, b, c may give erroneous results 
in finite arithmetic. This instability is due to subtraction of two approximately equal 
large numbers in the numerator when b^ »  ac. Note that the roots may be calcu 
lated in a numerically stable way, using the mathematically equivalent, but numeri 
cally very different,  expression c/(-b^ 
J(b^  -  ac)). 
645 
646 
APPENDIX: 
Numerical 
Considerations 
We would of course always like to use numerically stable methods and we would 
prefer to have well-conditioned problems. In the following section, we briefly  discuss 
the problem of solving a set of algebraic equations given by Ax  =  b. We will show 
that a measure of how ill conditioned  a given problem is, is the size of the  condition 
number  (to be  defined)  of the matrix A.  There  are many  algorithms  to  numerically 
solve Ax  =  b, and we will briefly  discuss numerically  stable ones. 
Conditioning  of  a problem  and  numerical  stability  of  a method  are key  issues 
in  the  area  of  numerical  analysis.  Our  aim  in  this  appendix  is  to  make  the  reader 
aware  that,  depending  on  the  problem,  the  numerical  considerations  in  the  calcu 
lation of a solution may be nontrivial. These issues  are discussed  at length in many 
textbooks on numerical analysis. Examples of good books in this area include, Golub 
and Van Loan [6] and Stewart [9], where matrix computations are emphasized. Also, 
see Petkov  et  al.  [8]  and  Patel  et  al.  [7] for  computational  methods  with  emphasis 
on  system  and  control  problems.  For  background  on  the  theory  of  algorithms,  on 
optimization  algorithms,  and  their  numerical  properties,  see Bazaran  et  al.  [2]  and 
Bertsekas and Tsitsiklis [3]. 
In Section 2 we present methods for solving linear algebraic equations. Singular 
values  and  singular-value  decompositions  are discussed  in  Section  3. In  Section  4, 
an  approach  for  solving  polynomial  matrix  and  rational  matrix  equations  based  on 
polynomial matrix interpolation  is presented. 
A.2 
SOLVING  LINEAR  ALGEBRAIC  EQUATIONS 
Consider the set of linear algebraic equations given by 
Ax  =  b, 
(2.1) 
where  A  E  R^^^,  Its  solution  is important  in  many  engineering  problems.  It is of 
interest  to know  the  effects  of  small  variations  of A  and  b to the  solution x  of  this 
system  of  equations.  Note  that  such  variations  may  be  introduced  for  example  by 
rounding errors when calculating  a solution or by noisy  data. 
Condition  number 
Let A  E  R^^^  be nonsingular. If A is known exactly and b has some uncertainty 
AZ?, associated  with  it,  then  A{x  +  Ax)  =  b  + Afo. It  can  then  be  shown  that  the 
variation in the solution x is bounded by 
llAxll 
cond (A) \m\ 
(2.2) 
where | 
notes the condition  number  of A,  where cond (A) 
denotes any vector norm (and consistent matrix norm) and cond (A) de-
^  ||A||||A-i||. Note that 
cond{A) 
(Tn  .(A) 
.(AY 
(2.3) 
where  crjnax(^),  and  o-mm(A)  are  the  maximum  and  minimum  singular  values  of 
A,  respectively  (see  next  section).  From  the  property  of  matrix  norms,  ||AA~^||  < 
647 
APPENDIX: 
Numerical 
Considerations 
||A||||A~^||,  it  follows  that  cond(A)  >  1. This  also  follows  from  the  expression  in 
volving  singular  values. If  cond{A)  is  small, then A  is  said  to be well  conditioned 
with  respect  to  the  problem  of  solving  Hnear  equations.  If  cond{A)  is  large,  then 
A is  /// conditioned  with respect  to the problem  of  solving  linear  equations. In  this 
case the relative uncertainty  in the  solution  (||Ax||/||x||)  can be many  times  the rela 
tive uncertainty  in &(||AZ?||/||Z7||). This is of course undesirable. Similar results can be 
derived  when variations  in both b and A  are considered,  i.e., when b and A  become 
Z?  -h AZ?  and A  +  AA. Note that the conditioning  of A, and of the given  problem,  is 
independent  of the algorithm used to determine a solution. 
The condition number of A provides a measure of the distance of A to the set of 
singular  (reduced  rank)  matrices. In particular,  if  ||AA|| is the norm  of the  smallest 
perturbation AA such that A + AA is singular, and is denoted by d{A),  then (iA/||A||  = 
l/cond  (A). Thus, a large condition number indicates a short distance to a singularity, 
and  it  should  not  be  surprising  that  this  implies  great  sensitivity  of  the  numerical 
solution xof  Ax  =  bio  variations in the problem  data. 
The condition number of A plays a similar role in the case when A is not square. 
It can be determined in terms of the singular values of A defined  in the next  section. 
Computational  methods 
The  system  of  equations  Ax  =  b is  easily  solved  if A has  some  special  form, 
(e.g., if it is diagonal or triangular). Using the method of Gaussian  elimination,  any 
nonsingular matrix A can be reduced to an upper triangular matrix  U. These  opera 
tions can be represented by premultiplication of A by a sequence of lower triangular 
matrices. It can then be shown that A can be represented  as 
A  =  m 
(2.4) 
where L is a lower triangular  matrix with all diagonal elements equal to  1 and  U is 
an upper  triangular  matrix. The  solution  of  Ax  =  b is then reduced  to the  solution 
of  two  systems  of  equations  with  triangular  matrices,  Ly  =  b  and  Ux  =  y.  This 
method of solving Ax  =  bis  based on the decomposition  (2.4) of A, which is called 
the LU decomposition  of A. 
If A is a symmetric positive definite  matrix, then it may be represented  as 
A  =  U^U, 
(2.5) 
where U is an upper triangular matrix. This is known as the Cholesky  decomposition 
of  a positive  definite  matrix.  It can  be  obtained  using  a variant  of  Gaussian  ehmi-
nation. Note that this method requires half of the operations necessary  for  Gaussian 
elimination on an arbitrary nonsingular matrix A, since A is  symmetric. 
Now  consider  the  system  of  equations  Ax  =  b,  where  A  G  j^^nxn^ ^^^ 
j ^^ 
rank A  =  n(^  m).  Then 
A  =  Q 
=  [Qh  Qi\ 
=  QiR. 
(2.6) 
where  Q is an orthogonal matrix  (Q^  =  Q~^)  and R  G R^^^  is an upper  triangular 
matrix  of full  rank n. Expression  (2.6) is called  the  QR decomposition  of A. When 
rank A  =  r, the QR  decomposition  of A is expressed  as 
AP  =  Q 
Ri  R2 
0 
0 
(2.7) 
648 
APPENDIX: 
Numerical 
Considerations 
where  Q is  orthogonal,  Ri  G  R^^^  is  nonsingular  and  upper  triangular,  and  P  is  a 
permutation  matrix  that represents  the moving  of the columns  during  the  reduction 
(in  Q^AP). 
Q R decomposition can be used to determine solutions of Ax  =  b. In particular, 
consider A  G R^^^  with rank A  =  n(<  m) and assume that a solution exists. First, 
determine the 2/^ decomposition ofA  given in (2.6). Then 2^Ax  =  Q^box\  0  X  = 
Q^b  (since  Q^  =  Q'^)  or Rx  =  c. Solve this  system  of equations, where R  is tri 
angular  and  c  =  [In, 0]Q^b.  In the general  case  when  rank (A)  =  r  <  mm(n,  m), 
determine  the  QR  decomposition  of A (2.7) and  assume that  a solution  exists. The 
r DI 
solutions  are given  by  x  =  P\ 
arbitrary. 
\R^\c-R2y)] 
y 
c  =  [In OJG^Z?," where  y  G  R""^''  is "
A related problem is the linear  least  squares problem  where a solution x  of the 
system of equations Ax  =  bis  to be found that minimizes  \\b -  Ax\\2. This is a more 
general  problem  than  simply  solving  Ax  =  b,"  since  solving  it provides  the  ""best"" "
solution  in  the  above  sense,  even  when  an  exact  solution  does  not  exist.  The  least 
squares problem is discussed further  in the next  section. 
A.3 
SINGULAR  VALUES  AND  SINGULAR-VALUE  DECOMPOSITION 
The  singular  values  of  a  matrix  and  the  Singular  Value  Decomposition  Theorem 
play a significant role in a number of problems of interest in the area of systems and 
control, from the computation of solutions of linear systems of equations, to compu 
tations of the norm of transfer  matrices at specified  frequencies,  to model reduction, 
and  so forth.  In  the following  we provide  a brief  description  of  some basic  results 
and introduce  some terminology. 
Consider  A  E  %^^^  and  let  A*  =  A^,  the  complex  conjugate  transpose  of A. 
"A  G ^""><^ is  said  to be Hermitian  if  A*  =  A. If  A  G  /^^x^  then  A*  =  A^",  and if 
A  =  A^," thenA is ^jmm^mc. A G ^""^'^ is wn/^ryif  A*  =  A~^ In this case A*A  = "
"AA"""" =  4.  If A G /^'^xnhenA*  =  A^andif  A^  =  A'^", i.e., if A^A  =  AA^  =  In, 
then A is orthogonal  (refer  to Section  6.2). 
Singular  values 
Let  A  G  ^^^^'^  and  consider  AA''  G  ^ ^ x ^.  Let  A/, /  =  1,...,  m,  denote  the 
eigenvalues  of AA'',  and note that these  are  all real  and nonnegative  numbers. As 
sume  that  Ai  >  A2 ^  ---A^  >  •••  >  A;„. Note  that  if  r  === rank A  ===  rankiAA''), 
then  Ai  >  A2 ^  • • • ^  A^ >  0 and  A^+i  =  • • •  =  A^  =  0.  The  singular  values  at 
of A  are  the  positive  square  roots  of  A/, /  =  1,..., min(m, n).  In  fact,  the  nonzero 
singular values of A are 
A/2 
CTi  =  (KY 
/  =  1, . 
>  r. 
(3.1) 
where  r  =  rank A,  while the remaining  (min(m, n)  -  r) of the  singular  values  are 
zero. Note that  cri  >  0*2 ^  • • • ^  cr^ >  0,"  and  cr^+i  =  (j^+2  =  ""  ^  o-mm{m",n)  = 
0. The  singular  values could have  also been found  as the square roots of the eigen 
"values of A* A G %''^'' (instead of AA* G ^""^x^). To see this", consider the  following 
result. 
LEMMA 3.1.  Letm 
n. Then 
"AA*| =  A'^-""|A/„ -  A*A|", 
(3.2) 
i.e.,  all eigenvalues  of A*A are eigenvalues  of AA* which  also has  m -  n additional 
eigenvalues  at zero. Thus," AA* E ^'w><^ and A*A E ^""^^  have precisely  the same r "
nonzero eigenvalues  (r  =  rank A); their remaining  eigenvalues,  (m -  r) for AA* and 
(n —  r) for A*A, are all at zero. Therefore, either AA* or A*A can be used to determine 
the r nonzero singular values of A. All remaining singular values are zero. 
Proof of the lemma.  The proof is based on Schur's formula for determinants. In partic 
ular, we have 
649 
APPENDIX: 
Numerical 
Considerations 
\X^'^J 
^''^ = \J^  A\ 
A  I 
|Ai/^/^||Ai/2/,-A*A-i/^/^A| 
\X'^'aX-'^W\\In-A*A\ 
= 
=  A(^-«)/2 . |A/„ -  A*A|, 
(3.3) 
where Schur's formula was applied to the (1,1) block of the matrix. If it is applied to the 
(2, 2) block, then 
Equating (3.3) and (3.4)," we obtain |A/^ -  AA*| = A^-""|A/„ "
D(A)  =  A^«-^V2 . |A/^ -  AA*|. 
(3.4) 
A*A|, which is (3.2).  • 
EXAMPLE  3.1 
|o  0  0 
E  R^''\  Here rank A  =  r  =  1, A^AA*) 
-  Ar 
=  {5,0}, and Ai  =  5, A2 =  0. Also, A/(A*A)  = 
=  A. 
"""4 "
2 
.0 
2 
1 
0 
"0"" "
0 
0_ 
and  Ai  =  5,  A2 =  0,  and  A3 =  0. The 
only nonzero singular value is ori  =  J~\i  =  + V5. The remaining singular values are 
zero. 
• 
There is an important relation between the singular values of A and its induced 
Hilbert or 2-norm, also called the spectral norm ||A||2  =  \\A\\s, In particular, 
l|A||2(-
,)  =  sup  \\Ax\\2  =  max{(AKA*A))i/2}  =  a(A), 
M2 = l 
(3.5) 
where  &(A)  denotes  the largest  singular  value  of A. Using  the inequalities  that  are 
axiomatically true for induced norms (see Subsection  I.IOB), it is possible to estab 
lish relations between  singular  values of various matrices that are useful  in  MIMO 
control  design.  The  significance  of  the  singular  values  of  a  gain  matrix  A(ja))  is 
discussed  later in this  section. 
There is an interesting relation between the eigenvalues and the singular values 
of  a (square)  matrix. Let  A/, /  =  1,...,  n, denote  the eigenvalues  of A  E  R^^^^  let 
A(A)  =  min/ |A/|, and let A(A)  =  max/ |A/|. Then 
a(A)  <  A(A) <  A(A) <  &(A). 
(3.6) 
Note that the ratio a(A)/a(A), 
i.e., the ratio of the largest and smallest  singular 
values of A, is called the condition  number  of A,  and is denoted by cond{A).  This is 
a very useful measure of how well conditioned a system of linear algebraic equations 
650 
APPENDIX: 
Numerical 
Considerations 
Ax  =  bis  (refer  to the discussion in previous  section). The singular values provide 
^ reliable  way  of  determining  how  far  a  square  matrix  is  from  being  singular,  or 
a  nonsquare  matrix  is  from  losing  rank.  This  is  accomplished  by  examining  how 
close to zero a(A)  is. In contrast, the eigenvalues  of a square matrix  are not a good 
indicator of how far  the matrix is from  being  singular, and a typical example in the 
literature to illustrate this point is an n  X n lower triangular matrix A  with  -  I's  on 
the diagonal  and  H-l's everywhere  else. In this case," a(A)  behaves  as  1/2""  and  the "
matrix is nearly  singular for large n while all of its eigenvalues are at  - 1.  In fact,  it 
"can be shown that adding  1/2""""^ to every element in the first column of A results in "
an exactly  singular matrix (try it for  n  =  2). 
Singular-value  decomposition 
Let A  E  ^^^^  with  rank A  =  r  <  min(m, n). Let A*  =  A^, the complex  con 
jugate transpose of A. 
"THEOREM 3.1.  There exist unitary matrices U G ^'""^'^ and V E ^""^""^ such that "
A  =  UXV\ 
(3.7) 
where  2  = 
^r 
• 
: 
^rX{n-r) 
with  Sr  =  diag(ai,  (72,.. .,crr)  E  R^^^ se-
LO(m-r)Xr 
• 
^(m-r)X(n-r)i 
"lected so that o-i  >  0-2 ^  • • •  >  o""^ > 0. "
Proof. For the proof, see for example, Golub and Van Loan [6] and Patel et al. [7]. 
• 
"Let  U  =  [Uu  U2] with  Ui  E  ^'""^^  U2 E  ^^^(^-') "
and  V  =  [Vi,  V2]  with 
"Vi  E  ^'^^^^ V2 E  ^""XC""-'-). Then "
A  =  f/SV*  =  UiXrVl 
Since  U and  V are unitary, we have 
u*u = 
-y*-
v*v = 
[Ul,U2]  =Im,U\U, 
=Ir 
[Vi,  V2]  =  /„. VlVx  =  /,. 
and 
(3.8) 
(3.9) 
(3.10) 
Note  that  the  columns  of  Ui  and  Vi  determine  orthonormal  bases  for  2/l(A)  and 
9l(A*), respectively. Now 
"AA"""" =  (UiXrVDiVarUl) "
IjT* 
=  UiXjUl 
(3.11) 
from  which we have 
AA*[/i  =  Ui^jUlUi  =  UiXl 
If  Ui, i  =  1,...,  r, is the ith column of  C/i, i.e.,  Ui  =  [u\, U2,...,  Ur], then 
AA*Ui  =  ajui, 
i  =  l,...,r. 
(3.12) 
(3.13) 
"This shows thattheo""? are thernonzeroeigenvaluesofAA*",i.e.,CT/,  /  =  1,...,  r,are 
the nonzero singular values of A. Furthermore,  M/, /  =  1,...,  r, are the eigenvectors 
of AA*  corresponding to cr?. They are the left singular  vectors  of A.  Note that the ut 
are orthonormal vectors (in view of  UIU\  =  /r). Similarly, 
651 
APPENDIX: 
Numerical 
Considerations 
A'^A  =  (Vi^rUlXUiXrVl) 
=  ViXjVl 
(3.14) 
from  which we obtain 
A*AVi  =  ViS^Vt^i  = 
Vill 
(3.15) 
If v„ /  =  1,..., r, is the /th column of Vi,  i.e.,  V\  =  [vi, V2,. 
Vr], then 
A*Avi  =  crjvi, 
i  =  1,2,..., r. 
(3.16) 
The vectors v/ are the eigenvectors of A*A corresponding to the eigenvalues a*?. They 
are the right singular  vectors  of A. Note that the vt are orthonormal vectors (in view 
0fVlVi=Ir), 
The  singular  values  are unique, while the singular  vectors  are not.  To see this, 
consider 
Vi  =  VidiagieJ^O 
and 
f/i  = 
Uidiagie'^^^ 
Their columns are also singular vectors of A (show this). 
Note also that A  =  t/iSrVj  implies  that 
A  = 
^diUiv]. 
/ =i 
(3.17) 
The significance of the singular values of a gain matrix A{jo))  is now briefly dis 
cussed. This is useful  in the control theory of MIMO systems. Consider the relation 
between  signals y and v, given by j  =  Av. Then 
max  I*  =  max  MHb  =  ^ ( ^) 
IHl2^o||v||2 
IMb^o 
||v||2 
or 
. m ax  \\y\\2  =  m ax  ||Av||2  =  &(A), 
IM|2 = 1 
IH|2 = 1 
(3.18) 
Thus, cr(A) yields the maximum  amplification,  in energy terms (2-norm), when  the 
transformation  A  operates on a signal v. Similarly, 
Therefore, 
,,min  Ibib  =  min  ||Av||2  =  cr(A). 
IH|2 = 1 
||v||2 = l 
QL(A) 
llAvlb 
IMb 
(T(A), 
(3.19) 
(3.20) 
where  ||v||2  T^ 0.  Thus  the  gain  (energy  amplification)  is  bounded  from  above 
and below by d-(A) and gi(A), respectively. The exact value depends on the direction 
of V. 
652 
APPENDIX: 
Numerical 
Considerations 
To  determine  the  particular  directions  of  vectors  v for  which  these  (max  and 
min) gains are achieved, consider (3.17) and write 
Av  =  ^ 
aiUiv]v. 
(3.21) 
Notice  that  |v*v| <  ||v/||||v||  =  ||v||, since  ||v/||  =  1, with  equality  holding  only  when 
V =  avi,a  E  ^.  Therefore,  to  maximize,  consider  v  along  the  singular  value 
directions  vt  and  let  v  =  avi  with  |a|  =  1  so  that  ||v||  =  1.  Then  in  view  of 
v]vj  =  0, /  #  7, and v]vj  =  I,  i  =  j, we have that y  =  Av  =  aAvi  =  aaiUi  and 
\y\i  =  \\Av\\2  =  cTi, since  ||w/||2  =  1. Thus, the  maximum  possible  gain  is cri,  i.e., 
max  ||j||2  =  max  ||Av||2  =  ai(= 
hh = 1 
occurs  when  v is  along  the right  singular  vector  vi. Then  Av  -  Av\  — a\U\  =  y 
in view  of (3.17), i.e., the projection  is along the left  singular  vector  u\,  also of the 
same  singular  value  a\.  Similarly,  for  the  minimum  gain  we  have  ar  =  ^(A)  = 
min  ||j||2  =  min  ||Av||2, in which case Av  =  Avr  =  (TfUr  =  y. 
IMb = 1 
(T(A)),  as was shown above. This maximum gain 
llvlb = 1 
Iklb = 1 
Additional interesting properties  include 
gi(A)  =  9l(f/i)  =  span{ui,...,  w^} 
J{(A)  =  91(^2)  =  span{vr+u • •.,  v j, 
(3.22) 
(3.23) 
where  U  =  [MI,  ..  Ur," Ur+h '""",Um\  =  [Ui,  U2]  and  V  =  [vi,..., Vr, v^+1,.. 
Least squares  problem 
Consider  now  the  least  squares  problem  where  a  solution  x  to  the  system  of 
linear  equations  Ax  =  b  is  to  be  determined  that  minimizes  \\b -  Ax||2.  Write 
min  \\b -  Ax\\l  =  mm(b  -  Axf{b 
-  2b^Ax  +  b'^b). Then 
-  Ax)  =  mm(x^A^Ax 
XX 
X 
Vjcix'^A'^Ax  -  Ib^Ax  +  b^b)  =  IPJAx  ~  IPJb  =  0 impUes that the x that mini 
mizes  \\b —  Ax\\2 is a solution of 
A^AJC  = 
A^b. 
(3.24) 
in  view  of  (3.14)  and 
Rewrite  this  as  ViX^.Vjx  =  (UiXrViVb  =  Vi%Ulb 
(3.8).  Now  X  =  ViX~^Ufb 
is  a  solution.  To  see  this,  substitute  and  note  that 
VjVi  =  Ir. In view  of the fact  that X(A'^A)  =  J{(A)  =  ^(¥2)  =  span{vr+h  • • •, 
v„}, the complete  solution is given by 
x^  - 
ViX;^Ujb-^V2W 
"for  some w  E  R""^~^. Since  Vi^'^Ujb "
is orthogonal to  V2W for  all w, 
xo =  ViX^Ulb 
is the optimal solution that minimizes  ||fc -  Ax||2 (prove this). 
The Moore-Penrose  pseudoinverse  of A  E  R^^^  can be shown to be 
A*  =  ViS.-'f/ 1  • 
(3.25) 
(3.26) 
(3.27) 
It was seen that x  =  A ^Z? is the solution to the least squares problem. Furthermore, 
it  can  be  shown  that  this  pseudoinverse  minimizes  \\AA^  -  Imllf,  where  \\A\\F  de 
notes  the  Frobenius  norm  of A  that  is  equal  to  the  square  root  of  trace[AA^]  — 
=  Xr=i^^(^)-  It  is  of  interest  to  note  that  the  Moore-Penrose 
YJ^^ihiAA^) 
pseudoinverse  of A  is  defined  as the  unique  matrix  that  satisfies  the  conditions  (i) 
AA+A  =  A, (ii) A+AA+  =  A+, (iii) (AA+f  =  AA+,  and (iv) (A+Af  =  A+A. 
653 
APPENDIX: 
Numerical 
Considerations 
Note that if rank A  =  m  ^  n, then it can be shown that A+  =  A'^(AA^y^; 
is in fact  the  right  inverse  of A,  since A(A^(AA^y^) 
n^  m, then A+  =  (A'^Ay^A'^, 
the left inverse  of A,  since ((A'^Ay^A'^)A  = In-
this 
=  Im- Similarly, if  rank A  = 
Singular values and singular-value decomposition  are discussed in a number of 
references.  See for  example  Golub  and  Van Loan  [6], Patel  et al.  [7], Petkov  et al. 
[8],andDeCarlo[4]. 
A.4 
SOLVING  POLYNOMIAL  AND  RATIONAL  MATRIX  EQUATIONS 
USING  INTERPOLATION  METHODS 
Many  system  and control problems  can be formulated  in terms  of matrix  equations 
where polynomial  or rational  solutions  with  specific  properties  are of interest.  It is 
known that equations involving just polynomials can be solved by either equating co 
efficients  of equal power of the indeterminate s, or equivalently, by using the values 
obtained  when  appropriate values for  s are substituted  in the given polynomials. In 
the latter case one uses results from the classical theory of polynomial  interpolation. 
Similarly,  one may  solve polynomial  matrix  equations  using  the theory  of polyno 
mial matrix interpolation. This approach has significant  advantages. Full details can 
be found  in AntsakHs and Gao  [1] (see also Gao and AntsakHs [51). 
First,  some required  results  from  the theory  of polynomial  and  rational  matrix 
interpolation  are briefly  summarized.  These are then used to determine  solutions of 
polynomial and rational matrix  equations. 
Polynomial matrix  interpolation 
Consider first the polynomial case. The following  is a fundamental  result of the 
theory of polynomial interpolation: given / distinct complex scalars Sj, j  =  1,...,  /, 
and  /  corresponding  complex  values  bj,  there  exists  a  unique  polynomial  q(s)  of 
degree /  -  1 for  which 
q(sj)  =  bj, 
j  =  1,...,  /. 
(4.1) 
Thus, an nth-degree polynomial  ^(.s*) can be uniquely represented by the /  =  n 4- 1 
interpolation  (points or doublets or) pairs (sj,  bj),  j  =  1,...,  /. 
The polynomial matrix interpolation theory deals with interpolation in the matrix 
case. In the following we cite a basic result upon which the solution to the polynomial 
matrix interpolation problem rests. 
Let S(s)  =  block  diag([1,  s,..., 
s^']^),  where thedt,  i  =  1,...,  m, are nonneg-
ative integers. Let aj  ^  0 and bj  denote m X 1 and p  X  I  complex vectors, respec 
tively, and let Sj be complex  scalars. 
THEOREM 4.1.  Given interpolation triplets (sj, aj, bj), j  =  1,...,  I (i.e., interpolation 
points), and nonnegative integers dt with /  =  Sjl ^di + m such that the (Xjl^dt  +  m)xl 
654 
APPENDIX: 
Numerical 
Considerations 
matrix 
(4.2) 
has  full  rank,  there  exists  a unique  p  X m polynomial  matrix  Q(s), with  /th-column 
degree equal to J/, /  =  1,..., m, for which 
Si  ^  [S(si)au...,S(si)ai] 
Proof. Since the column degrees of Q(s) are J/, Q(s) can be written as 
Q(sj)aj  = bj, 
j  =  h...J. 
Q(s) = QS(s), 
(4.3) 
(4.4) 
where the /? X (X/11 di + m) matrix 2 contains the coefficients of the polynomial entries. 
Substituting into (4.3), Q must satisfy 
(4.5) 
where Bi  =  [b\, ...,bi\.  Since Si is nonsingular,  g,  and therefore  Q{s), are uniquely 
determined. 
• 
QSi = Bu 
It should be noted that when/?  =  m  =^  l a n d Ji  =  l-l  =  n, the above theorem 
reduces to the Polynomial Interpolation Theorem. In that case, for Uj  =  1, Si reduces 
to a Vandermonde Matrix that is nonsingular if and only if Sj, j  =  1,... /, are distinct 
(show this). 
EXAMPLE 4.1.  Let Q(s) b e a l x2  =  /?Xm  polynomial matrix and let the follow 
ing  /  =  3 interpolation  points  {(Sj, aj, bj), j  =  1, 2, 3} be  specified:  {(-1, [1,0]^, 0), 
(0, [-1, 1]^, 0), (1, [0, 1]^, 1)}. In view of Theorem 4.1, Q(s) is uniquely specified when 
Ji  and (^2 are chosen so that /  =  3 =  Xdi + m  = {d\+d2) + 2,Qxd\+d2  =  1, assuming 
that ^3 has full rank. Clearly, there is more than one choice for d\ and ^2- The resulting 
Q{s) depends on the particular choice for the column degrees df. 
(i)  LetJi  =  lmdd2  = 0.Then S(s)  =  block diag([hsf,  I) and (4.5) becomes: 
QS3  =  Q[S(si)au  S(s2)a2, S(s3)a3] = 
--Q 
=  [0, 0, 1]  =  53, 
'  1 
-1 
0 
-1 
0 
1 
0 
0 
1 
from which we obtain g  =  [1, 1, 1] and Q{s) = QS(s) =  [^ +  1,  1]. 
(ii)  Let di  = 0 and J2  =  1- Then S(s)  = blockdiag(\,  [hsf)  and (4.5) yields 
Q  =  [0, 0, 1], from which we have Q(s) =  [0, s], which is clearly different  from (i).  • 
Rational matrix  interpolation 
Similar to the polynomial matrix case, the problem here is to represent a p  X m 
rational  matrix  H(s)  by  interpolation  triplets  or  points  (sj, aj,  bj),  j  =  1,...,  /, 
which  satisfies 
Hisj)aj  =  bj, 
j  =  \,...,l, 
(4.6) 
where the Sj are complex scalars and the aj  ¥=  0 and bj  are complex m X 1  and p X  1 
vectors, respectively. 
It can be shown that the rational matrix interpolation problem reduces to a special 
case of polynomial  matrix interpolation.  To see this, we write H{s)  =  D~^{s)N{s), 
where D{s) and N{s)  are pX  p  and pX  m polynomial matrices, respectively. Then 
(4.6) can be written as N(sj)aj  =  D{sj)bj,  or as 
VN{sj),  -D{sj)] 
bj 
=  Q{sj)cj  =  0, 
;• = 
l,...,l, 
(4.7) 
i.e., the rational  matrix  interpolation  problem  for  a p  X m rational  matrix H(s)  can 
be viewed as a polynomial interpolation problem for SL pX  (p  -\- m) polynomial ma 
trix  Q{s)  =  [N{s\  -D{s)\  with  interpolation  points  {sj, Cj, 0)  =  (sj,  [aj, b^jf,  0), 
j  =  1,...,  /. There is also the additional constraint that D~^(s)  exists. 
655 
APPENDIX: 
Numerical 
Considerations 
Solution of matrix  equations 
In this segment, polynomial matrix equations of the form M(s)L(s)  =  Q(s)  are 
considered.  The  main  result  is Theorem  4.2, which  essentially  states  that  all  solu 
tions M(s)  of degree r can be derived by solving Eq. (4.16). In this way, all solutions 
of  degree  r of  the  polynomial  equation,  if  they  exist,  are parameterized.  The  Dio-
phantine Equation  is an important  special case and is examined  at length. It is also 
shown that Theorem 4.2 can be applied to solve rational matrix equations of the form 
M(s)L(s)  -  Q(s), 
Consider the equation 
M{s)L(s)  =  Q(sl 
(4.8) 
where L(s)  and  Q(s)  are given  t  X  m and  kx  m polynomial  matrices,  respectively. 
We wish to determine thQ  kX  t polynomial matrix  solutions M(s)  when they  exist. 
First consider the left-hand  side of Eq. (4.8). Let 
M(s)  =  Mo +  • • • +  Mrs' 
(4.9) 
and let di  =  deg^^ [L{s)\, i  =  1,...,  m, denote the column degrees of L{s), If 
Q{s)  ^  M(s)L(s\ 
(4.10) 
then deg^i [Q(s)]  =  di + r for i  =  1,...,  m. According to the Polynomial Matrix In 
terpolation Theorem, Theorem 4.1, the matrix Q(s) can be uniquely  specified,  using 
^T=\(^i  +  r)  -h m  =  ^f=\di  +  m{r  +  1) interpolation  points. Therefore,  consider / 
interpolation points {sj, Uj, bj),  j  =  1,...,  /, where 
Z -  2 r . i J/  +  m ( r+  1). 
(4.11) 
Let Sr(s)  =  block  diag ([1, ^,...,  Z'+H^) and assume that the &Jlidi  -h m(r +1)) X / 
matrix 
Sri  = 
[Sr(si)ai,...,Sr(si)ai] 
(4.12) 
has full rank, i.e., the assumptions in Theorem 4.1 are satisfied. Note that for distinct 
Sj, Sri will have full  column rank for  almost  any  set of nonzero  aj.  Now in view of 
Theorem 4.1, the matrix  Q(s) that  satisfies 
Q(sj)aj  =  bj, 
;•  =  h...J, 
(4.13) 
is  uniquely  specified,  given  these  / interpolation  points  (sj, aj,  bj).  To  solve  (4.8), 
these interpolation points must be appropriately  chosen so that the equation 
Q(s)  (=  M(s)L(s))  =  Q(s) is  satisfied. 
We write (4.8) as 
MLris)  =  Q(s), 
(4.14) 
where  M  =  [MQ, . . .,  M^] and  Uis)  =  [L'^(s),...,  s''L'^(s)f  are k  X  t(r  +  1) and 
f(r +  1) X m matrices, respectively. Let s  =  sj  and postmultiply by  aj,  j  =  1,...,  /. 
656 
APPENDIX: 
Numerical 
Considerations 
Note that Sj and Uj, j  =  1,...,  /, must be such that Sri has full  rank.  Define 
bj  =  Q{sj)aj, 
j  =  1 , . . . , /, 
and combine the above equations to obtain 
MLri  =  Bu 
(4.15) 
(4.16) 
where L^/  == [L^(^i)ai,..., L^(5'/)a/] and5/  =  [^i,.. 
matrices, respectively. 
,bi\2irtt{r+ 
l)XlandkXl 
THEOREM 4.2.  Given L{s) and Q{s) in (4.8), let dt 
select r to satisfy 
degci [L{sy\, i  =  1,..., m, and 
Then a solution M(^) 
of (4.16) exists. 
degci [Q(s)]  <  di + r. 
(4.17) 
M[/, si,...,  s^lY  of degree r exists if and only if a solution M 
1, 
It is not difficult  to show that solving (4.16) is equivalent to solving 
(4.18) 
(4.19) 
(4.20) 
[/,  si, 
I. 
^i^j^j 
=  bp 
A 
j  =  h. 
.,/, 
where 
The M(s)  that satisfy  (4.18) are obtained by  solving 
bj  =  Q(sj)aj, 
Cj  =  L(sj)aj, 
j  =  1 , . . . , /. 
MSri  =  Bu 
"where Sri  ""=  [Sr(si)ci",..., 
. . .,  5'''/]^ has dimensions  t(r  -\-  I)  X  t, and Bi  =  [b\ 
Solving (4.20) is an alternative to solving (4.16). 
Sr(si)ci]  has dimensions  t(r  +  1) X /, and  Sr(s) 
, bi\  has dimensions  kx 
Constraints on solutions.  When there are more unknowns than equations [t{r +1) and 
/  =  Sjl i<^/ + ^{r +1), respectively] in (4.16), this freedom can be exploited so that M{s) 
satisfies additional constraints. In particular, k  = t(r+\)-l  additional linear constraints, 
expressed in terms of the coefficients  of M{s) (in M), can in general be satisfied. The 
equations describing the constraints can be used to augment Eqs. (4.16). In this case the 
equations to be solved become 
(4.21) 
where MC  =  D represents the k linear constraints imposed on the coefficients  M, and 
C and D are matrices (real or complex) with k columns each. 
• 
MiLruC]  =  [Bi,Dl 
The Diophantine  Equation 
An important case of (4.8) is the Diophantine  Equation 
X(s)D(s)  +  Y(s)N(s)  =  Q(sl 
(4.22) 
where the polynomial  matrices  D(s), N{s),  and  Q(s)  are given  and X(s),  Y(s)  are to 
be determined. Note that if 
M(s)  =  [X(s\  Y(s)l 
L{s)  = 
D(s) 
N(s) 
(4.23) 
then  it  is  immediately  clear  that  the  Diophantine  Equation  is  a  polynomial  equa 
tion  of  the  form  (4.8)  and  all  previous  results  apply.  Theorem  4.2  guarantees  that 
all  solutions  of  (4.22)  of  degree  r  are  determined  by  solving  (4.16).  In  systems 
and control theory, the Diophantine Equation that is used involves  a matrix  L{s)  = 
[D^{s), N^{s)Y,  which  has  rather  specific  properties. These  are exploited  to solve 
the Diophantine Equation and to derive conditions for existence of solutions of (4.22) 
of degree r. It can be shown that the following  result is true. 
657 
APPENDIX: 
Numerical 
Considerations 
THEOREM 4.3.  Let r satisfy 
deg.i [Q{s)\  <  di + r, 
i  =  1,..., m,  and r • 
1, 
(4.24) 
where v is the observability index of the system {D, /, N, 0}. Then the Diophantine Equa 
tion (4.22) has solutions of degree r that can be determined by solving (4.16) [or (4.20)]. 
EXAMPLE 4.2.  Let 
D(s) =  s-2 
0 
0 
s+  1 
;v(^) =  s-\ 
1 
0 
1 
and 
Qis) 
1  0 
0  1 
We have di  = di  =  1, degd Q(s) =  0, /  =  1, 2, and /  =  2 + 2(r + 1). 
For r  =  I  Sj  =  -2,  - 1,  0, 1, 2, 3, and 
0 
1  ' 
1 
3  ' 
0 
-1 
' 
-1 
3  ' 
-1 
1  ' 
1 
-1 
A solution is given by 
M(s)  =  [X(s), Y(s)] 
-S 
0 
5 +1 
- i . +i 
Solving rational matrix  equations 
Now let us consider the rational matrix  equation 
M(s)L(s)  =  Q{s\ 
(4.25) 
where L{s) and Q{s) are given t  X  m and k  X  m rational matrices, respectively. The 
polynomial  matrix  interpolation  theory  developed  above  can  be  used  to  solve  this 
equation  and  determine  the rational  matrix  solutions M(s)  of dimension  kx 
t.  Let 
M(s)  =  D~^(s)N(s)  be a polynomial fraction  form of M(s)  that is to be  determined. 
Then (4.25) can be written as 
[A^(^),  -D(s)] 
L(s) 
=  0. 
Note that one could equivalently  solve 
[A^(^),  -D(s)] 
Lp(s) 
=  0, 
(4.26) 
(4.27) 
where [Lp(s)^,  Qp(s)^]^  =  [L(s)^,  Q(sW(t>(s)  is a polynomial matrix with (l)(s) the 
least common  denominator  of all entries  of L(s)  and  Q(s).  In general,  (l)(s)  may  be 
any matrix  denominator  in a right fractional  representation  of  [L(s)^,  QisW-  The 
problem to be solved is now of the form  (4.8), a polynomial matrix equation,  where 
L(s)  =  [Lp(sf,  Qp(sfV 
and  Q(s)  =  0.  Therefore,  all  solutions  [A^(^), -D(s)]  of 
degree r can be determined by solving (4.16) or (4.20). Let s  =  Sj and postmultiply 
(4.27) by aj,  j  =  1,...,  /, with aj  and / chosen properly.  Define 
658 
APPENDIX: 
Numerical 
Considerations 
\Lp(s)] 
[QP(S)\ 
1 , . . . , /. 
(4.28) 
The problem now is to determine a polynomial matrix  [N(s),  -D(s)]  that  satisfies 
[N(sj\  -D(sj)]cj  =  0, 
J  =  1,...,  /. 
(4.29) 
Note that restrictions on the solutions can easily be imposed to guarantee that  D~^(s) 
exists and/or that M(s)  =  D~^(s)N(s)  is proper. Additional constraints can be added 
so that the solution satisfies  additional specifications  [see (4.21)]. 
Pole  placement 
Output feedback.  All proper  output  controllers  of  degree  r (of  order  mr)  that 
assign  all  the  closed-loop  eigenvalues  to  arbitrary  locations  are  characterized  in  a 
convenient way using interpolation  results. 
Given N(s)D~^(s)  =  H(s),  which is assumed to be proper, we are interested in 
solutions [X(s),  Y{s)] of dimensions m X (p + m) of the Diophantine Equation where 
only the roots of  \Q(s)\ are specified.  Furthermore, X~^(s)Y(s)  =  C(s)  should  exist 
and be proper since it represents the controller. Here the equation to be solved is 
(X(sj)D(sj)  +  Y(sj)N(sj))aj  = 0, 
y  =  1,...,  /, 
(4.30) 
orMLri  =  0(1  =  l.Jl^di  + mr).Thus,thQ%^^^di  + mrrootsof\X(s)D(s)  +  Y(s)N(s)\ 
are to be assigned the values Sj, j  =  1,... /. Note the difference between the problem 
studied earlier, where  Q(s) is known, and the problem  studied here, where only  the 
roots  of  \Q(s)\  (or  of  |G('^)I  within  multiplication  by  some  nonzero  real  scalar)  are 
given. In the present case, the vectors aj  can be viewed as design parameters and can 
be selected almost arbitrarily to satisfy  requirements in addition to pole  assignment. 
Note  that  this  design  approach  is rather  well  known  in  the  state  feedback  case,  as 
is  discussed  later  in  this  section  (see  also  Chapter  4). The  following  result  can  be 
shown. 
THEOREM 4.4.  Let r >  v -  1. Then (X(s), Y(s)) exists such that all the n + mr zeros 
of \X{s)D{s) + Y{s)N{s)\ are arbitrarily assigned and X~^{s)Y{s) is proper. 
• 
EXAMPLE  4.3.  Let  D{s)  = 
Is-2 
L  0 
0 
s+l\ 
and  A^(^)  =  s-  1 
1 
with  n  = 
deg \D(s)\ =  2. In this case there are deg \X(s)D(s)  +  F(5')A^(5)|  =  n + mr  =  2 + 2r 
closed-loop poles to be assigned. Note that r > ^ ' -l  = 
l - l = 0. 
(i)  For r  =  0 and {(sp ajX j  =  1, 2} =  {(-1, [1, 0]^), (-2,  [0,1]^)}, a solution of 
MLri =  Ois 
M = 
For this case, M  = M(s)  =  [X(sX Y(s)] and C(s)  =  X-\s)Y(s)  =  ^ 
is a static output controller. 
(ii)  For  r  =  1,  and  {(sj,aj)J  =  1,...,4}  =  {(-1, [1,0]^), (-2,  [0, If,  (-3, 
-1,0]^), (-4,  [0,-1]^)},  a  solution  of  MLri  =  0  is  given  by  [X(s\Y(s)]  = 
s-1 
. Note that C{s) = X{s)  ^ Y{s) exists and is proper. 
-1 
5 +4 
12  5 + 1] 
-6 
5 +4 
-3  0 
1  2 
which 
State  feedback.  Let  A, B,  and  F  he  n  X  n,  n  X  m,  and  m  X  n  real  matri 
ces,  respectively.  Note  that  1^/ -  (A  +  BF)\  =  \sl  -  A\  • |/„  -  {si  -  A)~^BF\  = 
659 
APPENDIX: 
Numerical 
Considerations 
1^/ -  A\  ' \lm —  F(sl  -  Ay^B].  Now  if  the  desired  closed-loop  eigenvalues  Sj  are 
different  from  the  eigenvalues  of A,  then  F  will  assign  all  n  desired  closed-loop 
eigenvalues Sj if and only if 
F[(sjl  -  Ay^Baj]  =  Uj, 
j  =  l...,n. 
(4.31) 
The m X 1 vectors aj  are selected so that (sjl  — A)~^Baj,  j  =  1,,.  .,n,  are linearly 
independent vectors. Alternatively, one could approach the problem as follows  (see 
also Subsection 4.2B of Chapter 4). Let M(s)  and D(s)  be re polynomial matrices of 
dimensions  nX  m and mX  m, respectively,  such that (si  -  A)~^B  =  M(s)D~^(s). 
An internal representation equivalent to x  =  Ax  -^ Bu  in polynomial matrix form is 
Dz  =  u with  X  =  Mz  (see Subsection  7.3A  of Chapter 7). The eigenvalue  assign 
ment problem now is to assign all the roots of  \D(s) -  FM(s)l  or to determine F so 
that 
FM(sj)aj  =  D{sj)aj, 
J  =  h 
(4.32) 
Note  that  this  formulation  does  not  require  that  Sj  be  different  from  the  eigen 
values  of A  as  in  (4.31). The  m X  1 vectors  aj  are  selected  so that  M(sj)aj,  j  = 
1,...,  ^,  are  independent.  Note  that  M(sj)  has  the  same  column  rank  as  S(sj)  = 
sj'~^]^),  where  dt  are  the  controllability  indices  of  (A, 5). 
block  diag([l,  Sj,..., 
Therefore,  it is possible to select aj  so that M(sj)aj,  j  =  I,..  .,n,  are  independent, 
even  when  the  Sj  are repeated.  In  general  there  is  great  flexibility  in  selecting  the 
nonzero vectors aj.  For example  when the Sj  are distinct,  which is a very  common 
case, the aj  can be selected  almost  arbitrarily. For all the appropriate choices of  aj 
[M(sj)aj,  j  =  1,..  .,n,  linearly independent], the n eigenvalues  of the  closed-loop 
system  will be  at the desired  locations  Sj, j  =  \,.. 
.,n.  Different  aj  correspond  to 
different  F, which results in general in different  closed-loop  behavior. 
The  exact  relation  of  the  eigenvectors  to  the  aj  can  be  determined  by  [sjl 
{A + BF)\M{sj)aj  =  (sjI-A)M(sj)aj-BFM(sj)aj 
Therefore,  M(sj)aj  =  Vj are the closed-loop eigenvectors corresponding to  Sj. 
=  BD(sj)aj-BD(sj)aj 
-
=  0. 
One  may  select  aj  in  (4.32)  to  impose  constraints  on  the  gains  fij  in  F.  For 
example,  one  may  select  aj  so that  a column  of F  is  zero  (take  the  corresponding 
row  of  all  aj  to be  nonzero),  or  so that  an  element  of  F  is  zero. Alternatively,  one 
may  select aj  so that additional design goals are attained. 
Note that this approach for eigenvalue/eigenvector assignment by state feedback 
has  also  been  discussed  in  Subsection  4.2B  of  Chapter  4.  For  further  details,  see 
Antsaklis and Gao [1]. 
A.5 
REFERENCES 
1.  P. J. Antsaklis and Z. Gao," ""Polynomial and Rational Matrix Interpolation: Theory and "
Control Applications,""" Int. J. of Control", Vol. 58, No. 2, pp. 349-404, August 1993. 
2.  M. S. Bazaraa,  H. D. Sherali, and C. M. Shetty, Nonlinear Programming  Theory  and 
Algorithms, 2d edition, Wiley, New York, 1993. 
3.  D. P. Bertsekas and J. N. Tsitsiklis, Parallel and Distributed Computation—Numerical 
Methods,  Prentice-Hall, Englewood Cliffs, NJ, 1989. 
4.  R. A. DeCarlo, Linear Systems. A State Variable Approach with Numerical Implementa 
tion,  Prentice-Hall, Englewood CHffs, NJ, 1989. 
660 
APPENDIX: 
Numerical 
Considerations 
5.  Z. Gao and P. J. Antsaklis," ""New Methods for Control System Design Using Matrix Inter "
polation,""" Proc. of the IEEE Conference on Decision and Control", Orlando, FL, December 
1994. 
6.  G. H. Golub and C. F. Van Loan, Matrix Computations,  The Johns Hopkins University 
Press, Baltimore, 1983. 
7.  R. V. Patel, A. J. Laub, and P. M. VanDooren, eds.. Numerical Linear Algebra Techniques 
for Systems and Control,  IEEE Press, Piscataway, NJ, 1993. 
8.  P. Hr. Petkov, N. D. Christov, and M. M. Konstantinov, Computational Methods for Linear 
Control Systems, Prentice-Hall International Series, 1991. 
9.  G. W. Stewart, Introduction to Matrix Computations,  Academic Press, New York, 1973. 
INDEX 
Balanced representations,  430 
Basis, 99,  100,  170, 439, 551, 552 
See  also  Vector  space 
Bessel's inequality,  440 
Bezout identity, 553, 612 
See also  Diophantine  equation 
BIBO  stable, 481, 490, 505 
See  also  Bounded-input/bounded-output 
stable 
See  also  Linear  transformation 
Bilinear functional,  435 
signature, 435 
symmetric, 435, 436 
Binet-Cauchy  formula,  639 
Biproper, 552, 577 
See  also  Rational  function 
Block diagonal,  130 
See  also  Matrix 
Blocking property,  307 
See  also  Zero 
Bolzano-Weierstrass  property,  18, 44 
Bounded, 491, 493 
See also  Solutions  of  differential 
Bounded-input/bounded-output  stability, 
481,482,483,484,490,505 
See also  Stability 
Brunovsky  canonical form,  288 
See  also  Canonical  form 
Building, earthquake protection,  208 
B-W property,  18 
See  also  Bolzano-Weierstrass  property 
See also  Solutions of algebraic  equations 
Bijective,  101, 102 
Algebraic  multiplicity,  124, 444 
See  also  Eigenvalue 
Algebraic Riccati equation,  343, 349, 358, 363 
Asymptotically  stable,  159,  189, 449, 491, 494, 
497, 504, 563 
See also  Equilibrium 
Asymptotically  stable in the large, 450, 491, 
equations 
Abel's formula,  140 
Ackermann's  formula,  334, 353 
Adjoint  equation,  197 
Adjoint  of a matrix,  115, 442 
Aircraft,  209, 320, 381 
Algebra,  102 
associative,  103 
commutative,  103 
Algebraic  equation,  115 
See also  Riccati  equation 
Algebraically  closed,  123 
See  also  Field 
Ascoli-Arzela lemma,  22 
Asymptotic behavior,  156,  186 
See  also  Mode of  system 
Asymptotic  state estimator,  351 
See also  State  observers 
494, 499 
See  also  Equilibrium;  Globally 
asymptotically  stable 
At rest,  71,77 
See  also  System 
Attractive, 449, 491 
See  also  Equilibrium 
Automobile  suspension  system, 207, 380 
Autonomous,  11, 62 
See also  Linear ordinary  differential 
equation;  System 
Axioms: 
of a field, 37 
of a metric, 438 
of a norm, 438 
of a vector space, 38 
Canonical form,  116, 127, 535 
Brunovsky,  288 
Jordan,  130,  135, 136 
Canonical Structure Theorem,  270 
See  also  Kalman's  Decomposition 
Theorem 
661 
662 
INDEX 
Cartesian product,  8 
Cauchy  criterion,  20 
Cauchy  sequence,  18 
Cauchy-Peano  existence theorem,  25 
Causal, 67, 70, 71, 77 
See  also  System 
Cayley-Hamilton  Theorem,  124,  154 
Characteristic  equation,  123 
Characteristic  exponent,  163 
Characteristic polynomial,  123, 299, 563 
See also  Matrix; Transfer  function 
Characteristic  value,  122 
See  also  Eigenvalue 
Characteristic  vector,  122 
See  also  Eigenvector 
Chemical reaction process,  381 
Cholesky  decomposition,  647 
Closed loop control,  327 
Cofactor,  113 
See also  Matrix 
Column rank,  119 
See also  Matrix 
Column reduced,  526 
Column vector,  107 
See  also  Matrix 
Command input,  326 
See also  Polynomial  matrices 
See  also  Input; Reference  input 
Common divisor,  535 
left,  536 
right,  536 
See also  Divisor 
Commutative  algebra,  103 
See also  Algebra 
Compact  set, 9,  18 
Companion  form,  131, 153, 468 
See also  Matrix 
Complete instability, 473, 501 
See also  Equilibrium,  unstable 
Complete  space,  18 
Completeness  property,  288 
Complex vector space, 38 
Composite  system,  203 
See  also  System 
Condition number,  646, 647, 649 
See  also  Matrix 
Conformal  matrices,  109 
See  also  Matrix 
Congruent matrices, 435, 436 
See  also  Matrix 
Conservative  system,  81 
See also  System 
Constructibility,  219, 247, 251, 
252,  260 
continuous-time  system, 248, 252 
discrete-time  systeni, 219, 257 
Gramian, 251,256,  262 
See also  Observability 
Continuation  of solutions, 26, 27, 
See  also  Solutions of  differential 
31,37 
equations 
Continuous  dependence of solutions, 37 
See also  Solutions of  differential 
equations 
Continuous  function: 
over an interval, 9 
at a point, 9, 44 
uniformly,  9 
Continuous  time systems, 4 
See also  Systems 
Control problems,  632 
ControllabiHty,  214, 215, 228, 235, 242, 264, 
265, 274, 561 
continuous-time  system, 227, 235 
discrete-time  system, 215, 241 
eigenvalue/eigenvector  (PBH) test,  272 
Gramian,  233, 240, 245 
index,  283 
matrix,  217 
from  the origin, 215, 217, 228, 236 
See  also  Reachability 
totheorigin,  215, 218, 228 
output,  312 
subspace, 229, 236, 242 
Controllable, 228, 235, 561 
companion form,  279 
differentially,  315 
eigenvalues,  265 
instantaneously,  315 
mode, 265 
pair,  229 
single-input,  373 
state, 242 
subspace, 229, 236, 242 
uniformly,  315 
Controller: 
digital,  182 
feedback,  589 
implementations,  629 
with two degrees of  freedom, 
368,  622 
Controller companion form,  203 
Controller form,  279, 280, 285, 291 
multi-input,  283 
single-input,  280 
Convergence of a function,  18 
pointwise,  18,  19,44 
uniform,  18,  19,20 
Convergence  of a sequence,  18, 44 
Convergence  of a series, 21 
pointwise, 21 
uniform,  21 
Converse theorem,  513 
Converter  (A/D, D/A),  183 
Convolution: 
integral, 78 
sum, 70 
Coordinate representation,  100 
See  also  Vector 
Coprime, 535, 593 
See  also  Polynomial  matrices; 
Polynomials 
Critical, 460, 462 
See also  Eigenvalue 
Cyclic,  132 
See  also  Matrix 
D/A converter,  183 
Dead-beat: 
control, 201 
observer,  359 
Decoupling: 
diagonal, 377, 378, 633 
static, 634 
Decoupling  indices,  377 
See  also  Indices 
Degree, McMillan,  397 
polynomial vector,  526 
Detectable,  351 
Determinant,  112, 121, 586 
See also  Linear transformation;  Matrix; 
Return  difference  matrix 
Determinantal  divisor, 299, 534 
Diagonal decoupling,  377, 378, 633 
Difference  equations, 62, 63 
See also  Solutions of difference  equations 
Differential  equations,  ordinary: 
classification,  11 
first-order,  10 
linear, 47 
linear homogeneous,  13, 138 
linear homogeneous  with  constant 
coefficients,  148 
linear nonhomogeneous,  138, 145 
nth order,  12 
systems of first order,  37 
See also  Solutions of  differential 
equations 
Digital controller,  182 
Digital filter, 65 
Digital to analog converter,  183 
Dimension,  99 
See also  Vector  space 
Diophantine equation, 540, 612, 656 
all solutions, 550 
Bezout identity, 553, 612 
historical remarks, 552 
Dirac delta distribution, 72, 74,  154 
Direct form,  65 
Direct link matrix,  169 
Direct  sum,  126 
Discrete-time impulse, 68,  178 
Discrete-time  Kalman  filter,  363 
See  also  Kalman  filter 
Discrete-time  system, 3, 5, 60, 66,  174, 215, 
241, 242, 257, 348, 358, 362, 388, 392, 
401,489 
See also  System 
Distance function,  438 
Divisor: 
common,  535 
left,  right,  536 
greatest common, 535, 536 
Domain of attraction, 449, 491 
See also  Equilibrium 
Double integrator,  205 
Doubly coprime,  593 
See  also  Coprime 
Dual system, 222, 402 
Economic model, 205, 382 
Eigenvalue,  121, 122, 298, 301, 305, 564 
algebraic multiplicity,  124, 444 
controllable,  265 
critical, 460, 462 
geometric multiplicity,  122 
repeated,  129 
spectrum,  122 
direct method,  328 
eigenvector  assignment,  337 
using controller form,  332 
Eigenvector,  121, 122 
663 
INDEX 
Elementary  operations: 
column,  526 
row, 526 
Elementary  unimodular matrices,  526 
Eliminant  matrix, 542, 547 
e-approximate solution,  23 
Equicontinuous, 22, 46 
Equilibrium,  158, 189, 445, 446, 490 
asymptotically  stable,  158, 189, 449, 491, 
494, 497, 504, 563 
asymptotically  stable in the large, 450, 491, 
494,  499 
attractive, 449, 491 
completely  unstable, 473, 501 
domain of attraction, 449, 491 
exponentially  stable, 449, 477, 480, 512 
exponentially  stable in the large, 450, 
globally asymptotically  stable, 450, 491, 
459,471 
494, 499 
isolated,  446 
qualitative characterization,  447 
stable,  159,  189, 448, 452, 455, 459, 
491,492 
trivial solution,  138, 446 
uniformly  asymptotically  stable, 449 
uniformly  asymptotically  stable in the large, 
uniformly  stable, 448, 453, 454, 455, 459, 
450,459,451 
461,470,512 
unstable,  159,  189, 450, 459, 462, 472, 479, 
481, 491, 495, 497, 499, 504, 513 
See also  Stability 
Equivalence: 
of internal representations,  170,  180, 554 
relation,  535 
transformation,  181 
Equivalent,  116, 119, 172,  181, 535, 554 
Estimator,  361 
See  also  State  estimator 
Euclidean: 
norm, 42 
ring, 551 
space, 437, 441 
Euler: 
method, 25, 65, 85 
polygon,  25 
Exponentially  stable, 449, 477, 480, 512 
See  also  Equilibrium 
Exponentially  stable in the large, 450, 459, 471 
See  also  Equilibrium 
Extended  system matrix,  557 
External input,  326 
External  system description, 5, 65 
See  also  System 
Feedback,  326, 589 
configuration,  203, 573 
gain matrix,  327 
integral,  379 
output,  363, 379, 658 
state, 321, 323, 324, 326, 327, 
Feedback control  systems, 58, 589, 590 
See also  Feedback;  Output  feedback 
Feedback  stabilizing controller,  589 
paramererizations,  592 
Eigenvalue or pole assignment,  328, 330, 658 
364, 658 
664 
INDEX 
parameterizations, proper and stable (MFD), 
611,615 
two degrees of freedom,  622 
Fermat's Last Theorem,  553 
Field,  37 
algebraically  closed,  123 
complex numbers, 38 
rational functions,  37 
real numbers, 38 
Filtering theory,  357 
Floquet multipliers,  163 
Force field, inverse square law, 52 
Fractional description,  521 
See also  System  representations 
Frequency  response, 204, 463, 465 
Frobenius norm,  653 
Function, 8 
bijective,  101 
continuous, 9 
Hamiltonian,  81 
indefinite, 437, 469 
negative definite,  semidefinite,  437, 491 
one-to-one, or injective,  101 
onto, or surjective,  101 
piecewise continuous, 9, 58 
positive definite,  semidefinite,  437, 469, 491 
Fundamental  matrix,  139,  140 
Fundamental  sequence,  18 
Fundamental  set of solutions,  140 
Fundamental  theorem of linear equations,  101 
Gap and position criterion,  465 
See  also  Stability 
Gaussian  elimination,  647 
Generalized  distance function,  468 
See  also  Lyapunov  function 
Generalized  energy function,  468 
See  also  Lyapunov  function 
Generalized  function,  74 
See  also  Dirac delta  distribution 
Geometric multiplicity,  122 
See also  Eigenvalue 
Globally  asymptotically  stable, 491, 494 
See  also  Asymptotically  stable; 
Equilibrium 
Gram 
determinant,  234 
matrix,  234 
Gramian 
constructibility,  251, 256, 262 
controllability, 233, 240, 246 
observability,  249, 253, 259 
reachability, 230, 236, 245 
Gram-Schmidt process, 440 
Graphical  criteria,  462 
See  also  Stability 
Gronwall inequality,  29 
Hamiltonian: 
dynamical  system,  81 
function,  81 
matrix,  344, 349 
Hankel matrix,  399 
Hard disk, read/write head, 212, 382 
Harmonic oscillator,  198 
H-B property,  18,44 
Heine-Borel property,  18, 44 
Hermite form,  532 
Hermitian  matrix,  648 
Highest degree coefficient  matrix,  526 
Homogeneous  differential  equations,  138 
See  also  Differential  equations 
Homogeneous  solution, 58, 64,  145 
See  also  Solutions of  differential 
equations 
Hurwitz matrix,  460 
Hurwitz polynomial,  462 
Hybrid  system,  3,  183 
Impulse response matrix, 71, 77, 78, 79, 165, 
Idempotent matrix,  126 
Identity  matrix,  110 
Identity transformation,  103 
Ill-conditioned,  647 
Impulse response: 
continuous-time, 75, 77 
discrete-time,  70 
time-invariant,  78 
time-varying,  79 
166,  177 
Index: 
bilinear functional,  437 
nilpotent operator,  134 
set,  17 
Indices: 
controllability,  283 
decoupling,  377 
Kronecker,  288 
observability,  295 
Induced  norm,  43 
Infinite  series, convergence,  21 
Infinite  series method,  150 
See also  Matrix,  exponential 
Initial conditions, 4, 5 
Initialtime, 4, 5,  61,62 
Initial value problem,  10,  11, 12, 62 
examples,  13 
existence of solutions, 21 
Inner product,  437 
Inners, 498 
Input: 
command,  or reference,  326 
comparison  sensitivity matrix,  626 
decoupling  zeros, 302, 564 
external,  326 
function  observability,  302 
normal representations,  430 
output decoupling  zeros, 302, 564 
output  stability,  451,481 
vector, 4 
Input-output  description,  5, 65, 165,  174 
See  also  System  representations 
Input-output  stabiUty, 481, 505 
See also  Stability 
Instability,  159,  189, 450, 459, 472, 479, 481, 
491,495,497,499,504,513 
See  also  Equilibrium,  unstable 
Integral equation,  11 
Integral feedback,  379 
Integral representation,  72, 75, 76 
Integration, forward  rectangular rule, 85 
Interconnected  systems,  568 
feedback,  573 
parallel,  568 
series, 570 
665 
INDEX 
Interlacing,  464 
See also  Stability 
Internal description,  5 
See also  System  representations 
Internal qualitative properties, 490 
See also  Internal  stability 
Internal  stability, 448, 451, 481, 490, 
623,  624 
Internally balanced realization, 424, 430 
See also  System  representations 
Interpolation  of polynomial,  rational 
matrix,  653 
Invariance principle,  493 
See  also  Asymptotically  stable 
Invariant factors, polynomials, 298, 534 
Invariant property  of (A, B),  288 
Invariant  subspace,  260 
Invariant zeros, 302, 306, 563, 564, 565 
See also  Zero 
Inverse system, 377, 634 
Inverse z-transformation,  178 
Inverted pendulum,  89, 380 
See  also  Pendulum 
Jacobian matrix, 48, 447 
Jordan canonical form,  130, 135, 136 
Kalman  filter: 
continuous-time,  352 
discrete-time,  363 
Kalman-Bucy  filter,  357 
Kalman's Decomposition  Theorem, 
269,270 
Kronecker indices, 288 
Lagrange's  equation,  83 
Lagrangian,  83 
Lamda approach,  622 
Laplace transform,  75,  154 
La Salle's Theorem,  493 
principle 
Latent value,  122 
See  also  Eigenvalue 
Least squares, 648, 652 
Least-order realization,  394 
Left  coprime,  536 
See  also  Polynomial  matrices 
Leonhard-Mikhailov  stability criterion,  463 
Level curve, 471 
See  also  Lyapunov  function 
Lienard equation,  16, 479 
Limit cycle, 88 
Linear algebraic  equation: 
fundamental  theorem,  101 
homogeneous, nonhomogeneous,  115, 646 
Linear manifold,  97 
Linear matrix pencil, 288, 640 
Linear operator,  40 
nilpotent,  134 
See  also  Linear  transformation 
Linear ordinary  difference  equation: 
autonomous,  12 
homogenous, 62, 63, 174 
homogenous  w/constant coefficients,  175 
matrix,  495 
nonhomogenous, 62, 63 
periodic, 62, 63 
Linear ordinary  differential  equation 
autonomous,  12 
homogeneous,  12, 13, 62, 63, 138, 174 
homogeneous  w/constant coefficients,  148, 
164,  175 
matrix,  140, 495 
nonhomogeneous,  12, 54, 62, 63, 145 
periodic,  12, 13, 62, 63, 161 
systems: continuation,  54 
continuity  with respect to 
parameters,  54 
existence,  54 
uniqueness,  54 
See  also  Solutions of  differential 
equations 
Linear  space, 37 
See  also  Vector  space 
Linear subspace,  97,126 
direct sum,  126 
Linear system, 3, 60, 66, 94, 509 
Linear transformation,  40,  100 
bijective,  101, 102 
determinant,  121 
identity,  103 
injective,  102 
invariant,  127 
nilpotent,  134 
nullity,  101 
orthogonal,  441 
primary  decomposition  theorem, 
133,134 
principle of superposition,  66 
projection,  126, 445 
range space,  100 
reduced,  127 
representation  by a matrix,  104 
spectral theorem, 445 
spectrum,  122 
surjective,  101, 102 
Linearization,  5, 48, 477, 504, 574 
Linearized  equation, 50, 51 
Linearly  dependent,  98, 234, 524 
Linearly  independent,  97, 98, 99, 234, 524 
See  also  Vector 
See  also  Vector 
Lipschitz condition, 30, 45 
Lipscitz constant, 30, 45 
Lipschitz continuous,  30 
LQG  (linear quadratic Gaussian)  problem, 
352,  359 
LQR  (linear quadratic regulator)  problem: 
continuous-time,  342 
discrete-time,  348 
LU decomposition,  647 
Luenberger  observer,  351 
Lyapunov function,  468, 491 
construction  of,  474, 500 
level curve, 471 
Lyapunov  matrix equation, 468, 469, 499 
Lyapunov  stability, 445, 492 
linear systems, 452, 495 
See  also  Stability 
Lyapunov's Direct Method,  468 
Lyapunov's  Second Method,  468 
See also  Asymptotically  stable; Invariance 
examples,  52 
666 
INDEX 
Magnetic ball suspension, 91, 92,  174-2 
Mapping, 8 
See  also  Function 
Markov parameter,  204, 387, 399 
Matrix,  106 
block diagonal,  128 
characteristic polynomial,  123 
cofactor,  113 
column,  107 
column rank,  119 
companion,  461 
companion form,  131, 153, 468 
condition number, 646, 647, 649 
conformal,  109 
congruent,  436 
controllability,  217 
cyclic,  132 
determinant,  111, 113 
diagonal,  120 
elementary  unimodular,  526 
eliminant,  542, 546 
exponential, 57,  149,  150 
fundamental,  139,  140 
Gram,  234 
Hamiltonian,  344, 349 
Hankel,  399 
Hermite form,  532 
Hermitian,  648 
highest degree coefficient,  526 
Hurwitz,  460 
idempotent,  126 
identity,  110 
ill-conditioned,  647 
impulse response, 77,  166 
indefinite,  443 
inverse,  110 
Jacobian, 48, 447 
Jordan,  130,  135, 136 
left  inverse,  653 
linear pencil, 288, 640 
logarithm,  161 
lower triangular,  131 
LU decomposition,  647 
minimal polynomial,  132,  133, 299 
minor,  113,469 
modal,  128 
Moore-Penrose inverse,  652 
negative definite,  semidefinite,  443, 469 
nilpotent,  134 
nonsingular,  101, 110 
norm, 43 
null,  109 
observability,  219, 253, 258 
orthogonal, 441, 648 
permutation  of,  112 
positive definite,  semidefinite,  443 
principal minor,  113, 469 
proper rational,  391 
properties,  107 
QR decomposition,  647 
rank,  101, 107, 306, 437, 524, 525 
right inverse, 653 
Rosenbrock,  301, 554, 564 
self-adjoint,  443 
singular,  110 
square,  107 
state transition, 56, 63, 143 
Smith form,  531 
Sylvester,  541 
symmetric, 469, 648 
symmetric part,  436 
system,  301, 554, 564 
system, extended,  557 
Toeplitz,  259 
transfer  function,  78,  168, 178 
transpose, 8,  107 
unimodular,  526 
unitary,  648 
upper triangular,  131, 532 
well conditioned,  647 
Matrix difference  equation,  496 
Matrix differential  equation,  140 
Matrix fractional  description, 517, 521 
See  also  System  representations 
Maximal element,  27 
Zom's  lemma,  26 
McMillan  degree,  397 
Metric, 438 
Metric  space, 439 
Microphone,  84 
MIMO  system, multi input-multi  output,  66, 71 
Minimal basis, 552 
Minimal polynomial,  132,  133, 299 
Mode of system,  156,  157, 186,  187 
See  also  System 
Model matching problem,  374, 633, 644 
Module, free,  552 
Monic polynomial,  132, 298 
Moore-Penrose pseudo inverse,  652 
Motor,  servomotor,  14, 206, 380 
Natural basis,  100 
See  also  Basis; Vector  space 
Negative: 
definite, 437, 469, 491 
indefinite,  469 
semidefinite,  437, 469, 491 
See  also  Function;  Matrix 
Nilpotent  operator,  134 
See  also  Linear  transformation 
Nonhomogeneous  differential  equations, 
138,  145 
See  also  differential  equations 
Nonlinear  systems, 3, 451, 477 
Norm: 
Euclidean,  42 
Frobenius,  653 
induced,  43 
linear space,  41,438 
Manhattan,  42 
matrix, 43 
taxicab, 42 
Numerical  solutions of  algebraic 
equations,  646 
See  also  Solutions of algebraic  equations 
Numerical  solutions of differential  equations, 
25,  85, 86 
See  also  Solutions of differential  equations 
Numerical  stability,  645 
Observability,  169, 214, 219, 247, 249, 250, 
253, 258, 263, 268, 274, 560 
continuous-time  system, 248, 252 
discrete-time  system, 219, 257 
Pole assignment problem, 330, 658 
See also Eigenvalue or pole assignment 
Pole polynomial, 299 
Poles at infinity, 319 
Poles of a transfer function, 298, 299, 301, 488, 
508, 563 
Poles of the system, 298, 301, 564 
See also Eigenvalue 
667 
eigenvalue/eigenvector (PBH) test, 272 
Gramian, 249, 253, 259 
index, 295 
matrix, 219, 253, 258 
subspace, see Unobservable 
Observable, 562 
eigenvalue, 268 
mode, 268 
Observer, Luenberger, 351 
See also State observer 
Observer companion form, 203 
Observer form, 292, 293, 296, 297 
multi-output, 294 
single-input, 293 
Open covering, 18 
Open loop control, 327 
Operator, linear, 40,100 
See also Linear transformation 
Optimal: 
control problem, 342, 348 
estimation problem, 352, 357, 359, 362 
Optimality principle, 371 
Orbit, 492 
Order of a realization, 394 
Orthogonal, 439 
basis, 440 
complement, 441 
linear transformation, 441 
matrix, 441,648 
projection, 445 
Orthonormal basis, 439 
Orthonormal set of vectors, 439 
Output: 
decoupling zeros, 302, 564 
equation, 5, 58, 61 
function controllability, 313 
normal representations, 430 
reachability, controllability, 312 
vector, 4 
Output feedback: 
dynamic, 363, 589, 642, 658 
observer based, 363 
static, 379 
Parallelogram law, 438 
Parseval's identity, 440 
Partial state, 519 
Partial sum, 21 
Partially ordered set, 27 
Peano-Baker series, 56, 143,147 
Pendulum: 
inverted, 89, 380 
simple, 16, 52, 82, 93 
two-link, 83 
Periodic solution, 492 
See also Solutions of differential  equations 
Periodic system, 11, 62, 161 
Phase: 
plane, 198 
portrait, 88 
variable, 198 
Picard iteration, 31 
Piecewise continuous, 58 
derivative, 23 
function, 9 
Plant, 182 
Polynomial: 
Hurwitz, 462 
monic, 132, 298 
stable, 462 
Polynomial matrices, 524 
column, row reduced, 526 
common divisors, 535 
coprime, left, right, 536, 612 
division theorem, 545 
doubly coprime, 593 
equations, 540, 653 
equivalent, 535 
Hermite form, 532 
proper or reduced row, column, 527 
rank, 524 
regular, 528 
Smith form, 298, 531, 533 
unimodular, 526 
Polynomial matrix description, 517, 519, 
521,553 
See also System representations 
Polynomial matrix interpolation, 653 
Polynomial of linear transformation,  104 
Polynomial vector, 
degree, 526 
linear independence, 524 
definite, 437, 443, 469, 491 
indefinite, 469 
semidefinite, 437, 443, 469, 470, 491 
See also Function; Matrix 
Positive innerwise, 498 
Positive orbit, 492 
Positively invariant, 492 
Prediction estimator, 360 
Proper rational matrix, 391 
Proper transfer function,  170 
Proper value, 102 
See also Eigenvalue 
Proper vector, 122 
See also Eigenvector 
Pythagorean Theorem, 439 
QR decomposition, 647 
Quadratic form, 436 
Quantization, 183 
Radially unbounded, 491 
See also Lyapunov function 
Range space, 100 
Rank, 107, 524 
of a functional, 437 
normal, 306, 525 
test, 274 
Rational function: 
biproper, 552, 577 
proper and stable, 552 
zeroing, or blocking, property, 307 
Positive: 
668 
INDEX 
Rational  matrix: 
equations,  653 
right inverse,  313 
Smith-McMillan  form,  299, 563 
Rayleigh's  dissipation function,  83 
Reachability,  214, 215, 226, 235, 
242,244 
continuous-time  system, 227, 235 
discrete-time  system, 215, 241 
Gramian, 230, 236, 245 
matrix, see  Controllability 
output,  312 
subspace, 228, 235, 242 
See  also  Controllability,  from  the origin 
Reachable, 217, 228, 235 
pairs,  228 
state, 242 
subspace, 217, 228, 235, 242 
See  also  Controllable; Controllability,  from 
the origin 
Real numbers, 8 
Real sequence,  17 
Real vector space, 38 
Realization  algorithms, 402 
block companion form,  418 
controller/observer  form,  404 
matrix A  diagonal, 417 
singular value decomposition,  423 
Realization  of systems, 383, 385, 388, 565 
existence and minimality, 390, 394, 565 
impulse response,  386 
least order, irreducible, minimal  order, 
394,401,565 
order of,  394 
pulse response,  388 
transfer  function,  202, 388, 389 
Reconstructible,  255 
See  also  Constructibility 
Reduced  order model,  424 
Reference  input,  326 
Relation,  535 
Response, 4, 59, 61 
maps,  625 
total,  165, 166,  174,  176 
zero-input,  146,  165, 177 
zero-state,  146,  165, 166,  177 
Resultant,  542 
Return difference  matrix,  586 
Riccati equation,  343, 349, 358, 363 
continuous-time  case, 342, 343, 358 
discrete-time case, 349, 363 
Ring, 552 
Euclidean,  551 
RLC circuit,  14, 16, 206, 276 
Robust control,  327 
Rosenbrock  system matrix, 301, 554, 564 
Rosenbrock  system equivalence,  555 
Routh-Hurwitz  stability criterion,  466 
Row,  107 
Hermite form,  532 
proper, see Polynomial  matrices 
rank,  119 
vector,  107 
Row reduced,  526 
See also  Polynomial  matrix 
Sampled  data system, 65, 182, 183, 319 
Sampling period, rate,  185 
Scalar,  38 
Schur-Cohn  stability criterion,  498 
Schwarz inequality, 42,  49,438 
Semi-group property,  175 
Sensitivity  matrix, 599, 626 
Separation principle, property, 325, 365 
Sequence,  17 
functions,  18 
vectors, 44 
Series, 203 
Shift  operator, 68, 92 
Signal, digital,  183 
Similarity  transformation,  116,  120,  151 
Singular,  101 
value,  648 
value decomposition, 423, 430, 
648,650 
vector, left,  right,  651 
See  also  Linear transformation;  Matrix 
Skew  adjoint,  443 
Skew  symmetric, 435, 436 
Smith form,  298, 531, 533 
See  also  Polynomial  matrices 
Smith-McMillan  form,  298, 299, 563 
See also  Rational  matrix 
Solutions, bounded, 491, 493 
Solutions of algebraic equations,  101, 115, 646, 
Solutions of difference  equations: 
655,  657 
particular,  64 
total, 64 
Solutions of differential  equations,  10, 12 
bounded,  452 
continuable,  27 
continuation,  26, 27, 28, 31, 37, 45, 54 
continuous dependence, 33, 37, 45 
continuous dependence  on initial  conditions, 
continuous dependence on parameters, 
45,54 
47,54 
e-approximate,  23 
Euler's  method, 25, 85 
existence, 25, 37, 45, 54 
homogeneous, 58, 64,  145 
noncontinuable,  27 
particular,  58, 64,  145 
Peano-Baker  series, 56,  143, 147 
periodic,  492 
predictor-corrector  method,  86 
Runge-Kutta,  85 
successive approximations, 31, 
47,143 
Space: 
total, 58 
uniqueness, 29, 30, 32, 45 
See  also  Variation of constants  formula 
of linear transformations,  102 
of ^-tuples, 38 
of real-valued  continuous functions,  39 
span,  97 
Spectral theorem,  445 
Spectrum,  122 
Spring,  16, 88, 320 
Spring mass system,  13, 82, 83, 
206,  320 
Stability, 445, 492, 560 
algebraic criteria, 461, 462 
asymptotic,  159,  189, 449, 491, 494, 
497, 504, 563 
669 
INDEX 
asymptotic in the large, 450, 491, 
attractive equilibrium,  449 
bounded-input^ounded-output  (BIBO), 481, 
494, 499 
490,  505 
causal,  67,70,71,77 
domain of attraction, 449, 491 
exponential, 449, 477, 480, 512 
exponential  in the large, 450, 459, 471 
external, 481,490,  506 
gap and position  criterion,  464 
global asymptotic, 491, 492, 494, 499 
graphical, geometric criteria,  462 
input-output,  452, 481, 490, 505 
interlacing,  464 
internal, 452, 481, 490, 613, 623 
Leonhard-Mikhailov  criterion,  463 
linear systems, continuous,  159 
linear systems, discrete,  189 
Lyapunov, 445, 448, 590 
Routh-Hurwitz  criterion,  466 
Schur-Cohn,  498 
uniform,  448 
uniform  asymptotic, 449 
uniform  asymptotic  in the large, 450, 
459,  461 
See  also  Equilibrium 
StabiUzable,  330 
Stable,  159,  189, 448, 452, 455, 459, 491, 492 
See also  Stability 
Standard  form: 
Kalman's  canonical,  269 
uncontrollable  system, 264, 265 
unobservable  system, 267, 268 
State, 56, 58, 60, 228, 235 
controllable,  242 
partial,  519 
phase variable,  198 
variables, 4, 56, 58, 61 
vector, 4, 56, 58 
State constructibihty,  251, 260 
See also  Constructibihty 
State controllability,  229, 235, 242 
See also  Controllability 
State estimator,  351,359 
See  also  State  observer 
State equation, 5, 58, 61, 165 
linear solution, 55,  145 
State feedback,  321, 322, 326, 605 
input-output relations,  345 
See also  Feedback 
State observability, 250, 258 
See  also  Observability 
State observer,  321, 322, 350, 359, 608 
current,  360 
full-order,  350, 358 
identity,  350, 359 
optimal, 357, 362 
partial  state, 354, 362, 608 
reduced-order,  355, 362 
State reachability,  215, 235, 242, 243 
See  also  Reachability 
State space, 56, 58 
State space description,  5 
continuous-time,  58 
discrete-time,  60 
See  also  System  representations 
State transition matrix, 56, 63, 143 
State unconstructible,  250, 255 
State unobservable,  248, 253, 258 
Static: 
decoupling,  634 
output feedback,  379 
Structure  theorem: 
controllable version,  291 
observable  version,  297 
Subsequence,  18 
Successive approximations,  31, 47 
See  also  Solutions of  differential 
equations 
Superposition  principle, 60, 66 
Sylvester: 
matrix,  541 
rank inequality,  205, 396 
resultant,  542 
theorem,  437 
Symmetric, 435, 436, 648 
See also  Bilinear  functional; 
Matrix 
System: 
at rest,  71,77 
autonomous,  12, 62 
classification,  3 
composite,  203 
conservative,  81 
continuous time, 4 
description, external, 5, 65 
discrete-time, 5, 60, 68,  174 
distributed parameter,  3 
dual, 222, 402 
finite dimensional,  3, 4, 5 
Fuhrmann  equivalence,  554 
Hamiltonian,  81 
hybrid,  3,  183 
infinite  dimensional,  3 
input,  66 
inverse, 377, 634 
linear, 60, 66, 94, 509 
linear time-invariant,  59, 61 
linear time-varying,  59, 61 
lumped parameter,  3 
matrix,  301,564 
with memory,  67 
memoryless,  66 
mode,  156,  186,  187 
multi input/multi  output,  66, 71 
nonanticipative,  67 
nonlinear,  3, 451,477 
output,  66 
periodic,  12, 62,  161 
realization,  383 
response, 64 
Rosenbrock  equivalence,  555 
sampled data, 65,  183 
single input/single  output,  66 
strict equivalence,  555 
time-invariant,  5, 242 
time-varying, 5, 68 
zeros, 301, 565 
System  interconnections: 
feedback,  203, 573 
parallel, 203, 568 
series, or tandem, 203, 570 
System  representations: 
balanced,  430 
differential/difference  operator,  517 
equivalence, of,  170,  180, 554 
external,  65 
670 
fractional,  left,  right, 517, 521 
input normal,  430 
input-output,  66 
integral, 72, 75, 76 
internal, 5, 619 
linear continuous-time,  76 
linear discrete-time,  68 
matrix fractional,  521, 612, 619 
output normal,  430 
polynomial matrix, 517, 519, 521, 553 
standard form,  uncontrollable,  unobservable, 
265,267,  268 
state space, 5 
zero-input  equivalence,  170,  171, 173, 181 
zero-state equivalent,  170,  171, 173, 181 
Time reversibility,  145, 175 
Toeplitz matrix,  259 
Trajectory,  88, 198 
Transfer  function: 
McMillan  degree, 397 
pole polynomial, 299, 563 
proper,  170, 530 
strictly proper,  170, 530 
Transfer  function  matrix, 78,  168,  177,  178 
Transmission  zero, 303, 564, 565 
See  also  Zero 
Triangle inequality,  41 
Trivial  solution,  138,446 
See also  Equilibrium 
Truncation  operator,  92 
Two degrees  of freedom  controller,  622 
Uncertainties,  327 
Unconstructible,  250, 260 
subspace, 250, 255, 260 
See  also  Constructibility 
Uncontrollable, 264, 274 
eigenvalues, modes, 265 
See also  Controllability 
Uniformly  asymptotically  stable, 449 
Uniformly  asymptotically  stable in the large, 
450, 459, 461 
Uniformly  BIBO-stable  (bounded-
input/bounded-output  stable), 482, 
483,  4t84 
Uniformly  bounded,  22 
Uniformly  continuous, 9 
Uniformly  controllable,  315 
Uniformly  convergent,  19 
Uniformly  stable, 448, 453, 454, 455, 459, 461, 
470,511,512 
Unimodular matrix,  526 
Unit impulse, 74 
Unit pulse, or unit sample, 68,  178 
Unit pulse, or unit impulse, response,  70 
Unit step: 
function,  154 
sequence, 69 
Unity  feedback,  631, 642 
Unobservable,  264, 274 
eigenvalues, modes, 268 
subspace, 220, 253, 258 
See  also  Observability 
Unstable: 
complete instability, 273, 501 
See also  Equilibrium,  unstable 
van der Pol equation,  16, 88 
Variation of constants formula,  57,  146,  197 
Vector,  38 
coordinate representation,  100 
linearly dependent,  97, 98, 234, 524 
linearly  independent,  98, 234, 524 
normalized,  439 
null, 38 
unit, 439 
Vector space, 37, 38, 97 
basis, 99,  100,  170, 439, 552 
complex,  38 
dimension,  99 
finite dimensional,  99, 437 
inner product,  437 
normed, 42, 438, 439 
null,  100, 444 
real, 38 
Weierstrass M-test, 21 
See also  Infinite  series 
Without memory,  66 
Youla parameter,  595, 615, 635 
Zero, 298, 563 
blocking property,  307 
decoupling  input/output,  302, 564 
direction,  306 
at infinity,  320 
invariant,  302, 303, 564, 565 
polynomial,  302, 303, 564, 565 
system, 301,564,  565 
of transfer  functions,  301, 302, 303, 
564,  565 
transmission,  303, 564, 565 
Zero-input equivalence,  170,  171, 174,  181 
See  also  System  representations 
Zero-input response,  146,  165, 176 
See  also  Response 
Zero-order hold,  183 
See  also  Sampled  data  system 
Zero-state equivalence,  170,  171, 173, 181 
See  also  System  representations 
Zero-state response,  146,  165, 166,  177 
See  also  Response 
Zom's  lemma,  26 
z-transform,  177 

